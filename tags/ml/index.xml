<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>ML on Li Duo</title>
    <link>https://lizonglingo.github.io/tags/ml/</link>
    <description>Recent content in ML on Li Duo</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <lastBuildDate>Sun, 26 Jun 2022 15:00:34 +0800</lastBuildDate><atom:link href="https://lizonglingo.github.io/tags/ml/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Sinan: ML-Based and QoS-Aware Resource Management for Cloud Microservices</title>
      <link>https://lizonglingo.github.io/p/sinan-ml-based-and-qos-aware-resource-management-for-cloud-microservices/</link>
      <pubDate>Sun, 26 Jun 2022 15:00:34 +0800</pubDate>
      
      <guid>https://lizonglingo.github.io/p/sinan-ml-based-and-qos-aware-resource-management-for-cloud-microservices/</guid>
      <description>来源：ASPLOS&#39;21 ccf-a 作者：Cornell University 正如题目所说，这篇文章主要就是使用机器学习的方法，针对微服务架构的应用进行资源配置，当然是保</description>
    </item>
    
    <item>
      <title>Cocktail: A Multidimensional Optimization for Model Serving in Cloud</title>
      <link>https://lizonglingo.github.io/p/cocktail-a-multidimensional-optimization-for-model-serving-in-cloud/</link>
      <pubDate>Sun, 15 May 2022 21:07:08 +0800</pubDate>
      
      <guid>https://lizonglingo.github.io/p/cocktail-a-multidimensional-optimization-for-model-serving-in-cloud/</guid>
      <description>来源：NSDI&#39;22 推荐阅读！ 摘要 背景 越来越多的ML模型运行在公有云环境下。为这些模型服务的框架能够以最小的延迟提供高度准确的预测，并降低部</description>
    </item>
    
    <item>
      <title>MLaaS in the Wild: Workload Analysis and Scheduling in Large-Scale Heterogeneous GPU Clusters</title>
      <link>https://lizonglingo.github.io/p/mlaas-in-the-wild-workload-analysis-and-scheduling-in-large-scale-heterogeneous-gpu-clusters/</link>
      <pubDate>Mon, 21 Mar 2022 21:05:51 +0800</pubDate>
      
      <guid>https://lizonglingo.github.io/p/mlaas-in-the-wild-workload-analysis-and-scheduling-in-large-scale-heterogeneous-gpu-clusters/</guid>
      <description>来源： NSDI&#39;22 作者：Alibaba Group 摘要 在ML as a Service中，数据中心为ML提供算力保证。而多样的ML工作负载面对异构GPU集群时会出现一些</description>
    </item>
    
  </channel>
</rss>
