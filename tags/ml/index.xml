<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>ML on fmt.Println(&#34;Li Duo&#34;)</title>
        <link>https://lizonglingo.github.io/tags/ml/</link>
        <description>Recent content in ML on fmt.Println(&#34;Li Duo&#34;)</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-CN</language>
        <lastBuildDate>Sun, 26 Jun 2022 15:00:34 +0800</lastBuildDate><atom:link href="https://lizonglingo.github.io/tags/ml/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>Sinan: ML-Based and QoS-Aware Resource Management for Cloud Microservices</title>
        <link>https://lizonglingo.github.io/p/sinan-ml-based-and-qos-aware-resource-management-for-cloud-microservices/</link>
        <pubDate>Sun, 26 Jun 2022 15:00:34 +0800</pubDate>
        
        <guid>https://lizonglingo.github.io/p/sinan-ml-based-and-qos-aware-resource-management-for-cloud-microservices/</guid>
        <description>&lt;blockquote&gt;
&lt;p&gt;来源：ASPLOS&#39;21  ccf-a&lt;/p&gt;
&lt;p&gt;作者：Cornell University&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;正如题目所说，这篇文章主要就是使用&lt;strong&gt;机器学习&lt;/strong&gt;的方法，针对&lt;strong&gt;微服务架构&lt;/strong&gt;的应用进行&lt;strong&gt;资源配置&lt;/strong&gt;，当然是&lt;strong&gt;保证QoS的前提&lt;/strong&gt;下提高资源分配和使用的效率。&lt;/li&gt;
&lt;li&gt;利用ML方法帮助调度的决策&lt;/li&gt;
&lt;li&gt;面向以容器和虚拟机构建及部署的微服务应用&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;问题的痛点是什么或是要解决什么问题他们的idea有什么值得学习的地方&#34;&gt;问题的痛点是什么？或是要解决什么问题？他们的idea有什么值得学习的地方？&lt;/h2&gt;
&lt;h3 id=&#34;先前的工作&#34;&gt;先前的工作&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;为满足QoS而忽视资源利用率，往往有较高的资源分配上限，把边界划定的很远，虽然是为了更好的满足QoS要求但是牺牲了资源&lt;/li&gt;
&lt;li&gt;针对单体系统而没有考虑微服务架构的特点&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;本文idea&#34;&gt;本文idea&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;突出QoS、E2E时延&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;资源分配突出了一个满足QoS要求，并且多次提到OOM错误&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;考虑到微服务架构的层级结构(tier)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;考虑到微服务架构的拓扑图，也就是微服务之间的依赖关系&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;提到了微服务中某些排队队列的环节会因为QoS违规导致更长时间的排队等候，进而提出了需要一个较长时间的预测&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;具体是什么云环境应用以什么样的方式部署&#34;&gt;具体是什么云环境？应用以什么样的方式部署？&lt;/h2&gt;
&lt;p&gt;Docker + VM组成的云环境。应用以被打包成Docker镜像然后部署在虚拟机上。&lt;/p&gt;
&lt;h2 id=&#34;使用了什么机器学习方法这个学习解决的是什么问题&#34;&gt;使用了什么机器学习方法？这个学习解决的是什么问题？&lt;/h2&gt;
&lt;p&gt;文章提出了一个“two-stage model”。第一阶段，使用CNN预测下一个时间步的E2E时延，这对精确性提出了很高的要求；第二阶段，使用Boosted Trees预测QoS违规（需要使用CNN模型的输出）。&lt;/p&gt;
&lt;p&gt;第一阶段和第二阶段分别代表了短期和长期的预测结果，以辅助调度的决策。&lt;/p&gt;
&lt;h3 id=&#34;cnn卷积神经网络&#34;&gt;CNN卷积神经网络&lt;/h3&gt;
&lt;p&gt;CNN模型主要用于短期的性能预测。&lt;/p&gt;
&lt;p&gt;具体来说，使用CNN来预测下一个时间窗口的时延分布，是秒级的窗口(默认是5秒)。但是文章发现，预测时延是件很困难的事情，并且随着预测时间的增加，效果不理想。&lt;/p&gt;
&lt;p&gt;因此进一步的，文章将预测策略变为：预测是否出现QoS违规，也就是随后的时间段出现QoS违规的概率。（因为通常将QoS与E2E时延划等号，出现QoS违规相当于E2E时延过长，所以QoS违规给调度决策带来的信息是足够的）&lt;/p&gt;
&lt;h4 id=&#34;模型使用到的输入数据&#34;&gt;模型使用到的输入数据&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;CPU使用信息&lt;/li&gt;
&lt;li&gt;内存使用信息（包括常驻内存和缓存）&lt;/li&gt;
&lt;li&gt;网络使用信息（如接收和发送的数据包）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这些都是用Docker cgroup的接口收集。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;上一个窗口E2E时延的分布&lt;/li&gt;
&lt;li&gt;能够在下一个时间窗口分配的资源信息&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;模型的预测输出&#34;&gt;模型的预测输出&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;下一个时间窗口的时延信息，该信息会进一步用于Boosted Tree中&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;boosted-tree&#34;&gt;Boosted Tree&lt;/h3&gt;
&lt;p&gt;增长树模型主要用于长期的性能预测。具体来说，进行一个二分类问题的预测——接下来的资源分配是否会造成QoS违规，通过这个预测来减少未来预期之外的负面影响。&lt;/p&gt;
&lt;h4 id=&#34;模型使用到的输入数据-1&#34;&gt;模型使用到的输入数据&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;使用到CNN中的预测输出的时延信息&lt;/li&gt;
&lt;li&gt;资源分配信息&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;模型的预测输出-1&#34;&gt;模型的预测输出&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;在接下来时间步k中，是否会出现QoS违规现象&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;系统架构是什么样的如何分配资源&#34;&gt;系统架构是什么样的？如何分配资源？&lt;/h2&gt;
&lt;h3 id=&#34;系统架构&#34;&gt;系统架构&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/202206261434874.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220626143414765&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;中心化的调度器&lt;/li&gt;
&lt;li&gt;分布式的节点代理&lt;/li&gt;
&lt;li&gt;单独部署的预测服务&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;系统流程如上图。&lt;/p&gt;
&lt;h3 id=&#34;资源分配&#34;&gt;资源分配&lt;/h3&gt;
&lt;p&gt;系统中资源分配的几种动作如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/202206261443689.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220626144302597&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;评估怎么做的使用了什么应用&#34;&gt;评估怎么做的？使用了什么应用？&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;在本地集群和Google Cloud上面做的实验&lt;/li&gt;
&lt;li&gt;使用了微服务benchmark套件&lt;strong&gt;DeathStarBench&lt;/strong&gt;(有论文的这个套件)以及其中的应用Hotel Reservation，Social Network。&lt;/li&gt;
&lt;li&gt;使用Docker Swarm进行部署&lt;/li&gt;
&lt;li&gt;收集了31302和58499条Hotel和Social Network的数据&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;实验环境&#34;&gt;实验环境&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;本地集群：80core CPU/256GB RAM&lt;/li&gt;
&lt;li&gt;GCE集群：93containers&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;微服务应用&#34;&gt;微服务应用&lt;/h3&gt;
&lt;h4 id=&#34;hotel-reservation&#34;&gt;Hotel Reservation&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/202206242159386.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220624215932271&#34;
	
	
&gt;&lt;/p&gt;
&lt;h4 id=&#34;social-network&#34;&gt;Social Network&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/202206242159015.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220624215947934&#34;
	
	
&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;做实验时可以参考本文实验设计&lt;/p&gt;
&lt;/blockquote&gt;
</description>
        </item>
        <item>
        <title>Cocktail: A Multidimensional Optimization for Model Serving in Cloud</title>
        <link>https://lizonglingo.github.io/p/cocktail-a-multidimensional-optimization-for-model-serving-in-cloud/</link>
        <pubDate>Sun, 15 May 2022 21:07:08 +0800</pubDate>
        
        <guid>https://lizonglingo.github.io/p/cocktail-a-multidimensional-optimization-for-model-serving-in-cloud/</guid>
        <description>&lt;blockquote&gt;
&lt;p&gt;来源：&lt;a class=&#34;link&#34; href=&#34;https://www.usenix.org/conference/nsdi22/presentation/gunasekaran&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;NSDI&#39;22&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;推荐阅读！&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;摘要&#34;&gt;摘要&lt;/h2&gt;
&lt;h3 id=&#34;背景&#34;&gt;背景&lt;/h3&gt;
&lt;p&gt;越来越多的ML模型运行在公有云环境下。&lt;strong&gt;为这些模型服务的框架能够以最小的延迟提供高度准确的预测，并降低部署成本，这一点至关重要。&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;关键点&#34;&gt;关键点&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;模型集成可以通过智能地将不同模型并行组合来解决精度差距问题。然而，在运行时动态地选择合适的模型，以以最小的部署成本、低延迟来满足预期的准确性。&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;本文工作&#34;&gt;本文工作&lt;/h3&gt;
&lt;p&gt;提出&lt;em&gt;&lt;strong&gt;Cocktail&lt;/strong&gt;&lt;/em&gt;，基于模型集成的成本效益模型服务框架。包含两个关键的组件：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一个&lt;strong&gt;动态模型选择框架&lt;/strong&gt;，在满足&lt;strong&gt;精度和延迟&lt;/strong&gt;要求的同时，&lt;strong&gt;减少了集成中的模型数量&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;一个采用&lt;strong&gt;分布式主动自动伸缩策略的自适应资源管理&lt;/strong&gt;（RM，Resource Management）框架，有效地为模型分配资源。RM框架利用瞬态虚拟机实例来降低公共云中的部署成本&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;同时在AWS EC2实例中实现了一个原型系统，演示了使用各种工作负载的详尽评估。结果显示Cocktail减少了部署花费1.45x，与最先进的模型服务框架相比，减少了2x延迟，并满足高达96%的请求的目标精度。&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;h3 id=&#34;背景及问题引出&#34;&gt;背景及问题引出&lt;/h3&gt;
&lt;p&gt;背景案例：Facebook为用户交互应用程序提供了数万亿的推理请求，如对新提要进行排名，对照片进行分类等。这些应用程序必须在&lt;strong&gt;亚毫秒延迟&lt;/strong&gt;[27、34、35、39、44、83]提供准确的预测，因为它们严重影响用户体验。&lt;/p&gt;
&lt;p&gt;随着许多应用使用ML技术增强其用户体验，这种趋势正在扩大。&lt;/p&gt;
&lt;p&gt;通常这种模型服务运行在云平台上，如一些&lt;em&gt;model-serving&lt;/em&gt;框架[6, 28, 60]。&lt;/p&gt;
&lt;h3 id=&#34;挑战&#34;&gt;挑战&lt;/h3&gt;
&lt;p&gt;由于训练数据以及计算和内存资源紧张[59,65,84]造成的高方差一直是设计高精度和低延迟模型的主要障碍&lt;/p&gt;
&lt;p&gt;不同于单模型推理任务，&lt;code&gt;ensemble learning&lt;/code&gt;集成学习可以进一步提高服务精确度。（如，多模型的图片分类任务会提高最终的精确度）&lt;/p&gt;
&lt;p&gt;然而，对于集成，由于&lt;strong&gt;每个请求都需要运行大量的模型[27,56]而导致的非常高的资源占用，加剧了公共云的部署成本，并导致延迟的高度变化&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;因此，本文解决的主要问题为：&lt;/p&gt;
&lt;p&gt;⭐集成单一的模型推理服务；&lt;/p&gt;
&lt;p&gt;⭐同时提高模型服务的准确度；&lt;/p&gt;
&lt;p&gt;⭐并最小化部署成本。&lt;/p&gt;
&lt;h3 id=&#34;现有技术的不足&#34;&gt;现有技术的不足&lt;/h3&gt;
&lt;p&gt;对最先进的集成模型服务框架进行分析，存在如下不足：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在像Clipper[27]这样的框架中使用的&lt;strong&gt;集成模型选择策略是静态的，因为它们集成了所有可用的模型，并只专注于最小化准确性损失。这将导致更高的延迟，并进一步扩大资源使用&lt;/strong&gt;，从而加重部署成本。&lt;/li&gt;
&lt;li&gt;现有的集合权重估计[87]&lt;strong&gt;计算复杂度高&lt;/strong&gt;，在实践中仅限于一小部分现成模型。这导致&lt;strong&gt;精度损失严重&lt;/strong&gt;。此外，采用线性集成技术(如模型平均)计算量大[80]，且对大量可用模型&lt;strong&gt;不可伸缩，缺少弹性&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;现有的集成系统&lt;strong&gt;不关注公共云基础设施中的模型部署&lt;/strong&gt;，没有注意到部署成本和延迟。&lt;/li&gt;
&lt;li&gt;对单一模型的&lt;strong&gt;资源管理模采用的策略不能直接扩展到集成系统中&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;因此，重复之前亟待解决的问题：&lt;/p&gt;
&lt;p&gt;⚠️&lt;strong&gt;如何解决集成框架的成本、精度和延迟等复杂优化问题？&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;本文工作-1&#34;&gt;本文工作&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Cocktail&lt;/strong&gt;&lt;/em&gt;，首个&lt;strong&gt;成本友好&lt;/strong&gt;、&lt;strong&gt;集成多模型&lt;/strong&gt;的ML服务框架，&lt;strong&gt;针对于分类推理任务&lt;/strong&gt;，有很好的&lt;strong&gt;精确度和低延迟&lt;/strong&gt;表现。&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;它使用下面三方面解决框架优化问题：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;提出了一种动态模型选择策略，在满足延迟和精度要求的同时，显著减少了集成中使用的模型数量；&lt;/li&gt;
&lt;li&gt;利用分布式自动伸缩策略来减少托管集成模型的延迟可变性和资源消耗；&lt;/li&gt;
&lt;li&gt;利用transient VMs技术减少了推理服务部署成本（比传统的虚拟机减少79%-90%的成本）。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;contributions&#34;&gt;Contributions&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;通过&lt;strong&gt;描述集成模型的精度与延迟&lt;/strong&gt;，我们发现在给定的延迟下&lt;strong&gt;谨慎地选择可用模型的子集可以达到目标精度&lt;/strong&gt;。在&lt;em&gt;&lt;strong&gt;Cocktail&lt;/strong&gt;&lt;/em&gt;中利用这一点，&lt;strong&gt;设计了一种新颖的动态模型选择策略，在保证准确性的同时大大减少了模型的数量&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;关注基于分类的推理&lt;/strong&gt;，&lt;strong&gt;最小化来自多个模型的预测偏差&lt;/strong&gt;。&lt;em&gt;&lt;strong&gt;Cocktail&lt;/strong&gt;&lt;/em&gt;采用了一个pre-class加权多数投票政策，这使得它具有&lt;strong&gt;可扩展性&lt;/strong&gt;，与传统加权平均相比，有效地打破了不同模型之间的联系，从而最大限度地提高了准确性。&lt;/li&gt;
&lt;li&gt;集成模型资源需求的变动会导致资源的过度供应，为了最小化资源，我们构建了一个&lt;strong&gt;分布式的加权自动伸缩策略&lt;/strong&gt;，该策略利用重要&lt;strong&gt;抽样技术主动地为每个模型分配资源&lt;/strong&gt;。&lt;em&gt;&lt;strong&gt;Cocktail&lt;/strong&gt;&lt;/em&gt;使用transient VMs降低模型在云平台上部署的成本。&lt;/li&gt;
&lt;li&gt;使用AWS EC2的CPU和GPU实例，实现了原型系统&lt;em&gt;&lt;strong&gt;Cocktail&lt;/strong&gt;&lt;/em&gt;并对不同的请求进行了评估。与最先进的模型服务系统相比，部署成本降低1.4x，精确度提升至96%，延迟减少2x。&lt;/li&gt;
&lt;li&gt;同时表明，集成模型的&lt;em&gt;&lt;strong&gt;Cocktail&lt;/strong&gt;&lt;/em&gt;，&lt;em&gt;&lt;strong&gt;Cocktail&lt;/strong&gt;&lt;/em&gt;可以通过将准确度损失限制在0.6%以内来适应实例故障，对故障容忍性有较大提升。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;background-and-motivation&#34;&gt;Background and Motivation&lt;/h2&gt;
&lt;p&gt;本章结构如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;分析现有公有云中的集成模型服务；&lt;/li&gt;
&lt;li&gt;指出这些服务存在的问题；&lt;/li&gt;
&lt;li&gt;表明&lt;em&gt;&lt;strong&gt;Cocktail&lt;/strong&gt;&lt;/em&gt;基于以上问题需要做的改进。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;model-serving-in-public-cloud&#34;&gt;Model Serving in Public Cloud&lt;/h3&gt;
&lt;p&gt;现有公有云模型服务架构如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/image-20220515153406902.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220515153406902&#34;
	
	
&gt;&lt;/p&gt;
&lt;h4 id=&#34;application层&#34;&gt;Application层&lt;/h4&gt;
&lt;p&gt;关注SLO，本文指End2End的响应时间。如Ads服务在100ms、推荐服务可以容忍1000ms。&lt;/p&gt;
&lt;h4 id=&#34;model-层和-framework-层&#34;&gt;Model 层和 Framework 层&lt;/h4&gt;
&lt;p&gt;部署的如TensorFlow、PyTorch框架。以及提供的不同模型（这里以分类模型为例）：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/image-20220515153920197.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220515153920197&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;根据应用程序类型，最大的模型集成尺寸可以从数十到数百个模型不等。&lt;/p&gt;
&lt;h4 id=&#34;cloud-层&#34;&gt;Cloud 层&lt;/h4&gt;
&lt;p&gt;以VMs或者Container提供资源隔离和运行环境，基于异构的CPU、GPU实例。&lt;/p&gt;
&lt;p&gt;其中，&lt;strong&gt;瞬态实例&lt;/strong&gt;[69]与传统的VM类似，但可以由云提供商在任何时间通过中断通知撤销。这些资源的供应延迟、实例持久性和模型打包花费直接影响到托管模型服务的延迟和成本。&lt;/p&gt;
&lt;p&gt;本文&lt;strong&gt;从模型选择的角度关注于提高准确性和延迟，并从成本的角度考虑实例类型&lt;/strong&gt;。&lt;/p&gt;
&lt;h3 id=&#34;related-work&#34;&gt;Related Work&lt;/h3&gt;
&lt;p&gt;下图为本文工作和先前相关工作的对比：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/image-20220515172130602.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220515172130602&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;1️⃣现有的集成模型案例：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Azure ML-studio：最初集成了5个模型，现在逐渐扩展到200个模型。&lt;/li&gt;
&lt;li&gt;AWS Autogluon：集成了6-12个模型。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;用户可以手动选择模型数量规模。&lt;/p&gt;
&lt;p&gt;与它们不同的是，&lt;em&gt;&lt;strong&gt;Cocktail&lt;/strong&gt;&lt;/em&gt;的模型选择策略试图在给定延迟的情况下选择合适的集合大小，同时最大化准确性。&lt;/p&gt;
&lt;p&gt;2️⃣云上模型服务：&lt;/p&gt;
&lt;p&gt;InFaas、Clipper 、FrugalML、MArk 、Rafiki、 TF-Serving、 SageMaker、AzureML 、Deep-Studio等。&lt;/p&gt;
&lt;p&gt;3️⃣公有云自动缩放：&lt;/p&gt;
&lt;p&gt;现有相关的资源配置策略能分为两类：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;多路复用不同的实例类型；&lt;/li&gt;
&lt;li&gt;基于预测策略的主动资源发放。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Cocktail&lt;/strong&gt;&lt;/em&gt;使用了类似的负荷预测模型，并在模型集合方面以分布式的方式使用自动缩放虚拟机。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Cocktail&lt;/strong&gt;&lt;/em&gt;的自动缩放策略与Swayam[34]的分布式自动缩放策略有相似之处；然而，我们进一步引入了新颖的&lt;strong&gt;重要采样技术&lt;/strong&gt;，以减少未充分利用的模型的过度供应&lt;/p&gt;
&lt;h2 id=&#34;引出cocktail&#34;&gt;引出Cocktail&lt;/h2&gt;
&lt;p&gt;首先回答两个问题：&lt;/p&gt;
&lt;p&gt;1️⃣如何减少资源占用❓&lt;/p&gt;
&lt;p&gt;通过最小化模型集成数量，减少资源使用。文章通过实验，选取精度前50%的模型进行集成。&lt;/p&gt;
&lt;p&gt;完全集成的模型选择是一种过度的行为，而静态集成则会导致精度的损失。这就需要一个动态的模型选择策略，该策略可以根据模型选择策略的准确性和可伸缩性准确地确定所需的模型数量。&lt;/p&gt;
&lt;p&gt;2️⃣如何减少部署成本❓&lt;/p&gt;
&lt;p&gt;大多数云提供商提供瞬态虚拟机，如Amazon Spot实例[69]、谷歌preemptible VMs[9]和Azure Low-priority VMs[7]，可以降低高达10倍的云计算成本。文章**利用这些瞬态VMs(如spot实例)**来大幅降低部署集成模型框架的成本。&lt;/p&gt;
&lt;h2 id=&#34;cocktail整体设计&#34;&gt;Cocktail整体设计&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Cocktail&lt;/strong&gt;&lt;/em&gt;架构如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/image-20220515175157818.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220515175157818&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Master VM：运行了模型选择算法；1a）来决定将哪些模型集成；1b）被选中的模型加载到缓存中，在相同请求到来时加快响应速度。&lt;/li&gt;
&lt;li&gt;Queries：各个请求分派到不同的实例池。&lt;/li&gt;
&lt;li&gt;Aggregator：用来处理集成模型的返回结果，使用加权多数投票聚合器返回正确的预测。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;为了有效地解决资源管理和可伸缩性的挑战，&lt;em&gt;&lt;strong&gt;Cocktail&lt;/strong&gt;&lt;/em&gt;应用多种策略。它维护专用的实例池服务于各个模型，这简化了每个模型的管理和负载平衡开销。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Resource Controller：主要管理实例的增减，通过 4a）4b）基于CPU和GPU的开销进行实例数量的管理。&lt;/li&gt;
&lt;li&gt;Load Balancer：将Queries分配给适当的实例，并确保所有获取的实例都被打包到VM中。&lt;/li&gt;
&lt;li&gt;Autoscaler：利用 6a）预测策略为实例池中的实例预测请求负载，确保资源不会被过度配置；同时使用 6b）重要性抽样算法，通过计算每个模型池在给定时间间隔内所服务的请求的百分比来估计每个模型的重要性。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;动态模型选择策略&#34;&gt;动态模型选择策略&lt;/h3&gt;
&lt;h4 id=&#34;目标函数&#34;&gt;目标函数&lt;/h4&gt;
&lt;p&gt;本文使用一个基于窗口的动态模型选择策略，使用下面描述的两个&lt;strong&gt;目标函数&lt;/strong&gt;：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/image-20220515195954517.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;目标时减小延迟和花费并最大化准确率。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\mu_{AL}$： latency-accuracy metric&lt;/li&gt;
&lt;li&gt;$\mu_c$：cost metric&lt;/li&gt;
&lt;li&gt;$Acc_{target}$：目标准确度&lt;/li&gt;
&lt;li&gt;$Lat_{target}$：目标延迟&lt;/li&gt;
&lt;li&gt;$N$：参与集成的模型数量&lt;/li&gt;
&lt;li&gt;$inst_cost$： VM实例的花费&lt;/li&gt;
&lt;li&gt;$m$：指每个模型&lt;/li&gt;
&lt;li&gt;$P_{f_m}$：在单个实例中可以并发执行而不违反延迟指标的推理数量，越大越好&lt;/li&gt;
&lt;li&gt;$k$：常量，取决于VM的性能配置&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;第一个目标函数&lt;/strong&gt;$O_1$就是满足$Acc_{target}$和$Lat_{target}$时最大化$\mu_{AL}$。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/image-20220515200819258.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220515200819258&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;为此，初始模型列表在满足$Lat_{target}$的模型中选择，并尝试集成使其满足$Acc_{target}$。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Cocktail&lt;/strong&gt;&lt;/em&gt;会将每个模型的准确性作为正确概率，然后迭代地构建一个模型列表，其中它们执行分类的联合概率在准确性目标内。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$Acc_{margin}$：为0.2%&lt;/li&gt;
&lt;li&gt;$Lat_{margin}$：为5ms&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;第二个目标函数&lt;/strong&gt;$O_2$是最小化$\mu_c$。&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;该目标调整模型清单的大小，并进一步调整资源采购。因此最大化$P_{f_m}$，最小化$k$。&lt;/p&gt;
&lt;p&gt;对于$N$个模型，每个模型都有一个最小精度，因此选取最小精度前50%的模型，数量为${N\over2} + 1$。来保证集成模型达到预期精度。结果正确率如下：&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;h4 id=&#34;模型选择和加权多数投票策略&#34;&gt;模型选择和加权多数投票策略&lt;/h4&gt;
&lt;p&gt;为最小化$\mu_c$，设计了一个模型数量缩减策略，只要有超过${N\over2}+1$的模型选择同一种结果，如下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/image-20220515205825292.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220515205825292&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;资源管理&#34;&gt;资源管理&lt;/h3&gt;
&lt;h4 id=&#34;资源控制器-resource-controller&#34;&gt;资源控制器 Resource Controller&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Resource Types： CPU和GPU实例。GPU实例在&lt;strong&gt;打包大量请求&lt;/strong&gt;执行时是划算的。文章提出自适应打包策略，考虑每个实例的$P_f$ 以及在时间$T$到来的请求数量。只有工作负载匹配$P_f$时，才会将负载分发到对应实例。&lt;/li&gt;
&lt;li&gt;Cost-aware Procurement： 在一个完全封装的实例中执行请求的成本决定了每个实例的开销。在扩展实例之前，需要估计将它们与现有实例一起运行的成本。在时间$T$时，基于预测负载$L_p$和运行实例$R_N$，使用&lt;em&gt;cost-aware greedy&lt;/em&gt;策略来决定要增加的实例数量。&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;Load  Balancer： 在每个模型池中维护一个请求队列，为增加实例池中实例的利用率，负载均衡器将来自队列的每个请求提交到剩余空闲槽位（free slots）。文章使用预期超时10分钟的间隔，来回收实例池中没有被使用的实例。贪婪地分配请求可以使负载较轻的实例更早地伸缩。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;自动伸缩器-autoscaler&#34;&gt;自动伸缩器 Autoscaler&lt;/h4&gt;
&lt;p&gt;我们需要自动伸缩实例数量，来弹性的满足到来的请求负载。&lt;strong&gt;Cocktail&lt;/strong&gt;能准确预测给定时间间隔内的预期负荷。如果需要，&lt;strong&gt;Cocktail&lt;/strong&gt;增加实例到实例池。每隔10秒对SLO违例进行采样，并根据所有实例的资源利用率聚合为每个池生成额外的实例。捕获由于错误预测而导致的SLO违反。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;预测策略：本文设计了DeepARestimator模型。每个模型有1分钟的定期调度间隔$T_s$，在时间$T+T_p$使用预测负责$L_p$，与当前负载$C_p$进行比较，来决定实例数量$I_n$。其中，$T_p$为新实例的平均启动时间。$T_s$设定为1分钟是考虑到AWS  EC2 VMs实例的启动时间。为计算$L_p$，对过去S秒内大小为$W$的相邻窗口的到达率进行采样。使用所有窗口的全局到达率，来预测时间$T$在加减$T_p$时间单元中的$L_p$。$T_p$设置为10分钟，使它有足够的时间来捕捉未来长期的变化。所有这些参数都可以根据系统的需要进行调整。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Importance Sampling： 在自动伸缩中一个重要的问题是模型选择策略为给定的请求约束动态地确定集合中的模型。**基于预测的负载，为每个模型平等地自动伸缩实例，将固有地导致为未充分使用的模型提供过多的实例。**为了解决这个问题，设计了一个加权自动缩放策略，它基于权重智能地为每个池自动缩放实例。算法如下图：&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;自动缩放策略如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/image-20220515210458324.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220515210458324&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;权重取决于模型被请求(get_popularity)的频率。权重与每个模型池的伸缩实例(launch_workers)的预测负载相乘。这种方法称为Importance Sampling，因为模型池的大小与它们的受欢迎程度成正比。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;本论文实验做得非常充分！可以作为范本。&lt;/p&gt;
&lt;/blockquote&gt;
</description>
        </item>
        <item>
        <title>MLaaS in the Wild: Workload Analysis and Scheduling in Large-Scale Heterogeneous GPU Clusters</title>
        <link>https://lizonglingo.github.io/p/mlaas-in-the-wild-workload-analysis-and-scheduling-in-large-scale-heterogeneous-gpu-clusters/</link>
        <pubDate>Mon, 21 Mar 2022 21:05:51 +0800</pubDate>
        
        <guid>https://lizonglingo.github.io/p/mlaas-in-the-wild-workload-analysis-and-scheduling-in-large-scale-heterogeneous-gpu-clusters/</guid>
        <description>&lt;blockquote&gt;
&lt;p&gt;来源： NSDI&#39;22&lt;/p&gt;
&lt;p&gt;作者：Alibaba Group&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;摘要&#34;&gt;摘要&lt;/h2&gt;
&lt;p&gt;在ML as a Service中，数据中心为ML提供算力保证。而多样的ML工作负载面对&lt;strong&gt;异构GPU集群&lt;/strong&gt;时会出现一些问题。通过两个月的数据收集，采集了超过&lt;strong&gt;6000个GPU&lt;/strong&gt;的生产数据。并发现集群调度面临的一些问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;低GPU利用率&lt;/li&gt;
&lt;li&gt;长队列延迟&lt;/li&gt;
&lt;li&gt;需要高端GPU的任务调度难度大&lt;/li&gt;
&lt;li&gt;异构机器负载不均衡&lt;/li&gt;
&lt;li&gt;CPU潜在的瓶颈问题&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;文章对上述问题提供了一些解决方案。&lt;/p&gt;
&lt;p&gt;本文的最大贡献是提供了一个真实的大规模生产级别的ML集群的追踪数据，并在此基础之上进行分析，为ML as a Service - 云环境下的ML工作负载调度提供了重要的一手数据。&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;在ML框架下的任务需要不同的调度策略，例如GPU局部性、群调度，而且需要调配跨数量级的资源。同时集群中的机器是异构的，一些配置如下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/image-20220320210534789.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220320210534789&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;而异构的运行环境给资源管理和调度带来新的困难。&lt;/p&gt;
&lt;h4 id=&#34;gpu碎片化使用带来的低利用率&#34;&gt;GPU碎片化使用带来的低利用率&lt;/h4&gt;
&lt;p&gt;例如一个任务实例只使用GPU资源的一部分。流处理程序的GPU利用率的中位数值只有0.042GPU。&lt;strong&gt;粗粒度的GPU分配&lt;/strong&gt;使得资源使用率低下。&lt;/p&gt;
&lt;p&gt;为解决这个问题，文章提出了&lt;strong&gt;GPU sharing&lt;/strong&gt;，一种可以以&lt;strong&gt;时分复用的方式让多个任务共享GPU&lt;/strong&gt;的控制方式。使用该方式，将许多低GPU的工作负载整合起来，使用一个GPU，提高资源使用效率。此外，这种共享方式&lt;strong&gt;不会引起资源争用干扰&lt;/strong&gt;，资源竞争的概率十分小。&lt;/p&gt;
&lt;h4 id=&#34;短任务面临的长排队延迟&#34;&gt;短任务面临的长排队延迟&lt;/h4&gt;
&lt;p&gt;短时间运行的任务实例容易由于队列头阻塞而导致长队列延迟，&lt;strong&gt;大约9%的任务排队等待的时间超过他们的执行时间&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;一种有效的解决方案是&lt;strong&gt;预测任务运行时间&lt;/strong&gt;，&lt;strong&gt;并将短任务优先级尽可能提高&lt;/strong&gt;，避免与长任务竞争。通过仔细的特征工程，我们可以预测大多数重复任务的持续时间，误差在25%以内，这足以根据之前的工作建议做出质量调度决策（因为，通过观察，集群中有65%的任务有重复的工作负载）。跟踪驱动的仿真结果表明，通过预测任务持续时间采用最短作业优先调度，平均完成时间减少63%以上。&lt;/p&gt;
&lt;h4 id=&#34;高gpu使用的作业难以进行调度&#34;&gt;高GPU使用的作业难以进行调度&lt;/h4&gt;
&lt;p&gt;集群中的&lt;strong&gt;一些任务要求无共享的使用GPU，以利用高级硬件特性，达到加速训练的目的&lt;/strong&gt;，如NVLink[12]，因此，对这些任务难以进行调度。&lt;/p&gt;
&lt;p&gt;集群中的调度器使用一个简单的 reserving-and-packing 策略在集群中分辨出这样的任务。它&lt;strong&gt;保留高端的GPU机器&lt;/strong&gt;，如，V100 with NVLinks，用于少数具有挑剔调度要求的高GPU任务，同时将其他工作负载打包到不太高级的机器上，使用GPU共享策略&lt;strong&gt;保证资源的利用率&lt;/strong&gt;。此外，该策略还&lt;strong&gt;提升了平均队列等待延迟，加快了任务调度&lt;/strong&gt;。&lt;/p&gt;
&lt;h4 id=&#34;负载不均衡&#34;&gt;负载不均衡&lt;/h4&gt;
&lt;p&gt;明显的是，&lt;strong&gt;低端GPU比高端GPU更加拥挤&lt;/strong&gt;，前者被分配了70%的GPU和CPU资源，而后者只被分配35%的CPU和49%的GPU资源。&lt;/p&gt;
&lt;p&gt;工作负载和机器之间也存在供应不匹配的问题。例如，工作在8GPU的工作负载对CPU的需求是那些可以提供12GPU的1.9倍，简而言之就是，那些&lt;strong&gt;性能更弱的机器被分配了与其能力不匹配的工作负载&lt;/strong&gt;。&lt;/p&gt;
&lt;h4 id=&#34;cpu瓶颈&#34;&gt;CPU瓶颈&lt;/h4&gt;
&lt;p&gt;一些机器学习、深度学习作业不仅仅需要GPU，有的也需要CPU资源，这造成CPU瓶颈。同时发现， 工作在高CPU利用率机器上的任务容易减速。&lt;/p&gt;
&lt;h2 id=&#34;工作负载特征分析&#34;&gt;工作负载特征分析&lt;/h2&gt;
&lt;h3 id=&#34;追踪概述&#34;&gt;追踪概述&lt;/h3&gt;
&lt;p&gt;关于数据集的数据内容和下载请查看&lt;a class=&#34;link&#34; href=&#34;https://github.com/alibaba/clusterdata&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;clusterdata&lt;/a&gt;。实际上并不能明确的知道容器里执行的到底是什么类型的训练任务，但是可以从作业名中得到一些线索。&lt;/p&gt;
&lt;p&gt;下图为PAI和Trace的架构：&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;h4 id=&#34;jobs-tasks-and-instances&#34;&gt;Jobs, tasks, and instances&lt;/h4&gt;
&lt;p&gt;用户提交jobs，一个job有一个或多个tasks来扮演不同的计算角色，每个task使用Docker运行一个或多个instances。&lt;/p&gt;
&lt;p&gt;例如，一个分布式训练job有一个参数服务task，该task有两个实例，此外还有一个worker task有10个实例。一个task的所有instances有相同的资源需求，并且需要gang-schedule。&lt;/p&gt;
&lt;p&gt;我们主要&lt;strong&gt;关注任务实例，也就是instance这一级别的工作&lt;/strong&gt;。&lt;/p&gt;
&lt;h4 id=&#34;heavy-skewed-instance-distribution&#34;&gt;Heavy-skewed instance distribution&lt;/h4&gt;
&lt;p&gt;PAI追踪了120万个tasks，超过750万个instances，由超过1300个用户提交。下图展示了用户提交的task instance的分布，表现出严重的不平衡：&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;5%的用户提交了大概77%的task instances，大概每个用户运行1.75万instance。而50%的用户每人运行少于180个instances。&lt;/p&gt;
&lt;h4 id=&#34;the-prevalence-of-gang-scheduling&#34;&gt;The prevalence of gang-scheduling&lt;/h4&gt;
&lt;p&gt;分布式的任务需要gang-schedule（认为超过2个GPU的调度），如下图：&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;大约85%的任务需要这样的需求，有20%的任务需要超过100个GPU的调度，还有的甚至要进行超过1000个GPU的调度。&lt;/p&gt;
&lt;h4 id=&#34;gpu-locality&#34;&gt;GPU locality&lt;/h4&gt;
&lt;p&gt;除了gang-schedule，一个任务可能会在同一台机器上的多个GPU上运行它的所有实例，也就是存在&lt;strong&gt;GPU局部性&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;虽然这种情况会引发调度延迟的加剧（一些任务等待调度的时间延长），但是在单节点的GPU上进行训练减少了GPU to GPU的通信时间。&lt;/p&gt;
&lt;p&gt;但是通过增强GPU局部性，可以&lt;strong&gt;让某些任务的训练速度加快10倍&lt;/strong&gt;。&lt;/p&gt;
&lt;h4 id=&#34;gpu-sharing&#34;&gt;GPU sharing&lt;/h4&gt;
&lt;p&gt;GPU sharing利用时分复用的原理使得多用户可共享一个GPU进行训练。&lt;/p&gt;
&lt;h4 id=&#34;various-gpu-types-to-choose-from&#34;&gt;Various GPU types to choose from&lt;/h4&gt;
&lt;p&gt;PAI提供异构的GPU可供任务选择。在集群中只有6%的训练任务需要运行在特定的GPU上，其他的任务则对GPU类型没有限制。&lt;/p&gt;
&lt;h3 id=&#34;时间模型&#34;&gt;时间模型&lt;/h3&gt;
&lt;p&gt;从时间角度来观察PAI工作负载。&lt;/p&gt;
&lt;h4 id=&#34;diurnal-task-submissions-and-resource-requests&#34;&gt;Diurnal task submissions and resource requests&lt;/h4&gt;
&lt;p&gt;下图是一周中task和instance的提交情况，还有总体的资源请求情况：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/image-20220321104136979.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220321104136979&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;从中可以得到以下几点信息：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;周中提交数量多余周末&lt;/li&gt;
&lt;li&gt;夜晚也有任务提交的高峰&lt;/li&gt;
&lt;li&gt;大多数在夜间提交的任务并非计算密集型&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;instance-run-time-in-a-wide-range&#34;&gt;Instance run-time in a wide range&lt;/h4&gt;
&lt;p&gt;下图展示了instance运行时间的分布：&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;运行时间的变化范围很大，有4个数量级&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;non-uniform-queueing-delays&#34;&gt;Non-uniform queueing delays&lt;/h4&gt;
&lt;p&gt;理解为在队列中等待调度的时间。这段时间指task提交到instance执行的时间，如下图：&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;对比long-task，short-task通常花费更多比例的时间在等待调度上&lt;/li&gt;
&lt;li&gt;大约9%的短作业实例花费超过完成时间的一半去等待调度，而长左右这个数值只有3%&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;此外，task instance的队列延迟还取决于GPU的需求，如下图：&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;那些可以共享GPU的instance（GPU需求为0-1）可以更快的被调度，其等待调度的等待时间P90值为497s&lt;/li&gt;
&lt;li&gt;而不支持共享GPU的任务的这一值为1150&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;同时，长队列等待时间也出现在一些需要高端GPU的任务中，如下图：&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;例如在V100和V100M32上的instance需要更多等待时间&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;空间模型&#34;&gt;空间模型&lt;/h3&gt;
&lt;p&gt;通过分析资源请求和使用，分析了PAI task instance的空间模型。每15s进行一次测量，并使用虚拟化工具[2, 25]去分析用户的负载模式和他们的资源需求。&lt;/p&gt;
&lt;h4 id=&#34;heavy-tailed-distribution-of-resource-requests&#34;&gt;Heavy-tailed distribution of resource requests&lt;/h4&gt;
&lt;p&gt;如下图：&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;图5(a)(b)(c)中的蓝色实现表示，大约20%的实例占用了80%的资源，而其余的只要很少一部分资源&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;以P95和中位数比较，P95需要12vCPU、1GPU、59GB内存，而中位数只要6vCPU、0.5GPU和29GB内存。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;uneven-resource-usage-low-on-gpu-but-high-on-cpu&#34;&gt;Uneven resource usage: Low on GPU but high on CPU&lt;/h4&gt;
&lt;p&gt;集群中instance的资源使用中位数在1.4vCPU、0.042GPU和3.5GB内存，远小于资源请求的中位数。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;观察到存在GPU空闲和CPU不够用的情况，并推断GPU的低利用率不是因为对GPU的需求少，而是CPU瓶颈限制了GPU的使用&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;从5(b)中也可以看到，对GPU的实际使用远小于GPU资源的需求&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;从5(d)中，对应X坐标&amp;gt;1的值表示CPU的使用量大于申请的量，有19%的instance出现这种情况，而超量使用GPU的只有约3%的实例，对内存来说这一值也只有9%&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;gpu利用率&#34;&gt;GPU利用率&lt;/h2&gt;
&lt;h3 id=&#34;计算资源利用率&#34;&gt;计算资源利用率&lt;/h3&gt;
&lt;p&gt;包括CPU、GPU和Memory。监控系统每15s收集数据，并存到时间序列数据库中。&lt;/p&gt;
&lt;p&gt;如下图：&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;相比内存来说，GPU和CPU利用率普遍高，也说明大部分任务不是内存集中型&lt;/li&gt;
&lt;li&gt;GPU利用率的P90跨度很广，这与GPU使用有突发性相关，同时也与调度策略有关&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;网络和io的低利用率&#34;&gt;网络和I/O的低利用率&lt;/h3&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;网络中数据接收量普遍较低&lt;/li&gt;
&lt;li&gt;网络带宽普遍不能达到指定数值(如不能达到保证的10Gbps、32Gbps)&lt;/li&gt;
&lt;li&gt;iowait模式比usr和kernel模式少三个数量级，这意味着CPU大多数时间在进行计算而不是在等待I/O&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;优化集群管理的方向&#34;&gt;优化集群管理的方向&lt;/h2&gt;
&lt;p&gt;在PAI中，集群管理有两个优化目标：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;实现GPU的高利用率&lt;/li&gt;
&lt;li&gt;缩短task的运行时间&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;gpu共享&#34;&gt;GPU共享&lt;/h3&gt;
&lt;p&gt;与CPU不同，GPU天生就没有共享特性。PAI以&lt;strong&gt;时分复用和空分复用（内存）方式&lt;/strong&gt;，使多个任务实例可以共享一个GPU。&lt;/p&gt;
&lt;h4 id=&#34;benefits-of-gpu-sharing&#34;&gt;Benefits of GPU sharing&lt;/h4&gt;
&lt;p&gt;下图将是否使用GPU sharing的表现进行对比：&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;平均而言，共享只需要50%的GPU资源，可节省高达73%的费用，节省大量的GPU资源&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;does-gpu-sharing-cause-contention&#34;&gt;Does GPU sharing cause contention?&lt;/h4&gt;
&lt;p&gt;随着利用率的增加，运行在共享GPU上的实例开始争夺资源。&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;由于大多数高利用率的GPU上面运行单个实例(平均4.5%的GPU运行多个实例)，因此不会发生争用，所以认为GPU共享不会在集群中引起严重的争用&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;预测重复任务的持续时间&#34;&gt;预测重复任务的持续时间&lt;/h3&gt;
&lt;p&gt;文章认为预测ML认为实例的运行时间是实现更好调度的关键。现存的预测方案基于迭代次数、损耗曲线、目标精度和训练速度等指标。&lt;/p&gt;
&lt;h4 id=&#34;the-prevalence-of-recurring-tasks&#34;&gt;The prevalence of recurring tasks&lt;/h4&gt;
&lt;p&gt;文章发现大多数任务都是重复的，并且它们的实例运行时可以很好地从过去的执行中预测出来。通过对任务的元数据，如：脚本、命令行参数、数据源和输出，进行hash得到Group tag来标识重复的任务。&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;约65%的任务在trace中至少运行5轮&lt;/li&gt;
&lt;li&gt;大多数重复任务每个周期都有相似的运行时间&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;instance-duration-prediction-for-recurring-tasks&#34;&gt;Instance duration prediction for recurring tasks&lt;/h4&gt;
&lt;p&gt;实际的预测使用三个特征作为输入：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;task&amp;rsquo;s username - User&lt;/li&gt;
&lt;li&gt;resource request - Resource including GPU and other resources&lt;/li&gt;
&lt;li&gt;group tag - Group&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;利用上述特征，基于CART(Classification And Regression Tress)算法预测实例的平均运行时间。作为评估，使用至少重复5轮的任务，下图为预测详情：&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;从上图得知：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Group是重要指标&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;benefits-for-scheduling&#34;&gt;Benefits for scheduling&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/image-20220417180125631.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220417180125631&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;上图展示不同调度方法。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;SJF-Oracle明显好于其他算法，该算法基于真实的任务持续时间和预测算法&lt;/li&gt;
&lt;li&gt;给的特征越多，效果越好&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;调度面临的挑战&#34;&gt;调度面临的挑战&lt;/h2&gt;
&lt;p&gt;本部分使用两个案例：典型的ML tasks，分别有高/低GPU资源需求的特性。&lt;/p&gt;
&lt;h3 id=&#34;高gpu需求任务的研究&#34;&gt;高GPU需求任务的研究&lt;/h3&gt;
&lt;p&gt;集群中一些任务有计算密集型实例，需要很高的GPU资源。&lt;/p&gt;
&lt;h4 id=&#34;nlp-with-advanced-language-models&#34;&gt;NLP with advanced language models&lt;/h4&gt;
&lt;p&gt;NLP任务中，73%的有大规模的输入，需要16GB或更高的内存。下图展示了NLP实例对GPU资源的需求和使用情况：&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;约40%的实例需要超过1个GPU，超过那些常规的任务&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;image-classification-with-massive-output&#34;&gt;Image classification with massive output&lt;/h4&gt;
&lt;p&gt;集群中还有些任务需要GPU to GPU的高效率通信，GPU局部性可以提高通信效率。典型代表就是图像分类模型，其中存在规模庞大的全连接层，要求在工作实例之间进行大量的梯度更新，需要使用大量的通信资源，使通信成为瓶颈。&lt;/p&gt;
&lt;p&gt;如图14(b)中，启用NVLink极大缩短了任务的运行时间。&lt;/p&gt;
&lt;h3 id=&#34;低gpu需求的任务研究&#34;&gt;低GPU需求的任务研究&lt;/h3&gt;
&lt;p&gt;使用三种广泛使用的任务进行研究。一些CPU密集型的任务可能会导致GPU的利用率低下。&lt;/p&gt;
&lt;h4 id=&#34;ctr-prediction-model-training-and-inference&#34;&gt;CTR prediction model training and inference&lt;/h4&gt;
&lt;p&gt;在追踪中，有6.7%的广告点击率预测系统（ advertisement click- through rate (CTR) prediction）使用了CTR模型。其中有25%的实例负责训练，75%的实例负责推理工作。这些实例的CPU和GPU资源分布如下：&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;与训练相比，执行推理任务的实例具有更高的CPU利用率，因为它们处理源源不断到达的大量数据&lt;/li&gt;
&lt;li&gt;有近75%的实例使用的GPU小于0.1&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;下图展示了这些模型运行时资源情况：&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;CPU资源的使用明显高于其他资源&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;gnn-training&#34;&gt;GNN training&lt;/h4&gt;
&lt;p&gt;图神经网络也是计算密集型任务， CPU的使用率远超GPU，如下图所示：&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;在模型训练阶段，需要进行大量的CPU操作&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;reinforcement-learning&#34;&gt;Reinforcement learning&lt;/h4&gt;
&lt;p&gt;加强学习算法通过并行模拟迭代生成一批数据将生成的数据放到GPU上进行训练，以改进学习策略。&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;有72%的任务需要超过10个实例来完成，加大调度难度&lt;/li&gt;
&lt;li&gt;但是大多数RL任务对GPU的需求极低&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;部署调度策略&#34;&gt;部署调度策略&lt;/h3&gt;
&lt;h4 id=&#34;reserving-and-packing&#34;&gt;Reserving-and-packing&lt;/h4&gt;
&lt;p&gt;集群中有&lt;strong&gt;意保留高端GPU资源&lt;/strong&gt;，而尽可能将任务打包在一起，共享使用低端GPU资源。&lt;/p&gt;
&lt;p&gt;对于每个任务，调度程序生成一个有序的分配计划序列；每个计划指定了预期的GPU设备，并与尝试超时值相关联。&lt;/p&gt;
&lt;p&gt;对于需要高端GPU的任务，先尝试高端GPU的分配，然后再尝试较低端GPU的分配；对于其他任务，顺序颠倒过来，GPU调度器是在基于局部树的调度系统Fuxi[26,71]上实现的。&lt;/p&gt;
&lt;h4 id=&#34;load-balancing&#34;&gt;Load-balancing&lt;/h4&gt;
&lt;p&gt;在Reserving-and-packing的前提下，调度器还会优先将实例调度到分配率较低的机器上，分配率衡量为已分配的CPU、内存和GPU的加权总和，这些资源按机器的容量进行标准化。&lt;/p&gt;
&lt;h4 id=&#34;benefits&#34;&gt;Benefits&lt;/h4&gt;
&lt;p&gt;具体对应两种调度方法：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;简单地使用渐进式填充的负载平衡机器(总是将任务的实例调度到利用率最低的节点)&lt;/li&gt;
&lt;li&gt;不考虑负载均衡，只执行Reserving-and-packing&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;下图展示了这两种策略的实际表现：&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;请注意，任务的排队延迟也包括在它的组调度实例的排队延迟&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;在这两个策略下，超过90%的实例和任务会立即启动&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;与负载均衡算法相比，Reserving-and-packing算法将平均任务排队率降低了45%，主要原因是尾部延迟的显著缩短超过10000秒&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;进一步比较了业务关键型任务和请求V100的实例的排队延迟，在两种策略下，GPU的平均任务排队延迟减少了68%&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;其他待解决的问题&#34;&gt;其他待解决的问题&lt;/h3&gt;
&lt;h4 id=&#34;mismatch-between-machine-specs-and-instance-requests&#34;&gt;Mismatch between machine specs and instance requests&lt;/h4&gt;
&lt;p&gt;该问题带来的影响如下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/image-20220417191055419.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220417191055419&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;这直接导致：相较于高端机器来说，低端机器明显更拥挤，它们的资源使用率也高于高端机器&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;overcrowded-weak-gpu-machines&#34;&gt;Overcrowded weak-GPU machines&lt;/h4&gt;
&lt;h4 id=&#34;imbalanced-load-in-high-end-machines&#34;&gt;Imbalanced load in high-end machines&lt;/h4&gt;
&lt;h4 id=&#34;cpu-can-be-the-bottleneck&#34;&gt;CPU can be the bottleneck&lt;/h4&gt;
</description>
        </item>
        <item>
        <title>ML学习笔记</title>
        <link>https://lizonglingo.github.io/p/ml%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</link>
        <pubDate>Fri, 08 Oct 2021 12:52:45 +0800</pubDate>
        
        <guid>https://lizonglingo.github.io/p/ml%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</guid>
        <description>&lt;h1 id=&#34;吴恩达ml学习笔记&#34;&gt;吴恩达ML学习笔记&lt;/h1&gt;
&lt;h2 id=&#34;机器学习定义&#34;&gt;机器学习定义&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;计算机从经验&lt;code&gt;E&lt;/code&gt;中学习，解决任务&lt;code&gt;T&lt;/code&gt;，进行某个性能度量&lt;code&gt;P&lt;/code&gt;，通过&lt;code&gt;P&lt;/code&gt;测定在&lt;code&gt;T&lt;/code&gt;上的表现因经验&lt;code&gt;E&lt;/code&gt;而提高。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;机器学习分类&#34;&gt;机器学习分类&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Supervised learning监督学习：教会计算机做某件事情&lt;/li&gt;
&lt;li&gt;Unsupervised learning无监督学习：让计算机自己去学习&lt;/li&gt;
&lt;li&gt;Reinforcement learning强化学习&lt;/li&gt;
&lt;li&gt;Recommend systems推荐系统&lt;/li&gt;
&lt;li&gt;···&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;监督学习&#34;&gt;监督学习&lt;/h2&gt;
&lt;p&gt;给算法一个数据集，这个数据集中包含了正确的答案，并告诉计算机什么是正确的、什么是错误的（或者说数据对应的明确标签）；算法的目的是让机器给出更多正确的答案。&lt;/p&gt;
&lt;h3 id=&#34;回归问题-regression&#34;&gt;回归问题-regression&lt;/h3&gt;
&lt;p&gt;预测连续的数值属性。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;预测房价&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;单变量线性回归-linear-regression-with-one-variable&#34;&gt;单变量线性回归-Linear regression with one variable&lt;/h4&gt;
&lt;p&gt;$$
Hypothesis：			h_{\theta}(x)=\theta_0+\theta_1x
$$&lt;/p&gt;
&lt;p&gt;$$
Parameters:		\theta_0,\theta_1
$$&lt;/p&gt;
&lt;p&gt;$$
Cost Function:		J(\theta_0,\theta_1) = {1\over2m}\sum_{i=1}^m(h_{\theta}(x^{(i)})-y^{(i)})^2
$$&lt;/p&gt;
&lt;p&gt;$$
Goal: minimize_{(\theta_0,\theta_1)}J(\theta_0,\theta_1)
$$&lt;/p&gt;
&lt;p&gt;既然我们的目标是将代价函数最小化，那一个一个试参数将会非常麻烦。所以这里引入&lt;strong&gt;梯度函数&lt;/strong&gt;，快速将代价函数&lt;code&gt;J&lt;/code&gt;最小化。&lt;/p&gt;
&lt;h4 id=&#34;梯度下降算法-gradient-descent-batch&#34;&gt;梯度下降算法-Gradient descent-Batch&lt;/h4&gt;
&lt;p&gt;$$
重复直至收敛：\theta_j := \theta_j - \alpha\frac{\partial }{\partial \theta_j}J(\theta_0,\theta_1){,}{,}(for{,}{,}j=0{,}{,}and{,}{,}j=1)
$$&lt;/p&gt;
&lt;p&gt;或者换一种表达方法(同样的要进行到收敛)：
$$
\theta_0 :=\theta_0-\alpha{1\over m}\sum_{i=1}^m(h_{\theta}(x^{(i)})-y^{(i)})
$$&lt;/p&gt;
&lt;p&gt;$$
\theta_1:=\theta_1-\alpha{1\over m}\sum_{i=1}^m(h_{\theta}(x^{(i)})-y^{(i)})·x^{(i)}
$$&lt;/p&gt;
&lt;p&gt;其中：
$$
\alpha
$$
表示学习率，也就是梯度下降时我们迈出多大的步子。越小则说明梯度下降的速率越缓慢，越大则说明梯度下降的速率越迅速。&lt;/p&gt;
&lt;p&gt;梯度下降是很常用的算法，它是一个一阶的最优化算法，不仅被用在线性回归上，还被用在众多的机器学习领域中。&lt;/p&gt;
&lt;p&gt;它可以解决更一般的问题。&lt;/p&gt;
&lt;p&gt;Have some function:
$$
J(\theta_0,\theta_1,\theta_2,&amp;hellip;,\theta_n)
$$
Want:
$$
min_{(\theta_0,&amp;hellip;,\theta_n)}J(\theta_0,&amp;hellip;,\theta_n)
$$
特点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;沿着不同路线下降，会有多个局部最优解，容易陷入局部最优化&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;多元线性回归模型及梯度下降算法&#34;&gt;多元线性回归模型及梯度下降算法&lt;/h4&gt;
&lt;p&gt;$$
Hypothesis:h_\theta(x)=\theta^Tx=\theta_0x_0+\theta_1x_1+\theta_2x_2+···+\theta_nx_n
$$&lt;/p&gt;
&lt;p&gt;$$
Parameters:\theta_0,\theta_1,···,\theta_n
$$&lt;/p&gt;
&lt;p&gt;$$
Cost Function:J(\theta_0,\theta_1,···,\theta_n)={1\over2m}\sum_{i=1}^m(h_{\theta}(x^{(i)})-y^{(i)})^2
$$&lt;/p&gt;
&lt;p&gt;$$
GradientDescent:Repeat{\theta_j:=\theta_j-\alpha\frac{\partial }{\partial \theta_j}J(\theta_0,\theta_1,···,\theta_n)}
$$&lt;/p&gt;
&lt;p&gt;将&lt;code&gt;GradientDescent&lt;/code&gt;的偏导数展开，就是：
$$
\theta_j:=\theta_j-\alpha{1\over m}\sum_{i=1}^m(h_{\theta}(x^{(i)})-y^{(i)})x^{(i)}_j
$$&lt;/p&gt;
&lt;h4 id=&#34;处理梯度下降的常用技巧&#34;&gt;处理梯度下降的常用技巧&lt;/h4&gt;
&lt;h5 id=&#34;特征缩放&#34;&gt;特征缩放&lt;/h5&gt;
&lt;p&gt;如果一个问题有很多特征，这些特征的取值都处在一个相近的范围，那么梯度下降算法就能更快地收敛。&lt;/p&gt;
&lt;p&gt;特征缩放的目的是：将特征的取值约束到&lt;code&gt;-1&lt;/code&gt;到&lt;code&gt;+1&lt;/code&gt;的范围内。&lt;/p&gt;
&lt;h5 id=&#34;归一化&#34;&gt;归一化&lt;/h5&gt;
&lt;p&gt;进行如下替换，让特征值具有为0的平均值：
$$
x_i-&amp;gt;(x_i-\mu_i)
$$
其中：
$$
x_i:第i个特征
$$&lt;/p&gt;
&lt;p&gt;$$
\mu_i:第i个特征x_i的平均值
$$&lt;/p&gt;
&lt;p&gt;然后用：
$$
x_i-\mu_i\over s_i
$$
去替换特征值：
$$
x_i
$$
其中：
$$
s_i:特征x_i的规模或者说是取值范围
$$&lt;/p&gt;
&lt;h4 id=&#34;正规方程用来最小化代价函数&#34;&gt;正规方程用来最小化代价函数&lt;/h4&gt;
&lt;p&gt;除了可以使用梯度下降法求解最优代价方程的&lt;code&gt;θ&lt;/code&gt;，还可以使用最小化代价函数直接求解最优&lt;code&gt;θ&lt;/code&gt;。
$$
\theta = (X^TX)^{-1}X^Ty
$$
其中：
$$
X：特征矩阵
$$&lt;/p&gt;
&lt;p&gt;$$
y:结果向量
$$&lt;/p&gt;
&lt;p&gt;如此得到的&lt;code&gt;θ&lt;/code&gt;就可以将代价函数最小化。&lt;/p&gt;
&lt;h3 id=&#34;分类问题-classification&#34;&gt;分类问题-classification&lt;/h3&gt;
&lt;p&gt;预测离散的数值属性。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;判断肿瘤良性与否&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;logistic-regression&#34;&gt;Logistic regression&lt;/h4&gt;
&lt;p&gt;有$h_\theta(x)=g(\theta^Tx)$；其中$g(z)={1\over1+e^{-z}}$​​ ，又叫做&amp;quot;logistic function&amp;quot;或者“sigmoid function”。在这里&lt;/p&gt;
&lt;p&gt;$h_\theta(x)$预测的是在参数$\theta$、特征值$x$的条件下，$y=1$​的概率。&lt;/p&gt;
&lt;h4 id=&#34;logistic-regression-的-cost-function&#34;&gt;Logistic regression 的 cost function&lt;/h4&gt;
&lt;p&gt;与上面回归模型不同是，在使用“logistic function”后，我们的$J(\theta)$​代价函数的图像会变成“非凸”的，会存在多个局部最小值。所以我们想找一个只有一个最值的图像。这里引入逻辑回归的代价函数：&lt;/p&gt;
&lt;p&gt;整体的代价函数如下：
$$
J(\theta)={1\over m}\sum_{i=1}^mCost(h_\theta(x)^{(i)},y^{(i)})
$$&lt;/p&gt;
&lt;p&gt;其中：
$$
Cost(h_\theta(x),y) =
\begin{cases}
-log(h_\theta(x)),,,if ,, y=1\
-log(1-h_\theta(x)),,,if ,, y=0\
\end{cases}
$$
这里需要注意：$y=0 ,, or ,, 1 ,, always$​&lt;/p&gt;
&lt;p&gt;所以，$Cost(h_\theta(x),y)$又可以写成：
$$
Cost(h_\theta(x),y)=-ylog(h_\theta(x))-(1-y)log(1-h_\theta(x))
$$
最终，新的代价函数$J(\theta)$就是：
$$
J(\theta)=-{1\over m}[\sum_{i=1}^my^{(i)}log(h_\theta(x^{(i)}))+(1-y^{(i)})log(1-h_\theta(x^{(i)}))]
$$
接下来，我们仍希望去最小化代价函数，得到$min_\theta J(\theta)$。&lt;/p&gt;
&lt;p&gt;与上面回归问题相似，我们依旧使用梯度下降法：
$$
Repeat{\
\theta_j:=\theta_j-\alpha\frac{\partial }{\partial \theta_j}J(\theta) \
simulataneously,,update,,all ,,\theta_j}
$$
&lt;strong&gt;需要注意的是&lt;/strong&gt;：这里的公式看似与前面相同，但是我们对$h_{\theta}(x)$的定义发生了变化，所以这是完全不同的。&lt;/p&gt;
&lt;h2 id=&#34;无监督学习&#34;&gt;无监督学习&lt;/h2&gt;
&lt;p&gt;给算法的数据集没有明确的目的和用途，也不清楚每个数据点的意义，让计算机从中找出某种结构（比如让机器能够将数据分成若干个”簇“），&lt;/p&gt;
&lt;h3 id=&#34;聚类算法-clustering-algorithm&#34;&gt;聚类算法-clustering algorithm&lt;/h3&gt;
&lt;p&gt;告诉算法，这有一堆数据，不知道这些数据是什么、不知道谁是什么类型、甚至不知道有哪些类型（当然也无法告诉机器什么是正确答案），让机器自动找出这些数据的结构并按照得到的结构类型将这些数据个体分成”簇“&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Google news&lt;/li&gt;
&lt;li&gt;genes自动分类&lt;/li&gt;
&lt;li&gt;自动管理计算机集群&lt;/li&gt;
&lt;li&gt;社会网络分析&lt;/li&gt;
&lt;li&gt;星际数据分析&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;评估模型&#34;&gt;评估模型&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;过拟合-高方差：直接表现为训练误差大，同时交叉验证误差也很大&lt;/li&gt;
&lt;li&gt;欠拟合-高偏差：直接表现为训练 误差较小，但是交叉验证误差很大&lt;/li&gt;
&lt;li&gt;修正高方差(variance)问题：使用更多的训练样本、减少特征数量、增大正则化项系数$\lambda$的值​​&lt;/li&gt;
&lt;li&gt;修正高偏差(bias)问题：增加样本数 或 增加多项式特征、减小正则化系数$\lambda$的值&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;常见问题&#34;&gt;常见问题&lt;/h2&gt;
&lt;h3 id=&#34;过拟合问题&#34;&gt;过拟合问题&lt;/h3&gt;
&lt;p&gt;过拟合问题通常在变量过多时出现，在训练时的假设可以很好的拟合训练集，代价函数实际上很可能接近于甚至等于0，这样一来模型会千方百计的去拟合训练集，最终导致&lt;strong&gt;模型无法泛化到新的样本中&lt;/strong&gt;。&lt;/p&gt;
&lt;h4 id=&#34;如何解决过拟合&#34;&gt;如何解决过拟合&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;减少特征的数量&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;人工的去决定哪些特征变量是重要的。&lt;/li&gt;
&lt;li&gt;使用模型选择算法，让算法去决定保留哪些特征变量。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这种方法的缺点是：会舍弃一些信息，尽管这些信息是有用的。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;正则化Regularization&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;保持所有的特征变量，但是减少量级或者参数$\theta$的大小。&lt;/li&gt;
&lt;li&gt;这样就保留了所有特征变量，因为每一个变量都会对预测的模型产生或大或小的影响。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;欠拟合问题&#34;&gt;欠拟合问题&lt;/h3&gt;
&lt;p&gt;与过拟合相反。&lt;/p&gt;
&lt;h2 id=&#34;符号定义&#34;&gt;符号定义&lt;/h2&gt;
&lt;p&gt;$$
m：训练样本的数量
$$&lt;/p&gt;
&lt;p&gt;$$
x&amp;rsquo;s：输入变量，或者说是特征
$$&lt;/p&gt;
&lt;p&gt;$$
y&amp;rsquo;s：输出变量，也就是要预测的目标变量
$$&lt;/p&gt;
&lt;p&gt;$$
(x,y)：表示一个训练样本
$$&lt;/p&gt;
&lt;p&gt;$$
(x^{(i)},y^{(i)})：表示第i个训练样本
$$&lt;/p&gt;
&lt;p&gt;$$
h：假设函数(hypothesis)，接收x，尝试输出y
$$&lt;/p&gt;
&lt;p&gt;$$
假设函数h_{\theta}(x)=\theta_0+\theta_1x，那么\theta_0和\theta_1叫做模型参数
$$&lt;/p&gt;
</description>
        </item>
        
    </channel>
</rss>
