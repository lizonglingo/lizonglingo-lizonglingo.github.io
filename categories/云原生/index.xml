<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>云原生 on Li Duo</title>
        <link>https://lizonglingo.github.io/categories/%E4%BA%91%E5%8E%9F%E7%94%9F/</link>
        <description>Recent content in 云原生 on Li Duo</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-CN</language>
        <lastBuildDate>Mon, 01 Aug 2022 18:10:59 +0800</lastBuildDate><atom:link href="https://lizonglingo.github.io/categories/%E4%BA%91%E5%8E%9F%E7%94%9F/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>cri-dockerd，在kubernetes1.24后继续使用Docker作为容器运行时</title>
        <link>https://lizonglingo.github.io/p/cri-dockerd%E5%9C%A8kubernetes1.24%E5%90%8E%E7%BB%A7%E7%BB%AD%E4%BD%BF%E7%94%A8docker%E4%BD%9C%E4%B8%BA%E5%AE%B9%E5%99%A8%E8%BF%90%E8%A1%8C%E6%97%B6/</link>
        <pubDate>Mon, 01 Aug 2022 18:10:59 +0800</pubDate>
        
        <guid>https://lizonglingo.github.io/p/cri-dockerd%E5%9C%A8kubernetes1.24%E5%90%8E%E7%BB%A7%E7%BB%AD%E4%BD%BF%E7%94%A8docker%E4%BD%9C%E4%B8%BA%E5%AE%B9%E5%99%A8%E8%BF%90%E8%A1%8C%E6%97%B6/</guid>
        <description>&lt;blockquote&gt;
&lt;p&gt;为体验Kubernetes以及Cilium组合在一起产生的新特性，我计划将Kubernetes升级到1.24+，并使用最新的稳定版cilium1.12来作集群网络。&lt;/p&gt;
&lt;p&gt;我所看重的最大改变：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;kubernetes1.24+正式移除dockershim，关于“kubernetes弃用Docker”这一话题也算是尘埃落定，kubernetes正式拥抱纯净的CRI。&lt;/li&gt;
&lt;li&gt;cilium1.12后正式支持kubernetes1.24.0，并且其重大的新特性cilium service mesh引起了我的兴趣，“multi control plan”、“sidercar/sidercar-free”等亮点让我很想尝试，是不是基于eBPF的service mesh在性能开销、指标粒度上能够给云上可观测性带来更好的体验。&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;所以，第一个问题来了，移除dockershim后，我们怎样继续使用docker engine作为底层的容器管理以及运行时管理者呢？&lt;/p&gt;
&lt;h2 id=&#34;dockershim和容器运行时&#34;&gt;Dockershim和容器运行时&lt;/h2&gt;
&lt;p&gt;我们知道，提供服务的终点是Pod中运行的容器，kubernetes本身并不提供这种能力，而是依赖CRI去接入其他容器运行时，实现这样的能力的。我们最直接的体会就是kubernetes可以按照声明文件自动拉取、运行容器，其实这都是容器运行时的工作。例如docker，它就有这样的能力，并且在k8s发展初期，Docker甚至比k8s更有知名度，同时Docker比k8s CRI这样概念要早，docker engine也就没有实现CRI接口这一说，所以k8s使用&lt;code&gt;dockershim&lt;/code&gt;作为支撑docker这一容器运行时的过渡。因此在k8s早期版本，就针对docker这个容器运行时做了适配。&lt;/p&gt;
&lt;p&gt;每个节点上的kubelet在dockershim的能力下，可以与节点上的docker engine进行交互，去使用docker的能力。&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/image-20220730233109830.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220730233109830&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;从上图中可以看出，dockershim的作用与一个CRI实现是一样的。尽管目前docker底层也是使用了&lt;code&gt;containerd&lt;/code&gt;，但是我们还需要多一个中间环节，用docker调用containerd。&lt;/p&gt;
&lt;p&gt;而k8s中CRI之一&lt;code&gt;containerd&lt;/code&gt;则为k8s提供了直接调用containerd的能力。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;目前主要的CRI实现有：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;containerd&lt;/li&gt;
&lt;li&gt;cri-o&lt;/li&gt;
&lt;li&gt;cri-dockerd&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;正因如此，k8s不必局限于docker这一种运行时，CRI的能力可以让k8s使用特性不同的容器运行时。&lt;/p&gt;
&lt;h3 id=&#34;弃用dockershim后docker还有用吗&#34;&gt;弃用dockershim后，Docker还有用吗？&lt;/h3&gt;
&lt;p&gt;当然。&lt;/p&gt;
&lt;p&gt;在我的印象里，docker仍然是目前使用最多的容器打包构建、镜像管理和运行工具。docker hub有丰富镜像资源、有很多开发者在使用docker去构建自己应用镜像。使用&lt;code&gt;docker build&lt;/code&gt;打包的镜像依然符合CRI的标准（因为已经容器运行时以及有标准化组织OCI为其制定规范了）。&lt;/p&gt;
&lt;p&gt;只不过，原来为docker engine做适配工作现在已经不属于k8s社区的管辖范围，需要其他社区自己去按照CRI的标准，为docker engine编写接入k8s的“转接头”。因此，就有了&lt;code&gt;cri-dockerd&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;如果我们想继续使用在k8s中使用docker，就必须使用&lt;code&gt;cri-dockerd&lt;/code&gt;作为适配器，它让我们可以通过CRI来使用docker engine。&lt;/p&gt;
&lt;h2 id=&#34;在新版本集群中使用cri-dockerd&#34;&gt;在新版本集群中使用cri-dockerd&lt;/h2&gt;
&lt;p&gt;之前的博客中我们分享到，搭建集群只需要节点上有docker engine就可以，然后按照&lt;code&gt;kubeadm&lt;/code&gt;，&lt;code&gt;kubelet&lt;/code&gt;，&lt;code&gt;kubectl&lt;/code&gt;就可以了，不会去刻意、显式的配置容器运行时。那是因为k8s内置的dockershim自动帮我们完成了这个工作。&lt;/p&gt;
&lt;p&gt;在1.24.0之后，我们在创建集群之前，也要像安装CNI那样先配置我们的容器运行时，才可以正常初始化k8s集群。&lt;/p&gt;
&lt;h3 id=&#34;安装并配置cri-dockerd&#34;&gt;安装并配置cri-dockerd&lt;/h3&gt;
&lt;p&gt;:warning:这需要节点上有正常运行的docker engine。同时要在所有节点上安装cri-dockerd。&lt;/p&gt;
&lt;p&gt;我们这里使用Ubuntu22.04作为环境，直接在&lt;a class=&#34;link&#34; href=&#34;https://github.com/Mirantis/cri-dockerd/releases&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;release&lt;/a&gt;下载构建好的对应Ubuntu版本的&lt;code&gt;.deb&lt;/code&gt;安装文件。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/202207311437400.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220731143731223&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;然后，进行安装：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&amp;gt; dpkg -i cri-dockerd_0.2.3.3-0.ubuntu-jammy_amd64.deb
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Selecting previously unselected package cri-dockerd.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;Reading database ... &lt;span style=&#34;color:#ae81ff&#34;&gt;212454&lt;/span&gt; files and directories currently installed.&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Preparing to unpack cri-dockerd_0.2.3.3-0.ubuntu-jammy_amd64.deb ...
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Unpacking cri-dockerd &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;0.2.3~3-0~ubuntu-jammy&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt; ...
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Setting up cri-dockerd &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;0.2.3~3-0~ubuntu-jammy&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt; ...
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Created symlink /etc/systemd/system/multi-user.target.wants/cri-docker.service → /lib/systemd/system/cri-docker.service.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Created symlink /etc/systemd/system/sockets.target.wants/cri-docker.socket → /lib/systemd/system/cri-docker.socket.
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;安装log里有两个很重要的信息点：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Created symlink /etc/systemd/system/multi-user.target.wants/cri-docker.service → /lib/systemd/system/cri-docker.service.&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Created symlink /etc/systemd/system/sockets.target.wants/cri-docker.socket → /lib/systemd/system/cri-docker.socket.&lt;/code&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;sysmlink&lt;/code&gt;是Linux中的一种文件类型，称为“符号链接”、“软链接”，指向计算机上另一个文件或者文件夹。类似于Windows中的快捷方式。这种链接文件记录了被链接文件的路径，更方便的访问某些文件。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;在安装cri-dockerd时，为&lt;code&gt;cri-docker.service&lt;/code&gt;，和&lt;code&gt;cri-docker.socket&lt;/code&gt;创建了软链接。&lt;/p&gt;
&lt;p&gt;安装后，我们执行&lt;code&gt;cri-dockerd -h&lt;/code&gt; 了解一下基本信息：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&amp;gt; cri-dockerd -h
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;CRI that connects to the Docker Daemon
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Usage:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  cri-dockerd &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;flags&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Flags:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      --buildinfo                               Prints the build information about cri-dockerd
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      --cni-bin-dir string                      &amp;lt;Warning: Alpha feature&amp;gt; A comma-separated list of full paths of directories in which to search &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; CNI plugin binaries. &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;default &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/opt/cni/bin&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      --cni-cache-dir string                    &amp;lt;Warning: Alpha feature&amp;gt; The full path of the directory in which CNI should store cache files. &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;default &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/var/lib/cni/cache&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      --cni-conf-dir string                     &amp;lt;Warning: Alpha feature&amp;gt; The full path of the directory in which to search &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; CNI config files &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;default &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/etc/cni/net.d&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      --container-runtime-endpoint string       The endpoint of backend runtime service. Currently unix socket and tcp endpoints are supported on Linux, &lt;span style=&#34;color:#66d9ef&#34;&gt;while&lt;/span&gt; npipe and tcp endpoints are supported on windows.  Examples:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;unix:///var/run/cri-dockerd.sock&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;npipe:////./pipe/cri-dockerd&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;default &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;unix:///var/run/cri-dockerd.sock&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      --cri-dockerd-root-directory string       Path to the cri-dockerd root directory. &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;default &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/var/lib/cri-dockerd&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      --docker-endpoint string                  Use this &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; the docker endpoint to communicate with. &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;default &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;unix:///var/run/docker.sock&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      --hairpin-mode HairpinMode                &amp;lt;Warning: Alpha feature&amp;gt; The mode of hairpin to use. &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;default none&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  -h, --help                                    Help &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; cri-dockerd
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      --image-pull-progress-deadline duration   If no pulling progress is made before this deadline, the image pulling will be cancelled. &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;default 1m0s&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      --ipv6-dual-stack                         Enable IPv6 dual stack support
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      --log-level string                        The log level &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; cri-docker &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;default &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;info&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      --network-plugin string                   &amp;lt;Warning: Alpha feature&amp;gt; The name of the network plugin to be invoked &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; various events in kubelet/pod lifecycle.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      --network-plugin-mtu int32                &amp;lt;Warning: Alpha feature&amp;gt; The MTU to be passed to the network plugin, to override the default. Set to &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; to use the default &lt;span style=&#34;color:#ae81ff&#34;&gt;1460&lt;/span&gt; MTU.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      --pod-cidr string                         The CIDR to use &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; pod IP addresses, only used in standalone mode.  In cluster mode, this is obtained from the master. For IPv6, the maximum number of IP&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;&amp;#39;&lt;/span&gt;s allocated is &lt;span style=&#34;color:#ae81ff&#34;&gt;65536&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      --pod-infra-container-image string        The image whose network/ipc namespaces containers in each pod will use &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;default &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;k8s.gcr.io/pause:3.6&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      --runtime-cgroups string                  Optional absolute name of cgroups to create and run the runtime in.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      --version                                 Prints the version of cri-dockerd
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;从“CRI that connects to the Docker Daemon”中看到，cri-dockerd的作用是连接节点上的docker daemon的，然后k8s再连接cri-dockerd，就能使用docker作为容器运行时了。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;--cni-bin-dir string&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--cni-cache-dir string&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--cni-conf-dir string&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;上面三个参数是关于容器网络的，暂时在alpha阶段。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;--container-runtime-endpoint&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这个参数需要我们注意，它指定了k8s需要连接CRI端点，默认是&lt;code&gt;unix:///var/run/cri-dockerd.sock&lt;/code&gt;，在后面配置kubeadm config时需要用到。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;--docker-endpoint string&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这个参数就是cri-dockerd要去连接的docker daemon的端点，来使用docker的能力。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;--pod-cidr string&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;该参数只有在单节点部署时才会用到，在集群环境下cri-dockerd通过获取master node的信息知晓pod的cidr划分。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;--pod-infra-container-image&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;该参数可以用来设置Pod中的pause容器的镜像版本，默认使用&lt;code&gt;k8s.gcr.io/pause:3.6&lt;/code&gt;这个镜像。但是在k8s1.24中，应该使用3.7版本，并且要换成aliyun镜像，在后面需要设置。&lt;/p&gt;
&lt;h3 id=&#34;修改kubeadm-config文件&#34;&gt;修改kubeadm config文件&lt;/h3&gt;
&lt;p&gt;我先导出&lt;code&gt;kubeadm&lt;/code&gt;默认的启动配置文件。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;kubeadm config print init-defaults &amp;gt; kubeadm1.24.conf&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;然后做一些修改，我的修改如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;apiVersion: kubeadm.k8s.io/v1beta3
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;bootstrapTokens:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;- groups:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  - system:bootstrappers:kubeadm:default-node-token
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  token: abcdef.0123456789abcdef
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  ttl: 24h0m0s
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  usages:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  - signing
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  - authentication
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kind: InitConfiguration
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;localAPIEndpoint:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  advertiseAddress: 192.168.153.21
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  bindPort: &lt;span style=&#34;color:#ae81ff&#34;&gt;6443&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;nodeRegistration:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  criSocket: unix:///var/run/cri-dockerd.sock
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  imagePullPolicy: IfNotPresent
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  name: nm
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  taints: null
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;---
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;apiServer:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  timeoutForControlPlane: 4m0s
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;apiVersion: kubeadm.k8s.io/v1beta3
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;certificatesDir: /etc/kubernetes/pki
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;clusterName: kubernetes
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;controllerManager: &lt;span style=&#34;color:#f92672&#34;&gt;{}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;dns: &lt;span style=&#34;color:#f92672&#34;&gt;{}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;etcd:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  local:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    dataDir: /var/lib/etcd
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;imageRepository: registry.aliyuncs.com/google_containers
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kind: ClusterConfiguration
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubernetesVersion: 1.24.0
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;networking:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  dnsDomain: cluster.local
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  serviceSubnet: 10.96.0.0/12
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  podSubnet: 10.5.0.0/16
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;scheduler: &lt;span style=&#34;color:#f92672&#34;&gt;{}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;需要注意的几个点有：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;advertiseAddress: 192.168.153.21&lt;/code&gt;：设置控制平面API Server的地址和端口。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;criSocket: unix:///var/run/cri-dockerd.sock&lt;/code&gt;：这需要特别注意，criSocket就是上面我们说的cri-dockerd中的&lt;code&gt;--container-runtime-endpoint&lt;/code&gt;参数，如果使用了别的容器运行时这里也要相应修改。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;name: nm&lt;/code&gt;：本机的hostname。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;imageRepository: registry.aliyuncs.com/google_containers&lt;/code&gt;：国内用aliyun的镜像。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;podSubnet: 10.5.0.0/16&lt;/code&gt;：Pod cidr信息。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;启动集群启动失败&#34;&gt;启动集群(启动失败)&lt;/h3&gt;
&lt;p&gt;然后我们尝试启动集群：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# kubeadm init --config ../create-cluster/kubeadm1.24.conf &lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;init&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Using Kubernetes version: v1.24.0
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;preflight&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Running pre-flight checks
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;	&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;WARNING SystemVerification&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;: missing optional cgroups: blkio
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;error execution phase preflight: &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;preflight&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Some fatal errors occurred:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;	&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;ERROR CRI&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;: container runtime is not running: output: time&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;2022-07-31T15:41:42+08:00&amp;#34;&lt;/span&gt; level&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;debug msg&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;get runtime connection&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;time&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;2022-07-31T15:41:42+08:00&amp;#34;&lt;/span&gt; level&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;fatal msg&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;unable to determine runtime API version: rpc error: code = Unavailable desc = connection error: desc = \&amp;#34;transport: Error while dialing dial unix /var/run/cri-dockerd.sock: connect: connection refused\&amp;#34;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;, error: exit status &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;preflight&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; If you know what you are doing, you can make a check non-fatal with &lt;span style=&#34;color:#e6db74&#34;&gt;`&lt;/span&gt;--ignore-preflight-errors&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;...&lt;span style=&#34;color:#e6db74&#34;&gt;`&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;To see the stack trace of this error execute with --v&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt; or higher
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;发现报错了&lt;code&gt;level=fatal msg=&amp;quot;unable to determine runtime API version: rpc error: code = Unavailable desc = connection error: desc = \&amp;quot;transport: Error while dialing dial unix /var/run/cri-dockerd.sock: connect: connection refused\&amp;quot;&lt;/code&gt;。我们的socket没有连上。&lt;/p&gt;
&lt;p&gt;原因就是，&lt;strong&gt;我们安装了cri-dockerd后，它并不会像systemctl所管理的service，或者守护进程那样自动驻留在本机上。我们必须手动的启动cri-dockerd。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;所以，需要手动运行cri-dockerd，并且添加&lt;code&gt;--pod-infra-container-image&lt;/code&gt;参数。（使用&lt;code&gt;kubeadm config images list --config kubeadm1.24.conf&lt;/code&gt;可以知道需要的镜像版本）&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&amp;gt; cri-dockerd --pod-infra-container-image&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;registry.aliyuncs.com/google_containers/pause:3.7
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;INFO&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;0000&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Connecting to docker on the Endpoint unix:///var/run/docker.sock 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;INFO&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;0000&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Start docker client with request timeout 0s  
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;INFO&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;0000&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Hairpin mode is set to none                  
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;INFO&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;0000&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Docker cri networking managed by network plugin kubernetes.io/no-op 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;INFO&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;0000&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Docker Info: &amp;amp;&lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;ID:HEPZ:PXCZ:XHZR:SKBX:TJL5:EG5L:U6P3:PI5A:PVZZ:ASKB:QJUC:QEDR Containers:2 ContainersRunning:1 ContainersPaused:0 ContainersStopped:1 Images:13 Driver:overlay2 DriverStatus:&lt;span style=&#34;color:#f92672&#34;&gt;[[&lt;/span&gt;Backing Filesystem extfs&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;Supports d_type true&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;Native Overlay Diff true&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;userxattr false&lt;span style=&#34;color:#f92672&#34;&gt;]]&lt;/span&gt; SystemStatus:&lt;span style=&#34;color:#f92672&#34;&gt;[]&lt;/span&gt; Plugins:&lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;Volume:&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;local&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Network:&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;bridge host ipvlan macvlan null overlay&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Authorization:&lt;span style=&#34;color:#f92672&#34;&gt;[]&lt;/span&gt; Log:&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog&lt;span style=&#34;color:#f92672&#34;&gt;]}&lt;/span&gt; MemoryLimit:true SwapLimit:true KernelMemory:false KernelMemoryTCP:false CPUCfsPeriod:true CPUCfsQuota:true CPUShares:true CPUSet:true PidsLimit:true IPv4Forwarding:true BridgeNfIptables:true BridgeNfIP6tables:true Debug:false NFd:31 OomKillDisable:false NGoroutines:39 SystemTime:2022-07-31T15:49:40.481000763+08:00 LoggingDriver:json-file CgroupDriver:systemd NEventsListener:0 KernelVersion:5.15.0-41-generic OperatingSystem:Ubuntu 22.04 LTS OSType:linux Architecture:x86_64 IndexServerAddress:https://index.docker.io/v1/ RegistryConfig:0xc0001de540 NCPU:4 MemTotal:8302116864 GenericResources:&lt;span style=&#34;color:#f92672&#34;&gt;[]&lt;/span&gt; DockerRootDir:/var/lib/docker HTTPProxy: HTTPSProxy: NoProxy: Name:nm Labels:&lt;span style=&#34;color:#f92672&#34;&gt;[]&lt;/span&gt; ExperimentalBuild:false ServerVersion:20.10.17 ClusterStore: ClusterAdvertise: Runtimes:map&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;io.containerd.runc.v2:&lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;Path:runc Args:&lt;span style=&#34;color:#f92672&#34;&gt;[]}&lt;/span&gt; io.containerd.runtime.v1.linux:&lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;Path:runc Args:&lt;span style=&#34;color:#f92672&#34;&gt;[]}&lt;/span&gt; runc:&lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;Path:runc Args:&lt;span style=&#34;color:#f92672&#34;&gt;[]}]&lt;/span&gt; DefaultRuntime:runc Swarm:&lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;NodeID: NodeAddr: LocalNodeState:inactive ControlAvailable:false Error: RemoteManagers:&lt;span style=&#34;color:#f92672&#34;&gt;[]&lt;/span&gt; Nodes:0 Managers:0 Cluster:&amp;lt;nil&amp;gt; Warnings:&lt;span style=&#34;color:#f92672&#34;&gt;[]}&lt;/span&gt; LiveRestoreEnabled:false Isolation: InitBinary:docker-init ContainerdCommit:&lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;ID:10c12954828e7c7c9b6e0ea9b0c02b01407d3ae1 Expected:10c12954828e7c7c9b6e0ea9b0c02b01407d3ae1&lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt; RuncCommit:&lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;ID:v1.1.2-0-ga916309 Expected:v1.1.2-0-ga916309&lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt; InitCommit:&lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;ID:de40ad0 Expected:de40ad0&lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt; SecurityOptions:&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;name&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;apparmor name&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;seccomp,profile&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;default name&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;cgroupns&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; ProductLicense: Warnings:&lt;span style=&#34;color:#f92672&#34;&gt;[]}&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;INFO&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;0000&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Setting cgroupDriver systemd                 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;INFO&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;0000&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Docker cri received runtime config &amp;amp;RuntimeConfig&lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;NetworkConfig:&amp;amp;NetworkConfig&lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;PodCidr:,&lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;,&lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;INFO&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;0000&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Starting the GRPC backend &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; the Docker CRI interface. 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;INFO&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;0000&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Start cri-dockerd grpc backend
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;我们看到，它已经连上了docker的endpoint。&lt;/p&gt;
&lt;p&gt;这时我们再另起一个终端，启动集群。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;需要注意，在清理集群时，要添加一个socket参数，如&lt;code&gt;kubeadm reset --cri-socket unix:///var/run/cri-dockerd.sock&lt;/code&gt;。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&amp;gt; kubeadm init --config kubeadm1.24.3.conf 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;init&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Using Kubernetes version: v1.24.0
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;preflight&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Running pre-flight checks
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;	&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;WARNING SystemVerification&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;: missing optional cgroups: blkio
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;preflight&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Pulling images required &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; setting up a Kubernetes cluster
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;preflight&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; This might take a minute or two, depending on the speed of your internet connection
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;preflight&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; You can also perform this action in beforehand using &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;kubeadm config images pull&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;certs&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Using certificateDir folder &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/etc/kubernetes/pki&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;...
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;在cri-dockerd的终端中，有了新的输出：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;INFO&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;0000&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Start cri-dockerd grpc backend               
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;INFO&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;0157&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Will attempt to re-write config file /var/lib/docker/containers/000f099fa98530c39e69458881c051f25200feb4f25dfd3d8f02f7444e6763ac/resolv.conf as &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;nameserver 192.168.153.2 nameserver 192.168.153.2 search &lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;INFO&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;0157&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Will attempt to re-write config file /var/lib/docker/containers/ed0aa34e77adbf4ff444998b75e2365f1ebe44e831cdf4c55d3eecd4b6582958/resolv.conf as &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;nameserver 192.168.153.2 nameserver 192.168.153.2 search &lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;INFO&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;0157&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Will attempt to re-write config file /var/lib/docker/containers/3431d46d839451adc30f1c44994990daed5b24899959aae34b5cfd3d5c695fc6/resolv.conf as &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;nameserver 192.168.153.2 nameserver 192.168.153.2 search &lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;INFO&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;0157&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Will attempt to re-write config file /var/lib/docker/containers/50ae6ccb6e7c1420f58c1873bf2c17e291a26597a3b042b0df86a1ef2729470c/resolv.conf as &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;nameserver 192.168.153.2 nameserver 192.168.153.2 search &lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ERRO&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;0167&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; ContainerStats resp: &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;0xc00098ea80 linux&lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;    
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ERRO&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;0168&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; ContainerStats resp: &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;0xc00098f440 linux&lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;    
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ERRO&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;0168&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; ContainerStats resp: &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;0xc000791b00 linux&lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;    
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;然而这里还报出一些奇怪的错误。&lt;/p&gt;
&lt;p&gt;我们查看docker容器：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&amp;gt; docker container ls
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;CONTAINER ID   IMAGE                                               COMMAND                  CREATED         STATUS         PORTS                                       NAMES
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;bbded4be83db   a4ca41631cc7                                        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/coredns -conf /etc…&amp;#34;&lt;/span&gt;   &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; minutes ago   Up &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; minutes                                               k8s_coredns_coredns-74586cf9b6-s6n6g_kube-system_68e930db-ac76-4995-bef2-a9f094b5cf88_0
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;173154bfdc43   a4ca41631cc7                                        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/coredns -conf /etc…&amp;#34;&lt;/span&gt;   &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; minutes ago   Up &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; minutes                                               k8s_coredns_coredns-74586cf9b6-wstwx_kube-system_178e7a4e-3c35-42e6-b78b-1053274d9d4d_0
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;fb2810fe84a3   77b49675beae                                        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/usr/local/bin/kube…&amp;#34;&lt;/span&gt;   &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; minutes ago   Up &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; minutes                                               k8s_kube-proxy_kube-proxy-fpfq7_kube-system_3a52d7e5-ffa8-4193-a2de-948861818bf0_0
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;640f6546ff97   registry.aliyuncs.com/google_containers/pause:3.7   &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/pause&amp;#34;&lt;/span&gt;                 &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; minutes ago   Up &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; minutes                                               k8s_POD_coredns-74586cf9b6-s6n6g_kube-system_68e930db-ac76-4995-bef2-a9f094b5cf88_0
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;8933a7f18e54   registry.aliyuncs.com/google_containers/pause:3.7   &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/pause&amp;#34;&lt;/span&gt;                 &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; minutes ago   Up &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; minutes                                               k8s_POD_coredns-74586cf9b6-wstwx_kube-system_178e7a4e-3c35-42e6-b78b-1053274d9d4d_0
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;c2319d389da4   registry.aliyuncs.com/google_containers/pause:3.7   &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/pause&amp;#34;&lt;/span&gt;                 &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; minutes ago   Up &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; minutes                                               k8s_POD_kube-proxy-fpfq7_kube-system_3a52d7e5-ffa8-4193-a2de-948861818bf0_0
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;c441aae26e22   88784fb4ac2f                                        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;kube-controller-man…&amp;#34;&lt;/span&gt;   &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; minutes ago   Up &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; minutes                                               k8s_kube-controller-manager_kube-controller-manager-nm_kube-system_0b57267fec9fa21f5d899c064341d122_0
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;c2251251c6be   e3ed7dee73e9                                        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;kube-scheduler --au…&amp;#34;&lt;/span&gt;   &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; minutes ago   Up &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; minutes                                               k8s_kube-scheduler_kube-scheduler-nm_kube-system_4b1a2622b0a7caad68556441288e8374_0
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;90df81c294fc   aebe758cef4c                                        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;etcd --advertise-cl…&amp;#34;&lt;/span&gt;   &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; minutes ago   Up &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; minutes                                               k8s_etcd_etcd-nm_kube-system_c305f8ecb58a3de0b142aa31e3c6e6cc_0
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;d14f4a822e37   529072250ccc                                        &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;kube-apiserver --ad…&amp;#34;&lt;/span&gt;   &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; minutes ago   Up &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; minutes                                               k8s_kube-apiserver_kube-apiserver-nm_kube-system_a38fd4cf236ff9d9bba5bb8f006ffdfd_0
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;000f099fa985   registry.aliyuncs.com/google_containers/pause:3.7   &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/pause&amp;#34;&lt;/span&gt;                 &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; minutes ago   Up &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; minutes                                               k8s_POD_kube-scheduler-nm_kube-system_4b1a2622b0a7caad68556441288e8374_0
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;50ae6ccb6e7c   registry.aliyuncs.com/google_containers/pause:3.7   &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/pause&amp;#34;&lt;/span&gt;                 &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; minutes ago   Up &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; minutes                                               k8s_POD_kube-controller-manager-nm_kube-system_0b57267fec9fa21f5d899c064341d122_0
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ed0aa34e77ad   registry.aliyuncs.com/google_containers/pause:3.7   &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/pause&amp;#34;&lt;/span&gt;                 &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; minutes ago   Up &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; minutes                                               k8s_POD_kube-apiserver-nm_kube-system_a38fd4cf236ff9d9bba5bb8f006ffdfd_0
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;3431d46d8394   registry.aliyuncs.com/google_containers/pause:3.7   &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/pause&amp;#34;&lt;/span&gt;                 &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; minutes ago   Up &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; minutes                                               k8s_POD_etcd-nm_kube-system_c305f8ecb58a3de0b142aa31e3c6e6cc_0
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;系统的组件都启动了。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&amp;gt; kubectl get cs
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Warning: v1 ComponentStatus is deprecated in v1.19+
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;NAME                 STATUS    MESSAGE                         ERROR
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;scheduler            Healthy   ok                              
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;controller-manager   Healthy   ok                              
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;etcd-0               Healthy   &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;health&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;true&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;reason&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;   
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&amp;gt; kubectl get pod -A
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;NAMESPACE     NAME                         READY   STATUS    RESTARTS   AGE
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kube-system   coredns-74586cf9b6-vpdp5     1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          33s
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kube-system   coredns-74586cf9b6-zdfpw     1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          33s
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kube-system   etcd-nm                      1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          46s
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kube-system   kube-apiserver-nm            1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          49s
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kube-system   kube-controller-manager-nm   1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          49s
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kube-system   kube-proxy-gs9lq             1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          33s
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kube-system   kube-scheduler-nm            1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          46s
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;加入工作节点。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&amp;gt; kubeadm join 192.168.153.21:6443 --token abcdef.0123456789abcdef &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;        --discovery-token-ca-cert-hash sha256:d1902aa47f486d6fd1d35f7fb92286ffaa39da0437ded9be8d2de5670d52a8ca
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Found multiple CRI endpoints on the host. Please define which one &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt; you wish to use by setting the &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;criSocket&amp;#39;&lt;/span&gt; field in the kubeadm configuration file: unix:///var/run/containerd/containerd.sock, unix:///var/run/cri-dockerd.sock
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;我们发现这里出现了运行时冲突，需要指定，这里就直接在命令行指明，如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&amp;gt; kubeadm join 192.168.153.21:6443 --token abcdef.0123456789abcdef --discovery-token-ca-cert-hash sha256:d1902aa47f486d6fd1d35f7fb92286ffaa39da0437ded9be8d2de5670d52a8ca --cri-socket unix:///var/run/cri-dockerd.sock
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;preflight&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Running pre-flight checks
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;	&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;WARNING SystemVerification&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;: missing optional cgroups: blkio
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;preflight&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Reading configuration from the cluster...
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;preflight&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; FYI: You can look at this config file with &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;kubectl -n kube-system get cm kubeadm-config -o yaml&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;kubelet-start&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Writing kubelet configuration to file &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/var/lib/kubelet/config.yaml&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;kubelet-start&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Writing kubelet environment file with flags to file &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/var/lib/kubelet/kubeadm-flags.env&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;kubelet-start&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Starting the kubelet
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;kubelet-start&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Waiting &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; the kubelet to perform the TLS Bootstrap...
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;This node has joined the cluster:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;* Certificate signing request was sent to apiserver and a response was received.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;* The Kubelet was informed of the new secure connection details.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Run &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;kubectl get nodes&amp;#39;&lt;/span&gt; on the control-plane to see this node join the cluster.
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;然后，我们看到节点已加入集群：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&amp;gt; kubectl get nodes
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;NAME   STATUS   ROLES           AGE     VERSION
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;na     Ready    &amp;lt;none&amp;gt;          2m14s   v1.24.3
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;nb     Ready    &amp;lt;none&amp;gt;          24s     v1.24.3
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;nm     Ready    control-plane   7m33s   v1.24.3
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;这里我不解的是，之前设置CNI前，core-dns的状态是pending，而且节点状态也是Not Ready。但是现在却看似一切正常。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;我们先使用简单的flannel做集群网络，注意不要忘记修改cidr为集群创建时指定的。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&amp;gt; kubectl get pods -A
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;NAMESPACE      NAME                         READY   STATUS    RESTARTS   AGE
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kube-flannel   kube-flannel-ds-5v2vn        1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          41s
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kube-flannel   kube-flannel-ds-bcgwm        1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          41s
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kube-flannel   kube-flannel-ds-ctt4v        1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          41s
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kube-system    coredns-74586cf9b6-vpdp5     1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          14m
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kube-system    coredns-74586cf9b6-zdfpw     1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          14m
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kube-system    etcd-nm                      1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          15m
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kube-system    kube-apiserver-nm            1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          15m
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kube-system    kube-controller-manager-nm   1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          15m
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kube-system    kube-proxy-6px66             1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          9m56s
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kube-system    kube-proxy-cc4fw             1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          8m6s
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kube-system    kube-proxy-gs9lq             1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          14m
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kube-system    kube-scheduler-nm            1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          15m
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;网络CNI也正常工作了。&lt;/p&gt;
&lt;p&gt;然后我们部署一个简单的微服务应用试试。&lt;/p&gt;
&lt;p&gt;看似一切正常，但是我发现集群网络出现问题，不能访问service的服务。而且通过&lt;code&gt;-o wide&lt;/code&gt;查看Pod发现他们并不在我所指定的CIDR网段，而是在一个奇怪的172网段。&lt;/p&gt;
&lt;p&gt;结合上面的，“还没有部署CNI节点和core-dns就Ready”这个奇怪的现象。我认为cri-dockerd的网络配置有问题。于是我又详细查看的参考资料，发现有一个配置和参考资料中的不一样。&lt;/p&gt;
&lt;p&gt;并且我们详细查看上面的cri-docker启动日志：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;INFO&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;0000&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Docker cri networking managed by network plugin kubernetes.io/no-op
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;cri-dockerd的网络是由&lt;code&gt;network plugin kubernetes.io/no-op&lt;/code&gt;管理的，这是个啥？&lt;/p&gt;
&lt;h3 id=&#34;cni&#34;&gt;CNI&lt;/h3&gt;
&lt;p&gt;所以，这里就不得不讨论下kubernetes1.24之后的另一个重大改变：&lt;strong&gt;在 Kubernetes 1.24 之前，CNI 插件也可以由 kubelet 使用命令行参数 &lt;code&gt;cni-bin-dir&lt;/code&gt; 和 &lt;code&gt;network-plugin&lt;/code&gt; 管理。Kubernetes 1.24 移除了这些命令行参数， CNI 的管理不再是 kubelet 的工作。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;也就是说，kubelet已经从管理CNI中得到了解放。谁来管理cni呢？&lt;/p&gt;
&lt;p&gt;容器运行时。&lt;/p&gt;
&lt;p&gt;又回到参考资料中对cri-dockerd的配置，是这样写的：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ExecStart&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;/usr/bin/cri-dockerd --network-plugin&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;cni --pod-infra-container-image&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;registry.aliyuncs.com/google_containers/pause:3.7
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;对&lt;code&gt;--network-plugin=cni&lt;/code&gt;进行了配置。上述cri-dockerd的启动参数中，有一句：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;--network-plugin string                   &amp;lt;Warning: Alpha feature&amp;gt; The name of the network plugin to be invoked &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; various events in kubelet/pod lifecycle.
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;于是我按照这个提示找到一篇解读kubelet配置cni的博文，Warning这句话正是原来在kubelet代码中的（见&lt;a class=&#34;link&#34; href=&#34;https://www.cnblogs.com/lianngkyle/p/15171630.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;kubernetes/k8s CNI分析-容器网络接口分析&lt;/a&gt;）。&lt;/p&gt;
&lt;p&gt;kubelet网络插件有下面三种类型：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;cni&lt;/li&gt;
&lt;li&gt;kubenet&lt;/li&gt;
&lt;li&gt;noop：不配置网络插件&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这样我们就明白了，在最初启动cri-dockerd的日志就表示我们并没有给cri-dockerd配置网络插件&lt;code&gt;INFO[0000] Docker cri networking managed by network plugin kubernetes.io/no-op&lt;/code&gt;，结合它的启动参数&lt;code&gt;--network-plugin&lt;/code&gt;，因此这个问题应该就是出于此。&lt;/p&gt;
&lt;h3 id=&#34;再次启动集群&#34;&gt;再次启动集群&lt;/h3&gt;
&lt;p&gt;我们先清除集群环境，包括flannel网络环境。&lt;/p&gt;
&lt;p&gt;在启动cri-dockerd的命令中加上网络插件参数。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&amp;gt; cri-dockerd --pod-infra-container-image&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;registry.aliyuncs.com/google_containers/pause:3.7 --network-plugin&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;cni
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;INFO&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;0000&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Connecting to docker on the Endpoint unix:///var/run/docker.sock 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;INFO&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;0000&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Start docker client with request timeout 0s  
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;INFO&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;0000&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Hairpin mode is set to none                  
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;INFO&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;0000&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Loaded network plugin cni                    
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;INFO&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;0000&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Docker cri networking managed by network plugin cni 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;INFO&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;0000&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Docker Info: &amp;amp;&lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;ID:HEPZ:PXCZ:XHZR:SKBX:TJL5:EG5L:U6P3:PI5A:PVZZ:ASKB:QJUC:QEDR Containers:16 ContainersRunning:12 ContainersPaused:0 ContainersStopped:4 Images:15 Driver:overlay2 DriverStatus:&lt;span style=&#34;color:#f92672&#34;&gt;[[&lt;/span&gt;Backing Filesystem extfs&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;Supports d_type true&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;Native Overlay Diff true&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;userxattr false&lt;span style=&#34;color:#f92672&#34;&gt;]]&lt;/span&gt; SystemStatus:&lt;span style=&#34;color:#f92672&#34;&gt;[]&lt;/span&gt; Plugins:&lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;Volume:&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;local&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Network:&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;bridge host ipvlan macvlan null overlay&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Authorization:&lt;span style=&#34;color:#f92672&#34;&gt;[]&lt;/span&gt; Log:&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog&lt;span style=&#34;color:#f92672&#34;&gt;]}&lt;/span&gt; MemoryLimit:true SwapLimit:true KernelMemory:false KernelMemoryTCP:false CPUCfsPeriod:true CPUCfsQuota:true CPUShares:true CPUSet:true PidsLimit:true IPv4Forwarding:true BridgeNfIptables:true BridgeNfIP6tables:true Debug:false NFd:89 OomKillDisable:false NGoroutines:83 SystemTime:2022-07-31T16:59:32.329402283+08:00 LoggingDriver:json-file CgroupDriver:systemd NEventsListener:0 KernelVersion:5.15.0-41-generic OperatingSystem:Ubuntu 22.04 LTS OSType:linux Architecture:x86_64 IndexServerAddress:https://index.docker.io/v1/ RegistryConfig:0xc000468a10 NCPU:4 MemTotal:8302116864 GenericResources:&lt;span style=&#34;color:#f92672&#34;&gt;[]&lt;/span&gt; DockerRootDir:/var/lib/docker HTTPProxy: HTTPSProxy: NoProxy: Name:nm Labels:&lt;span style=&#34;color:#f92672&#34;&gt;[]&lt;/span&gt; ExperimentalBuild:false ServerVersion:20.10.17 ClusterStore: ClusterAdvertise: Runtimes:map&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;io.containerd.runc.v2:&lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;Path:runc Args:&lt;span style=&#34;color:#f92672&#34;&gt;[]}&lt;/span&gt; io.containerd.runtime.v1.linux:&lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;Path:runc Args:&lt;span style=&#34;color:#f92672&#34;&gt;[]}&lt;/span&gt; runc:&lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;Path:runc Args:&lt;span style=&#34;color:#f92672&#34;&gt;[]}]&lt;/span&gt; DefaultRuntime:runc Swarm:&lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;NodeID: NodeAddr: LocalNodeState:inactive ControlAvailable:false Error: RemoteManagers:&lt;span style=&#34;color:#f92672&#34;&gt;[]&lt;/span&gt; Nodes:0 Managers:0 Cluster:&amp;lt;nil&amp;gt; Warnings:&lt;span style=&#34;color:#f92672&#34;&gt;[]}&lt;/span&gt; LiveRestoreEnabled:false Isolation: InitBinary:docker-init ContainerdCommit:&lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;ID:10c12954828e7c7c9b6e0ea9b0c02b01407d3ae1 Expected:10c12954828e7c7c9b6e0ea9b0c02b01407d3ae1&lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt; RuncCommit:&lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;ID:v1.1.2-0-ga916309 Expected:v1.1.2-0-ga916309&lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt; InitCommit:&lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;ID:de40ad0 Expected:de40ad0&lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt; SecurityOptions:&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;name&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;apparmor name&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;seccomp,profile&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;default name&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;cgroupns&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; ProductLicense: Warnings:&lt;span style=&#34;color:#f92672&#34;&gt;[]}&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;INFO&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;0000&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Setting cgroupDriver systemd                 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;INFO&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;0000&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Docker cri received runtime config &amp;amp;RuntimeConfig&lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;NetworkConfig:&amp;amp;NetworkConfig&lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;PodCidr:,&lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;,&lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;INFO&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;0000&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Starting the GRPC backend &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; the Docker CRI interface. 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;INFO&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;0000&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Start cri-dockerd grpc backend     
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;可以看到&lt;code&gt;INFO[0000] Loaded network plugin cni&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;在另一个终端里，初始化集群，并安装flannel插件。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&amp;gt; kubectl get pods -A
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;NAMESPACE     NAME                         READY   STATUS    RESTARTS   AGE
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kube-system   coredns-74586cf9b6-2p28x     0/1     Pending   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          46s
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kube-system   coredns-74586cf9b6-lkrn6     0/1     Pending   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          46s
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kube-system   etcd-nm                      1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          58s
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kube-system   kube-apiserver-nm            1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          58s
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kube-system   kube-controller-manager-nm   1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          59s
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kube-system   kube-proxy-qcgfk             1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          46s
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kube-system   kube-scheduler-nm            1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          58s
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&amp;gt; kubectl get node
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;NAME   STATUS     ROLES           AGE     VERSION
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;na     NotReady   &amp;lt;none&amp;gt;          10s     v1.24.3
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;nb     NotReady   &amp;lt;none&amp;gt;          13s     v1.24.3
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;nm     NotReady   control-plane   2m34s   v1.24.3
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&amp;gt; kubectl apply -f ../network/flannel.yaml 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;namespace/kube-flannel created
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;clusterrole.rbac.authorization.k8s.io/flannel created
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;clusterrolebinding.rbac.authorization.k8s.io/flannel created
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;serviceaccount/flannel created
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;configmap/kube-flannel-cfg created
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;daemonset.apps/kube-flannel-ds created
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&amp;gt; kubectl get pods -A
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;NAMESPACE      NAME                         READY   STATUS    RESTARTS   AGE
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kube-flannel   kube-flannel-ds-2rcs4        1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          19s
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kube-flannel   kube-flannel-ds-9szxg        1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          19s
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kube-flannel   kube-flannel-ds-cxw5k        1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          19s
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kube-system    coredns-74586cf9b6-2p28x     1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          3m22s
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kube-system    coredns-74586cf9b6-lkrn6     1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          3m22s
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kube-system    etcd-nm                      1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          3m34s
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kube-system    kube-apiserver-nm            1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          3m34s
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kube-system    kube-controller-manager-nm   1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          3m35s
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kube-system    kube-proxy-7lsdq             1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          77s
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kube-system    kube-proxy-fb96h             1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          74s
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kube-system    kube-proxy-qcgfk             1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          3m22s
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kube-system    kube-scheduler-nm            1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          3m34s
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&amp;gt; kubectl get node
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;NAME   STATUS   ROLES           AGE     VERSION
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;na     Ready    &amp;lt;none&amp;gt;          76s     v1.24.3
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;nb     Ready    &amp;lt;none&amp;gt;          79s     v1.24.3
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;nm     Ready    control-plane   3m40s   v1.24.3
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;安装flannel前，core-dns为pending、节点为NotReady。安装后正常，这是符合预期的。&lt;/p&gt;
&lt;p&gt;并且cri-dockerd中也打印了cni的信息：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;INFO&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;3090&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Using CNI configuration file /etc/cni/net.d/10-flannel.conflist 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;INFO&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;3095&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Using CNI configuration file /etc/cni/net.d/10-flannel.conflist
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;再次部署用于测试的服务，一切正常：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&amp;gt; kubectl get pods -o wide -n cinema
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;NAME                            READY   STATUS    RESTARTS   AGE   IP         NODE   NOMINATED NODE   READINESS GATES
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;bookings-78c77d68f9-j5jzf       1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          17s   10.5.2.2   na     &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;mongo-deploy-57dc8c8f49-n6psq   1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          17s   10.5.1.6   nb     &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;movies-6fbc5986b9-vs6j8         1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          17s   10.5.2.3   na     &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;showtimes-56fc847b7-4bq87       1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          17s   10.5.1.4   nb     &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;users-6996b995d4-5l5tq          1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          17s   10.5.2.4   na     &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;website-867ff4b9dd-5zz49        1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          17s   10.5.1.5   nb     &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&amp;gt; kubectl get svc -o wide -n cinema
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;NAME          TYPE        CLUSTER-IP      EXTERNAL-IP   PORT&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;S&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;          AGE   SELECTOR
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;bookings      ClusterIP   10.110.129.6    &amp;lt;none&amp;gt;        8080/TCP         27s   app&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;bookings
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;mongodb-svc   ClusterIP   10.103.92.132   &amp;lt;none&amp;gt;        27017/TCP        27s   app&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;mongodb
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;movies        ClusterIP   10.103.102.97   &amp;lt;none&amp;gt;        8080/TCP         27s   app&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;movies
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;showtimes     ClusterIP   10.96.139.99    &amp;lt;none&amp;gt;        8080/TCP         27s   app&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;showtimes
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;users         ClusterIP   10.106.152.98   &amp;lt;none&amp;gt;        8080/TCP         27s   app&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;users
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;website       NodePort    10.96.103.3     &amp;lt;none&amp;gt;        8080:30021/TCP   27s   app&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;website
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/202207311754304.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220731175441143&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;到这里，1.24.0版本的集群就正常部署Pod并提供服务了。&lt;/p&gt;
&lt;h2 id=&#34;一些问题&#34;&gt;一些问题&lt;/h2&gt;
&lt;h3 id=&#34;cri-dockerd报错&#34;&gt;cri-dockerd报错&lt;/h3&gt;
&lt;p&gt;虽然目前功能上看来没啥问题，但是cri-dockerd一直打印错误信息：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ERRO&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;3404&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; ContainerStats resp: &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;0xc0003c8900 linux&lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;    
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ERRO&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;3404&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; ContainerStats resp: &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;0xc0005dcb00 linux&lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;    
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ERRO&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;3404&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; ContainerStats resp: &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;0xc0003c9c40 linux&lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;    
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ERRO&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;3404&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; ContainerStats resp: &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;0xc0005dd700 linux&lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;    
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ERRO&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;3404&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; ContainerStats resp: &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;0xc0007be540 linux&lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;我尝试在当前版本的源码中需要这句日志的输出位置，结果没有发现。然后在社区中提了&lt;a class=&#34;link&#34; href=&#34;https://github.com/Mirantis/cri-dockerd/issues/98&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;这个issue&lt;/a&gt;。这个问题和社区中&lt;a class=&#34;link&#34; href=&#34;https://github.com/Mirantis/cri-dockerd/issues/85&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Lots of obscure error logging #85&lt;/a&gt;问题大概是一样的，可能是一些测试中的遗留，被误合并到主分支上去了。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/image-20220801181830962.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220801181830962&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;好在容器运行时的功能貌似没有受影响。&lt;/p&gt;
&lt;h3 id=&#34;cri-dockerd常驻一个终端&#34;&gt;cri-dockerd常驻一个终端&lt;/h3&gt;
&lt;p&gt;这种方法在安装cri-dockerd时将其视为一个软件，必须手动启动它，才可以让它监听socket实现和k8s以及docker的通信。博文&lt;a class=&#34;link&#34; href=&#34;https://www.modb.pro/db/428370&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;基于docker和cri-dockerd部署Kubernetes 1.24&lt;/a&gt;中则是使用了另一种方法，并且为我本次的测试提供了很大的帮助。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;当然也可以按照cri-dockerd的文档，手动编译、部署。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;在博文&lt;a class=&#34;link&#34; href=&#34;https://www.modb.pro/db/428370&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;基于docker和cri-dockerd部署Kubernetes 1.24&lt;/a&gt;中，作者的思路与&lt;a class=&#34;link&#34; href=&#34;https://github.com/Mirantis/cri-dockerd&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;官方的安装思路&lt;/a&gt;思路是一样的，即，创建一个可以被systemctl管理的service和socket对。让cri-dockerd在后台启动，不用显式启动并占用一个终端。&lt;/p&gt;
&lt;p&gt;其中，关键部分如下。&lt;/p&gt;
&lt;p&gt;首先，出于系统通用性，使用&lt;a class=&#34;link&#34; href=&#34;https://github.com/Mirantis/cri-dockerd/releases&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;cri-dockerd的release&lt;/a&gt;中的&lt;code&gt;.amd64.tgz&lt;/code&gt;版本。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/image-20220730234545013.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220730234545013&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;将文件解压，并将里面的可执行文件移动到&lt;code&gt;/usr/bin/&lt;/code&gt;下面。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&amp;gt; tar -xf cri-dockerd-0.2.3.amd64.tgz 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&amp;gt; cp cri-dockerd/cri-dockerd /usr/bin/
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&amp;gt; chmod +x /usr/bin/cri-dockerd 
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;然后很重要的一步，配置cri-dockerd的启动文件。在&lt;code&gt;/usr/lib/systemd/system/cri-docker.service&lt;/code&gt;中写入以下内容：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;Unit&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Description&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;CRI Interface &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; Docker Application Container Engine
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Documentation&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;https://docs.mirantis.com
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;After&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;network-online.target firewalld.service docker.service
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Wants&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;network-online.target
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Requires&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;cri-docker.socket
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;Service&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Type&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;notify
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ExecStart&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;/usr/bin/cri-dockerd --network-plugin&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;cni --pod-infra-container-image&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;registry.aliyuncs.com/google_containers/pause:3.7
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ExecReload&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;/bin/kill -s HUP $MAINPID
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;TimeoutSec&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;RestartSec&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Restart&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;always
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;StartLimitBurst&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;StartLimitInterval&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;60s
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;LimitNOFILE&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;infinity
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;LimitNPROC&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;infinity
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;LimitCORE&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;infinity
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;TasksMax&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;infinity
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Delegate&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;yes
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;KillMode&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;process
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;Install&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;WantedBy&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;multi-user.target
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;在&lt;code&gt;/usr/lib/systemd/system/cri-docker.socket&lt;/code&gt;写入下面内容：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;Unit&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Description&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;CRI Docker Socket &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; the API
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;PartOf&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;cri-docker.service
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;Socket&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ListenStream&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;%t/cri-dockerd.sock
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;SocketMode&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0660&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;SocketUser&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;root
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;SocketGroup&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;docker
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;Install&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;WantedBy&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;sockets.target
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;关于这两个配置文件，可以参考&lt;a class=&#34;link&#34; href=&#34;https://www.cnblogs.com/ggzhangxiaochao/p/15039617.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Linux配置service服务&lt;/a&gt;，&lt;a class=&#34;link&#34; href=&#34;http://www.jinbuguo.com/systemd/systemd.socket.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;systemd.socket 中文手册&lt;/a&gt;，这篇文章。&lt;/p&gt;
&lt;p&gt;然后我们启动这个服务，这样cri-dockerd实际上就有我们刚才创建的名叫cri-docker的service所管理：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code class=&#34;language-she&#34; data-lang=&#34;she&#34;&gt;systemctl daemon-reload
systemctl start cri-docker
systemctl enable cri-docker
systemctl status cri-docker
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这样一来，在每次启动集群前，就不要手动的配置运行cri-dockerd，systemd就帮我们完成这些操作了。&lt;/p&gt;
&lt;h2 id=&#34;参考资料&#34;&gt;参考资料&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.modb.pro/db/428370&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;基于docker和cri-dockerd部署Kubernetes 1.24&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.qikqiak.com/post/containerd-usage/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;一文搞懂容器运行时 Containerd&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://opencontainers.org/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Open Container Initiative&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://kubernetes.io/zh-cn/docs/tasks/administer-cluster/migrating-from-dockershim/migrate-dockershim-dockerd/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;将 Docker Engine 节点从 dockershim 迁移到 cri-dockerd&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://kubernetes.io/zh-cn/blog/2022/02/17/dockershim-faq/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;更新：移除 Dockershim 的常见问题&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://kubernetes.io/zh-cn/docs/tasks/administer-cluster/migrating-from-dockershim/check-if-dockershim-removal-affects-you/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;检查移除 Dockershim 是否对你有影响&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://kubernetes.io/zh-cn/docs/tasks/administer-cluster/migrating-from-dockershim/troubleshooting-cni-plugin-related-errors/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;排查 CNI 插件相关的错误&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://kubernetes.io/zh-cn/docs/setup/production-environment/container-runtimes/#cri-versions&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;容器运行时&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://kubernetes.io/zh-cn/docs/concepts/extend-kubernetes/compute-storage-net/network-plugins/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;网络插件&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/kubernetes-sigs&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;kubernetes-sigs&lt;/a&gt;/&lt;strong&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/kubernetes-sigs/cri-tools&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;cri-tools&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/Mirantis&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Mirantis&lt;/a&gt;/&lt;strong&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/Mirantis/cri-dockerd&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;cri-dockerd&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://blog.51cto.com/liuzhengwei521/2382257&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;k8s卸载flannel网络&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.cnblogs.com/lianngkyle/p/15171630.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;kubernetes/k8s CNI分析-容器网络接口分析&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.cnblogs.com/ggzhangxiaochao/p/15039617.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Linux配置service服务&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Sinan: ML-Based and QoS-Aware Resource Management for Cloud Microservices</title>
        <link>https://lizonglingo.github.io/p/sinan-ml-based-and-qos-aware-resource-management-for-cloud-microservices/</link>
        <pubDate>Sun, 26 Jun 2022 15:00:34 +0800</pubDate>
        
        <guid>https://lizonglingo.github.io/p/sinan-ml-based-and-qos-aware-resource-management-for-cloud-microservices/</guid>
        <description>&lt;blockquote&gt;
&lt;p&gt;来源：ASPLOS&#39;21  ccf-a&lt;/p&gt;
&lt;p&gt;作者：Cornell University&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;正如题目所说，这篇文章主要就是使用&lt;strong&gt;机器学习&lt;/strong&gt;的方法，针对&lt;strong&gt;微服务架构&lt;/strong&gt;的应用进行&lt;strong&gt;资源配置&lt;/strong&gt;，当然是&lt;strong&gt;保证QoS的前提&lt;/strong&gt;下提高资源分配和使用的效率。&lt;/li&gt;
&lt;li&gt;利用ML方法帮助调度的决策&lt;/li&gt;
&lt;li&gt;面向以容器和虚拟机构建及部署的微服务应用&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;问题的痛点是什么或是要解决什么问题他们的idea有什么值得学习的地方&#34;&gt;问题的痛点是什么？或是要解决什么问题？他们的idea有什么值得学习的地方？&lt;/h2&gt;
&lt;h3 id=&#34;先前的工作&#34;&gt;先前的工作&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;为满足QoS而忽视资源利用率，往往有较高的资源分配上限，把边界划定的很远，虽然是为了更好的满足QoS要求但是牺牲了资源&lt;/li&gt;
&lt;li&gt;针对单体系统而没有考虑微服务架构的特点&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;本文idea&#34;&gt;本文idea&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;突出QoS、E2E时延&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;资源分配突出了一个满足QoS要求，并且多次提到OOM错误&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;考虑到微服务架构的层级结构(tier)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;考虑到微服务架构的拓扑图，也就是微服务之间的依赖关系&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;提到了微服务中某些排队队列的环节会因为QoS违规导致更长时间的排队等候，进而提出了需要一个较长时间的预测&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;具体是什么云环境应用以什么样的方式部署&#34;&gt;具体是什么云环境？应用以什么样的方式部署？&lt;/h2&gt;
&lt;p&gt;Docker + VM组成的云环境。应用以被打包成Docker镜像然后部署在虚拟机上。&lt;/p&gt;
&lt;h2 id=&#34;使用了什么机器学习方法这个学习解决的是什么问题&#34;&gt;使用了什么机器学习方法？这个学习解决的是什么问题？&lt;/h2&gt;
&lt;p&gt;文章提出了一个“two-stage model”。第一阶段，使用CNN预测下一个时间步的E2E时延，这对精确性提出了很高的要求；第二阶段，使用Boosted Trees预测QoS违规（需要使用CNN模型的输出）。&lt;/p&gt;
&lt;p&gt;第一阶段和第二阶段分别代表了短期和长期的预测结果，以辅助调度的决策。&lt;/p&gt;
&lt;h3 id=&#34;cnn卷积神经网络&#34;&gt;CNN卷积神经网络&lt;/h3&gt;
&lt;p&gt;CNN模型主要用于短期的性能预测。&lt;/p&gt;
&lt;p&gt;具体来说，使用CNN来预测下一个时间窗口的时延分布，是秒级的窗口(默认是5秒)。但是文章发现，预测时延是件很困难的事情，并且随着预测时间的增加，效果不理想。&lt;/p&gt;
&lt;p&gt;因此进一步的，文章将预测策略变为：预测是否出现QoS违规，也就是随后的时间段出现QoS违规的概率。（因为通常将QoS与E2E时延划等号，出现QoS违规相当于E2E时延过长，所以QoS违规给调度决策带来的信息是足够的）&lt;/p&gt;
&lt;h4 id=&#34;模型使用到的输入数据&#34;&gt;模型使用到的输入数据&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;CPU使用信息&lt;/li&gt;
&lt;li&gt;内存使用信息（包括常驻内存和缓存）&lt;/li&gt;
&lt;li&gt;网络使用信息（如接收和发送的数据包）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这些都是用Docker cgroup的接口收集。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;上一个窗口E2E时延的分布&lt;/li&gt;
&lt;li&gt;能够在下一个时间窗口分配的资源信息&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;模型的预测输出&#34;&gt;模型的预测输出&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;下一个时间窗口的时延信息，该信息会进一步用于Boosted Tree中&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;boosted-tree&#34;&gt;Boosted Tree&lt;/h3&gt;
&lt;p&gt;增长树模型主要用于长期的性能预测。具体来说，进行一个二分类问题的预测——接下来的资源分配是否会造成QoS违规，通过这个预测来减少未来预期之外的负面影响。&lt;/p&gt;
&lt;h4 id=&#34;模型使用到的输入数据-1&#34;&gt;模型使用到的输入数据&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;使用到CNN中的预测输出的时延信息&lt;/li&gt;
&lt;li&gt;资源分配信息&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;模型的预测输出-1&#34;&gt;模型的预测输出&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;在接下来时间步k中，是否会出现QoS违规现象&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;系统架构是什么样的如何分配资源&#34;&gt;系统架构是什么样的？如何分配资源？&lt;/h2&gt;
&lt;h3 id=&#34;系统架构&#34;&gt;系统架构&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/202206261434874.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220626143414765&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;中心化的调度器&lt;/li&gt;
&lt;li&gt;分布式的节点代理&lt;/li&gt;
&lt;li&gt;单独部署的预测服务&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;系统流程如上图。&lt;/p&gt;
&lt;h3 id=&#34;资源分配&#34;&gt;资源分配&lt;/h3&gt;
&lt;p&gt;系统中资源分配的几种动作如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/202206261443689.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220626144302597&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;评估怎么做的使用了什么应用&#34;&gt;评估怎么做的？使用了什么应用？&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;在本地集群和Google Cloud上面做的实验&lt;/li&gt;
&lt;li&gt;使用了微服务benchmark套件&lt;strong&gt;DeathStarBench&lt;/strong&gt;(有论文的这个套件)以及其中的应用Hotel Reservation，Social Network。&lt;/li&gt;
&lt;li&gt;使用Docker Swarm进行部署&lt;/li&gt;
&lt;li&gt;收集了31302和58499条Hotel和Social Network的数据&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;实验环境&#34;&gt;实验环境&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;本地集群：80core CPU/256GB RAM&lt;/li&gt;
&lt;li&gt;GCE集群：93containers&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;微服务应用&#34;&gt;微服务应用&lt;/h3&gt;
&lt;h4 id=&#34;hotel-reservation&#34;&gt;Hotel Reservation&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/202206242159386.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220624215932271&#34;
	
	
&gt;&lt;/p&gt;
&lt;h4 id=&#34;social-network&#34;&gt;Social Network&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/202206242159015.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220624215947934&#34;
	
	
&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;做实验时可以参考本文实验设计&lt;/p&gt;
&lt;/blockquote&gt;
</description>
        </item>
        <item>
        <title>Cocktail: A Multidimensional Optimization for Model Serving in Cloud</title>
        <link>https://lizonglingo.github.io/p/cocktail-a-multidimensional-optimization-for-model-serving-in-cloud/</link>
        <pubDate>Sun, 15 May 2022 21:07:08 +0800</pubDate>
        
        <guid>https://lizonglingo.github.io/p/cocktail-a-multidimensional-optimization-for-model-serving-in-cloud/</guid>
        <description>&lt;blockquote&gt;
&lt;p&gt;来源：&lt;a class=&#34;link&#34; href=&#34;https://www.usenix.org/conference/nsdi22/presentation/gunasekaran&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;NSDI&#39;22&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;推荐阅读！&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;摘要&#34;&gt;摘要&lt;/h2&gt;
&lt;h3 id=&#34;背景&#34;&gt;背景&lt;/h3&gt;
&lt;p&gt;越来越多的ML模型运行在公有云环境下。&lt;strong&gt;为这些模型服务的框架能够以最小的延迟提供高度准确的预测，并降低部署成本，这一点至关重要。&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;关键点&#34;&gt;关键点&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;模型集成可以通过智能地将不同模型并行组合来解决精度差距问题。然而，在运行时动态地选择合适的模型，以以最小的部署成本、低延迟来满足预期的准确性。&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;本文工作&#34;&gt;本文工作&lt;/h3&gt;
&lt;p&gt;提出&lt;em&gt;&lt;strong&gt;Cocktail&lt;/strong&gt;&lt;/em&gt;，基于模型集成的成本效益模型服务框架。包含两个关键的组件：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一个&lt;strong&gt;动态模型选择框架&lt;/strong&gt;，在满足&lt;strong&gt;精度和延迟&lt;/strong&gt;要求的同时，&lt;strong&gt;减少了集成中的模型数量&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;一个采用&lt;strong&gt;分布式主动自动伸缩策略的自适应资源管理&lt;/strong&gt;（RM，Resource Management）框架，有效地为模型分配资源。RM框架利用瞬态虚拟机实例来降低公共云中的部署成本&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;同时在AWS EC2实例中实现了一个原型系统，演示了使用各种工作负载的详尽评估。结果显示Cocktail减少了部署花费1.45x，与最先进的模型服务框架相比，减少了2x延迟，并满足高达96%的请求的目标精度。&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;h3 id=&#34;背景及问题引出&#34;&gt;背景及问题引出&lt;/h3&gt;
&lt;p&gt;背景案例：Facebook为用户交互应用程序提供了数万亿的推理请求，如对新提要进行排名，对照片进行分类等。这些应用程序必须在&lt;strong&gt;亚毫秒延迟&lt;/strong&gt;[27、34、35、39、44、83]提供准确的预测，因为它们严重影响用户体验。&lt;/p&gt;
&lt;p&gt;随着许多应用使用ML技术增强其用户体验，这种趋势正在扩大。&lt;/p&gt;
&lt;p&gt;通常这种模型服务运行在云平台上，如一些&lt;em&gt;model-serving&lt;/em&gt;框架[6, 28, 60]。&lt;/p&gt;
&lt;h3 id=&#34;挑战&#34;&gt;挑战&lt;/h3&gt;
&lt;p&gt;由于训练数据以及计算和内存资源紧张[59,65,84]造成的高方差一直是设计高精度和低延迟模型的主要障碍&lt;/p&gt;
&lt;p&gt;不同于单模型推理任务，&lt;code&gt;ensemble learning&lt;/code&gt;集成学习可以进一步提高服务精确度。（如，多模型的图片分类任务会提高最终的精确度）&lt;/p&gt;
&lt;p&gt;然而，对于集成，由于&lt;strong&gt;每个请求都需要运行大量的模型[27,56]而导致的非常高的资源占用，加剧了公共云的部署成本，并导致延迟的高度变化&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;因此，本文解决的主要问题为：&lt;/p&gt;
&lt;p&gt;:star:集成单一的模型推理服务；&lt;/p&gt;
&lt;p&gt;:star:同时提高模型服务的准确度；&lt;/p&gt;
&lt;p&gt;:star:并最小化部署成本。&lt;/p&gt;
&lt;h3 id=&#34;现有技术的不足&#34;&gt;现有技术的不足&lt;/h3&gt;
&lt;p&gt;对最先进的集成模型服务框架进行分析，存在如下不足：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在像Clipper[27]这样的框架中使用的&lt;strong&gt;集成模型选择策略是静态的，因为它们集成了所有可用的模型，并只专注于最小化准确性损失。这将导致更高的延迟，并进一步扩大资源使用&lt;/strong&gt;，从而加重部署成本。&lt;/li&gt;
&lt;li&gt;现有的集合权重估计[87]&lt;strong&gt;计算复杂度高&lt;/strong&gt;，在实践中仅限于一小部分现成模型。这导致&lt;strong&gt;精度损失严重&lt;/strong&gt;。此外，采用线性集成技术(如模型平均)计算量大[80]，且对大量可用模型&lt;strong&gt;不可伸缩，缺少弹性&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;现有的集成系统&lt;strong&gt;不关注公共云基础设施中的模型部署&lt;/strong&gt;，没有注意到部署成本和延迟。&lt;/li&gt;
&lt;li&gt;对单一模型的&lt;strong&gt;资源管理模采用的策略不能直接扩展到集成系统中&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;因此，重复之前亟待解决的问题：&lt;/p&gt;
&lt;p&gt;:warning:&lt;strong&gt;如何解决集成框架的成本、精度和延迟等复杂优化问题？&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;本文工作-1&#34;&gt;本文工作&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Cocktail&lt;/strong&gt;&lt;/em&gt;，首个&lt;strong&gt;成本友好&lt;/strong&gt;、&lt;strong&gt;集成多模型&lt;/strong&gt;的ML服务框架，&lt;strong&gt;针对于分类推理任务&lt;/strong&gt;，有很好的&lt;strong&gt;精确度和低延迟&lt;/strong&gt;表现。&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;它使用下面三方面解决框架优化问题：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;提出了一种动态模型选择策略，在满足延迟和精度要求的同时，显著减少了集成中使用的模型数量；&lt;/li&gt;
&lt;li&gt;利用分布式自动伸缩策略来减少托管集成模型的延迟可变性和资源消耗；&lt;/li&gt;
&lt;li&gt;利用transient VMs技术减少了推理服务部署成本（比传统的虚拟机减少79%-90%的成本）。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;contributions&#34;&gt;Contributions&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;通过&lt;strong&gt;描述集成模型的精度与延迟&lt;/strong&gt;，我们发现在给定的延迟下&lt;strong&gt;谨慎地选择可用模型的子集可以达到目标精度&lt;/strong&gt;。在&lt;em&gt;&lt;strong&gt;Cocktail&lt;/strong&gt;&lt;/em&gt;中利用这一点，&lt;strong&gt;设计了一种新颖的动态模型选择策略，在保证准确性的同时大大减少了模型的数量&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;关注基于分类的推理&lt;/strong&gt;，&lt;strong&gt;最小化来自多个模型的预测偏差&lt;/strong&gt;。&lt;em&gt;&lt;strong&gt;Cocktail&lt;/strong&gt;&lt;/em&gt;采用了一个pre-class加权多数投票政策，这使得它具有&lt;strong&gt;可扩展性&lt;/strong&gt;，与传统加权平均相比，有效地打破了不同模型之间的联系，从而最大限度地提高了准确性。&lt;/li&gt;
&lt;li&gt;集成模型资源需求的变动会导致资源的过度供应，为了最小化资源，我们构建了一个&lt;strong&gt;分布式的加权自动伸缩策略&lt;/strong&gt;，该策略利用重要&lt;strong&gt;抽样技术主动地为每个模型分配资源&lt;/strong&gt;。&lt;em&gt;&lt;strong&gt;Cocktail&lt;/strong&gt;&lt;/em&gt;使用transient VMs降低模型在云平台上部署的成本。&lt;/li&gt;
&lt;li&gt;使用AWS EC2的CPU和GPU实例，实现了原型系统&lt;em&gt;&lt;strong&gt;Cocktail&lt;/strong&gt;&lt;/em&gt;并对不同的请求进行了评估。与最先进的模型服务系统相比，部署成本降低1.4x，精确度提升至96%，延迟减少2x。&lt;/li&gt;
&lt;li&gt;同时表明，集成模型的&lt;em&gt;&lt;strong&gt;Cocktail&lt;/strong&gt;&lt;/em&gt;，&lt;em&gt;&lt;strong&gt;Cocktail&lt;/strong&gt;&lt;/em&gt;可以通过将准确度损失限制在0.6%以内来适应实例故障，对故障容忍性有较大提升。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;background-and-motivation&#34;&gt;Background and Motivation&lt;/h2&gt;
&lt;p&gt;本章结构如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;分析现有公有云中的集成模型服务；&lt;/li&gt;
&lt;li&gt;指出这些服务存在的问题；&lt;/li&gt;
&lt;li&gt;表明&lt;em&gt;&lt;strong&gt;Cocktail&lt;/strong&gt;&lt;/em&gt;基于以上问题需要做的改进。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;model-serving-in-public-cloud&#34;&gt;Model Serving in Public Cloud&lt;/h3&gt;
&lt;p&gt;现有公有云模型服务架构如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/image-20220515153406902.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220515153406902&#34;
	
	
&gt;&lt;/p&gt;
&lt;h4 id=&#34;application层&#34;&gt;Application层&lt;/h4&gt;
&lt;p&gt;关注SLO，本文指End2End的响应时间。如Ads服务在100ms、推荐服务可以容忍1000ms。&lt;/p&gt;
&lt;h4 id=&#34;model-层和-framework-层&#34;&gt;Model 层和 Framework 层&lt;/h4&gt;
&lt;p&gt;部署的如TensorFlow、PyTorch框架。以及提供的不同模型（这里以分类模型为例）：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/image-20220515153920197.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220515153920197&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;根据应用程序类型，最大的模型集成尺寸可以从数十到数百个模型不等。&lt;/p&gt;
&lt;h4 id=&#34;cloud-层&#34;&gt;Cloud 层&lt;/h4&gt;
&lt;p&gt;以VMs或者Container提供资源隔离和运行环境，基于异构的CPU、GPU实例。&lt;/p&gt;
&lt;p&gt;其中，&lt;strong&gt;瞬态实例&lt;/strong&gt;[69]与传统的VM类似，但可以由云提供商在任何时间通过中断通知撤销。这些资源的供应延迟、实例持久性和模型打包花费直接影响到托管模型服务的延迟和成本。&lt;/p&gt;
&lt;p&gt;本文&lt;strong&gt;从模型选择的角度关注于提高准确性和延迟，并从成本的角度考虑实例类型&lt;/strong&gt;。&lt;/p&gt;
&lt;h3 id=&#34;related-work&#34;&gt;Related Work&lt;/h3&gt;
&lt;p&gt;下图为本文工作和先前相关工作的对比：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/image-20220515172130602.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220515172130602&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;:one:现有的集成模型案例：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Azure ML-studio：最初集成了5个模型，现在逐渐扩展到200个模型。&lt;/li&gt;
&lt;li&gt;AWS Autogluon：集成了6-12个模型。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;用户可以手动选择模型数量规模。&lt;/p&gt;
&lt;p&gt;与它们不同的是，&lt;em&gt;&lt;strong&gt;Cocktail&lt;/strong&gt;&lt;/em&gt;的模型选择策略试图在给定延迟的情况下选择合适的集合大小，同时最大化准确性。&lt;/p&gt;
&lt;p&gt;:two:云上模型服务：&lt;/p&gt;
&lt;p&gt;InFaas、Clipper 、FrugalML、MArk 、Rafiki、 TF-Serving、 SageMaker、AzureML 、Deep-Studio等。&lt;/p&gt;
&lt;p&gt;:three:公有云自动缩放：&lt;/p&gt;
&lt;p&gt;现有相关的资源配置策略能分为两类：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;多路复用不同的实例类型；&lt;/li&gt;
&lt;li&gt;基于预测策略的主动资源发放。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Cocktail&lt;/strong&gt;&lt;/em&gt;使用了类似的负荷预测模型，并在模型集合方面以分布式的方式使用自动缩放虚拟机。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Cocktail&lt;/strong&gt;&lt;/em&gt;的自动缩放策略与Swayam[34]的分布式自动缩放策略有相似之处；然而，我们进一步引入了新颖的&lt;strong&gt;重要采样技术&lt;/strong&gt;，以减少未充分利用的模型的过度供应&lt;/p&gt;
&lt;h2 id=&#34;引出cocktail&#34;&gt;引出Cocktail&lt;/h2&gt;
&lt;p&gt;首先回答两个问题：&lt;/p&gt;
&lt;p&gt;:one:如何减少资源占用:question:&lt;/p&gt;
&lt;p&gt;通过最小化模型集成数量，减少资源使用。文章通过实验，选取精度前50%的模型进行集成。&lt;/p&gt;
&lt;p&gt;完全集成的模型选择是一种过度的行为，而静态集成则会导致精度的损失。这就需要一个动态的模型选择策略，该策略可以根据模型选择策略的准确性和可伸缩性准确地确定所需的模型数量。&lt;/p&gt;
&lt;p&gt;:two:如何减少部署成本:question:&lt;/p&gt;
&lt;p&gt;大多数云提供商提供瞬态虚拟机，如Amazon Spot实例[69]、谷歌preemptible VMs[9]和Azure Low-priority VMs[7]，可以降低高达10倍的云计算成本。文章**利用这些瞬态VMs(如spot实例)**来大幅降低部署集成模型框架的成本。&lt;/p&gt;
&lt;h2 id=&#34;cocktail整体设计&#34;&gt;Cocktail整体设计&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Cocktail&lt;/strong&gt;&lt;/em&gt;架构如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/image-20220515175157818.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220515175157818&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Master VM：运行了模型选择算法；1a）来决定将哪些模型集成；1b）被选中的模型加载到缓存中，在相同请求到来时加快响应速度。&lt;/li&gt;
&lt;li&gt;Queries：各个请求分派到不同的实例池。&lt;/li&gt;
&lt;li&gt;Aggregator：用来处理集成模型的返回结果，使用加权多数投票聚合器返回正确的预测。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;为了有效地解决资源管理和可伸缩性的挑战，&lt;em&gt;&lt;strong&gt;Cocktail&lt;/strong&gt;&lt;/em&gt;应用多种策略。它维护专用的实例池服务于各个模型，这简化了每个模型的管理和负载平衡开销。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Resource Controller：主要管理实例的增减，通过 4a）4b）基于CPU和GPU的开销进行实例数量的管理。&lt;/li&gt;
&lt;li&gt;Load Balancer：将Queries分配给适当的实例，并确保所有获取的实例都被打包到VM中。&lt;/li&gt;
&lt;li&gt;Autoscaler：利用 6a）预测策略为实例池中的实例预测请求负载，确保资源不会被过度配置；同时使用 6b）重要性抽样算法，通过计算每个模型池在给定时间间隔内所服务的请求的百分比来估计每个模型的重要性。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;动态模型选择策略&#34;&gt;动态模型选择策略&lt;/h3&gt;
&lt;h4 id=&#34;目标函数&#34;&gt;目标函数&lt;/h4&gt;
&lt;p&gt;本文使用一个基于窗口的动态模型选择策略，使用下面描述的两个&lt;strong&gt;目标函数&lt;/strong&gt;：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/image-20220515195954517.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;目标时减小延迟和花费并最大化准确率。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\mu_{AL}$： latency-accuracy metric&lt;/li&gt;
&lt;li&gt;$\mu_c$：cost metric&lt;/li&gt;
&lt;li&gt;$Acc_{target}$：目标准确度&lt;/li&gt;
&lt;li&gt;$Lat_{target}$：目标延迟&lt;/li&gt;
&lt;li&gt;$N$：参与集成的模型数量&lt;/li&gt;
&lt;li&gt;$inst_cost$： VM实例的花费&lt;/li&gt;
&lt;li&gt;$m$：指每个模型&lt;/li&gt;
&lt;li&gt;$P_{f_m}$：在单个实例中可以并发执行而不违反延迟指标的推理数量，越大越好&lt;/li&gt;
&lt;li&gt;$k$：常量，取决于VM的性能配置&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;第一个目标函数&lt;/strong&gt;$O_1$就是满足$Acc_{target}$和$Lat_{target}$时最大化$\mu_{AL}$。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/image-20220515200819258.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220515200819258&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;为此，初始模型列表在满足$Lat_{target}$的模型中选择，并尝试集成使其满足$Acc_{target}$。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Cocktail&lt;/strong&gt;&lt;/em&gt;会将每个模型的准确性作为正确概率，然后迭代地构建一个模型列表，其中它们执行分类的联合概率在准确性目标内。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$Acc_{margin}$：为0.2%&lt;/li&gt;
&lt;li&gt;$Lat_{margin}$：为5ms&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;第二个目标函数&lt;/strong&gt;$O_2$是最小化$\mu_c$。&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;该目标调整模型清单的大小，并进一步调整资源采购。因此最大化$P_{f_m}$，最小化$k$。&lt;/p&gt;
&lt;p&gt;对于$N$个模型，每个模型都有一个最小精度，因此选取最小精度前50%的模型，数量为${N\over2} + 1$。来保证集成模型达到预期精度。结果正确率如下：&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;h4 id=&#34;模型选择和加权多数投票策略&#34;&gt;模型选择和加权多数投票策略&lt;/h4&gt;
&lt;p&gt;为最小化$\mu_c$，设计了一个模型数量缩减策略，只要有超过${N\over2}+1$的模型选择同一种结果，如下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/image-20220515205825292.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220515205825292&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;资源管理&#34;&gt;资源管理&lt;/h3&gt;
&lt;h4 id=&#34;资源控制器-resource-controller&#34;&gt;资源控制器 Resource Controller&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Resource Types： CPU和GPU实例。GPU实例在&lt;strong&gt;打包大量请求&lt;/strong&gt;执行时是划算的。文章提出自适应打包策略，考虑每个实例的$P_f$ 以及在时间$T$到来的请求数量。只有工作负载匹配$P_f$时，才会将负载分发到对应实例。&lt;/li&gt;
&lt;li&gt;Cost-aware Procurement： 在一个完全封装的实例中执行请求的成本决定了每个实例的开销。在扩展实例之前，需要估计将它们与现有实例一起运行的成本。在时间$T$时，基于预测负载$L_p$和运行实例$R_N$，使用&lt;em&gt;cost-aware greedy&lt;/em&gt;策略来决定要增加的实例数量。&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;Load  Balancer： 在每个模型池中维护一个请求队列，为增加实例池中实例的利用率，负载均衡器将来自队列的每个请求提交到剩余空闲槽位（free slots）。文章使用预期超时10分钟的间隔，来回收实例池中没有被使用的实例。贪婪地分配请求可以使负载较轻的实例更早地伸缩。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;自动伸缩器-autoscaler&#34;&gt;自动伸缩器 Autoscaler&lt;/h4&gt;
&lt;p&gt;我们需要自动伸缩实例数量，来弹性的满足到来的请求负载。&lt;strong&gt;Cocktail&lt;/strong&gt;能准确预测给定时间间隔内的预期负荷。如果需要，&lt;strong&gt;Cocktail&lt;/strong&gt;增加实例到实例池。每隔10秒对SLO违例进行采样，并根据所有实例的资源利用率聚合为每个池生成额外的实例。捕获由于错误预测而导致的SLO违反。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;预测策略：本文设计了DeepARestimator模型。每个模型有1分钟的定期调度间隔$T_s$，在时间$T+T_p$使用预测负责$L_p$，与当前负载$C_p$进行比较，来决定实例数量$I_n$。其中，$T_p$为新实例的平均启动时间。$T_s$设定为1分钟是考虑到AWS  EC2 VMs实例的启动时间。为计算$L_p$，对过去S秒内大小为$W$的相邻窗口的到达率进行采样。使用所有窗口的全局到达率，来预测时间$T$在加减$T_p$时间单元中的$L_p$。$T_p$设置为10分钟，使它有足够的时间来捕捉未来长期的变化。所有这些参数都可以根据系统的需要进行调整。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Importance Sampling： 在自动伸缩中一个重要的问题是模型选择策略为给定的请求约束动态地确定集合中的模型。**基于预测的负载，为每个模型平等地自动伸缩实例，将固有地导致为未充分使用的模型提供过多的实例。**为了解决这个问题，设计了一个加权自动缩放策略，它基于权重智能地为每个池自动缩放实例。算法如下图：&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;自动缩放策略如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/image-20220515210458324.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220515210458324&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;权重取决于模型被请求(get_popularity)的频率。权重与每个模型池的伸缩实例(launch_workers)的预测负载相乘。这种方法称为Importance Sampling，因为模型池的大小与它们的受欢迎程度成正比。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;本论文实验做得非常充分！可以作为范本。&lt;/p&gt;
&lt;/blockquote&gt;
</description>
        </item>
        <item>
        <title>IEEE CLOUD 21 云上资源管理相关合辑</title>
        <link>https://lizonglingo.github.io/p/ieee-cloud-21-%E4%BA%91%E4%B8%8A%E8%B5%84%E6%BA%90%E7%AE%A1%E7%90%86%E7%9B%B8%E5%85%B3%E5%90%88%E8%BE%91/</link>
        <pubDate>Thu, 21 Apr 2022 14:33:47 +0800</pubDate>
        
        <guid>https://lizonglingo.github.io/p/ieee-cloud-21-%E4%BA%91%E4%B8%8A%E8%B5%84%E6%BA%90%E7%AE%A1%E7%90%86%E7%9B%B8%E5%85%B3%E5%90%88%E8%BE%91/</guid>
        <description>&lt;blockquote&gt;
&lt;p&gt;本篇整理自IEEE CLOUD&#39;21会议中的文章，主题为云背景下的资源管理。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;runwild-resource-management-system-withgeneralized-modeling-for-microservices-on-cloud&#34;&gt;RunWild: Resource Management System withGeneralized Modeling for Microservices on Cloud&lt;/h2&gt;
&lt;h3 id=&#34;star摘要&#34;&gt;:star:摘要&lt;/h3&gt;
&lt;h4 id=&#34;问题背景&#34;&gt;问题背景&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;微服务内部通信的复杂性，必须考虑资源利用、调度策略和请求均衡之间的平衡，以防止跨微服务级联的服务质量下降。&lt;/strong&gt;&lt;/p&gt;
&lt;h4 id=&#34;文章做了什么&#34;&gt;文章做了什么&lt;/h4&gt;
&lt;p&gt;提出资源管理系统&lt;strong&gt;RunWild&lt;/strong&gt;，可以控制所有节点涉及到的微服务管理：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;扩缩容&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;调度&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;自动&lt;/strong&gt;的根据&lt;strong&gt;指定性能表现&lt;/strong&gt;的&lt;strong&gt;负载和性能平衡优化&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;统一的&lt;strong&gt;持续部署方案&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;着重强调了&lt;strong&gt;协同metrics感知&lt;/strong&gt;在&lt;strong&gt;预测资源使用和制定部署计划&lt;/strong&gt;中的重要性。&lt;/p&gt;
&lt;p&gt;在IBM云进行实验，&lt;strong&gt;以K8s的自动调度为基线&lt;/strong&gt;，减少P90响应时间11%，增加10%的吞吐率，降低30%的资源使用。&lt;/p&gt;
&lt;h4 id=&#34;贡献&#34;&gt;贡献&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;扩展的部署框架：&lt;strong&gt;适用于K8s的调度框架&lt;/strong&gt;，用来在资源分配、部署、和运行时来控制部署机制；&lt;/li&gt;
&lt;li&gt;通用的建模方法：综合考虑微服务特性、节点的相对独立性、工作负载和全局协同节点状态感知，通过结合聚类和回归技术预测资源使用；&lt;/li&gt;
&lt;li&gt;微服务间交互指标：一个称为内聚的指标反映了在同一个&lt;strong&gt;节点上放置高度相互通信的微服务的优势&lt;/strong&gt;；&lt;/li&gt;
&lt;li&gt;通过&lt;strong&gt;Service Mesh&lt;/strong&gt;对运行时工作负载进行分区：利用服务网格操作流量路由，用其控制能力来划分工作负载以匹配资源的分配。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;star现有技术存在的问题&#34;&gt;:star:现有技术存在的问题&lt;/h3&gt;
&lt;h4 id=&#34;水平伸缩&#34;&gt;水平伸缩&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;超过某个阈值时，实例的增多与性能表现的增长不匹配，正如收益递减定律所解释的那样；&lt;/li&gt;
&lt;li&gt;资源过度分配并不会显著增加性能表现；&lt;/li&gt;
&lt;li&gt;而资源不足会导致性能下降或者致命错误。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;垂直伸缩&#34;&gt;垂直伸缩&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;K8s虽然可以支持HPA和VPA，但是不能一起工作，同时进行HPA和VPA难免会造成干扰。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;此外，复杂的资源依赖，全局的资源调度策略使得伸缩方案受多方面影响。&lt;/p&gt;
&lt;p&gt;文章的动机是&lt;strong&gt;识别、描述和管理所有因素和维度&lt;/strong&gt;，以实现&lt;strong&gt;统一的部署解决方案&lt;/strong&gt;，而不是运行相互干扰的机制。&lt;/p&gt;
&lt;h4 id=&#34;部署的三个角度&#34;&gt;部署的三个角度&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;所部署的服务的实例副本数；&lt;/li&gt;
&lt;li&gt;节点上每个实例所得到的资源；&lt;/li&gt;
&lt;li&gt;每个实例的网络容量。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;然后引出下面4个重要的问题：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;调度所涉及到的策略、资源和具体情景很复杂，要考虑的东西太多；&lt;/li&gt;
&lt;li&gt;同一节点上部署的服务可能&lt;strong&gt;对资源的争用很敏感&lt;/strong&gt;；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;微服务之间的通信，亲和性&lt;/strong&gt;等因素会影响到&lt;strong&gt;全局的服务性能表现、响应事件及吞吐量&lt;/strong&gt;，最好的方式是使部署的微服务&lt;strong&gt;减少跨节点的通信&lt;/strong&gt;；&lt;/li&gt;
&lt;li&gt;如何将&lt;strong&gt;请求负载均衡到不同实例以带来更好的网络表现&lt;/strong&gt;，虽然Service Mesh能够实现负载的分发，但是难以解决上述问题。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;文章列举了一些其他文章做的工作，并对比这些工作解决了上述4个问题中的哪些：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/image-20220423213910376.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220423213910376&#34;
	
	
&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;该文会精读，请关注最新的文章。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;fast-and-efficient-performance-tuning-of-microservices&#34;&gt;Fast and Efficient Performance Tuning of Microservices&lt;/h2&gt;
&lt;h3 id=&#34;star摘要-1&#34;&gt;:star:摘要&lt;/h3&gt;
&lt;p&gt;针对使用&lt;strong&gt;容器部署的微服务架构应用&lt;/strong&gt;，&lt;strong&gt;以Kubernetes、Docker Swarm容器管理平台为依托&lt;/strong&gt;。在应用正式部署上线之前，也就是在&lt;strong&gt;pre-deployment&lt;/strong&gt;阶段，&lt;strong&gt;迭代的根据资源使用相关指标&lt;/strong&gt;，结合&lt;strong&gt;类多目标优化算法(文章称为heuristic optimization algorithm)&lt;strong&gt;对&lt;/strong&gt;资源分配进行调优&lt;/strong&gt;。&lt;/p&gt;
&lt;h3 id=&#34;star系统架构&#34;&gt;:star:系统架构&lt;/h3&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ol&gt;
&lt;li&gt;将应用部署到云平台；&lt;/li&gt;
&lt;li&gt;进行负载注入；&lt;/li&gt;
&lt;li&gt;基于Jaeger的监控系统开始进行性能测试和追踪(对每个微服务)，收集数据，如响应时间和资源的使用量；&lt;/li&gt;
&lt;li&gt;通过Jaeger解析服务调用序列；&lt;/li&gt;
&lt;li&gt;由Tuning Agent参照服务序列信息、不同类别请求的响应时间和平均资源使用进行调优；&lt;/li&gt;
&lt;li&gt;Tuning Agent预估每个微服务的新的CPU配额信息；&lt;/li&gt;
&lt;li&gt;将这些信息存储到Tuning数据库中；&lt;/li&gt;
&lt;li&gt;编排器根据这些信息对服务进行迭代部署。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;star测量优化的依赖指标&#34;&gt;:star:测量、优化的依赖指标&lt;/h3&gt;
&lt;p&gt;需要对服务进行&lt;strong&gt;请求的注入&lt;/strong&gt;来进行测量，主要指标是&lt;strong&gt;服务响应时间&lt;/strong&gt;。涉及到&lt;strong&gt;链路追踪、性能监控&lt;/strong&gt;。&lt;/p&gt;
&lt;h3 id=&#34;star调优模型抽象&#34;&gt;:star:调优模型抽象&lt;/h3&gt;
&lt;h4 id=&#34;小背景前提和假设&#34;&gt;小背景、前提和假设&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;应用需要一些特定的工作负载$W$&lt;/strong&gt;，这些工作负载发生在特定的情境，例如在线商城的Black Friday。因此，调优过程可以对其他感兴趣的工作负载重放，从而产生一系列特定于工作负载的配置，可以在部署应用程序时适当地使用。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;本文重点关注CPU资源的限制&lt;/strong&gt;，但是该模型可以拓展到其他资源。&lt;/li&gt;
&lt;li&gt;应用包含**$K$个微服务**，每个微服务运行在自己的container中。&lt;/li&gt;
&lt;li&gt;每个应用支持**$C$种不同的请求类别**。&lt;/li&gt;
&lt;li&gt;每个请求类别**$c$关联到不同的响应时间$T_c$**。&lt;/li&gt;
&lt;li&gt;每类请求**$c$涉及到一个微服务调用序列$S_c$**。&lt;/li&gt;
&lt;li&gt;因此这个序列中每个&lt;strong&gt;微服务$k$都涉及到一个CPU需求&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;主机上对应的&lt;strong&gt;服务$k$所需的CPU配额表示为$\alpha_k$&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;资源分配问题抽象&#34;&gt;资源分配问题抽象&lt;/h4&gt;
&lt;p&gt;问题可以抽象为：在&lt;strong&gt;满足响应时间的需求下，求解对每个微服务CPU配额的最小值&lt;/strong&gt;。&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ol&gt;
&lt;li&gt;目标为最小化CPU配额；&lt;/li&gt;
&lt;li&gt;需要满足前提条件，即：资源配额能够使某类请求的响应时间$R_c$小于等于目标值$T_c$；&lt;/li&gt;
&lt;li&gt;其中响应时间$R_c$是工作负载$W$和对$K$个服务CPU配额的函数；&lt;/li&gt;
&lt;li&gt;最后限制CPU需求总额是有限的。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;star应用案例及实验&#34;&gt;:star:应用案例及实验&lt;/h3&gt;
&lt;p&gt;使用的微服务案例&lt;strong&gt;Bookstore&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/image-20220419153253242.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220419153253242&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;star我的问题&#34;&gt;:star:我的问题&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;工作负载的模拟具体如何实现？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;有哪些开源微服务应用真正可用又具有一定的代表性？&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&#34;skynet-performance-driven-resource-management-for-dynamic-workloads&#34;&gt;Skynet: Performance-driven Resource Management for Dynamic Workloads&lt;/h2&gt;
&lt;h3 id=&#34;star摘要-2&#34;&gt;:star:摘要&lt;/h3&gt;
&lt;h4 id=&#34;问题背景和主要矛盾&#34;&gt;问题背景和主要矛盾&lt;/h4&gt;
&lt;p&gt;云环境下，资源利用率和应用的性能表现之间的矛盾。&lt;/p&gt;
&lt;h4 id=&#34;难点&#34;&gt;难点&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;用户常会&lt;strong&gt;分配过多的资源&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;应用的&lt;strong&gt;多样性和动态性&lt;/strong&gt;，&lt;strong&gt;工作负载的动态性及难以预测性&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;性能表现取决于&lt;strong&gt;多种不同资源&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;文章做了什么怎么做的&#34;&gt;文章做了什么，怎么做的&lt;/h4&gt;
&lt;p&gt;提出Skynet，针对上述三个难点，可以自动对云资源进行管理。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;评估资源需求&lt;strong&gt;依赖的指标&lt;/strong&gt;：Skynet使用performance level objectives(PLOs)准确捕捉用户对所需性能的意图，将用户从资源分配循环中解放。Skynet&lt;strong&gt;通过目标PLO去预估资源需求&lt;/strong&gt;，使用Poportional Integral Derivative(PID)控制器对每个应用调整对应的参数。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;资源需求&lt;strong&gt;计算、分配、调度方法&lt;/strong&gt;：为捕获每个应用对不同资源依赖，&lt;strong&gt;Skynet扩展了传统的一维PID控制器&lt;/strong&gt;(传统的单输入单输出)，实现对CPU、内存、I/O和网络吞吐的预估。Skynet建立一个动态模型，对于每个应用，将目标PLOs映射到资源，同时考虑多种资源和变化的输入负载。事实上，Skynet处于一个&lt;strong&gt;动态循环控制&lt;/strong&gt;来预估资源。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;实现和评估&lt;/strong&gt;：在&lt;strong&gt;kubernetes中将skynetas实现为端到端的定制调度程序&lt;/strong&gt;，并在5个节点的私有集群和60个裸金属服务器AWS上使用真实的工作负载对其进行评估。以K8s为基线，PLO违规降低7.4倍，资源利用提高两倍。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;star系统架构-1&#34;&gt;:star:系统架构&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/image-20220421114835655.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220421114835655&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;用户可以指定PLOs，明确对吞吐量、延迟、处理时间等指标的需求。Skynet根据这些PLOs，使用PID[41]预估每个应用的资源需求量。动态的将PLO映射到资源需求，这样一来可以让Skynet适应变化的工作负载和每个应用不同的生命阶段。&lt;/p&gt;
&lt;h4 id=&#34;示例&#34;&gt;示例&lt;/h4&gt;
&lt;p&gt;一个web应用PLO为1000请求/秒。Skynet给每个新应用分配一个预定义容器。在执行阶段，Skynet主要使用两个组件：Resource Estimator(RE)和Resource Assigner(RA)，来周期性的调整资源配额以满足PLO：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Skynet周期性监控应用性能指标，如果触发PLO违规，会触发RE。&lt;/li&gt;
&lt;li&gt;RE基于PLO调整PIDs的参数。&lt;/li&gt;
&lt;li&gt;基于目标PLO，RE预估应用新的资源需求。&lt;/li&gt;
&lt;li&gt;当可分配资源满足条件时，RA调整应用容器。&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;放置应用以及根据控制器更新应用放置&#34;&gt;放置应用以及根据控制器更新应用放置&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;确定应用资源需求量后，Skynet决定容器的资源限额和放置。具体来说，包括容器打包，节点绑定以及资源配额。其中，容器大小和放置由于需要考虑多种资源的约束，远比打包应用复杂。放置应用的目标是：避免应用间干扰，提高应用性能表现。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;当新应用到来时，Skynet进行扫描，查看是否有某个服务节点可以单独满足应用的资源需求，如果不存在这样的服务节点，就迭代执行下列步骤：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;增加一个容器的数量；&lt;/li&gt;
&lt;li&gt;在容器之间平均分配资源；&lt;/li&gt;
&lt;li&gt;找到能够满足容器需求，并且负载最高的服务节点；&lt;/li&gt;
&lt;li&gt;如果没有，循环执行上述步骤。&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;调整应用资源配额。每次请求改变资源需求时，有三种可能：(理解的有些别扭？)&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;资源不够。该情况下，Skynet决定有没有现存的容器可以移除。然后基于节点负载对节点进行排序，移除额外的容器。&lt;/li&gt;
&lt;li&gt;节点上的可用资源早已被分配给应用。Skynet在容器之间平均增加应用程序的资源，以匹配新的请求。&lt;/li&gt;
&lt;li&gt;可用资源分布在不同的服务节点上。Skynet以放置新应用的思路放置新的容器。&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;总的说，就是处理，&lt;strong&gt;容器应该放置在哪个节点上的问题&lt;/strong&gt;。算法思路如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/image-20220421143003087.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220421143003087&#34;
	
	
&gt;&lt;/p&gt;
&lt;h4 id=&#34;在kubernetes上的实现&#34;&gt;在Kubernetes上的实现&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/image-20220421132506202.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220421132506202&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;使用Golang实现自定义调度器。使用Prometheus进行监控。代码开源[11]。&lt;/p&gt;
&lt;h3 id=&#34;star我的问题-1&#34;&gt;:star:我的问题&lt;/h3&gt;
&lt;h4 id=&#34;关于pid控制理论的补充&#34;&gt;关于PID控制理论的补充&lt;/h4&gt;
&lt;p&gt;已经不止一次在论文中看到使用PID来调整资源分配了。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://zhuanlan.zhihu.com/p/39573490&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://zhuanlan.zhihu.com/p/39573490&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&#34;如果要使用pid算法再细读&#34;&gt;如果要使用PID算法，再细读&lt;/h4&gt;
&lt;p&gt;获得监控数据后具体怎处理？&lt;/p&gt;
&lt;p&gt;分配资源的具体方法？&lt;/p&gt;
&lt;h2 id=&#34;konveyor-move2kube-automatedreplatforming-of-applications-to-kubernetes&#34;&gt;Konveyor Move2Kube: AutomatedReplatforming of Applications to Kubernetes&lt;/h2&gt;
&lt;h3 id=&#34;star摘要-3&#34;&gt;:star:摘要&lt;/h3&gt;
&lt;p&gt;文章提出Move2Kube，一个再部署框架，能够自动调整部署细节，并通过部署pipeline&lt;strong&gt;将非Kubernetes平台部署的应用转移到Kubernetes平台上&lt;/strong&gt;，同时最小限度修改应用架构和实现。&lt;/p&gt;
&lt;p&gt;此外，文章提出&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一个最小化的中间表示，不同的应用部署构建都可以转化到这个中间表示上来。&lt;/li&gt;
&lt;li&gt;一个扩展框架，用于添加对新的部署源平台和目标中间件的支持，同时允许定制化。&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Move2Kube已经开源：https://move2kube.konveyor.io/&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&#34;要解决什么问题&#34;&gt;要解决什么问题&lt;/h4&gt;
&lt;p&gt;在不是K8s平台部署的应用迁移到K8s平台上，同时应该最小限度的修改原系统的实现和软件架构。&lt;/p&gt;
&lt;h4 id=&#34;挑战难点在哪里&#34;&gt;挑战、难点在哪里&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;应用规模：企业级应用往往有上千个组件，人工迁移费时费力；&lt;/li&gt;
&lt;li&gt;应用异构：多样的部署平台，多样的应用架构和种类；&lt;/li&gt;
&lt;li&gt;不同的代码源、组件仓库：代码源或者使用的组件分布在不同的仓库中，很难将其组织到一起，如何分布的数千个目录中找到正确的文件很有挑战；&lt;/li&gt;
&lt;li&gt;容器化挑战：将应用容器化时，对于优化配置和分层安全很有必要，需要对容器内部、镜像技术和应用配置有深入的理解；&lt;/li&gt;
&lt;li&gt;目标平台映射：找到正确的不同平台的配置映射关系是困难的，例如如何选择从简单的K8s service转换到Istio的配置中；&lt;/li&gt;
&lt;li&gt;应用的最佳实践：K8s有最佳实践[6]，如何确保迁移使用K8s的最佳实践；&lt;/li&gt;
&lt;li&gt;定制化的需求和有效的Day 2 Operation：针对不同应用和需求定制化的配置以适应平台特性需要一定的经验和时间，同时需要考虑Day 2 Operation。&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;关于什么是Day 2 Operation：https://jimmysong.io/blog/what-is-day-2-operation/&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&#34;move2kube&#34;&gt;Move2Kube&lt;/h4&gt;
&lt;p&gt;这个开源框架旨在解决应用迁移到Kubernetes平台过程中出现的上述问题。它提供了标准化的Pipeline，包括&lt;strong&gt;容器化、参数化、配置优化、定制化&lt;/strong&gt;等解决方案，满足面向&lt;strong&gt;特定平台的多源、多服务&lt;/strong&gt;的应用部署迁移。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;该文不太属于资源管理方面。&lt;/p&gt;
&lt;/blockquote&gt;
</description>
        </item>
        <item>
        <title>MLaaS in the Wild: Workload Analysis and Scheduling in Large-Scale Heterogeneous GPU Clusters</title>
        <link>https://lizonglingo.github.io/p/mlaas-in-the-wild-workload-analysis-and-scheduling-in-large-scale-heterogeneous-gpu-clusters/</link>
        <pubDate>Mon, 21 Mar 2022 21:05:51 +0800</pubDate>
        
        <guid>https://lizonglingo.github.io/p/mlaas-in-the-wild-workload-analysis-and-scheduling-in-large-scale-heterogeneous-gpu-clusters/</guid>
        <description>&lt;blockquote&gt;
&lt;p&gt;来源： NSDI&#39;22&lt;/p&gt;
&lt;p&gt;作者：Alibaba Group&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;摘要&#34;&gt;摘要&lt;/h2&gt;
&lt;p&gt;在ML as a Service中，数据中心为ML提供算力保证。而多样的ML工作负载面对&lt;strong&gt;异构GPU集群&lt;/strong&gt;时会出现一些问题。通过两个月的数据收集，采集了超过&lt;strong&gt;6000个GPU&lt;/strong&gt;的生产数据。并发现集群调度面临的一些问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;低GPU利用率&lt;/li&gt;
&lt;li&gt;长队列延迟&lt;/li&gt;
&lt;li&gt;需要高端GPU的任务调度难度大&lt;/li&gt;
&lt;li&gt;异构机器负载不均衡&lt;/li&gt;
&lt;li&gt;CPU潜在的瓶颈问题&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;文章对上述问题提供了一些解决方案。&lt;/p&gt;
&lt;p&gt;本文的最大贡献是提供了一个真实的大规模生产级别的ML集群的追踪数据，并在此基础之上进行分析，为ML as a Service - 云环境下的ML工作负载调度提供了重要的一手数据。&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;在ML框架下的任务需要不同的调度策略，例如GPU局部性、群调度，而且需要调配跨数量级的资源。同时集群中的机器是异构的，一些配置如下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/image-20220320210534789.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220320210534789&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;而异构的运行环境给资源管理和调度带来新的困难。&lt;/p&gt;
&lt;h4 id=&#34;gpu碎片化使用带来的低利用率&#34;&gt;GPU碎片化使用带来的低利用率&lt;/h4&gt;
&lt;p&gt;例如一个任务实例只使用GPU资源的一部分。流处理程序的GPU利用率的中位数值只有0.042GPU。&lt;strong&gt;粗粒度的GPU分配&lt;/strong&gt;使得资源使用率低下。&lt;/p&gt;
&lt;p&gt;为解决这个问题，文章提出了&lt;strong&gt;GPU sharing&lt;/strong&gt;，一种可以以&lt;strong&gt;时分复用的方式让多个任务共享GPU&lt;/strong&gt;的控制方式。使用该方式，将许多低GPU的工作负载整合起来，使用一个GPU，提高资源使用效率。此外，这种共享方式&lt;strong&gt;不会引起资源争用干扰&lt;/strong&gt;，资源竞争的概率十分小。&lt;/p&gt;
&lt;h4 id=&#34;短任务面临的长排队延迟&#34;&gt;短任务面临的长排队延迟&lt;/h4&gt;
&lt;p&gt;短时间运行的任务实例容易由于队列头阻塞而导致长队列延迟，&lt;strong&gt;大约9%的任务排队等待的时间超过他们的执行时间&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;一种有效的解决方案是&lt;strong&gt;预测任务运行时间&lt;/strong&gt;，&lt;strong&gt;并将短任务优先级尽可能提高&lt;/strong&gt;，避免与长任务竞争。通过仔细的特征工程，我们可以预测大多数重复任务的持续时间，误差在25%以内，这足以根据之前的工作建议做出质量调度决策（因为，通过观察，集群中有65%的任务有重复的工作负载）。跟踪驱动的仿真结果表明，通过预测任务持续时间采用最短作业优先调度，平均完成时间减少63%以上。&lt;/p&gt;
&lt;h4 id=&#34;高gpu使用的作业难以进行调度&#34;&gt;高GPU使用的作业难以进行调度&lt;/h4&gt;
&lt;p&gt;集群中的&lt;strong&gt;一些任务要求无共享的使用GPU，以利用高级硬件特性，达到加速训练的目的&lt;/strong&gt;，如NVLink[12]，因此，对这些任务难以进行调度。&lt;/p&gt;
&lt;p&gt;集群中的调度器使用一个简单的 reserving-and-packing 策略在集群中分辨出这样的任务。它&lt;strong&gt;保留高端的GPU机器&lt;/strong&gt;，如，V100 with NVLinks，用于少数具有挑剔调度要求的高GPU任务，同时将其他工作负载打包到不太高级的机器上，使用GPU共享策略&lt;strong&gt;保证资源的利用率&lt;/strong&gt;。此外，该策略还&lt;strong&gt;提升了平均队列等待延迟，加快了任务调度&lt;/strong&gt;。&lt;/p&gt;
&lt;h4 id=&#34;负载不均衡&#34;&gt;负载不均衡&lt;/h4&gt;
&lt;p&gt;明显的是，&lt;strong&gt;低端GPU比高端GPU更加拥挤&lt;/strong&gt;，前者被分配了70%的GPU和CPU资源，而后者只被分配35%的CPU和49%的GPU资源。&lt;/p&gt;
&lt;p&gt;工作负载和机器之间也存在供应不匹配的问题。例如，工作在8GPU的工作负载对CPU的需求是那些可以提供12GPU的1.9倍，简而言之就是，那些&lt;strong&gt;性能更弱的机器被分配了与其能力不匹配的工作负载&lt;/strong&gt;。&lt;/p&gt;
&lt;h4 id=&#34;cpu瓶颈&#34;&gt;CPU瓶颈&lt;/h4&gt;
&lt;p&gt;一些机器学习、深度学习作业不仅仅需要GPU，有的也需要CPU资源，这造成CPU瓶颈。同时发现， 工作在高CPU利用率机器上的任务容易减速。&lt;/p&gt;
&lt;h2 id=&#34;工作负载特征分析&#34;&gt;工作负载特征分析&lt;/h2&gt;
&lt;h3 id=&#34;追踪概述&#34;&gt;追踪概述&lt;/h3&gt;
&lt;p&gt;关于数据集的数据内容和下载请查看&lt;a class=&#34;link&#34; href=&#34;https://github.com/alibaba/clusterdata&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;clusterdata&lt;/a&gt;。实际上并不能明确的知道容器里执行的到底是什么类型的训练任务，但是可以从作业名中得到一些线索。&lt;/p&gt;
&lt;p&gt;下图为PAI和Trace的架构：&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;h4 id=&#34;jobs-tasks-and-instances&#34;&gt;Jobs, tasks, and instances&lt;/h4&gt;
&lt;p&gt;用户提交jobs，一个job有一个或多个tasks来扮演不同的计算角色，每个task使用Docker运行一个或多个instances。&lt;/p&gt;
&lt;p&gt;例如，一个分布式训练job有一个参数服务task，该task有两个实例，此外还有一个worker task有10个实例。一个task的所有instances有相同的资源需求，并且需要gang-schedule。&lt;/p&gt;
&lt;p&gt;我们主要&lt;strong&gt;关注任务实例，也就是instance这一级别的工作&lt;/strong&gt;。&lt;/p&gt;
&lt;h4 id=&#34;heavy-skewed-instance-distribution&#34;&gt;Heavy-skewed instance distribution&lt;/h4&gt;
&lt;p&gt;PAI追踪了120万个tasks，超过750万个instances，由超过1300个用户提交。下图展示了用户提交的task instance的分布，表现出严重的不平衡：&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;5%的用户提交了大概77%的task instances，大概每个用户运行1.75万instance。而50%的用户每人运行少于180个instances。&lt;/p&gt;
&lt;h4 id=&#34;the-prevalence-of-gang-scheduling&#34;&gt;The prevalence of gang-scheduling&lt;/h4&gt;
&lt;p&gt;分布式的任务需要gang-schedule（认为超过2个GPU的调度），如下图：&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;大约85%的任务需要这样的需求，有20%的任务需要超过100个GPU的调度，还有的甚至要进行超过1000个GPU的调度。&lt;/p&gt;
&lt;h4 id=&#34;gpu-locality&#34;&gt;GPU locality&lt;/h4&gt;
&lt;p&gt;除了gang-schedule，一个任务可能会在同一台机器上的多个GPU上运行它的所有实例，也就是存在&lt;strong&gt;GPU局部性&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;虽然这种情况会引发调度延迟的加剧（一些任务等待调度的时间延长），但是在单节点的GPU上进行训练减少了GPU to GPU的通信时间。&lt;/p&gt;
&lt;p&gt;但是通过增强GPU局部性，可以&lt;strong&gt;让某些任务的训练速度加快10倍&lt;/strong&gt;。&lt;/p&gt;
&lt;h4 id=&#34;gpu-sharing&#34;&gt;GPU sharing&lt;/h4&gt;
&lt;p&gt;GPU sharing利用时分复用的原理使得多用户可共享一个GPU进行训练。&lt;/p&gt;
&lt;h4 id=&#34;various-gpu-types-to-choose-from&#34;&gt;Various GPU types to choose from&lt;/h4&gt;
&lt;p&gt;PAI提供异构的GPU可供任务选择。在集群中只有6%的训练任务需要运行在特定的GPU上，其他的任务则对GPU类型没有限制。&lt;/p&gt;
&lt;h3 id=&#34;时间模型&#34;&gt;时间模型&lt;/h3&gt;
&lt;p&gt;从时间角度来观察PAI工作负载。&lt;/p&gt;
&lt;h4 id=&#34;diurnal-task-submissions-and-resource-requests&#34;&gt;Diurnal task submissions and resource requests&lt;/h4&gt;
&lt;p&gt;下图是一周中task和instance的提交情况，还有总体的资源请求情况：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/image-20220321104136979.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220321104136979&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;从中可以得到以下几点信息：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;周中提交数量多余周末&lt;/li&gt;
&lt;li&gt;夜晚也有任务提交的高峰&lt;/li&gt;
&lt;li&gt;大多数在夜间提交的任务并非计算密集型&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;instance-run-time-in-a-wide-range&#34;&gt;Instance run-time in a wide range&lt;/h4&gt;
&lt;p&gt;下图展示了instance运行时间的分布：&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;运行时间的变化范围很大，有4个数量级&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;non-uniform-queueing-delays&#34;&gt;Non-uniform queueing delays&lt;/h4&gt;
&lt;p&gt;理解为在队列中等待调度的时间。这段时间指task提交到instance执行的时间，如下图：&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;对比long-task，short-task通常花费更多比例的时间在等待调度上&lt;/li&gt;
&lt;li&gt;大约9%的短作业实例花费超过完成时间的一半去等待调度，而长左右这个数值只有3%&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;此外，task instance的队列延迟还取决于GPU的需求，如下图：&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;那些可以共享GPU的instance（GPU需求为0-1）可以更快的被调度，其等待调度的等待时间P90值为497s&lt;/li&gt;
&lt;li&gt;而不支持共享GPU的任务的这一值为1150&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;同时，长队列等待时间也出现在一些需要高端GPU的任务中，如下图：&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;例如在V100和V100M32上的instance需要更多等待时间&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;空间模型&#34;&gt;空间模型&lt;/h3&gt;
&lt;p&gt;通过分析资源请求和使用，分析了PAI task instance的空间模型。每15s进行一次测量，并使用虚拟化工具[2, 25]去分析用户的负载模式和他们的资源需求。&lt;/p&gt;
&lt;h4 id=&#34;heavy-tailed-distribution-of-resource-requests&#34;&gt;Heavy-tailed distribution of resource requests&lt;/h4&gt;
&lt;p&gt;如下图：&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;图5(a)(b)(c)中的蓝色实现表示，大约20%的实例占用了80%的资源，而其余的只要很少一部分资源&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;以P95和中位数比较，P95需要12vCPU、1GPU、59GB内存，而中位数只要6vCPU、0.5GPU和29GB内存。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;uneven-resource-usage-low-on-gpu-but-high-on-cpu&#34;&gt;Uneven resource usage: Low on GPU but high on CPU&lt;/h4&gt;
&lt;p&gt;集群中instance的资源使用中位数在1.4vCPU、0.042GPU和3.5GB内存，远小于资源请求的中位数。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;观察到存在GPU空闲和CPU不够用的情况，并推断GPU的低利用率不是因为对GPU的需求少，而是CPU瓶颈限制了GPU的使用&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;从5(b)中也可以看到，对GPU的实际使用远小于GPU资源的需求&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;从5(d)中，对应X坐标&amp;gt;1的值表示CPU的使用量大于申请的量，有19%的instance出现这种情况，而超量使用GPU的只有约3%的实例，对内存来说这一值也只有9%&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;gpu利用率&#34;&gt;GPU利用率&lt;/h2&gt;
&lt;h3 id=&#34;计算资源利用率&#34;&gt;计算资源利用率&lt;/h3&gt;
&lt;p&gt;包括CPU、GPU和Memory。监控系统每15s收集数据，并存到时间序列数据库中。&lt;/p&gt;
&lt;p&gt;如下图：&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;相比内存来说，GPU和CPU利用率普遍高，也说明大部分任务不是内存集中型&lt;/li&gt;
&lt;li&gt;GPU利用率的P90跨度很广，这与GPU使用有突发性相关，同时也与调度策略有关&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;网络和io的低利用率&#34;&gt;网络和I/O的低利用率&lt;/h3&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;网络中数据接收量普遍较低&lt;/li&gt;
&lt;li&gt;网络带宽普遍不能达到指定数值(如不能达到保证的10Gbps、32Gbps)&lt;/li&gt;
&lt;li&gt;iowait模式比usr和kernel模式少三个数量级，这意味着CPU大多数时间在进行计算而不是在等待I/O&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;优化集群管理的方向&#34;&gt;优化集群管理的方向&lt;/h2&gt;
&lt;p&gt;在PAI中，集群管理有两个优化目标：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;实现GPU的高利用率&lt;/li&gt;
&lt;li&gt;缩短task的运行时间&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;gpu共享&#34;&gt;GPU共享&lt;/h3&gt;
&lt;p&gt;与CPU不同，GPU天生就没有共享特性。PAI以&lt;strong&gt;时分复用和空分复用（内存）方式&lt;/strong&gt;，使多个任务实例可以共享一个GPU。&lt;/p&gt;
&lt;h4 id=&#34;benefits-of-gpu-sharing&#34;&gt;Benefits of GPU sharing&lt;/h4&gt;
&lt;p&gt;下图将是否使用GPU sharing的表现进行对比：&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;平均而言，共享只需要50%的GPU资源，可节省高达73%的费用，节省大量的GPU资源&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;does-gpu-sharing-cause-contention&#34;&gt;Does GPU sharing cause contention?&lt;/h4&gt;
&lt;p&gt;随着利用率的增加，运行在共享GPU上的实例开始争夺资源。&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;由于大多数高利用率的GPU上面运行单个实例(平均4.5%的GPU运行多个实例)，因此不会发生争用，所以认为GPU共享不会在集群中引起严重的争用&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;预测重复任务的持续时间&#34;&gt;预测重复任务的持续时间&lt;/h3&gt;
&lt;p&gt;文章认为预测ML认为实例的运行时间是实现更好调度的关键。现存的预测方案基于迭代次数、损耗曲线、目标精度和训练速度等指标。&lt;/p&gt;
&lt;h4 id=&#34;the-prevalence-of-recurring-tasks&#34;&gt;The prevalence of recurring tasks&lt;/h4&gt;
&lt;p&gt;文章发现大多数任务都是重复的，并且它们的实例运行时可以很好地从过去的执行中预测出来。通过对任务的元数据，如：脚本、命令行参数、数据源和输出，进行hash得到Group tag来标识重复的任务。&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;约65%的任务在trace中至少运行5轮&lt;/li&gt;
&lt;li&gt;大多数重复任务每个周期都有相似的运行时间&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;instance-duration-prediction-for-recurring-tasks&#34;&gt;Instance duration prediction for recurring tasks&lt;/h4&gt;
&lt;p&gt;实际的预测使用三个特征作为输入：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;task&amp;rsquo;s username - User&lt;/li&gt;
&lt;li&gt;resource request - Resource including GPU and other resources&lt;/li&gt;
&lt;li&gt;group tag - Group&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;利用上述特征，基于CART(Classification And Regression Tress)算法预测实例的平均运行时间。作为评估，使用至少重复5轮的任务，下图为预测详情：&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;从上图得知：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Group是重要指标&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;benefits-for-scheduling&#34;&gt;Benefits for scheduling&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/image-20220417180125631.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220417180125631&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;上图展示不同调度方法。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;SJF-Oracle明显好于其他算法，该算法基于真实的任务持续时间和预测算法&lt;/li&gt;
&lt;li&gt;给的特征越多，效果越好&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;调度面临的挑战&#34;&gt;调度面临的挑战&lt;/h2&gt;
&lt;p&gt;本部分使用两个案例：典型的ML tasks，分别有高/低GPU资源需求的特性。&lt;/p&gt;
&lt;h3 id=&#34;高gpu需求任务的研究&#34;&gt;高GPU需求任务的研究&lt;/h3&gt;
&lt;p&gt;集群中一些任务有计算密集型实例，需要很高的GPU资源。&lt;/p&gt;
&lt;h4 id=&#34;nlp-with-advanced-language-models&#34;&gt;NLP with advanced language models&lt;/h4&gt;
&lt;p&gt;NLP任务中，73%的有大规模的输入，需要16GB或更高的内存。下图展示了NLP实例对GPU资源的需求和使用情况：&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;约40%的实例需要超过1个GPU，超过那些常规的任务&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;image-classification-with-massive-output&#34;&gt;Image classification with massive output&lt;/h4&gt;
&lt;p&gt;集群中还有些任务需要GPU to GPU的高效率通信，GPU局部性可以提高通信效率。典型代表就是图像分类模型，其中存在规模庞大的全连接层，要求在工作实例之间进行大量的梯度更新，需要使用大量的通信资源，使通信成为瓶颈。&lt;/p&gt;
&lt;p&gt;如图14(b)中，启用NVLink极大缩短了任务的运行时间。&lt;/p&gt;
&lt;h3 id=&#34;低gpu需求的任务研究&#34;&gt;低GPU需求的任务研究&lt;/h3&gt;
&lt;p&gt;使用三种广泛使用的任务进行研究。一些CPU密集型的任务可能会导致GPU的利用率低下。&lt;/p&gt;
&lt;h4 id=&#34;ctr-prediction-model-training-and-inference&#34;&gt;CTR prediction model training and inference&lt;/h4&gt;
&lt;p&gt;在追踪中，有6.7%的广告点击率预测系统（ advertisement click- through rate (CTR) prediction）使用了CTR模型。其中有25%的实例负责训练，75%的实例负责推理工作。这些实例的CPU和GPU资源分布如下：&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;与训练相比，执行推理任务的实例具有更高的CPU利用率，因为它们处理源源不断到达的大量数据&lt;/li&gt;
&lt;li&gt;有近75%的实例使用的GPU小于0.1&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;下图展示了这些模型运行时资源情况：&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;CPU资源的使用明显高于其他资源&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;gnn-training&#34;&gt;GNN training&lt;/h4&gt;
&lt;p&gt;图神经网络也是计算密集型任务， CPU的使用率远超GPU，如下图所示：&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;在模型训练阶段，需要进行大量的CPU操作&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;reinforcement-learning&#34;&gt;Reinforcement learning&lt;/h4&gt;
&lt;p&gt;加强学习算法通过并行模拟迭代生成一批数据将生成的数据放到GPU上进行训练，以改进学习策略。&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;有72%的任务需要超过10个实例来完成，加大调度难度&lt;/li&gt;
&lt;li&gt;但是大多数RL任务对GPU的需求极低&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;部署调度策略&#34;&gt;部署调度策略&lt;/h3&gt;
&lt;h4 id=&#34;reserving-and-packing&#34;&gt;Reserving-and-packing&lt;/h4&gt;
&lt;p&gt;集群中有&lt;strong&gt;意保留高端GPU资源&lt;/strong&gt;，而尽可能将任务打包在一起，共享使用低端GPU资源。&lt;/p&gt;
&lt;p&gt;对于每个任务，调度程序生成一个有序的分配计划序列；每个计划指定了预期的GPU设备，并与尝试超时值相关联。&lt;/p&gt;
&lt;p&gt;对于需要高端GPU的任务，先尝试高端GPU的分配，然后再尝试较低端GPU的分配；对于其他任务，顺序颠倒过来，GPU调度器是在基于局部树的调度系统Fuxi[26,71]上实现的。&lt;/p&gt;
&lt;h4 id=&#34;load-balancing&#34;&gt;Load-balancing&lt;/h4&gt;
&lt;p&gt;在Reserving-and-packing的前提下，调度器还会优先将实例调度到分配率较低的机器上，分配率衡量为已分配的CPU、内存和GPU的加权总和，这些资源按机器的容量进行标准化。&lt;/p&gt;
&lt;h4 id=&#34;benefits&#34;&gt;Benefits&lt;/h4&gt;
&lt;p&gt;具体对应两种调度方法：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;简单地使用渐进式填充的负载平衡机器(总是将任务的实例调度到利用率最低的节点)&lt;/li&gt;
&lt;li&gt;不考虑负载均衡，只执行Reserving-and-packing&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;下图展示了这两种策略的实际表现：&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;请注意，任务的排队延迟也包括在它的组调度实例的排队延迟&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;在这两个策略下，超过90%的实例和任务会立即启动&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;与负载均衡算法相比，Reserving-and-packing算法将平均任务排队率降低了45%，主要原因是尾部延迟的显著缩短超过10000秒&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;进一步比较了业务关键型任务和请求V100的实例的排队延迟，在两种策略下，GPU的平均任务排队延迟减少了68%&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;其他待解决的问题&#34;&gt;其他待解决的问题&lt;/h3&gt;
&lt;h4 id=&#34;mismatch-between-machine-specs-and-instance-requests&#34;&gt;Mismatch between machine specs and instance requests&lt;/h4&gt;
&lt;p&gt;该问题带来的影响如下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/image-20220417191055419.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220417191055419&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;这直接导致：相较于高端机器来说，低端机器明显更拥挤，它们的资源使用率也高于高端机器&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;overcrowded-weak-gpu-machines&#34;&gt;Overcrowded weak-GPU machines&lt;/h4&gt;
&lt;h4 id=&#34;imbalanced-load-in-high-end-machines&#34;&gt;Imbalanced load in high-end machines&lt;/h4&gt;
&lt;h4 id=&#34;cpu-can-be-the-bottleneck&#34;&gt;CPU can be the bottleneck&lt;/h4&gt;
</description>
        </item>
        <item>
        <title>3MileBeach: A Tracer with Teeth</title>
        <link>https://lizonglingo.github.io/p/3milebeach-a-tracer-with-teeth/</link>
        <pubDate>Mon, 14 Mar 2022 19:12:33 +0800</pubDate>
        
        <guid>https://lizonglingo.github.io/p/3milebeach-a-tracer-with-teeth/</guid>
        <description>&lt;blockquote&gt;
&lt;p&gt;来源：ACM SoCC&#39;21&lt;/p&gt;
&lt;p&gt;作者：UC Santa Cruz&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;摘要&#34;&gt;摘要&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;提出&lt;em&gt;3MileBeach&lt;/em&gt;，一个针对微服务架构的追踪和故障注入平台。&lt;/li&gt;
&lt;li&gt;通过介入一个消息序列化库，避免了代码层面的监控（这是传统的追踪和故障注入会做的），可以提供更细粒度的追踪和故障注入。&lt;/li&gt;
&lt;li&gt;&lt;em&gt;3MileBeach&lt;/em&gt;提供了一个消息级别的分布式追踪，其开销只有最先进追踪框架的一半；提供故障注入比现有方案有更高的精度。&lt;/li&gt;
&lt;li&gt;使用&lt;em&gt;3MileBeach&lt;/em&gt;进行一种新型故障注入&lt;em&gt;Temporal Fault Injection&lt;/em&gt;（TFI）。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;追踪和故障注入现存的问题&#34;&gt;追踪和故障注入现存的问题&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;运行时开销和工作量过大；&lt;/li&gt;
&lt;li&gt;对异构应用程序和基础代码，基础设置的入侵性改动；&lt;/li&gt;
&lt;li&gt;微服务组件以不同的语言进行设计，之间使用不同的通信机制；&lt;/li&gt;
&lt;li&gt;故障注入需要在精度、粒度和成本上进行取舍。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;3milebeach的能力&#34;&gt;3MileBeach的能力&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;其只需要应用程序级的插件就能实现功能；&lt;/li&gt;
&lt;li&gt;提供细粒度的追踪，比最先进的技术节省25%~50%的成本；&lt;/li&gt;
&lt;li&gt;提供丰富且严格的跟踪指标；&lt;/li&gt;
&lt;li&gt;支持大规模并发故障注入，适用于生产环境；&lt;/li&gt;
&lt;li&gt;实现新型故障注入模式TFI，这基于时序谓词（nlp中的技术），可以识别可能处于休眠状态中的技术。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;motivation&#34;&gt;Motivation&lt;/h2&gt;
&lt;p&gt;目前最先进的分布式系统故障注入存在两个基础的问题：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;存在对细粒度、并发测试、不受blast radius影响的需求；&lt;/li&gt;
&lt;li&gt;现有的故障注入技术没有足够的表现力。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;time-of-check-to-time-of-usertocttou-error&#34;&gt;Time of Check to Time of User(TOCTTOU error)&lt;/h3&gt;
&lt;p&gt;假设一个在线购物平台存在如下问题，用户准备为购物车的物品付款时调用前端：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;前端发送一条消息给信用卡服务来验证（一个下游服务用来验证用户信用卡信息）；&lt;/li&gt;
&lt;li&gt;如果验证成功，前端会发送信息给商品服务来计算费用；&lt;/li&gt;
&lt;li&gt;计算完成后再次调用信用服务，扣除费用。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;试想这种情况：第一次调用信用卡服务成功，通过验证，而第二次（提出扣费申请时）发送了一个错误请求。&lt;/p&gt;
&lt;p&gt;简单来说，同一个服务在一小段时间后从可用状态变为不可用。&lt;/p&gt;
&lt;h3 id=&#34;temporal-discretization&#34;&gt;Temporal Discretization&lt;/h3&gt;
&lt;p&gt;大多数故障注入工具没有考虑到时间维度上的故障。&lt;/p&gt;
&lt;p&gt;首先，时间是一个连续的概念，往往考虑在请求的生命周期里发生故障，而忽略在发送请求时刻、流传输中发生故障；在一个确定时间引入故障或许没有什么意义。&lt;/p&gt;
&lt;p&gt;以上述案例为例，将前端服务视为黑盒，可以观察到信用卡服务可能不可用的四个离散的逻辑时间：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;在前端的第一次请求到来之前；&lt;/li&gt;
&lt;li&gt;在前端第一次请求到来之后，信用卡服务返回响应之前；&lt;/li&gt;
&lt;li&gt;在信用卡服务返回第一次响应之后，和前端请求第二次到来之前；&lt;/li&gt;
&lt;li&gt;在前端第二次请求到来之后，信用卡服务返回第二次响应之前。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;如果以粗粒度来看，前端调用信用卡服务发生的错误实际上又&lt;strong&gt;可以分为粒度更小的四种导致错误的原因&lt;/strong&gt;。&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;h3 id=&#34;communication-is-the-thing&#34;&gt;Communication is The Thing&lt;/h3&gt;
&lt;p&gt;3MileBeach为能够达成细粒度故障注入，从消息序列化、反序列化入手。例如从gRPC请求转换为HTTP请求，存在Protocol Buffer到JSON的序列化和反序列化过程。&lt;strong&gt;在该过程中添加元数据来装饰消息，以跟踪每个消息的上下文&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;因为远程服务的故障总是表现为服务边界出现的延迟、报错等错误。通过错误处理，避免引发blast radius，从而可以实现并发测试。&lt;/p&gt;
&lt;p&gt;通过对第三方库的修改（增加请求和响应消息的上下文传播），来对事件进行持续跟踪，记录完整的服务调用历程。&lt;/p&gt;
&lt;p&gt;通过故障注入逻辑检查这些数据，就可以得知以下信息：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;错误来自哪一个请求？which&lt;/li&gt;
&lt;li&gt;当前是哪一个服务遇到了错误？where&lt;/li&gt;
&lt;li&gt;注入的是什么服务？how&lt;/li&gt;
&lt;li&gt;故障何时被注入？when&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;实现&#34;&gt;实现&lt;/h2&gt;
&lt;h3 id=&#34;架构抽象&#34;&gt;架构抽象&lt;/h3&gt;
&lt;p&gt;下图定义了边界组件模型，即微服务框架和服务处理程序之间的边界。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/image-20220312124636575.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220312124636575&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;大多数微服务框架都提供了服务处理handler和边界组件的交互方式。&lt;/p&gt;
&lt;p&gt;Panorama [40] 通过将可观察性抽象为直接调用处理程序函数的方向和以（输入/输出）队列/代理作为缓存层的异步调用处理程序函数的间接性，引入了组件交互的四种设计模式。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Full direction。所有的函数被分配到一个线程，在该线程中依次调用入站操作、处理请求、出站操作。&lt;/li&gt;
&lt;li&gt;Inbound indirection。在被工作线程选择之前，将入站消息存到队列中，当出站组件调用时，被唤醒执行。&lt;/li&gt;
&lt;li&gt;Outbound indirection。入站组件和服务handler直接在一个工作线程中调用，处理后将消息放到出站线程队列等待被网络运输。&lt;/li&gt;
&lt;li&gt;Full indirection。将入站和出站的消息都放入队列进行调度，中间通过服务handler和网络请求唤醒调用。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;第2，3，4种做法都实现了上下文传播机制，可以通过handler和边界组件传递身份信息。&lt;/p&gt;
&lt;p&gt;因此3MileBeach选择上述的上下文传播的设计模式。&lt;/p&gt;
&lt;p&gt;入站组件对从网络来的row message进行反序列化，调用service handler。出站组件将处理后的message进行序列化。&lt;/p&gt;
&lt;p&gt;对数据流进行两种抽象：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Direct Response Circle（&lt;strong&gt;DRC&lt;/strong&gt;）；&lt;/li&gt;
&lt;li&gt;Synchronized Request-Response Circle（&lt;strong&gt;SRC&lt;/strong&gt;）。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;数据结构&#34;&gt;数据结构&lt;/h3&gt;
&lt;p&gt;将负载命名为&lt;em&gt;3mb-payload&lt;/em&gt;，具体实现称为&lt;strong&gt;Trace&lt;/strong&gt;。Trace是一个高层数据结构，由以下三部分组成：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;一系列的事件（Event-s）；&lt;/li&gt;
&lt;li&gt;必要的追踪元数据（如ID），来帮助3MileBeach为追踪识别和组装事件；&lt;/li&gt;
&lt;li&gt;一个故障注入配置列表（fault injection configuration-s，FIC-s）&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;event&#34;&gt;Event&lt;/h4&gt;
&lt;p&gt;Event记录了一个事件的必要信息，从中可以知道在什么时候那哪个服务接收或者发送了一个请求或一个响应，并且具体的服务名字。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Timestamp&lt;/li&gt;
&lt;li&gt;Service&lt;/li&gt;
&lt;li&gt;Action&lt;/li&gt;
&lt;li&gt;MessageType&lt;/li&gt;
&lt;li&gt;Name&lt;/li&gt;
&lt;li&gt;UUID&lt;/li&gt;
&lt;li&gt;&amp;hellip;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如下图所示，有4个事件联系到同一个UUID，指明一个SRC。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/image-20220312135514421.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220312135514421&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;其中两个由Svc1记录，一个是在Svc1发送请求时记录的，另一个是在Svc1接收响应时记录的。&lt;/p&gt;
&lt;h4 id=&#34;fault-injection-configuration&#34;&gt;Fault Injection Configuration&lt;/h4&gt;
&lt;p&gt;使用FIC来描述一个TFI和RLFI（Request Level Fault Injection）测试案例。&lt;/p&gt;
&lt;p&gt;考虑一个应用由n个服务组成。RLFI在客户端级请求生命周期中将故障注入服务。我们使用FIC{Type: Crash, Name: Svc_i}来表示服务i的故障。为测试所有的崩溃模式，RLFI的实验空间有$2^n$个。但是在模拟客户端级别的请求时，不需要调用全部的微服务。例如有m个服务不会被调用，实际上只需要调用$2^{n-m}$个案例。&lt;/p&gt;
&lt;p&gt;在TFI中，根据逻辑时序在某个测试的执行期间模拟故障。文章使用&lt;strong&gt;After&lt;/strong&gt;，这是一个&lt;strong&gt;TFIMetas&lt;/strong&gt;列表，用此存储故障的临时先决条件。TFI 可以触发的故障空间是RLFI故障空间的超集，因为当After为空时，RLFI是TFI的特例。&lt;/p&gt;
&lt;p&gt;另外通过时间离散化，FIC可以大大减少TFI的测试空间。&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;如上图 ，Svc1在处理客户端请求时，从Svc0处接收到Req1和Req2。RLFI只判断这两个请是成功还是失败。如果希望Req2失败而不影响Req1，我们模拟的错误应发生在t1-t2时，而在t3之后结束。&lt;/p&gt;
&lt;p&gt;而TFI通过模拟崩溃时间来缩减故障的注入时间段，即在t1-t2之间注入故障，使用如下FIC来描述：FIC{Type: Crash, Name: Req2, After: [TFIMeta{Name: Req1, Times:1}]}。&lt;/p&gt;
&lt;h3 id=&#34;算法&#34;&gt;算法&lt;/h3&gt;
&lt;p&gt;本部分主要讲如何通过序列化&lt;em&gt;3mb-payload&lt;/em&gt;来接入边界组件，以及重写序列化函数在数据流中的作用。&lt;/p&gt;
&lt;h4 id=&#34;interpose-via-serialization-functions&#34;&gt;Interpose via Serialization Functions&lt;/h4&gt;
&lt;p&gt;为追踪处理客户端请求的服务，3MileBeach扩展了序列化函数，叫做&lt;strong&gt;Deserialize’ Serialize’&lt;/strong&gt;。使用存储S来存储追踪的上下文对象Ctx。Ctx来源于现存的上下文传播机制，携带了请求的元数据。&lt;/p&gt;
&lt;p&gt;在入站组件中，3MileBeach从入站消息获取ID，并将ID分配给Ctx（算法1）。当服务handler发送请求时，3MileBeach将观测到的追踪数据（这个数据存在S中）附加在出站消息中（算法2）。下表中有相关的关键函数。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/image-20220313151022017.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220313151022017&#34;
	
	
&gt;&lt;/p&gt;
&lt;h4 id=&#34;serialization-functions-and-data-flows&#34;&gt;Serialization Functions and Data Flows&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Direct Response Circle (DRC)&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
&lt;li&gt;框架从上游服务或client接收请求；&lt;/li&gt;
&lt;li&gt;入站组件唤醒Deserialize’将请求反序列化，将事件作为追踪记录，并存储到S中，将追踪元数据写到Ctx中；&lt;/li&gt;
&lt;li&gt;框架调用服务handler并等待调用结束;&lt;/li&gt;
&lt;li&gt;框架收到响应；&lt;/li&gt;
&lt;li&gt;出站组件唤醒Serialize’，并从S中检索追踪Ctx的元数据，追加到发送事件，序列化响应；&lt;/li&gt;
&lt;li&gt;框架返回响应到上游服务或client。&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Synchronized Request-Response Circle (SRC)&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
&lt;li&gt;服务handler通过阻塞函数调用发送一个请求到下游服务；&lt;/li&gt;
&lt;li&gt;出站组件唤醒Serialize’，从S和Ctx中检索追踪数据，这些数据是微服务从上游服务或client的SEND事件中来的，模拟了故障信息。调用序列化函数对消息进行序列化；&lt;/li&gt;
&lt;li&gt;框架发送请求给下游服务并等待响应；&lt;/li&gt;
&lt;li&gt;框架收到下游的响应；&lt;/li&gt;
&lt;li&gt;入站请求唤醒Deserialize将响应反序列化，追加事件并存储；&lt;/li&gt;
&lt;li&gt;服务handler会接受响应。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/image-20220313155122436.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220313155122436&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/image-20220313155136954.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220313155136954&#34;
	
	
&gt;&lt;/p&gt;
&lt;h4 id=&#34;fault-simulation&#34;&gt;Fault Simulation&lt;/h4&gt;
&lt;p&gt;3MileBeach通过模拟下游的外部可观测错误来实现故障注入，从请求者的角度来看，这些错误可能是由于网络问题或者返回响应的handler产生。&lt;/p&gt;
&lt;p&gt;3MileBeach不会因为故障测试而崩溃或者重启，因此可以执行并发测试，也能控制blast radius。&lt;/p&gt;
&lt;p&gt;典型的SRC包括两个服务和两个数据流。（Requester Responder ReqFlow RespFlow）。故障触发时，requester不能知道下游的故障根源，这取决于具体的实现，它能知道这些错误的返回码，例如timeout、connection closed、package loss等，依次证实的确发现了问题。&lt;/p&gt;
&lt;p&gt;3MileBeach在FICs定义的故障触发条件得到满足时触发故障。&lt;/p&gt;
&lt;h2 id=&#34;实验&#34;&gt;实验&lt;/h2&gt;
&lt;p&gt;测量3MileBeach框架的端到端的延迟来展示其效率表现，并提供两个本地案例。&lt;/p&gt;
&lt;h3 id=&#34;实验设置&#34;&gt;实验设置&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;演示程序：Hipster Shop，一个部署在GKE上的微服务程序。&lt;/li&gt;
&lt;li&gt;客户端生成测试用例来进行跟踪和故障注入、应用性能调整及错误定位。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;hipster-shop&#34;&gt;Hipster Shop&lt;/h4&gt;
&lt;p&gt;包含以下微服务：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Frontend - &lt;strong&gt;Svc_fe&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;CART - &lt;strong&gt;Svc_cart&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Recommendation&lt;/li&gt;
&lt;li&gt;ProductCatalog - &lt;strong&gt;Svc_p&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Shipping&lt;/li&gt;
&lt;li&gt;Currency - &lt;strong&gt;Svc_c&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Payment&lt;/li&gt;
&lt;li&gt;Email&lt;/li&gt;
&lt;li&gt;Checkout&lt;/li&gt;
&lt;li&gt;Ad - &lt;strong&gt;Svc_a&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;涉及到的序列化库有：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;JSON&lt;/li&gt;
&lt;li&gt;PROTOCOL&lt;/li&gt;
&lt;li&gt;RESTFUL&lt;/li&gt;
&lt;li&gt;GRPC&lt;/li&gt;
&lt;li&gt;GORILLA等&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;开发语言：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GO&lt;/li&gt;
&lt;li&gt;C#&lt;/li&gt;
&lt;li&gt;Node.js&lt;/li&gt;
&lt;li&gt;Python&lt;/li&gt;
&lt;li&gt;Java&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;综上，可以看出这个应用很适合作为microservice的代表来对3MileBeach进行测试。&lt;/p&gt;
&lt;h4 id=&#34;clusters&#34;&gt;Clusters&lt;/h4&gt;
&lt;p&gt;集群情况如下：&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;h4 id=&#34;client&#34;&gt;Client&lt;/h4&gt;
&lt;p&gt;客户端在不同级别的并发下向Svc_fe发送请求，使用N来确定并发数。同时，将应用和Client部署在一个集群上以最大程度减少网络延迟。&lt;/p&gt;
&lt;h3 id=&#34;tracing-benchmark&#34;&gt;Tracing Benchmark&lt;/h3&gt;
&lt;p&gt;本部分涉及到链路追踪情况，主要考察增加链路追踪给系统带来的延迟上的开销。通过并发测量端到端延迟来比较。&lt;/p&gt;
&lt;p&gt;在进行追踪时势必会给系统增加开销，因此在这方面进行比较，与Jaeger框架进行比较。以下为延迟情况以及延迟和吞吐量之间的关系。&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/image-20220314162513457.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220314162513457&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;fault-injection&#34;&gt;Fault Injection&lt;/h3&gt;
&lt;p&gt;为测试3MileBeach对TFI测试的速度，在Svc_fe中设计了两个bug：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;DEEPRLFI。它在Svc_a和Svc_c都关闭时可以触发，不受事件影响。所以需要使用&lt;em&gt;3mb-payloads&lt;/em&gt;来同时触发Svc_a和Svc_c的崩溃。&lt;/li&gt;
&lt;li&gt;SimpleTFI。是一个TOCTTOU bug。为了触发这个问题，需要让请求携带可以使Svc_c崩溃的&lt;em&gt;3mb-payloads&lt;/em&gt;。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;通过下面几个图详细说明：&lt;/p&gt;
&lt;p&gt;（a）第一次调用Svc_c，Svc_fe可以容错；若Svc_c可访问，Svc_fe会认为在整个过程中Svc_c都是可以工作的；反正，Svc_fe会执行回退策略，使用默认的价钱。注意红色！的位置，Currency没有正常返回数据，但Svc_fe最终仍可以正常运行完，参考最后的绿色箭头。使用RLFI去模拟Svc_c的崩溃可以得到对应的结果。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/image-20220314163636670.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220314163636670&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;（b）当Svc_a不可用时，Svc_fe会应用回退策略，使用默认的广告推荐，并继续向Svc_c发送请求进行结算。使用RLFI去模拟Svc_a的崩溃可以得到对应的结果。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/image-20220314163715311.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220314163715311&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;（c）由上面两张图看出，在Currency和Ad二者中，只有一个出现问题时并不会引发Frontend的崩溃。下图则表示当Ad和Currency都崩溃时，Fronted才会崩。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/image-20220314163733335.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220314163733335&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/image-20220314163756339.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220314163756339&#34;
	
	
&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Faa$T: A Transparent Auto-Scaling Cache for Serverless Applications</title>
        <link>https://lizonglingo.github.io/p/faat-a-transparent-auto-scaling-cache-for-serverless-applications/</link>
        <pubDate>Mon, 07 Mar 2022 15:48:15 +0800</pubDate>
        
        <guid>https://lizonglingo.github.io/p/faat-a-transparent-auto-scaling-cache-for-serverless-applications/</guid>
        <description>&lt;blockquote&gt;
&lt;p&gt;来源：ACM SoCC&#39;21&lt;/p&gt;
&lt;p&gt;作者：Microsoft Research&amp;amp;Stanford University&amp;amp;Microsoft Azure&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;摘要&#34;&gt;摘要&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;问题来源：FaaS平台依赖远程存储来维护状态信息，限制了FaaS应用的运行效率。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;难点：FaaS平台的一些缓存工作尝试解决这个问题，但是&lt;strong&gt;由于FaaS应用不同的特点，难以基于业务负载的弹性的调整缓存容量&lt;/strong&gt;。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;解决方案：文章提出了Faa$T，一个自动伸缩的分布式FaaS缓存系统：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;每个FaaS应用有自己的缓存，在被调用、函数被激活时，应用程序从内存加载到缓存；&lt;/li&gt;
&lt;li&gt;在下一次调用时，可以使用缓存将应用程序“预热”，加快访问速度（冷启动问题？）。&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;缩放依据：根据工作集和对象的大小管理缓存I/O带宽。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;实验表现：最大提高92%的FaaS应用性能表现（平均57%）。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;问题来源&#34;&gt;问题来源&lt;/h2&gt;
&lt;h3 id=&#34;faas内存回收和冷启动&#34;&gt;FaaS内存回收和冷启动&lt;/h3&gt;
&lt;p&gt;FaaS厂商为控制效益，在function不工作时会将其从内存中卸载掉。&lt;/p&gt;
&lt;h3 id=&#34;stateless应用的状态维护依赖远端存储&#34;&gt;Stateless应用的状态维护依赖远端存储&lt;/h3&gt;
&lt;p&gt;FaaS function通常具有无状态的特点，但在业务中往往需要维护一些状态，例如以下场景：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;下一次函数的调用需要上一次调用的状态信息；&lt;/li&gt;
&lt;li&gt;函数pipeline多阶段执行，一个函数的执行需要依赖另一个函数的结果；&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这是现实的问题，&lt;strong&gt;现有的解决方案是将状态信息写到远端存储中&lt;/strong&gt;（如Amazon S3），在需要时将其从远端存储读出来。&lt;/p&gt;
&lt;p&gt;而&lt;strong&gt;远端存储的一个不可避免的问题在于更高的延迟和更低的带宽&lt;/strong&gt;，同时增加开销和管理成本。&lt;/p&gt;
&lt;h2 id=&#34;研究现状&#34;&gt;研究现状&lt;/h2&gt;
&lt;p&gt;本地缓存策略作为缓解上述问题的方案，已经有了初步的解决方案。&lt;/p&gt;
&lt;h3 id=&#34;现有方案存在如下不足&#34;&gt;现有方案存在如下不足&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;为多个应用实现单个缓存，&lt;strong&gt;忽略了FaaS应用程序的广泛不同特性&lt;/strong&gt;。例如很多应用的调用频率非常低[48]，为这种应用实现缓存实际上没有必要；但是，如果不为这些应用配置缓存又会影响到服务质量。&lt;/li&gt;
&lt;li&gt;先前的方案中，要么就是&lt;strong&gt;缓存大小是固定的&lt;/strong&gt;，要么就是&lt;strong&gt;缓存伸缩仅根据计算负载&lt;/strong&gt;。这些方案在数据访问模式稳定和工作集大小小于缓存容量时很有效。&lt;/li&gt;
&lt;li&gt;没有考虑到&lt;strong&gt;大数据对象访问的问题&lt;/strong&gt;，由于数据量大、VM/容器资源竞争、I/O带宽的限制，在访问大数据对象时会出现性能下降问题。在如机器学习推理这样的大数据量应用中，缓存的横向扩容能使这种服务的性能大大提升。&lt;/li&gt;
&lt;li&gt;现有的&lt;strong&gt;缓存机制对用户来说不透明&lt;/strong&gt;，需要明确的指定；要么就是提供了一个单独的API来访问缓存。这违背了FaaS平台让用户在管理不必要资源中解脱出来的初衷。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;文章做的工作&#34;&gt;文章做的工作&lt;/h3&gt;
&lt;p&gt;文章表示，问题的根源在于，&lt;strong&gt;Serverless的Cache层从未实现真正的Serverless——与应用程序无感绑定、自动缩放、对上层用户透明&lt;/strong&gt;。&lt;/p&gt;
&lt;h4 id=&#34;faat的特性和作用&#34;&gt;Faa$T的特性和作用&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;是&lt;strong&gt;内存层面的缓存&lt;/strong&gt;；&lt;/li&gt;
&lt;li&gt;每个应用将本地Faa$T缓存加载到内存中，缓存在应用程序运行时&lt;strong&gt;透明的管理&lt;/strong&gt;程序所访问的数据；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;应用从内存中被卸载时，Faa$T也会被卸载&lt;/strong&gt;（对那些调用频率低的应用来说，在他们很长时间不被调用时，其缓存也会被卸载）；&lt;/li&gt;
&lt;li&gt;该方法&lt;strong&gt;消除的对远程缓存存储的需求，减少远程流量开销&lt;/strong&gt;，降低成本；&lt;/li&gt;
&lt;li&gt;针对不同的应用提供&lt;strong&gt;不同的替换策略和维持策略&lt;/strong&gt;；&lt;/li&gt;
&lt;li&gt;应用重新加载时可以&lt;strong&gt;预先将最常用的数据加载至缓存&lt;/strong&gt;中。&lt;/li&gt;
&lt;li&gt;对缓存的扩缩容策略的方案是：a）为从远程存储中获取大对象&lt;strong&gt;增加传输带宽&lt;/strong&gt;；b）&lt;strong&gt;增加经常访问的远程数据的整体缓存大小&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;对于分布式缓存存储，默认是&lt;strong&gt;强数据一致性&lt;/strong&gt;，一致性和扩展策略也支持自定义。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;contributions&#34;&gt;Contributions&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;通过FaaS提供商的工作负载，总结了数据访问模型；&lt;/li&gt;
&lt;li&gt;设计和实现了Faa$T，一个透明的FaaS应用自动扩缩容缓存；&lt;/li&gt;
&lt;li&gt;提出Faa$T扩展策略，根据数据访问模式和对象大小调整带宽和缓存大小；&lt;/li&gt;
&lt;li&gt;拓宽了可以在FaaS上以接近本机性能运行程序的范围，如ML程序和Jupyter notebook。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;对faas应用和缓存的分析&#34;&gt;对FaaS应用和缓存的分析&lt;/h2&gt;
&lt;h3 id=&#34;表征当前的faas应用&#34;&gt;表征当前的FaaS应用&lt;/h3&gt;
&lt;p&gt;文章收集了一段时间内FaaS Provider的日志数据，信息如下。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lizonglin313/MyPicGo/master/image-20220305194809781.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220305194809781&#34;
	
	
&gt;&lt;/p&gt;
&lt;h4 id=&#34;数据大小&#34;&gt;数据大小&lt;/h4&gt;
&lt;p&gt;包括20.3million不同的对象，大小有1.9TB。数据访问模式分布如下图：&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;80%的数据大小小于12KB；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;有25%的数据小于600B；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;也有很少的一些数据大于1.8GB；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;对数据的&lt;strong&gt;读取次数远远大于对数据的写入次数&lt;/strong&gt;；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;虽然应用到后端数据存储有较大的带宽，但&lt;strong&gt;对小数据对象大量的访问加剧了存储延迟&lt;/strong&gt;。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;数据访问和重用&#34;&gt;数据访问和重用&lt;/h4&gt;
&lt;p&gt;下图展示了FaaS应用每次调用访问不同的Blobs（一个存储系统）的比率。&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;大部分应用被调用时只访问一个单独的存储&lt;/strong&gt;；&lt;/li&gt;
&lt;li&gt;约11%的应用被调用时访问多个存储系统；&lt;/li&gt;
&lt;li&gt;超过32%的应用在&lt;strong&gt;多次数据访问中访问同一个Blob&lt;/strong&gt;，更有7.7%的应用在100次调用中访问同一个Blob，还有一个应用在1000次调用中访问一个Blob；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;大多数应用会使用不超过100个不同的Blobs&lt;/strong&gt;；&lt;/li&gt;
&lt;li&gt;所有的数据访问&lt;strong&gt;一共涉及到2.6TB的数据，而所有的数据语料只有1.9TB&lt;/strong&gt;；&lt;/li&gt;
&lt;li&gt;这意味如果缓存已访问过的数据会节省27%的流量和54.3%的远程存储；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;跨应用、用户和地区的数据共享情况极为罕见&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;时间访问模式&#34;&gt;时间访问模式&lt;/h4&gt;
&lt;p&gt;下图展示了每个应用访问Blob的时间维度的模式：X轴是读写Blob函数的调用次数，Y轴是这些调用的到达间隔时间的变异系数（CoV， coefficient of variation），每个点代表具有3次访问次数以上的blob（少于三次不能计算变异系数）。&lt;/p&gt;
&lt;p&gt;CoV为1表示到达间隔呈泊松分布，接近0表示周期性到达，大于1表示比泊松到达更大的突发性。&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;可以看出，多数时间访问模式具有突发性的特点。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;访问性能&#34;&gt;访问性能&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;写操作通常快于读操作&lt;/strong&gt;（因为写入操作使用到了buffer，而且不需要在所有实例间同步持久化数据，读数据需要等待存储处理数据）；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;较小的Blob的吞吐量相对较低&lt;/strong&gt;，因为握手的开销相对于数据量来说过大。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;多样的调用模式&#34;&gt;多样的调用模式&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;调用模式的差异较大，&lt;strong&gt;81%的应用平均每分钟最多调用一次，更有45%的应用每小时平均调用一次&lt;/strong&gt;；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;不到20%的应用产生了99%以上的调用次数&lt;/strong&gt;，这与在日志中的数据表现一致。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这就带来一个问题，为这些&lt;strong&gt;调用次数很少的应用缓存数据可能是浪费的，但这又关系到大部分用户体验&lt;/strong&gt;。&lt;/p&gt;
&lt;h4 id=&#34;其他发现&#34;&gt;其他发现&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;超过30%的请求调用相同的数据&lt;/strong&gt;，这意味着缓存在数据复用上可以产生效果；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;访问的数据大小跨越了9个数量级&lt;/strong&gt;，从bytes到GBs；&lt;/li&gt;
&lt;li&gt;函数调用的频率也有9个数量级的不同。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;缓存分析&#34;&gt;缓存分析&lt;/h3&gt;
&lt;p&gt;如果缓存可以起作用，那么应满足如下三个关键条件：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;数据访问有良好的&lt;strong&gt;时间局部性和重用&lt;/strong&gt;；&lt;/li&gt;
&lt;li&gt;应&lt;strong&gt;同时适用于调用频繁和调用次数很少的应用&lt;/strong&gt;；&lt;/li&gt;
&lt;li&gt;缓存应利用&lt;strong&gt;空间局部性&lt;/strong&gt;尽可能&lt;strong&gt;减少访问大数据对象的开销&lt;/strong&gt;。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;根据后续分析，还应有以下的特点：&lt;/p&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;缓存还应和应用程序进行绑定，不需要独立管理；&lt;/li&gt;
&lt;li&gt;缓存还需要对用户透明，并且没有代码入侵性；&lt;/li&gt;
&lt;li&gt;有多样的伸缩策略，如：a）根据应用负载变化扩展能力？，b）根据数据重用模式改变缓存大小，c）基于访问的数据对象大小改变远程存储带宽。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;现有的缓存系统的局限性&#34;&gt;现有的缓存系统的局限性&lt;/h3&gt;
&lt;p&gt;下图是一些缓存系统的表征：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lizonglin313/MyPicGo/master/image-20220305194853159.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220305194853159&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;缓存系统和应用是分离的，缓存系统独立管理，当应用在内存中卸载时，用户需要额外管理缓存状态或缓存所在的服务，&lt;strong&gt;所以缓存还应和应用程序进行绑定&lt;/strong&gt;；&lt;/li&gt;
&lt;li&gt;需要进行配置，并表现出代码入侵的现象，需要改动代码来使用缓存，&lt;strong&gt;所以缓存还需要对用户透明，并且没有入侵性&lt;/strong&gt;；&lt;/li&gt;
&lt;li&gt;在伸缩上仅基于计算负载，但实际的工作情况更加负载，文章建议是缓存层的弹性应考虑以下几点：&lt;strong&gt;a）根据应用负载变化扩展能力？，b）根据数据重用模式改变缓存大小，c）基于访问的数据对象大小改变远程存储带宽&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;为现有faas平台扩展新的应用类型&#34;&gt;为现有FaaS平台扩展新的应用类型&lt;/h3&gt;
&lt;h4 id=&#34;机器学习推理pipeline&#34;&gt;机器学习推理pipeline&lt;/h4&gt;
&lt;p&gt;许多业务如健康检查、广告推荐、零售都依赖机器学习。FaaS的按需计算和伸缩很适合ML这种工作负载难以预测的应用。但机器学习需要较低的时延，例如实时人脸识别的需求。下图是一个应用场景：&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;完成这一个场景通常需要秒级的性能甚至不超过1s。文章将上述场景部署在本地的虚拟机和真实的FaaS生产环境中，下图表明在FaaS平台上的速度比本地慢3.8倍，同时可以看出存层存储层的低效是造成延迟的最大因素：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lizonglin313/MyPicGo/master/image-20220306130658707.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220306130658707&#34;
	
	
&gt;&lt;/p&gt;
&lt;h4 id=&#34;jupyter-notebooks&#34;&gt;Jupyter notebooks&lt;/h4&gt;
&lt;p&gt;为验证Jupyter notebooks的性能，文章将其移植到FaaS平台，叫做JupyterLess。每一个cell被看作一个function被调用，cell之间的状态通过共享的中间存储层来保存。文章使用了一个350MB的DataFrame，共10个cell，在本地虚拟机和FaaS平台上进行比较。&lt;/p&gt;
&lt;p&gt;由于存在加载中间存储和从远程存储拉取DataFrame的问题，JupyterLess比本地慢63倍。&lt;/p&gt;
&lt;h2 id=&#34;faat设计&#34;&gt;Faa$T设计&lt;/h2&gt;
&lt;p&gt;Faa$T缓存在函数执行期间访问的对象，以便可以跨调用重用数据对象。不需要外部存储层和额外的服务，因此可以透明的绑定到应用上（而且是语言无关性）。&lt;/p&gt;
&lt;p&gt;当应用被卸载时，Faa$T收集有关缓存对象的元数据，并在程序重新加载到内存时用其预热缓存中常被访问到的对象，这对调用频繁的应用有很大的帮助。&lt;/p&gt;
&lt;p&gt;Faa$T的自动缩放依赖三个方面：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;基于一个&lt;strong&gt;应用每秒被调用的次数&lt;/strong&gt;，对那些调用频繁的应用非常有必要；（计算维度的伸缩）&lt;/li&gt;
&lt;li&gt;基于&lt;strong&gt;数据重用模式&lt;/strong&gt;，对涉及到大数据量、大工作集的应用很有必要；（缓存容量维度的伸缩）&lt;/li&gt;
&lt;li&gt;基于&lt;strong&gt;数据对象大小&lt;/strong&gt;，以扩展远程存储访问的带宽资源，加速应用和远程存储之间的网络I/O；（网络带宽维度的伸缩）。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;在应用加载到内存后，Faa$T使用一致散列有效的跨实例定位对象，无需大量的位置数据。&lt;/p&gt;
&lt;h3 id=&#34;系统架构&#34;&gt;系统架构&lt;/h3&gt;
&lt;p&gt;下图展示了FaaS平台上的Faa$T的架构：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lizonglin313/MyPicGo/master/image-20220306140156075.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220306140156075&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Faa$T和应用是一对一的，共同运行在FaaS Runtime中；&lt;/li&gt;
&lt;li&gt;Cachelet通过Member Daemon交互，确定数据对象的位置和所有者，所有者负载上传和下载远程数据对象；&lt;/li&gt;
&lt;li&gt;Load Daemon收集缓存对象的元数据，并用来决定在加载应用程序时需要预热哪些数据对象；&lt;/li&gt;
&lt;li&gt;Memory Darmon用来监控函数和缓存的内存消耗，避免内存占用导致应用出现问题；&lt;/li&gt;
&lt;li&gt;Frontend负责将请求负载均衡，Scale Controller负责根据运行时指标来增减实例数量。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;访问和缓存数据&#34;&gt;访问和缓存数据&lt;/h3&gt;
&lt;h4 id=&#34;读操作&#34;&gt;读操作&lt;/h4&gt;
&lt;p&gt;下图为读数据操作:&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;local hit：在本地的Faa$T数据缓存中命中；&lt;/li&gt;
&lt;li&gt;local miss：本地的Faa$T缓存中不存在要访问的数据，cachelet会从远程仓库中寻找数据；&lt;/li&gt;
&lt;li&gt;remote hit：在本地的Faa$T缓存中没有找到数据，但是在该数据的所有者的缓存中找到数据；&lt;/li&gt;
&lt;li&gt;remote miss：在本地缓存和数据对象所有者的缓存中均没有命中。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Faa$T使用一致哈希确定对象所有权。&lt;/p&gt;
&lt;h4 id=&#34;写操作&#34;&gt;写操作&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;当应用程序需要输出数据时，Faa$T会直接写入数据所有者缓存；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;执行该函数的实例将数据发送到所有者缓存，然后将其写入远程存储；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;写缓存和写远程存储是同步写入的。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这保证了所有者始终拥有应用数据的最新版本。应用程序可以将 Faa$T配置为异步写入或根本不写入远程存储。因为Faa$T绑定到每个应用程序，不同的应用程序可以同时使用不同的策略。&lt;/p&gt;
&lt;h4 id=&#34;一致性&#34;&gt;一致性&lt;/h4&gt;
&lt;p&gt;下图展示了可能发生的读写设置、性能和一致性表现、还有容错情况：&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;默认在读对象时，先验证缓存的版本是否与远程存储的版本是否匹配，在此期间不发生数据传输；&lt;strong&gt;如果匹配，不再检索对象是否发生变动，这种验证提供了强一致性保证&lt;/strong&gt;。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;但有些应用会放弃强一致性来换取性能&lt;/strong&gt;。此时，Faa$T可以读取任何缓存版本并异步写入远程存储。这样只能保证最终一致性，允许在某些时刻存在数据不一致的表现。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;还有，&lt;strong&gt;应用程序也可以完全跳过写入远程存储并依赖分布式缓存&lt;/strong&gt;。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;数据预热&#34;&gt;数据预热&lt;/h3&gt;
&lt;p&gt;为达到这一目的，Faa$T在应用被卸载时，记录了有关缓存的元数据。包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;缓存对象的大小；&lt;/li&gt;
&lt;li&gt;数据对象的版本；&lt;/li&gt;
&lt;li&gt;每个访问类型的次数（local hit、remote miss等）；&lt;/li&gt;
&lt;li&gt;对象的平均访问间隔时间等。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;使用卸载时间为时间戳，为收集的每个元数据进行标记，以捕获缓存的状态历史。&lt;/p&gt;
&lt;p&gt;Faa$T需要决定何时将应用加载到内存中，这里使用了混合直方图策略[48]，直方图跟踪应用调用之间的空闲时间，当应用被卸载时，使用直方图预测下一次调用可能到达的时间，并在该事件之前重新加载应用。这也适用于解决冷启动问题。&lt;/p&gt;
&lt;p&gt;同时，Faa$T也需要决定将哪些数据对象被加载到新的cachelet中。使用下面两个条件确定需要加载的对象：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;对象的local或remote命中率大于阈值，就加载该对象；&lt;/li&gt;
&lt;li&gt;在记录的元数据中多次设计一个对象，就加载该对象。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;在faat中清除数据&#34;&gt;在Faa$T中清除数据&lt;/h3&gt;
&lt;p&gt;FaaS应用所拥有的内存是事先规定好的，当函数和缓存对象消耗的内存达到一定数量时，就会将部分数据对象从缓存中剔除。&lt;/p&gt;
&lt;p&gt;这里文章实现了两种策略。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;LRU最近最少使用；&lt;/li&gt;
&lt;li&gt;目标对象的大小大于阈值。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;如果需要更多的内存，那么就先使用策略2，再使用策略1。&lt;/p&gt;
&lt;h2 id=&#34;faat扩缩容&#34;&gt;Faa$T扩缩容&lt;/h2&gt;
&lt;p&gt;Scale Controller监控了端到端性能和每个应用的工作负载。它也会周期性的询问每个应用是否需要投票以增减实例，正数表示增加实例，负数表示减少实例。&lt;/p&gt;
&lt;p&gt;Faa$T有三种缩放类型。&lt;/p&gt;
&lt;h3 id=&#34;compute-scaling&#34;&gt;Compute Scaling&lt;/h3&gt;
&lt;p&gt;基于请求数量、请求处理队列的大小以及平均响应时间，来扩展实例数量。&lt;/p&gt;
&lt;p&gt;服务性能下降、请求率过高或者处理队列过长，都会使实例数量增加，反之会减少实例数量。&lt;/p&gt;
&lt;h3 id=&#34;cache-size-scaling&#34;&gt;Cache size scaling&lt;/h3&gt;
&lt;p&gt;Faa$T还可以拓展来匹配工作集大小。例如JupyterLess的一个数据密集型难以提高缓存命中率，因此换入、换出的概率非常高。为解决这个问题，cachelet会跟踪缓存对象换入换出的次数，如果发现这样的情况经常发生，就扩大缓存容量。反之，缩小缓存容量。&lt;/p&gt;
&lt;h3 id=&#34;bandwidth-scaling&#34;&gt;Bandwidth scaling&lt;/h3&gt;
&lt;p&gt;Faa$T 还支持具有大型输入对象的应用程序。对于此类对象，Faa$T 将远程存储的下载平均分配到多个缓存中，以达到两个目的：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;为远程存储创建更高的累积 I/O 带宽；&lt;/li&gt;
&lt;li&gt;利用实例之间更高的通信带宽（与每个实例和远程存储之间的带宽相比，实例间的带宽更好，网络I/O更有效率）。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;当cachelet接收到对象访问时，使用如下公式计算多个实例和对象大小S的数据传输延迟$T_{DR}$:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lizonglin313/MyPicGo/master/image-20220307142349577.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220307142349577&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;N：实例数量；&lt;/li&gt;
&lt;li&gt;S：对象的大小；&lt;/li&gt;
&lt;li&gt;$T_{Load}$：实例加载的延迟；&lt;/li&gt;
&lt;li&gt;$BW_{BS}$和$BW_{Inst}$：记录不同的网络和远程存储的带宽。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;迭代过程在$T_{DR}$的变化小于10%或$T_{DR}$在迭代过程中增加时停止。&lt;/p&gt;
&lt;h3 id=&#34;handling-conflicting-scaling-requests&#34;&gt;Handling conflicting scaling requests&lt;/h3&gt;
&lt;p&gt;当扩缩容策略发生冲突时，控制器会优先处理扩容策略，因为这样更加保守。但是，如果所有策略都表明缩减实例不会导致问题时，就会缩容。&lt;/p&gt;
&lt;h3 id=&#34;idle-function-computation-resources&#34;&gt;Idle function computation resources&lt;/h3&gt;
&lt;p&gt;在一些情况，实例数量扩容可能会导致资源浪费。此时可以将一些低优先级的任务拿出来运行。&lt;/p&gt;
&lt;h2 id=&#34;实现&#34;&gt;实现&lt;/h2&gt;
&lt;h3 id=&#34;生产级别的faas平台&#34;&gt;生产级别的FaaS平台&lt;/h3&gt;
&lt;p&gt;应用包含一个或多个功能，Faa$T透明的加载和管理对象：触发器（接收http request）、数据输入（blob）、输出（消息队列）。用户可在使用时配置Faa$T的一些策略，如扩展策略、一致性策略、缓存置换策略等。&lt;/p&gt;
&lt;p&gt;下图展示了应用实例、FaaS Runtime还有function在VM或Docker Container中运行：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lizonglin313/MyPicGo/master/image-20220307144606555.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220307144606555&#34;
	
	
&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;接收到请求；&lt;/li&gt;
&lt;li&gt;Runtime收集请求输入并调用function，将参数传递；&lt;/li&gt;
&lt;li&gt;function处理完后，将结果返回给Runtime；&lt;/li&gt;
&lt;li&gt;Runtime继续执行，如将数据写入远程存储或消息队列。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;缓存数据&#34;&gt;缓存数据&lt;/h3&gt;
&lt;p&gt;运行时和function使用持久的RPC进行控制和数据交换。共享内存时Faa$T缓存数据的地方，通过传递共享内存中数据的地址，减少端到端时延。&lt;/p&gt;
&lt;p&gt;当运行时在调用函数前，准备进行数据绑定时，Faa$T先拦截并检查缓存。当函数产生输出时，Faa$T会缓存起来备用。&lt;/p&gt;
&lt;h2 id=&#34;实验评估&#34;&gt;实验评估&lt;/h2&gt;
&lt;h3 id=&#34;两个比较点&#34;&gt;两个比较点&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Faa$T给应用带来的性能提升；&lt;/li&gt;
&lt;li&gt;评估四种缓存访问情况：local hit、local miss、remote hit、remote miss。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;六个基准&#34;&gt;六个基准&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;本地的大型虚拟机，所有访问都在本地进行；&lt;/li&gt;
&lt;li&gt;没有集成Faa$T的大型FaaS平台Vanilla，对象的访问都在远程存储，它的最佳性能表现等同于Faa$T LM；&lt;/li&gt;
&lt;li&gt;InfiniCache[55]（IC），为远程实例配置Faa$T，类比Faa$T RH；&lt;/li&gt;
&lt;li&gt;Cloudburst（CB）的存储层，最佳实例表现等同Faa$T LH；&lt;/li&gt;
&lt;li&gt;Pocket，近似于手动管理的Redis VM，所有数据均已内存速度访问；&lt;/li&gt;
&lt;li&gt;商业级Redis服务。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;两个应用&#34;&gt;两个应用&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;ML推理应用；&lt;/li&gt;
&lt;li&gt;Jupyter notebook。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;主要以程序延迟和成本为指标。对ML应用，使用单模型和带有pipeline的推理。&lt;/p&gt;
&lt;p&gt;对于单模型，使用了两个不同的模型，在资源使用和延迟上都有所不同：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;SqueezeNet，5MB；&lt;/li&gt;
&lt;li&gt;AlexNet，239MB。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;带有推理管道的模型使用了上面提到的识别汽车和人脸的应用，边界模型（35MB）的输出被输入到人体识别（97MB）和汽车识别（5MB）的模型中。&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;对于 JupyterLess，有5个notebooks：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;单消息日志记录；&lt;/li&gt;
&lt;li&gt;对 350MB 的 DataFrame 列求和；&lt;/li&gt;
&lt;li&gt;进行数据收集和绘图的能力规划；&lt;/li&gt;
&lt;li&gt;FaaS数据表征特征；&lt;/li&gt;
&lt;li&gt;计数到 1K。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;函数数据对象由每个单元执行后的笔记本状态组成，以 JSON 格式存储。&lt;/p&gt;
&lt;h3 id=&#34;结果&#34;&gt;结果&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lizonglin313/MyPicGo/master/image-20220307153746200.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220307153746200&#34;
	
	
&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;hr&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lizonglin313/MyPicGo/master/image-20220307153938569.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220307153938569&#34;
	
	
&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lizonglin313/MyPicGo/master/image-20220307154114309.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220307154114309&#34;
	
	
&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lizonglin313/MyPicGo/master/image-20220307154157216.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220307154157216&#34;
	
	
&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lizonglin313/MyPicGo/master/image-20220307154307461.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220307154307461&#34;
	
	
&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lizonglin313/MyPicGo/master/image-20220307154412346.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220307154412346&#34;
	
	
&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lizonglin313/MyPicGo/master/image-20220307154445374.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Service-Level Fault Injection Testing</title>
        <link>https://lizonglingo.github.io/p/service-level-fault-injection-testing/</link>
        <pubDate>Thu, 24 Feb 2022 19:25:41 +0800</pubDate>
        
        <guid>https://lizonglingo.github.io/p/service-level-fault-injection-testing/</guid>
        <description>&lt;blockquote&gt;
&lt;p&gt;来源：ACM SoCC&#39;21&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://acmsocc.org/2021/accepted-papers.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://acmsocc.org/2021/accepted-papers.html&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;摘要为什么需要服务级别的故障注入测试&#34;&gt;摘要——为什么需要服务级别的故障注入测试&lt;/h2&gt;
&lt;p&gt;由于微服务架构的特点，负责每个模块的工程师只需专注自己的部分而不需要过多关注整个应用系统。这些应用程序的开发人员不一定都是分布式系统工程师，因此无法预计系统出现部分故障：一旦部署到生产环境中，他们的服务会面临一个或多个依赖项不可用的问题。&lt;/p&gt;
&lt;p&gt;作者提出了一种称为服务级故障注入测试的方法和一种称为 Filibuster 的原型实现，可用于在微服务应用程序开发的早期系统地识别弹性问题。&lt;/p&gt;
&lt;p&gt;Filibuster 将静态分析和 concolic-style 执行与一种新颖的动态缩减算法相结合，以扩展现有的功能测试套件，以最少的开发人员工作量覆盖故障场景。&lt;/p&gt;
&lt;p&gt;并使用 4 个真实工业微服务应用程序的语料库来进行实验。&lt;/p&gt;
&lt;h2 id=&#34;贡献&#34;&gt;贡献&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;一种测试微服务应用程序弹性的方法：服务级故障注入测试 (SFIT) &lt;strong&gt;结合了静态分析和 concolic 测试&lt;/strong&gt;，以探索微服务之间所有可能的故障，从现有的通过功能测试套件开始。&lt;/li&gt;
&lt;li&gt;一种新颖的动态缩减算法： SFIT 使用一种算法，通过利用将应用程序分解为独立的微服务来&lt;strong&gt;减少搜索空间的组合爆炸&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;实现了SFIT的原型Filibuster：这个基于 Python 的工具可用于测试与 HTTP 通信的服务。我们的原型允许在本地测试服务的弹性，并证明它可以在 Amazon CodeBuild CI/CD 环境中运行，以便在问题进入生产之前检测它们。&lt;/li&gt;
&lt;li&gt;用 Python 实现的微服务应用程序和错误的语料库：该语料库包含 8 个小型微服务应用程序，每个应用程序都展示了微服务应用程序中使用的单一模式；和 4 个从公开会议演讲中重新实现的行业示例：Audible、Expedia、Mailchimp 和 Netflix。&lt;/li&gt;
&lt;li&gt;在该语料库上对Filibuster进行评价：证明 Filibuster 可用于识别语料库中的所有错误。我们展示了通过动态缩减可能进行的优化，并提供了有关如何最好地设计微服务应用程序以实现可测试性的见解。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;难点&#34;&gt;难点&lt;/h2&gt;
&lt;p&gt;缺乏开源微服务工业应用程序及其相关的错误报告（这两个主要的语料库通常有助于软件测试领域的研究），回答这些错误是否可以在开发过程的早期检测到的问题并不简单。&lt;/p&gt;
&lt;p&gt;最终作者构建了4个案例语料库。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Audible：一家提供有声读物流媒体移动应用程序的公司。在他们的演示文稿中，他们描述了一个错误，即应用程序服务器在从 Amazon S3 读取数据时不会收到 NotFound 错误。此错误在代码中未处理，并通过一般错误消息传播回移动客户端。他们使用混沌工程发现了这个错误。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Expedia：一家提供旅行预订的公司。他们讨论了使用混沌工程来验证如果他们的应用程序服务器尝试从基于相关性对它们进行排序的服务中检索酒店评论，并且该服务不可用，他们将回退到另一个提供按时间排序的评论。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Mailchimp：一款用于电子邮件通讯管理的产品。在他们的演示中，他们讨论了两个错误。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;遗留代码无法处理其数据库服务器返回的指示其为只读情况的错误代码。&lt;/li&gt;
&lt;li&gt;一项服务变得不可用并将未处理的错误返回给应用程序。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Netflix：讨论了他们使用混沌工程基础设施发现的几个错误。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;错误配置的超时，某个服务调用不正确配置，导致请求花费比预期更长的时间，但保持在超时间隔内。&lt;/li&gt;
&lt;li&gt;服务配置了回退指向错误的服务。&lt;/li&gt;
&lt;li&gt;关键的为服务没有配置回退。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;架构概述&#34;&gt;架构概述&lt;/h2&gt;
&lt;p&gt;SFIT 采用开发人员优先的方法，尽早将故障注入测试集成到开发过程中，而无需开发人员使用特定的规范语言编写规范。&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;SFIT 建立在开发微服务应用程序的以下三个关键点上。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;微服务独立开发：由于微服务之间可以通过约定的API进行通信，负责其他模块的个别团队成员通常不能很好地理解超出其控制范围的服务的状态或内部结构，无法编写应用程序的详细规范以使用模型检查器自动验证它。&lt;/li&gt;
&lt;li&gt;Mock测试可以防止问题出现：虽然编写模拟测试可以查出一些问题，但是由于这费时费力，对开发来说效益太少，所以开发人员很少进行测试。&lt;/li&gt;
&lt;li&gt;功能测试的重要性：开发人员编写多个验证应用程序行为的端到端功能测试，而不是编写规范。任何成功的故障注入方法都应该从功能测试开始。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;sfit的实现思路&#34;&gt;SFIT的实现思路&lt;/h3&gt;
&lt;p&gt;基于上述三个关键点及下面的两个简单假设：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;服务通过HTTP进行通信。&lt;/li&gt;
&lt;li&gt;一个单一的功能测试可以实现所有应用程序行为。&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;测试流程概述&#34;&gt;测试流程概述&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;假设从一个通过的功能测试开始，该测试由开发人员编写，在一些未失败的场景下执行应用程序，并验证一些应用程序行为。我们假设通过测试已经排除了逻辑错误。&lt;/li&gt;
&lt;li&gt;在该测试点注入故障。如果请求出现多种错误，则为每一个错误安排一次测试。这些后续执行被放置在堆栈上，并递归地应用该策略，直到所有路径都被探索。这种算法的灵感来自于DART的concolic测试算法[28]。&lt;/li&gt;
&lt;li&gt;以Audible App的例子来说，第一个请求发现内容分发服务出现了&lt;em&gt;Timeout or ConnectionError&lt;/em&gt;。然后我们向堆栈中追加两次测试执行。&lt;/li&gt;
&lt;li&gt;接着对内容分发服务进行堆栈中的测试，如果测试中暴露出新的问题，就可以寻找新的错误路径，内容交付引擎的故障可能会导致另一条路径暴露给日志服务。我们继续探索，直到所有的道路都被充分探索。（如：内容交付引擎的故障可能是由于日志服务暴露出的问题，因此搜索到日志服务路径。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;在本例中，多个服务具有相互依赖关系；例如，音频下载服务与所有权服务、激活服务和统计服务对话。在这种情况下，我们必须安排覆盖整个失败空间的执行——每个服务可能独立失败的所有方式，以及由于微服务相互影响而导致失败的所有组合。在第4节中，我们将讨论如何减少冗余的路径搜索。&lt;/p&gt;
&lt;p&gt;此外，在进行故障注入测试时，需要根据故障情况调整功能测试。为此作者开发了帮助组件使得开发者可以编写条件断言来判断错误的出现。还提供了一个机制来重现错误。&lt;/p&gt;
&lt;h4 id=&#34;故障注入&#34;&gt;故障注入&lt;/h4&gt;
&lt;p&gt;该注入方法可以对远程调用继续注入，并通过远程库改变响应。例如一些HTTP、gRPC的库。故障注入的设计思路如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;不返回远程服务的实际响应&lt;/li&gt;
&lt;li&gt;基于注入的故障返回故障响应（通过修改远程服务响应）&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;故障识别&#34;&gt;故障识别&lt;/h4&gt;
&lt;p&gt;故障识别主要包含&lt;strong&gt;识别具体的故障&lt;/strong&gt;和&lt;strong&gt;识别故障发生于哪一个微服务&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;注入的故障类型都源自于微服务可能发生的故障类型。通常有以下两种错误：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;服务调用端故障。如Python的&lt;em&gt;request&lt;/em&gt;库在发出请求时会有23中意外情况。可以通过指定包含异常的模块或者配置中手动指定这些问题，依此识别故障。这里作者将该类请求中的&lt;em&gt;Timeout&lt;/em&gt;和&lt;em&gt;ConnectionError&lt;/em&gt;作为主要考虑的错误类型。&lt;/li&gt;
&lt;li&gt;被调用端故障。被调用的服务也可能返回一个错误响应。例如一个服务依赖的另一个微服务抛出了&lt;em&gt;Timeout&lt;/em&gt;，那这个服务就可能返回&lt;em&gt;500&lt;/em&gt;。作者通过对程序源码使用静态分析技术对类似的响应进行识别。例如在Flask框架中查找&lt;em&gt;return&lt;/em&gt;或&lt;em&gt;raise&lt;/em&gt;语句。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;但还存在一个问题：在使用HTTP做请求时，&lt;strong&gt;请求的URL并不能作为识别服务本体的标识&lt;/strong&gt;。为解决这个问题，使用额外的工具记录调用的服务。该工具放置在接收服务请求的Web框架上，因此可以在被调用之前记录被调用者的服务信息。在获取该被调用者的信息后，将信息传给中台，以便进行后续的测试。&lt;/p&gt;
&lt;h4 id=&#34;注入故障后对功能的调整&#34;&gt;注入故障后对功能的调整&lt;/h4&gt;
&lt;p&gt;开发者需要根据故障注入的结果去调整功能，修复没有考虑到的问题。作者提供了一个帮助模块去编写故障断言，例如：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;a&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;fault&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;was&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;injected&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;on&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;Service&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;A&lt;/span&gt; {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;...&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;对系统行为在失败的情况下进行捕获和处理。开发人员应将这些条件断言添加到现有的功能测试中。&lt;/p&gt;
&lt;p&gt;一个典型的流程如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;开发者进行功能测试并通过。&lt;/li&gt;
&lt;li&gt;注入故障&lt;/li&gt;
&lt;li&gt;原有的功能测试因为故障的注入出现问题&lt;/li&gt;
&lt;li&gt;开发者通过提供的帮助工具，可以对新出现的故障进行断言，从而捕获因故障注入出现的故障。例如：Audible会报出&lt;code&gt;if a fault was injected on the stats ser- vice, the service should still play the audiobook.&lt;/code&gt;。基于此，开发者可以使用反例来重现先前的测试，以证明这些断言。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;故障搜索路径动态缩减&#34;&gt;故障搜索路径动态缩减&lt;/h2&gt;
&lt;p&gt;为了识别尽可能多的错误，必须理想地探索服务失败的组合。为了实现故障空间的最大覆盖所需的测试执行次数是非常多的。&lt;/p&gt;
&lt;p&gt;但是，可将应用分解成多个独立的微服务来显著减少搜索空间并且保证完整性。以下图为例：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lizonglin313/MyPicGo/master/image-20220224122453207.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220224122453207&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;对于ads服务&#34;&gt;对于ADS服务&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;先只考虑服务子集的故障，如ADS下载服务和CDS内容分发服务以及他们的依赖项。&lt;/li&gt;
&lt;li&gt;对于ADS可能产生的故障，需要考虑三种依赖类别：
&lt;ol&gt;
&lt;li&gt;Ownership：验证某个用户是否拥有某本书的所有权；&lt;/li&gt;
&lt;li&gt;Activation：验证用户的请求；&lt;/li&gt;
&lt;li&gt;Stats：对本次事件改变的状态进行记录；&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;如果上面三个依赖服务中的任何一个出现失败，那么ADS服务就会返回错误。但需要注意，Stats的失败不会影响这次请求的结果（因为“where stats failures are ignored”）。&lt;/li&gt;
&lt;li&gt;因此，Ownership和Activation的失败会导致ADS返回&lt;em&gt;500&lt;/em&gt;，但Stats的失败不会影响ADS，如果Ownership和Activation成功而Stats失败，ADS仍返回&lt;em&gt;200&lt;/em&gt;。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;对于cds服务&#34;&gt;对于CDS服务&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;CDS服务依赖的微服务子集是Asset Metadata和Audio Assets，我们需要考虑这两个服务会发生的故障以及他们组合起来会发生的故障。&lt;/li&gt;
&lt;li&gt;但是，由于ADS的请求URL&lt;code&gt;/user/&amp;lt;uesr_id&amp;gt;/books/&amp;lt;book_id&amp;gt;&lt;/code&gt;与Stats的URL相同，又因为CDS服务依赖于ADS服务，所以也应当将Stats服务考虑进去。&lt;/li&gt;
&lt;li&gt;所以实际包含的CDS子服务应是：Asset Metadata+Audio Asset+Stats。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;三条准则&#34;&gt;三条准则&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;充分考虑服务依赖项的所有失败方式，让我们知道每个服务和多个依赖服务失败时会发生什么行为，返回什么结果。&lt;/li&gt;
&lt;li&gt;我们需要明确将故障注入后会对服务产生什么样的影响，并依据此简化注入。例如我们已经知道CDS的某个依赖项在发生错误时会返回&lt;em&gt;500&lt;/em&gt;，那么就可以直接在CDS中注入&lt;em&gt;500&lt;/em&gt;错误响应。&lt;/li&gt;
&lt;li&gt;如果已经在服务中注入了故障，那么就不用进行测试了，因为已经观察到了程序的行为。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;动态缩减算法&#34;&gt;动态缩减算法&lt;/h3&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;该算法将测试的搜索空间指数级缩小，基本思路是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;缩减前：数量级是&lt;strong&gt;服务请求总数&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;缩减后：数量级变成&lt;strong&gt;给定服务最大能发出的请求数&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;具体来说如图2：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;缩减前：最大有8条边需要处理，整个应用有8个请求路径&lt;/li&gt;
&lt;li&gt;缩减后：最大仅需要处理3条边，因为ADS是依赖项最多的服务，有3个请求发送路径&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;另外依据的一个前提是，&lt;strong&gt;微服务调用链拓扑结构上深度优先比广度优先更为明显&lt;/strong&gt;。&lt;/p&gt;
&lt;h2 id=&#34;原型实现filibuster&#34;&gt;原型实现：Filibuster&lt;/h2&gt;
&lt;p&gt;使用Python及相关的开源组件，如使用opentelemetry来实现请求链路追踪、识别服务依赖关系。&lt;/p&gt;
&lt;h3 id=&#34;组件功能&#34;&gt;组件功能&lt;/h3&gt;
&lt;p&gt;系统的组件可以实现服务请求识别、服务依赖关系分析，并于Filibuster通信。服务器负责在本地进程、Docker Compose 或 Kubernetes 中启动与应用程序关联的所有服务。&lt;strong&gt;运行功能测试、记录和维护要执行的测试执行堆栈、执行功能测试断言、报告测试失败并聚合测试覆盖率&lt;/strong&gt;。服务器提供了一个 API，&lt;strong&gt;功能测试可以使用该 API 来编写条件断言，并使用反例文件允许测试重放&lt;/strong&gt;。测试覆盖率由服务器从每个单独的服务中聚合而成。&lt;/p&gt;
&lt;h3 id=&#34;静态分析&#34;&gt;静态分析&lt;/h3&gt;
&lt;p&gt;Filibuster需要进行静态分析，以识别每个服务可以返回的错误类型。&lt;strong&gt;作者使用词法分析技术，遍历源代码的抽象语法树来识别错误&lt;/strong&gt;。Flask中的&lt;em&gt;raise&lt;/em&gt;语句可以被分析道，然后捕获这些语句要发送的HTTP错误响应及状态码。&lt;/p&gt;
&lt;h3 id=&#34;注入故障&#34;&gt;注入故障&lt;/h3&gt;
&lt;p&gt;Filibuster可以注入下面类型的故障；&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;调用端异常：这些异常由&lt;em&gt;request&lt;/em&gt;库抛出，如指示&lt;code&gt;Timeout&lt;/code&gt;的等错误。&lt;/li&gt;
&lt;li&gt;响应异常：来自被调用端返回异常。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;应用语料库&#34;&gt;应用语料库&lt;/h2&gt;
&lt;p&gt;一个包含8种变体示例的电影订票程序，每个示例都展示了微服务应用程序中观察到的特定模式。还有 4 个行业示例：Audible、Expedia、Mailchimp 和 Netflix。&lt;/p&gt;
&lt;p&gt;每个示例都包含单元测试以及验证应用程序功能行为的功能测试。这些示例可以在Docker或K8s环境中运行。&lt;/p&gt;
&lt;h3 id=&#34;电影院订票应用示例&#34;&gt;电影院订票应用示例&lt;/h3&gt;
&lt;p&gt;该应用由4个微服务组成：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Showtimes: returns the show times for movies;&lt;/li&gt;
&lt;li&gt;Movies: returns information for a given movie;&lt;/li&gt;
&lt;li&gt;Bookings: given a username, returns information about the bookings for that user;&lt;/li&gt;
&lt;li&gt;Users: 存储用户信息并处理用户订票请求，并在过程中为用户展示电影信息。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;它的另外7个变体有：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;bookings talks directly to the movies;&lt;/li&gt;
&lt;li&gt;same as 1, but the users service has a retry loop around its calls to the bookings service;&lt;/li&gt;
&lt;li&gt;same as 1, but each service talks to &lt;strong&gt;an external service before issuing any requests&lt;/strong&gt;, the users service makes a request to IMDB, the bookings service makes a request to Fandango, the movies service makes a request to Rotten Tomatoes;&lt;/li&gt;
&lt;li&gt;all requests happen regardless of failure; in the event of failure, a hardcoded, default, response is used;&lt;/li&gt;
&lt;li&gt;adds a second replica of bookings, that is contacted in the event of failure of the primary replica;&lt;/li&gt;
&lt;li&gt;same as 5, but the users service makes a call to a health check endpoint on the primary bookings replica before issuing the actual request;&lt;/li&gt;
&lt;li&gt;example is collapsed into monolith（单体结构） where an API server makes requests to the it with a retry loop.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;工业级应用&#34;&gt;工业级应用&lt;/h3&gt;
&lt;h4 id=&#34;audible&#34;&gt;Audible&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lizonglin313/MyPicGo/master/image-20220224122453207.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220224122453207&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;架构如上图2所示。包含如下服务：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Content Delivery Service (CDS):
&lt;ul&gt;
&lt;li&gt;IN： book_id 和 user_id&lt;/li&gt;
&lt;li&gt;OUT：（在验证之后） 音频内容和元数据&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Content Delivery Engine (CDE):
&lt;ul&gt;
&lt;li&gt;IN： book_id 和 user_id&lt;/li&gt;
&lt;li&gt;OUT：相关CDS的URL&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Audible App：模拟移动应用
&lt;ul&gt;
&lt;li&gt;首先向CDE请求获得内容的URL&lt;/li&gt;
&lt;li&gt;再根据URL请求CDS&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Audible Download Service: 鉴权、授权并记录日志
&lt;ul&gt;
&lt;li&gt;IN： book_id 和 user_id&lt;/li&gt;
&lt;li&gt;OUT：权限鉴别结果&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Ownership: 验证读者对图书的所有权
&lt;ul&gt;
&lt;li&gt;IN：book_id 和 user_id&lt;/li&gt;
&lt;li&gt;OUT：鉴权结果&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Activation：为用户激活DRM许可证
&lt;ul&gt;
&lt;li&gt;IN：book_id&lt;/li&gt;
&lt;li&gt;OUT：DRM Access&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Stats：记录读者和图书许可的信息
&lt;ul&gt;
&lt;li&gt;IN：book_id 和 user_id&lt;/li&gt;
&lt;li&gt;OUT：记录结果&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Asset Metadata：存储音频元数据，如章节信息
&lt;ul&gt;
&lt;li&gt;IN：book_id 和 license&lt;/li&gt;
&lt;li&gt;OUT：检索到的音频XML信息&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Audio Assets：提供音频存储服务
&lt;ul&gt;
&lt;li&gt;IN：book_id 和 license&lt;/li&gt;
&lt;li&gt;OUT：检索到的音频文件&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;作者在实际部署上进行了一些调整：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Asset Metadata和Audio Assets是 AWS S3 存储桶。为了模拟这一点创建 HTTP 服务，如果可用，则返回包含资产的 200 OK，如果资产不存在，则返回 404 Not Found。&lt;/li&gt;
&lt;li&gt;Ownership和Activation是 AWS RDS 实例。为了模拟这一点创建了实现 REST 模式的 HTTP 服务：如果用户不拥有该书，则返回 403 Forbidden，如果该书不存在，则返回 404 Not Found，否则返回 200 OK。&lt;/li&gt;
&lt;li&gt;Stats 服务是一个 AWS DynamoDB 实例。为了模拟这一点，我们创建了一个返回 200 OK 的 HTTP 服务。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;对于功能测试的尝试是为用户下载有声读物的测试。如果缺少图书的章节信息，Asset Metadata可以返回 404 Not Found 响应：这是 Audible 演示中讨论的错误，会导致在移动应用程序中向用户显示一般错误。&lt;/p&gt;
&lt;h4 id=&#34;expedia&#34;&gt;Expedia&lt;/h4&gt;
&lt;p&gt;包含如下三个微服务：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Review ML：按相关性顺序返回评论&lt;/li&gt;
&lt;li&gt;Review Time：按时间顺序返回评论&lt;/li&gt;
&lt;li&gt;API Gateway：根据服务可用性，从 Review ML 或 Review Time 将评论返回给用户&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;mailchimp&#34;&gt;Mailchimp&lt;/h4&gt;
&lt;p&gt;包含五个微服务：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Requestmapper：将电子邮件活动中的 URL 映射到实际资源&lt;/li&gt;
&lt;li&gt;DB Primary：数据库的主要副本&lt;/li&gt;
&lt;li&gt;DB Secondary：数据库次要副本&lt;/li&gt;
&lt;li&gt;App Server：向 Requestmapper 服务发出请求以解析 URL，然后对数据库执行读后写请求，并在主数据库不可用的情况下回退到辅助数据库副本&lt;/li&gt;
&lt;li&gt;Load Balancer：对请求进行负载均衡&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;同样的，在实际部署时做出一些调整：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;DB Primary 和 Secondary 服务是 MySQL 实例。为了模拟这一点创建一个 HTTP 服务，该服务要么在成功读取或写入时返回 200 OK，要么在数据库为只读时返回 403 Forbidden。&lt;/li&gt;
&lt;li&gt;负载均衡器服务是一个 HAProxy 实例。为了模拟这一点创建一个 HTTP 代理做负载均衡。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;故障信息有两个：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;MySQL instance is read-only：当 MySQL 实例为只读时，数据库会返回一个在代码的一个区域中未处理的错误。由于 Mailchimp 使用 PHP，这个错误会直接呈现到页面的输出中，我们通过将 403 Forbidden 响应转换为直接插入页面的输出来模拟这一点。&lt;/li&gt;
&lt;li&gt;Requestmapper is unavailable：当 Requestmapper 服务不可用时，App Server 无法正确处理错误，向负载均衡器返回 500 Internal Server Error。但是，负载均衡器仅配置为通过返回格式化的错误页面来处理 503 Service Unavailable 错误。&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;netflix&#34;&gt;Netflix&lt;/h4&gt;
&lt;p&gt;包含十个微服务。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Client：模拟移动客户端&lt;/li&gt;
&lt;li&gt;API Gateway：展示用户主页&lt;/li&gt;
&lt;li&gt;User Profile：返回用户信息&lt;/li&gt;
&lt;li&gt;Bookmarks：返回最后查看的位置&lt;/li&gt;
&lt;li&gt;My List：返回用户的电影列表&lt;/li&gt;
&lt;li&gt;User Recs.：返回用户推荐的电影&lt;/li&gt;
&lt;li&gt;Ratings：返回用户的评分&lt;/li&gt;
&lt;li&gt;Telemetry： 记录日志信息&lt;/li&gt;
&lt;li&gt;Trending：返回电影观看趋势&lt;/li&gt;
&lt;li&gt;Global Recs.：返回推荐电影&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;对于功能测试，我们有一个尝试为用户加载 Netflix 主页的功能测试。&lt;/p&gt;
&lt;p&gt;故障信息有三个：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Misconfigured timeouts：User Profile服务以 10 秒的超时时间调用日志服务；但是，API Gateway会以 1 秒的超时时间调用用户配置文件服务。&lt;/li&gt;
&lt;li&gt;Fallbacks to the same server：如果我My List服务不可用，系统将重试。&lt;/li&gt;
&lt;li&gt;Critical services with no fallbacks：User Profile服务没配置回退。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;实验评估&#34;&gt;实验评估&lt;/h2&gt;
&lt;p&gt;在具有 15 GB 内存和 8 个 vCPU 的 AWS CodeBuild 实例上运行了所有示例。在 Filibuster 运行开始时，启动了每个示例的所有服务，等待这些服务上线并在测试结束时终止它们，不会在测试执行之间重新启动服务。&lt;/p&gt;
&lt;h3 id=&#34;tests-generated-and-increased-coverage&#34;&gt;Tests Generated and Increased Coverage&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Test Gen/DR Gen：表示 Filibuster 生成和执行的测试数量。由于每个示例只有一个功能测试，因此这些数字包括该测试的总数，因为 Filibuster 必须首先执行初始通过的功能测试，以确定在哪里注入故障。在语料库中包含错误的所有示例中，可以使用Filibuster 识别错误。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Coverage After：表示报表覆盖率的增加。通过生成涵盖可能故障的测试，我们能够增加应用程序的覆盖率。这些数字仅用于功能测试。生成的测试增加了与未经修改的功能测试未执行的错误处理代码相关的覆盖率。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Time w/DR：表示启用动态缩减的执行时间。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;TG Overhead：表示生成测试的总开销时间。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lizonglin313/MyPicGo/master/image-20220224182652863.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220224182652863&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;dynamic-reduction&#34;&gt;Dynamic Reduction&lt;/h3&gt;
&lt;p&gt;当应用程序以服务图的深度而不是广度的方式构建时，应用程序可以从动态缩减中显着受益，例如Audible就是服务调用关系具有一定的深度。&lt;/p&gt;
&lt;h3 id=&#34;mocks&#34;&gt;Mocks&lt;/h3&gt;
&lt;p&gt;实现语料库时，作者为每个示例中的每个服务编写了单元测试，使用模拟来解释可能的远程服务故障。 在编写这些测试时，只测试了独立的故障。&lt;/p&gt;
&lt;p&gt;如图 2 的 Audible 下载服务，其单元测试包含一个模拟三个依赖项的失败：Ownership、Active和State。在这里省略了服务特定故障的列表，请读者参考图表获取列表。&lt;/p&gt;
&lt;p&gt;同时为&lt;em&gt;Timeout&lt;/em&gt;和&lt;em&gt;ConnectionError&lt;/em&gt;这两个异常分别编写了一个模拟。&lt;/p&gt;
&lt;h2 id=&#34;不足和未来工作&#34;&gt;不足和未来工作&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;语料库中的示例用HTTP 服务取代了真实云服务和数据库的使用，但在实际生产环境中，服务间的通信方式还包括如gRPC等多种服务通信。作者已经开始努力通过 gRPC 支持和对 AWS DynamoDB 和 AWS RDS 等云服务的支持来扩展系统原型。&lt;/li&gt;
&lt;li&gt;该设计不考虑服务响应的损坏，而是关注假设的响应或指示失败的响应。&lt;/li&gt;
&lt;li&gt;系统中将返回错误码就看作请求失败，但是在生产环境中，往往对一些错误响应会给出处理。在某些情况下，可能会提示开发人员编写异常处理程序和其他条件错误处理，以处理实际上可能不会在生产中发生的故障。&lt;/li&gt;
&lt;li&gt;动态缩减在微服务依赖呈现更大的调用深度时表现更好，广度更大时难以起到明显的作用。&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>SHOWAR: Right-Sizing And Efficient Scheduling of Microservices</title>
        <link>https://lizonglingo.github.io/p/showar-right-sizing-and-efficient-scheduling-of-microservices/</link>
        <pubDate>Tue, 22 Feb 2022 13:45:25 +0800</pubDate>
        
        <guid>https://lizonglingo.github.io/p/showar-right-sizing-and-efficient-scheduling-of-microservices/</guid>
        <description>&lt;blockquote&gt;
&lt;p&gt;来源：ACM SoCC&#39;21&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://acmsocc.org/2021/accepted-papers.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://acmsocc.org/2021/accepted-papers.html&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;概述&#34;&gt;概述&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;解决了什么问题：提出一个微服务资源调度框架，解决微服务的调度问题，具体来说从&lt;strong&gt;水平扩缩容——增减服务实例&lt;/strong&gt;和&lt;strong&gt;垂直扩缩容——控制每个服务CPU和内存等资源的配额&lt;/strong&gt;两个维度对微服务进行调度&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;适用于什么环境：该资源调度框架应用于&lt;strong&gt;使用K8s部署的微服务&lt;/strong&gt;上&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;实验的实施和结果：&lt;strong&gt;使用多个微服务应用和现实世界中的负载情况进行实验&lt;/strong&gt;，资源利用表现提高22%，用户端到端实验降低20%&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;目标和宗旨：找到一个最佳资源分配大小，&lt;strong&gt;保持良好服务质量的同时尽可能提高资源利用率&lt;/strong&gt;，减少资源配额&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;微服务调度存在的问题和挑战&#34;&gt;微服务调度存在的问题和挑战&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;确定微服务应用对资源的需求是个复杂工作，难以预先确定&lt;/li&gt;
&lt;li&gt;如果分配过多的资源会造成集群资源利用率低，增加开销&lt;/li&gt;
&lt;li&gt;分配资源过少则导致服务性能下降甚至服务不可用，带来更严重的问题&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;贡献&#34;&gt;贡献&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;垂直和水平扩缩容框架，旨在提高资源分配的效率&lt;/li&gt;
&lt;li&gt;调度亲和性和反亲和性规则，为K8s调度程序生成更好的微服务调度规则，提高调度效率&lt;/li&gt;
&lt;li&gt;实现上述要点并评估&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;设计思路&#34;&gt;设计思路&lt;/h2&gt;
&lt;h3 id=&#34;概述-1&#34;&gt;概述&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;垂直扩缩容：参照&lt;strong&gt;历史资源利用率&lt;/strong&gt;来寻找每个微服务的最佳资源配额，调度的资源是每个服务占用的CPU、RAM、Disk等资源&lt;/li&gt;
&lt;li&gt;水平扩缩容：使用Linux内核线程调度程序队列的指标（如&lt;strong&gt;eBPF runq latency&lt;/strong&gt;）为扩缩容指标，同时利用控制理论的思想，在微服务运行时对实例数量进行控制。并设计了一个&lt;em&gt;proportional-integral-derivative&lt;/em&gt;控制器，利用历史扩缩容操作和当前的运行时状态来做出下一个水平扩缩容决策，并保持服务的稳定，调度的资源是增减服务实例数量&lt;/li&gt;
&lt;li&gt;服务间依赖：同时考虑了&lt;strong&gt;服务间依赖关系&lt;/strong&gt;，优先调度应用中负载压力大的微服务（如某个微服务作为其他微服务的引用）&lt;/li&gt;
&lt;li&gt;服务性能：在找到一个最佳配额后，会协助集群调度微服务以获得更好的端到端性能&lt;/li&gt;
&lt;li&gt;K8s亲和性与反亲和性：通过不同微服务的历史资源使用情况为K8s生成调度规则（如某种微服务和某类资源有正相关性或负相关性）&lt;/li&gt;
&lt;li&gt;调度效率：能够快速适应工作负载变化&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;垂直扩缩容&#34;&gt;垂直扩缩容&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;调度依据指标：实例的历史资源使用情况（CPU、RAM、Disk、Network等）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;需要达成的效果有：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在运行时为服务找到合适的资源需求&lt;/li&gt;
&lt;li&gt;最大限度减少过度配置导致的资源使用松弛（松弛度=资源配额-资源使用量）&lt;/li&gt;
&lt;li&gt;最大限度减少OOM错误和CPU负载过高的情况，保证服务质量&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;垂直扩缩容的局限：每个实例的资源占有量最大不会超过虚拟机的资源量，所以某些情况下即使将虚拟机的所有资源都给到实例也难以满足要求，这就需要水平扩缩容&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;水平扩缩容&#34;&gt;水平扩缩容&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;调度依赖指标：eBPF指标数据&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;eBPF：允许在内核级别允许安全和低开销的程序，从内核级别收集准确的事件信息，如CPU调度程序决策事件、内存分配事件和网络堆栈中的数据包事件。已经被广泛用于微服务检测、性能提升、链路追踪、负载均衡、网络监控和安全中。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;具体思路&#34;&gt;具体思路&lt;/h3&gt;
&lt;h4 id=&#34;垂直自动扩缩容&#34;&gt;垂直自动扩缩容&lt;/h4&gt;
&lt;p&gt;K8s（Google Autopilot也是类似）通过检测一段时间窗口（几分钟到几天）中的CPU和内存使用量来设置下一个事件窗口中的资源。通过一个&lt;code&gt;margin&lt;/code&gt;和观测到的如P95、P99的百分位值，目的是为资源增加一些宽裕度，尽可能减少OOM错误和CPU不够用的情况发生。&lt;strong&gt;作者认为这还不够节约，存在资源浪费的情况发生&lt;/strong&gt;。$\alpha$为宽限额度，$\pi$是某个测量的百分位数值。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lizonglin313/MyPicGo/master/20220221103059.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;而SHOWAR使用“three-sigma”经验法则去分配资源&lt;/strong&gt;。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;SHOWAR收集持续时间W秒的最后一个窗口的每种资源使用的统计数据，每秒收集一次，用于递归计算该窗口上的资源使用平均值$\mu$和方差$\sigma^2$。&lt;/li&gt;
&lt;li&gt;计算$s=\mu + 3\sigma$，这里$s$就是特定资源的一个估计量&lt;/li&gt;
&lt;li&gt;然后每经过T秒（T &amp;laquo; W）评估资源使用量是否发生了很大的变化（如超过15%），一旦超过预期值就实施资源重新分配。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lizonglin313/MyPicGo/master/20220221104502.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;作者认为使用百分数值的3-σ法则能在保证服务良好运行的情况下最大限度的减少资源浪费，同时使用一个阈值来决定是否进行资源重新分配操作能在资源使用差异较小时不会过度配置资源。虽然$\mu+3\sigma$和$\pi(1+\alpha)$都有明确的统计解释，但是使用$3\sigma$可以更加准确的看到均值的分布。如果方差非常小，则分布几乎是恒定的，这是关于 Pod 资源使用情况的单独有用信息。然而，在$\pi(1+\alpha)$方法中，当方差非常小时，尾部百分位数不能传达有用的信息。此外，安全宽裕度参数 $\alpha$的选择可能是任意的，如果未正确指定，可能会导致资源利用率低下或更多OOM错误。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;关于P90、P95等百分位数值的补充资料：https://www.cnblogs.com/hunternet/p/14354983.html&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&#34;水平自动扩缩容&#34;&gt;水平自动扩缩容&lt;/h4&gt;
&lt;p&gt;水平自动扩缩容目前存在一些缺陷：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;由于水平扩缩容的主要形式是通过增减服务实例数量来调整资源分配，服务实例在遇到负载激变发生资源使用抖动时，可能导致极端过度配置或者配置严重不足。为了解决这种情况，有些自动缩放策略引入冷却期的概念，在最后一次操作之后的一段时间内不进行扩缩容。如果出现瞬时负载峰值过高的情况也会因为处于冷却期而避免不必要的扩容操作。&lt;/li&gt;
&lt;li&gt;系统不会将系统微服务的依赖关系考虑在内，而是单独处理某个微服务。实践表明在不考虑微服务相关性的前提下的资源分配和缩放效率低下，并且不一定有助于应对负载变化和保证服务质量。如下图对某个后端服务在5s时注入高负载，然后经过一段时间，后端的高延迟情况传到了前端，如果考虑微服务间依赖关系，那么仅扩容后端微服务就可以解决这个问题。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lizonglin313/MyPicGo/master/20220221112213.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;以往通常使用CPU利用率作为缩放指标，力求在所有微服务中保持目标 CPU 利用率。但CPU 利用率并不是自动缩放和资源分配的最有效指标，随着负载的增加，几乎所有微服务的 CPU 利用率都会增加，而上图的前端微服务的尾部延迟并不总是随着 CPU 利用率的增加而增加（主要是由于后端微服务的高延迟导致的）。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;SHOWAR旨在解决上述问题，使用控制理论基本框架来设计有状态的水平缩放系统，在满足SLO指标下保证服务稳定。&lt;/p&gt;
&lt;p&gt;通过观测值与目标值的差别来控制缩放是不准确的：$e=observation-target$​​，为此作者设计了更复杂的控制器&lt;em&gt;pro-portional–integral–derivative (PID) controller&lt;/em&gt;：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lizonglin313/MyPicGo/master/20220221113150.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;对资源的检测使用我们使用&lt;strong&gt;eBPF Linux&lt;/strong&gt;调度程序&lt;strong&gt;runq 延迟度量&lt;/strong&gt;，它表示线程可运行与获取CPU并运行之间的时间。使用Runq延迟的P95作为目标点。&lt;strong&gt;与CPU利用率不同，高runq延迟与每个单独的微服务的高请求尾延迟高度相关，这表明runq延迟可以用作水平自动缩放的合适指标，以防止请求延迟增加。直观地说，runq延迟优于CPU利用率的原因是它表明应用程序线程如何竞争CPU资源，因此需要更多（或更少）的CPU资源&lt;/strong&gt;。在SHOWAR中，使用者要指定目标runq的延迟值作为配置的一部分。&lt;/p&gt;
&lt;p&gt;水平扩缩容的传递函数很简单，如果runq超出目标值，则系统必须向外扩展并增加副本数量，反正小于目标值则缩减服务实例（这里目标是是一个范围？我是这么认为的）。为了防止执行过多的自动缩放操作以响应 runq 延迟指标中的快速变化和瞬时突发性，作者在目标周围设置了一个可配置的界限$\alpha%$​​（默认为 20%）作为缓冲区并且不执行自动缩放操作。自动缩放的增加或减少量是微服务当前副本数量的可配置 𝛽 百分比（默认为 10%），如果实际缩放副本数小于1则默认是1（我的理解是，如该实例有20个副本，则扩容20×0.1=2个副本，如果是4个副本4×0.1=0.4&amp;lt;1即扩容1个副本）。算法如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lizonglin313/MyPicGo/master/20220221120450.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;水平自动扩缩容的两种架构：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;One For All：单个控制器负责自动扩展所有微服务类型。在每个自动缩放决策中，所有微服务都会根据所有微服务中当前度量值观察的平均值一次缩放。虽然这种方法受益于 PID 控制器，但它没有考虑微服务的微服务依赖关系图。&lt;/li&gt;
&lt;li&gt;One For Each：控制器负责每个微服务。每个控制器监控其相应微服务的自动缩放指标runq，根据上述算法进行缩放。控制器输出的绝对值被排序，具有最高值（最大扩展需求）的那些被优先考虑。对于相等的控制器输出，我们会考虑微服务的依赖关系图，并将后端服务优先于依赖的前端服务（在图的拓扑排序之后）。&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;将二者串联&#34;&gt;将二者串联&lt;/h4&gt;
&lt;p&gt;在K8s等部署平台上推荐的方法是：一次部署仅使用一类缩放器（如为每个微服务确定固定的实例数量的前提下，部署垂直缩放器，自动调整每个实例的资源分配量；或是确定好资源分配量后，令服务通过水平缩放器自动进行实例数量的增减）。&lt;/p&gt;
&lt;p&gt;SHOWAR通过允许串联部署这二者。首先，作者将任何垂直自动缩放决策优先于任何水平自动缩放决策。因为，例如在内存自动缩放的情况下，如果 Pod 的内存不足，应用程序会遇到OOM错误并停止执行，而不管其副本数如何，所以水平自动缩放器无法解决OOM问题。因此，在水平自动缩放控制器动作之前，它首先检查共享通道以查看该微服务是否正在进行垂直自动缩放，如果是则不会继续操作。类似地，在垂直Pod自动缩放器动作之前，它会通过共享通道发送消息通知水平自动缩放器，然后执行其操作。&lt;/p&gt;
&lt;p&gt;此外，由于谷歌云平台的 Kubernetes 最佳实践，建议大多数 Pod 不需要超过一个核心，作者根据这个建议将其合并到 SHOWAR 的垂直自动缩放器设计中：如果垂直自动缩放器决定为 Pod 设置多个核心，它会改为通过共享通道向水平自动缩放器发出信号，并且不会继续执行垂直自动缩放操作。即：核心数增加转化为实例数量增加。&lt;/p&gt;
&lt;h4 id=&#34;利用k8s亲和性和反亲和性获取更好的调度性能&#34;&gt;利用K8s亲和性和反亲和性获取更好的调度性能&lt;/h4&gt;
&lt;p&gt;关于K8s的亲和性和反亲和性可以概括为：服务𝑆2与服务𝑆1的亲和性意味着调度程序将始终（或最好）尝试将服务 𝑆1 的 Pod 调度到服务 𝑆2 所在的节点上。类似地，服务𝑆2与服务𝑆1的反亲和性意味着调度程序永远不会（或最好不）这样做。&lt;/p&gt;
&lt;p&gt;SHOWAR监控和使用微服务的历史（即最后（可配置）时间窗口）CPU、内存和网络使用情况，并计算每对微服务使用模式之间的Paerson相关系数来计算相关性：给定两种微服务类型𝑋和𝑌的CPU（或内存或网络I/O）使用分布，𝑋和𝑌之间的相关系数$\rho$​为：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lizonglin313/MyPicGo/master/20220222104614.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;对于两个微服务𝑆1和𝑆2，资源使用模式（例如CPU或内存）的正相关性越高，它们之间对该资源的资源争用就越高。同样，负相关越低，两个服务之间对该资源的争用就越低。这是 SHOWAR 对 CPU、内存和网络 I/O 等计算资源的亲和性和反亲和性规则的简单基础。&lt;/p&gt;
&lt;p&gt;进一步产生亲和性和反亲和性规则，规则生成机制如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;CPU和NetWork：如果两个服务s1、s2的CPU和网络是用呈现强负相关（$\rho_{s1s2}\leq-0.8$​​​​​）,则为其生成亲和性规则。&lt;/li&gt;
&lt;li&gt;Memeory：如果任何一对微服务s1和s2在它们的内存使用模式中具有强正相关（例如$\rho_{s1s2}\geq-0.8$​），则SHOWAR 为调度程序生成s1和s2的反亲和性规则。(实际上也是负相关$\Longrightarrow$亲和性)。&lt;/li&gt;
&lt;li&gt;此外，为避免调度冲突，每个微服务在任意时间最多参与一个亲和性或反亲和性规则。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;实现&#34;&gt;实现&lt;/h2&gt;
&lt;h3 id=&#34;系统架构&#34;&gt;系统架构&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lizonglin313/MyPicGo/master/20220222110542.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;monitoring-agents&#34;&gt;Monitoring Agents&lt;/h3&gt;
&lt;p&gt;使用Prometheus从节点和容器收集不同的指标。通过集群中的每个节点上启动一个监控代理来收集容器指标，例如CPU使用率、内存使用率、网络带宽使用率等。代理被配置为每秒收集和报告一次指标。Prometheus附带一个时间序列数据库，代理存储收集到的指标。此外，还提供了一种查询语言来查询其他模块使用的时间序列数据库以利用收集的指标。&lt;/p&gt;
&lt;p&gt;此外作者还开发了一个eBPF程序作为监控代理部署在集群中的每个节点上，以收集水平自动缩放器使用的 &lt;em&gt;runq latency&lt;/em&gt;指标。该指标是每个Pod的CPU线程在获取CPU之前所经历的延迟的直方图。程序每 1 秒收集一次&lt;em&gt;runq latency&lt;/em&gt;直方图，并将其存储在Prometheus时间序列数据库中。&lt;/p&gt;
&lt;h3 id=&#34;the-vertical-autoscaler&#34;&gt;The Vertical Autoscaler&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;垂直自动缩放器是一个简单的循环，每分钟发生一次。&lt;/li&gt;
&lt;li&gt;它会在前5分钟的窗口中为每种资源类型r（CPU和内存）评估$s_r = \mu_r + 3*\sigma_r$，如果s的值变化超过 15%，它会更新服务的资源需求s。&lt;/li&gt;
&lt;li&gt;触发垂直自动缩放器的另一个条件是微服务报告 OOM 错误。&lt;/li&gt;
&lt;li&gt;在应用微服务的新资源需求之前，垂直自动缩放器通过共享通道向水平自动缩放器发送一条消息，以不继续任何水平自动缩放操作，因为&lt;strong&gt;垂直自动缩放操作优先于水平自动缩放&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;如果微服务的CPU数量超过一个CPU核心，垂直自动缩放器也不会继续执行微服务的自动缩放操作，在这种情况下，它会通过另一个共享通道向水平自动缩放器以触发水平自动缩放操作。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;the-horizontal-autoscaler&#34;&gt;The Horizontal Autoscaler&lt;/h3&gt;
&lt;p&gt;对于给定的目标&lt;em&gt;runq latency&lt;/em&gt;，它对该微服务执行水平自动缩放操作，使其始终具有目标值的&lt;em&gt;runq latency&lt;/em&gt;。控制器每1分钟决定eBPF程序收集60个度量直方图实例（每秒1个）。对于每个直方图，选择第 95个百分位数，控制器使用这60个数据点的平均值作为其当前观察值（也称为测量值）来执行其控制动作。每个水平扩展操作添加或删除至少1个或可配置百分比（默认为 10%）的微服务当前副本数，分别用于扩缩容。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lizonglin313/MyPicGo/master/20220222112427.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;PID控制参数的初始值取为$k_P=k_I=k_D=1/3$​​（每个参数限制为∈[0,10]，这几个参数会影响控制器的速度、稳定性和准确性）。这些参数的增量变化是 10%（我们通过实验发现 10% 可以提供非常好的性能）。控制器输出的波动是进行此类更改的基础，使用之前的N =10个样本进行测量。此外，控制器的“速度”被测量为达到区间[target(1 − 𝛼), target(1 + 𝛼)] 所需的迭代次数，因为 𝛼 =10%。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;增加$k_P$​会导致控制器速度执行增加（以达到稳定状态），同时过高的值可能引发不稳定性。&lt;/li&gt;
&lt;li&gt;增加$k_I$​也会增加控制器的速度并可能导致不稳定，但增加它会降低控制器的噪声（变化和波动）和稳态误差。&lt;/li&gt;
&lt;li&gt;增加$k_D$​会增加控制器的速度（达到稳态）以及不稳定的可能性，同时会显著放大控制器的噪声。&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
&lt;li&gt;控制器从系数的相等值开始。&lt;/li&gt;
&lt;li&gt;随后这些系数基于监控的工作负载性能和控制器状态进行自适应和增量自调整。&lt;/li&gt;
&lt;li&gt;如果当前指标值（尤其是runq延迟）远离目标指标值，则在每次迭代中增加$k_P$和$k_I$，以提高稳定性以及达到目标指标值的速度。&lt;/li&gt;
&lt;li&gt;此外，如果观察到度量值的波动（在控制器中称为噪声），$k_D$​会逐渐减小以减少工作负载突发性引入的噪声。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;the-affinity-rule-generator&#34;&gt;The Affinity Rule Generator&lt;/h3&gt;
&lt;p&gt;亲和性规则生成器每5分钟使用一次CPU、内存和网络利用率，这是一个由300个数据点组成的向量（每个数据点是微服务副本的平均值）来计算每个资源类型之间的相关系数一对微服务。为消除弱相关或无相关实例，[−0.8,+0.8]中的任何值都会被丢弃。其他强负相关和强正相关的微服务用于生成亲和性和反亲和性规则。资源使用模式会随着工作负载的变化（也称为工作负载转移）而变化，因此如果在随后的5分钟时间窗口内强烈的负相关或正相关变化超过20%（可配置），SHOWAR会撤销亲和性（或那对微服务的反亲和性）规则。&lt;/p&gt;
&lt;h3 id=&#34;其他要点&#34;&gt;其他要点&lt;/h3&gt;
&lt;p&gt;SHOWAR是作为Kubernetes控制器构建的，对于自动扩缩器和其他类型的控制器具有高度可插入性。此外，SHOWAR使用常用的Kubernetes监控代理（例如Prometheus）和一个自定义的eBPF指标监控代理。因此，与默认的Kubernetes自动缩放器相比，&lt;strong&gt;SHOWAR不会引入任何额外的开销&lt;/strong&gt;。此外，自动缩放器被调度在控制器节点上，并且不与调度在工作节点上的应用程序 Pod 共享资源。&lt;/p&gt;
&lt;h2 id=&#34;实验&#34;&gt;实验&lt;/h2&gt;
&lt;p&gt;在AWS部署K8s集群，用Google Autopilot和K8s默认的调度程序作比较。资源利用率提升22%，延迟降低20%。&lt;/p&gt;
&lt;h3 id=&#34;实验设置&#34;&gt;实验设置&lt;/h3&gt;
&lt;h4 id=&#34;applications&#34;&gt;Applications&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;社交网络应用：包含36个微服务，可以关注他人、撰写帖子、阅读他人帖子并与之互动。&lt;/li&gt;
&lt;li&gt;火车票应用：包含41个微服务的应用程序，允许其用户在线预订门票并进行支付。&lt;/li&gt;
&lt;li&gt;谷歌云平台的线上精品店：由 10 个微服务组成，用户可以通过他们的在线购物车购买在线商品并进行支付。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;实验将runq延迟的目标值设置为15𝑚𝑠，即 Linux 内核 sysctl_sched_latency[31] 调度程序参数的 2.5𝑥。&lt;/p&gt;
&lt;h4 id=&#34;cluster-setup&#34;&gt;Cluster Setup&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;在AWS上进行的。&lt;/li&gt;
&lt;li&gt;使用 𝑚5.𝑥𝑙𝑎𝑟𝑔𝑒 VM 实例，每个实例具有 4 个 vCPU、16 GB 内存和 0.192 美元/ℎ𝑟 价格。&lt;/li&gt;
&lt;li&gt;运行Ubuntu 18.04 LTS，配置为支持运行eBPF程序。&lt;/li&gt;
&lt;li&gt;除非另有说明，否则集群都是由25个VM实例组成。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;workload-and-load-generation&#34;&gt;Workload and Load Generation&lt;/h4&gt;
&lt;p&gt;我们使用Wikipedia访问跟踪[59]作为我们的主要工作负载。它是用户与Wikipedia网站交互的真实世界轨迹，由流量模式组成，包括&lt;strong&gt;泊松到达时间、短期突发性和昼夜水平变化&lt;/strong&gt;。由于我们正在评估的微服务是面向用户的应用程序，因此工作负载必须反映真实的用户行为。因此，维基百科访问跟踪非常适合我们的评估。我们以分布式方式使用&lt;strong&gt;locust&lt;/strong&gt; [26]作为我们的工作负载生成器。 Locust客户端驻留在与托管应用程序的主集群不同的VM实例上。&lt;/p&gt;
&lt;h4 id=&#34;baselines&#34;&gt;Baselines&lt;/h4&gt;
&lt;p&gt;Kubernetes默认自动缩放器和 Google Autopilot。&lt;/p&gt;
&lt;h3 id=&#34;vertical-autoscaling&#34;&gt;Vertical Autoscaling&lt;/h3&gt;
&lt;p&gt;首先评估 SHOWAR 的垂直自动缩放器（禁用水平自动缩放器）在减少相对内存松弛方面的有效性。&lt;/p&gt;
&lt;p&gt;使用来下图中所示的 Wikipedia 访问跟踪的一小时长的工作负载进行评估。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lizonglin313/MyPicGo/master/20220222120133.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;每5分钟记录一次垂直自动缩放器为每个微服务设置的内存限制以及微服务的实际使用情况，以计算其内存使用松弛（即松弛 = 限制 - 使用）。&lt;/p&gt;
&lt;p&gt;下图描绘了社交应用所有微服务相对内存使用松弛的&lt;strong&gt;累积分布函数&lt;/strong&gt;（the cumulative distribution function，CDF）。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lizonglin313/MyPicGo/master/20220222120655.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;可以看出，通过历史资源使用的变化（使用3-σ规则），SHOWAR 的垂直自动缩放器与Autopilot 和 Kubernetes 的垂直自动缩放器相比能够改善内存使用松弛度。特别是，对于95%的服务实例，相对内存使用松弛率小于46%，而 Kubernetes 和 Autopilot 分别为 63% 和 66%。这 20% 的内存使用松弛可用于调度更多的服务实例或在集群中使用更少的 VM 资源，这将明显降低成本（见 5.5 小节）。我们还观察到 Kubernetes 的性能优于 Autopilot，因为它在设置限制方面采用了更激进的方法（使用 P95 × 1.15 的过去使用量与最大值相比）。&lt;/p&gt;
&lt;p&gt;虽然低内存或 CPU 使用松弛可以导致高效且具有成本效益的资源分配，但它可能导致更高的 OOM 率或 CPU 节流，从而降低服务性能。下图显示了实验过程中 OOM 的数量。可以看出，虽然与 Kubernetes 相比，SHOWAR 的 OOM 数量相当，但与 Autopilot 相比，它们在内存扩展方面的激进方法导致了更多的 OOM。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lizonglin313/MyPicGo/master/20220222124148.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;下图则描绘了在实验过程中微服务的平均 CPU 节流（CPU 紧松弛的结果）。当 Pod 的 CPU 使用率超过其分配的 CPU 资源时，容器运行时（使用𝑐𝑔𝑟𝑜𝑢𝑝𝑠）会限制 Pod 的 CPU 份额。可以看出，由于微服务 CPU 使用率的高波动（方差），SHOWAR 的 CPU 节流与基线相当。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lizonglin313/MyPicGo/master/20220222124339.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;根据以上三图的分析，&lt;strong&gt;资源松弛度（也反映了资源使用效率）和系统稳定性之间存在权衡&lt;/strong&gt;。SHOWAR和K8s在带来更好的资源效率的同时回不可避免的导致更多的OOM错误和CPU性能限制。而 Autopilot 会导致更多的松弛和更少的 OOM。&lt;/p&gt;
&lt;p&gt;因此，根据任务目标可调整 SHOWAR 和 Kubernetes 以实现更高的稳定性，但代价是更高的资源使用松弛度。例如，在 SHOWAR 中，可以使用 𝑘𝜎 代替 3𝜎 ，其中 𝑘 &amp;gt;3 为单个 Pod 分配更多资源并减轻 OOM 和 CPU 节流。&lt;/p&gt;
&lt;h3 id=&#34;horizontal-autoscaling&#34;&gt;Horizontal Autoscaling&lt;/h3&gt;
&lt;p&gt;使用垂直扩缩容相同的工作负载来评估水平扩缩容。将 SHOWAR 的 One for Each 和 One for All 设计与 Autopilot 和 Kubernetes 水平自动缩放器进行比较。Autopilot 和 Kubernetes 在水平自动缩放中使用相同的方法。我们将 Autopilot 和 Kubernetes 的目标 CPU 利用率设置为 65%，这是通常的建议。&lt;/p&gt;
&lt;p&gt;下图描绘了在实验过程中社交网络应用程序中微服务副本数量的累积分布函数。我们观察到 SHOWAR 的水平自动缩放器都优于 Autopilot 和 Kubernetes 水平自动缩放器，因为它为大多数微服务分配了更少的副本，这反过来又可以更有效地分配资源并节省成本（见 5.5 小节）。通过为每个微服务定制一个控制器，SHOWAR 的 One for Each 设计也优于 One for All。这是因为在 One for All 设计中，单个控制器尝试使用单个目标 runq 延迟值和跨所有微服务的平均 runq 延迟测量来扩展微服务，这会导致不必要的微服务扩展和高 runq 延迟。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lizonglin313/MyPicGo/master/20220222125146.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;再次强调，SHOWAR 的有效性是由于：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;自动缩放器的状态控制器&lt;/li&gt;
&lt;li&gt;用于自动缩放决策的更好的代表性指标（即 runq 延迟而不是 CPU 利用率）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我们看到了在单个微服务的自动扩展决策中使用更有意义和代表性的指标的效果。特别是，在评估过程中，我们观察到 Kubernetes 和 Autopilot 通常为 nginx 设置 16 个副本，这主要是因为它的 CPU 利用率很高。但&lt;strong&gt;高 CPU 利用率并不总是对应于微服务性能的大幅提升&lt;/strong&gt;。相比之下，SHOWAR 只为这个微服务设置了 10 个副本。另一方面，对于其他几个微服务所依赖的 User 微服务，Kubernetes 和 Autopilot 通常只为其设置 3 个副本。相比之下，SHOWAR 通常为此微服务设置 6 个副本。&lt;/p&gt;
&lt;h3 id=&#34;the-effect-of-affinity-and-anti-affinity-rules&#34;&gt;The Effect of Affinity and Anti-Affinity Rules&lt;/h3&gt;
&lt;p&gt;实验使用不同微服务之间 CPU、内存和网络 I/O 使用率的相关性来评估 SHOWAR 生成的 Pod 亲和性和反亲和性规则的效果。仍使用相同的工作负载并禁用垂直和水平扩缩容控制器，以凸显亲和性和反亲和性生成器的工作效果，以此观察K8s调度器受其的影响。&lt;/p&gt;
&lt;p&gt;同时观测了这如何影响端到端请求延迟，如下图所示。通过为调度程序提供调度提示（使用亲和性和反亲和性），SHOWAR 能够改善用户体验的 P99 延迟。特别是，使用 SHOWAR 生成的亲和和反亲和规则，请求延迟的 P99 为 6600 毫秒，而使用 Kubernetes 默认调度决策为 9000 毫秒。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lizonglin313/MyPicGo/master/20220222125945.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;end-to-end-performance&#34;&gt;End-to-End performance&lt;/h3&gt;
&lt;p&gt;在端到端性能评估这部分使用三个组件协同工作，使用下图的工作负载进行测试。为了适应工作负载，我们将集群的大小增加到 30 个 VM 实例。结果表明，与基线相比，SHOWAR 改进了资源分配和利用率，同时保持性能的稳定。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lizonglin313/MyPicGo/master/20220222131341.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;下图描述了用户在实验的 24 小时内经历的端到端请求延迟的 CDF。可以看出，使用 SHOWAR 的端到端性能与基线相当，并且使用其亲和性和反亲和性规则生成器以及依赖关系感知的水平自动缩放，与 Autopilot 和 Kubernetes 相比SHOWAR 能够将 P99 延迟提高 20% 以上。 Autopilot 和 Kubernetes 在 P99th 延迟方面表现出相似的性能，但是，由于为副本分配了更多内存，Autopilot 通常在较低的尾部优于 Kubernetes。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lizonglin313/MyPicGo/master/20220222131527.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;下图显示了实验过程中集群中的总内存分配（即为微服务副本设置的内存限制总和）。与基线相比，SHOWAR 平均为微服务副本分配的内存更少。特别是，SHOWAR 平均分配了 205 GB，而 Autopilot 和 Kubernetes 分别分配了 264 GB 和 249 GB。主要是因为 SHOWAR 的垂直自动缩放器实现了较低的内存使用松弛度，并且其水平自动缩放器为微服务设置了较少的副本数量。因此，使用 SHOWAR 的总内存分配小于基线。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lizonglin313/MyPicGo/master/20220222131959.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;最后，在下图中，展示了每个实验的归一化集群成本。我们将平均内存分配标准化为集群中一台虚拟机的内存大小（即 16 GB 用于𝑚5.𝑥𝑙𝑎𝑟𝑔𝑒 实例），并将其乘以 24 小时内一台虚拟机的成本（即 $0.192/ℎ𝑜𝑢𝑟）。这是因为，通常虚拟机在公共云上的价格是内存大小的线性函数 [17]。可以看出，与 Autopilot 和 Kubernetes 相比，SHOWAR 将集群总成本效益分别提高了 22% 和 17%。这些改进来自这样一个事实，即与基线相比，SHOWAR 的垂直和水平自动缩放器用&lt;strong&gt;分配更少的计算资源就可以达到相同的性能和服务质量&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lizonglin313/MyPicGo/master/20220222135039.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;不足和未来工作&#34;&gt;不足和未来工作&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;SHOWAR是基于历史和现在进行反应式调度的，&lt;strong&gt;缺乏预测能力&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;我们将 SHOWAR 设计为计算量轻且适应性强，这与使用需要训练且无法应对工作负载转移的机器学习的“黑盒”方法形成对比，例如 [39,55,57]。然而，目前 SHOWAR 的一个主要限制是它对微服务的资源使用是反应性的。因此，&lt;strong&gt;一个合适的探索途径是为 SHOWAR 配备近期工作负载和资源使用预测&lt;/strong&gt;，例如 [18]。结合其当前设计，&lt;strong&gt;预测近期工作负载可以改善 SHOWAR 的资源分配并防止由于自动缩放操作不足而导致性能下降&lt;/strong&gt;。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;另一个限制是它只关注微服务自动扩展并假设一个固定大小的集群&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;解决应用程序自动缩放器请求的资源总量超过可用集群资源总量的场景非常重要&lt;/strong&gt;。虽然集群自动缩放与应用程序自动缩放是正交的，但它们需要协同工作以实现资源分配的整体效率和应用程序的性能要求。因此，需要两个自动扩缩器之间的通信和协调才能向集群添加更多资源。在未来的工作中，我们&lt;strong&gt;计划改进 SHOWAR 的自动缩放器以与现有的集群自动缩放器 [12] 一起使用&lt;/strong&gt;。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;还不适用于Serverless类型的工作负载&lt;/p&gt;
&lt;p&gt;原因之一是垂直自动缩放不适用，因为&lt;strong&gt;无服务器功能的容器大小是预定义的&lt;/strong&gt;。 SHOWAR 的水平自动缩放器可能面临额外的复杂性，例如，跟踪“休眠”无服务器函数的数量（可以热启动）以及每个函数“过期”的时间（因此需要冷启动延迟）。我们将探索无服务器功能水平扩展的控制理论方法留给未来的工作。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;计划改进 SHOWAR 的亲和性和反亲和性规则生成器&lt;/p&gt;
&lt;p&gt;目前使用简单的经验资源利用相关系数来确定微服务之间的成对亲和力。例如，我们可以在未来&lt;strong&gt;探索其他统计数据对亲和力的影响&lt;/strong&gt;，例如不同类型资源之间的互相关，并&lt;strong&gt;探索不同类型的调度机制&lt;/strong&gt;，这些调度机制可以直接利用这些“原始”统计信息来提高效率资源利用[19]。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Kubernetes Service的使用(k8s实践-4)</title>
        <link>https://lizonglingo.github.io/p/kubernetes-service%E7%9A%84%E4%BD%BF%E7%94%A8k8s%E5%AE%9E%E8%B7%B5-4/</link>
        <pubDate>Tue, 25 Jan 2022 20:06:01 +0800</pubDate>
        
        <guid>https://lizonglingo.github.io/p/kubernetes-service%E7%9A%84%E4%BD%BF%E7%94%A8k8s%E5%AE%9E%E8%B7%B5-4/</guid>
        <description>&lt;h2 id=&#34;为什么需要使用kubernetes-service&#34;&gt;为什么需要使用Kubernetes Service&lt;/h2&gt;
&lt;p&gt;如前文提到，集群中Pod的IP地址是不稳定的， 会随着Pod的删除、重启、扩缩容等活动发生变动。这就出现了一个问题：无法通过一个固定的地址来访问应用程序。&lt;/p&gt;
&lt;p&gt;Kubernetes Service则专门来解决这个问题。&lt;/p&gt;
&lt;h2 id=&#34;kubernetes-service&#34;&gt;Kubernetes Service&lt;/h2&gt;
&lt;p&gt;K8s Service有一个固定的IP地址、固定的DNS名称以及固定的端口。通过标签选择器在后端连接所有符合要求的Pod，前端则提供了一个固定的访问平面来接收所有访问Pod的请求，再将这些请求负载均衡到后端的Pod中。可以将Service理解为Pod的网关，一个前端固定而后端随着Pod变化而变化的K8s中间件。&lt;/p&gt;
&lt;h3 id=&#34;使用label达到service与pod间的松耦合&#34;&gt;使用Label达到Service与Pod间的松耦合&lt;/h3&gt;
&lt;p&gt;Service通过标签选择器来选择Pod。如下面的&lt;code&gt;deploy.yml&lt;/code&gt;和&lt;code&gt;svc.yml&lt;/code&gt;文件。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;apps/v1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Deployment&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;web-deploy&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#f92672&#34;&gt;replicas&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#f92672&#34;&gt;selector&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;matchLabels&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;       &lt;span style=&#34;color:#f92672&#34;&gt;app&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;hello-world&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#f92672&#34;&gt;template&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      &lt;span style=&#34;color:#f92672&#34;&gt;labels&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#f92672&#34;&gt;app&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;hello-world	# 在Deployment的模板中，定义了Pod所属的标签，即 app=hello-world&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      &lt;span style=&#34;color:#f92672&#34;&gt;containers&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      - &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;hello-ctr&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#f92672&#34;&gt;image&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;nigelpoulton/k8sbook:latest&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#f92672&#34;&gt;ports&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        - &lt;span style=&#34;color:#f92672&#34;&gt;containerPort&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;8080&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;通过上面的Deployment部署文件部署的Pod都具有&lt;code&gt;app=hello-world&lt;/code&gt;这一标签。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;v1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Service&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;hello-svc&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#f92672&#34;&gt;type&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;NodePort&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#f92672&#34;&gt;ports&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  - &lt;span style=&#34;color:#f92672&#34;&gt;port&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;8081&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;nodePort&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;30001&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;targetPort&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;8080&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;protocol&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;TCP&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#f92672&#34;&gt;selector&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;app&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;hello-world	# 选择器selector选择的Pod应具有的标签&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;上面的Service部署文件则通过选择器选定含有标签为&lt;code&gt;app=hello-world&lt;/code&gt;的Pod，为这些Pod做匹配关联。Pod必须含有Service所指定的全部标签，除此之外还有其他多余的标签也是可以的。&lt;/p&gt;
&lt;h3 id=&#34;service与endpoint&#34;&gt;Service与Endpoint&lt;/h3&gt;
&lt;p&gt;每一个Service在创建时会关联到一个Endpoint对象，该Endpoint对象中维护所有满足Service标签选择器的Pod的列表。&lt;/p&gt;
&lt;p&gt;Kubernetes会不断检查Service的Label选择器和当前集群中的健康Pod列表，如果有新的可以匹配该Label选择器的Pod，就将其加入Endpoint中，然后Service从这个Endpoint中选择流量转发的Pod。&lt;/p&gt;
&lt;h3 id=&#34;service相关的端口&#34;&gt;Service相关的端口&lt;/h3&gt;
&lt;p&gt;上述Service部署文件中，出现了这样几个端口：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;ports&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  - &lt;span style=&#34;color:#f92672&#34;&gt;port&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;8081&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;nodePort&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;30001&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;targetPort&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;8080&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;protocol&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;TCP&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;port：Service监听的端口，集群中通过Service IP访问Pod应用的流量首先需要访问Service IP+port&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;nodePort：为集群外流量开放的端口，可以使用集群中任何一台部署Pod的主机的IP+nodePort访问应用&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;targetPort：Pod所监听的端口，告诉Service将流量转发到Pod的该端口&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Pod和Deployment的使用(k8s实践-3)</title>
        <link>https://lizonglingo.github.io/p/pod%E5%92%8Cdeployment%E7%9A%84%E4%BD%BF%E7%94%A8k8s%E5%AE%9E%E8%B7%B5-3/</link>
        <pubDate>Fri, 21 Jan 2022 18:28:33 +0800</pubDate>
        
        <guid>https://lizonglingo.github.io/p/pod%E5%92%8Cdeployment%E7%9A%84%E4%BD%BF%E7%94%A8k8s%E5%AE%9E%E8%B7%B5-3/</guid>
        <description>&lt;h2 id=&#34;使用pod&#34;&gt;使用Pod&lt;/h2&gt;
&lt;p&gt;Pod.yaml&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;v1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Pod&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;hello-pod&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#f92672&#34;&gt;labels&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;zone&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;prod&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;version&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;v1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#f92672&#34;&gt;containers&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  - &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;hello-ctr&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;image&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;nigelpoulton/k8sbook:latest&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;ports&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    - &lt;span style=&#34;color:#f92672&#34;&gt;containerPort&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;8080&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;创建Pod&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;root@lzl:/home/lzl# kubectl apply -f ./WorkSpace/k8s/pod/Pod.yml 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;pod/hello-pod created
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;root@lzl:/home/lzl# kubectl get Pods
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;NAME        READY   STATUS              RESTARTS   AGE
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello-pod   0/1     ContainerCreating   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          12s
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 要等一会，因为有拉取镜像的时间&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;root@lzl:/home/lzl# kubectl get Pods
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;NAME        READY   STATUS    RESTARTS   AGE
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello-pod   1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          110s
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;获取pod信息&#34;&gt;获取Pod信息&lt;/h3&gt;
&lt;p&gt;获取Pod详细信息：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;kubectl get Pods hello-pod -o yaml&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;root@lzl:/home/lzl# kubectl get Pods hello-pod -o yaml
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;apiVersion: v1
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kind: Pod
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;metadata:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  annotations:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    kubectl.kubernetes.io/last-applied-configuration: |
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;apiVersion&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;v1&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;kind&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Pod&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;metadata&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;annotations&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#f92672&#34;&gt;{}&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;labels&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;version&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;v1&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;zone&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;prod&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;name&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;hello-pod&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;namespace&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;default&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;spec&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;containers&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#f92672&#34;&gt;[{&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;image&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;nigelpoulton/k8sbook:latest&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;name&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;hello-ctr&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;ports&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#f92672&#34;&gt;[{&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;containerPort&amp;#34;&lt;/span&gt;:8080&lt;span style=&#34;color:#f92672&#34;&gt;}]}]}}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  creationTimestamp: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;2022-01-19T10:26:35Z&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  labels:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    version: v1
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    zone: prod
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  name: hello-pod
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  namespace: default
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  resourceVersion: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;29553&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  uid: 1f41e62a-a951-4593-83f7-f3e7398b9d24
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;spec:	&lt;span style=&#34;color:#75715e&#34;&gt;# 这部分是Pod的期望状态&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  containers:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  - image: nigelpoulton/k8sbook:latest
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    imagePullPolicy: Always
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    name: hello-ctr
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    ports:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    - containerPort: &lt;span style=&#34;color:#ae81ff&#34;&gt;8080&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      protocol: TCP
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    resources: &lt;span style=&#34;color:#f92672&#34;&gt;{}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    terminationMessagePath: /dev/termination-log
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    terminationMessagePolicy: File
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    volumeMounts:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      name: kube-api-access-5kwmz
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      readOnly: true
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  dnsPolicy: ClusterFirst
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  enableServiceLinks: true
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  nodeName: lzl-c
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  preemptionPolicy: PreemptLowerPriority
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  priority: &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  restartPolicy: Always
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  schedulerName: default-scheduler
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  securityContext: &lt;span style=&#34;color:#f92672&#34;&gt;{}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  serviceAccount: default
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  serviceAccountName: default
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  terminationGracePeriodSeconds: &lt;span style=&#34;color:#ae81ff&#34;&gt;30&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  tolerations:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  - effect: NoExecute
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    key: node.kubernetes.io/not-ready
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    operator: Exists
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    tolerationSeconds: &lt;span style=&#34;color:#ae81ff&#34;&gt;300&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  - effect: NoExecute
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    key: node.kubernetes.io/unreachable
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    operator: Exists
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    tolerationSeconds: &lt;span style=&#34;color:#ae81ff&#34;&gt;300&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  volumes:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  - name: kube-api-access-5kwmz
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    projected:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      defaultMode: &lt;span style=&#34;color:#ae81ff&#34;&gt;420&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      sources:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      - serviceAccountToken:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;          expirationSeconds: &lt;span style=&#34;color:#ae81ff&#34;&gt;3607&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;          path: token
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      - configMap:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;          items:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;          - key: ca.crt
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            path: ca.crt
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;          name: kube-root-ca.crt
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      - downwardAPI:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;          items:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;          - fieldRef:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;              apiVersion: v1
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;              fieldPath: metadata.namespace
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            path: namespace
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;status:	&lt;span style=&#34;color:#75715e&#34;&gt;# 这部分是Pod的当前状态&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  conditions:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  - lastProbeTime: null
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    lastTransitionTime: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;2022-01-19T10:26:35Z&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    status: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;True&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    type: Initialized
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  - lastProbeTime: null
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    lastTransitionTime: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;2022-01-19T10:26:58Z&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    status: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;True&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    type: Ready
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  - lastProbeTime: null
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    lastTransitionTime: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;2022-01-19T10:26:58Z&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    status: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;True&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    type: ContainersReady
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  - lastProbeTime: null
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    lastTransitionTime: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;2022-01-19T10:26:35Z&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    status: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;True&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    type: PodScheduled
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  containerStatuses:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  - containerID: docker://a7cc9815fc32e3f99f57553c6c28aa264576dbc3076784fee485a4306a1f4fcb
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    image: nigelpoulton/k8sbook:latest
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    imageID: docker-pullable://nigelpoulton/k8sbook@sha256:a983a96a85151320cd6ad0cd9fda3b725a743ed642e58b0597285c6bcb46c90f
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    lastState: &lt;span style=&#34;color:#f92672&#34;&gt;{}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    name: hello-ctr
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    ready: true
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    restartCount: &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    started: true
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    state:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      running:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        startedAt: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;2022-01-19T10:26:58Z&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  hostIP: 192.168.230.13
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  phase: Running
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  podIP: 10.5.2.2
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  podIPs:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  - ip: 10.5.2.2
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  qosClass: BestEffort
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  startTime: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;2022-01-19T10:26:35Z&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;&lt;code&gt;kubectl describe Pods hello-pod&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;root@lzl:/home/lzl# kubectl describe Pods hello-pod
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Name:         hello-pod
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Namespace:    default
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Priority:     &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Node:         lzl-c/192.168.230.13
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Start Time:   Wed, &lt;span style=&#34;color:#ae81ff&#34;&gt;19&lt;/span&gt; Jan &lt;span style=&#34;color:#ae81ff&#34;&gt;2022&lt;/span&gt; 18:26:35 +0800
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Labels:       version&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;v1
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;              zone&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;prod
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Annotations:  &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Status:       Running
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;IP:           10.5.2.2
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;IPs:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  IP:  10.5.2.2
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Containers:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  hello-ctr:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    Container ID:   docker://a7cc9815fc32e3f99f57553c6c28aa264576dbc3076784fee485a4306a1f4fcb
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    Image:          nigelpoulton/k8sbook:latest
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    Image ID:       docker-pullable://nigelpoulton/k8sbook@sha256:a983a96a85151320cd6ad0cd9fda3b725a743ed642e58b0597285c6bcb46c90f
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    Port:           8080/TCP
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    Host Port:      0/TCP
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    State:          Running
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      Started:      Wed, &lt;span style=&#34;color:#ae81ff&#34;&gt;19&lt;/span&gt; Jan &lt;span style=&#34;color:#ae81ff&#34;&gt;2022&lt;/span&gt; 18:26:58 +0800
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    Ready:          True
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    Restart Count:  &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    Environment:    &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    Mounts:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-5kwmz &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;ro&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Conditions:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  Type              Status
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  Initialized       True 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  Ready             True 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  ContainersReady   True 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  PodScheduled      True 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Volumes:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  kube-api-access-5kwmz:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    Type:                    Projected &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;a volume that contains injected data from multiple sources&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    TokenExpirationSeconds:  &lt;span style=&#34;color:#ae81ff&#34;&gt;3607&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    ConfigMapName:           kube-root-ca.crt
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    ConfigMapOptional:       &amp;lt;nil&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    DownwardAPI:             true
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;QoS Class:                   BestEffort
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Node-Selectors:              &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Tolerations:                 node.kubernetes.io/not-ready:NoExecute op&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;Exists &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; 300s
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                             node.kubernetes.io/unreachable:NoExecute op&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;Exists &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; 300s
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Events:	&lt;span style=&#34;color:#75715e&#34;&gt;# Pod生命周期中的一些重要事件&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  Type    Reason     Age    From               Message
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  ----    ------     ----   ----               -------
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  Normal  Scheduled  6m56s  default-scheduler  Successfully assigned default/hello-pod to lzl-c
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  Normal  Pulling    6m54s  kubelet            Pulling image &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;nigelpoulton/k8sbook:latest&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  Normal  Pulled     6m33s  kubelet            Successfully pulled image &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;nigelpoulton/k8sbook:latest&amp;#34;&lt;/span&gt; in 21.212884013s
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  Normal  Created    6m33s  kubelet            Created container hello-ctr
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  Normal  Started    6m33s  kubelet            Started container hello-ctr
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;进入pod中的容器内部&#34;&gt;进入Pod中的容器内部&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;还可以进入容器执行命令，来查看Pod的信息：&lt;code&gt;kubectl exec hello-pod -- ps aux&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;root@lzl:/home/lzl# kubectl exec hello-pod -- ps aux
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;PID   USER     TIME  COMMAND
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; root      0:00 node ./app.js
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;   &lt;span style=&#34;color:#ae81ff&#34;&gt;13&lt;/span&gt; root      0:00 ps aux
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;登录到运行容器内部：&lt;code&gt;kubectl exec -it hello-pod -- sh&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;root@lzl:/home/lzl# kubectl exec -it hello-pod -- sh
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;/src &lt;span style=&#34;color:#75715e&#34;&gt;# ls&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Dockerfile         app.js             package-lock.json  views
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;README.md          node_modules       package.json
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;/src &lt;span style=&#34;color:#75715e&#34;&gt;# exit&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;root@lzl:/home/lzl# 
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;当Pod中有多个容器时，需要使用&lt;code&gt;--container&lt;/code&gt;参数指定想要创建交互式会话的容器，不指定的话默认是第一个容器。&lt;/p&gt;
&lt;p&gt;使用&lt;code&gt;exit&lt;/code&gt;退出当前容器。&lt;/p&gt;
&lt;h3 id=&#34;删除pod&#34;&gt;删除Pod&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;kubectl delete -f pod.yaml&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;root@lzl:/home/lzl# kubectl delete -f ./WorkSpace/k8s/pod/Pod.yml 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;pod &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;hello-pod&amp;#34;&lt;/span&gt; deleted
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;root@lzl:/home/lzl# kubectl get Pods
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;No resources found in default namespace.
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;使用deployment部署pod&#34;&gt;使用Deployment部署Pod&lt;/h2&gt;
&lt;p&gt;Deployment为Kubernetes带来自愈、自动扩缩容、滚动升级以及基于版本的回滚的能力。实际上在底层Deployment是使用的ReplicaSet来完成的，可以理解为，Deployment管理ReplicaSet，而ReplicaSet管理Pod。&lt;/p&gt;
&lt;h3 id=&#34;部署deployment&#34;&gt;部署Deployment&lt;/h3&gt;
&lt;p&gt;本次部署的文件&lt;code&gt;deploy.yaml&lt;/code&gt;如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;apiVersion: apps/v1
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kind: Deployment
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;metadata:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  name: hello-deploy
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;spec:                       &lt;span style=&#34;color:#75715e&#34;&gt;# spec下的内容都与Pod有关&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  replicas: &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  selector:                 &lt;span style=&#34;color:#75715e&#34;&gt;# 表示该Deployment所管理的Pod必须要有的标签&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    matchLabels:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      app: hello-world
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  minReadySeconds: &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  strategy:                 &lt;span style=&#34;color:#75715e&#34;&gt;# 表示更新策略&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    type: RollingUpdate
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    rollingUpdate:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      maxUnavailable: &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      maxSurge: &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  template:                 &lt;span style=&#34;color:#75715e&#34;&gt;# 所管理的Pod的模板，这里只有一个容器&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    metadata:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      labels:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        app: hello-world
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    spec:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      containers:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      - name: hello-pod
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        image: nigelpoulton/k8sbook:latest
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        ports:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        - containerPort: &lt;span style=&#34;color:#ae81ff&#34;&gt;8080&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;进行部署：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;root@lzl:/home/lzl# kubectl apply -f ./WorkSpace/k8s/deployment/deploy.yaml 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;deployment.apps/hello-deploy created
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;查看deployment&#34;&gt;查看Deployment&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;使用&lt;code&gt;kubectl get&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;root@lzl:/home/lzl# kubectl get deploy hello-deploy
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;NAME           READY   UP-TO-DATE   AVAILABLE   AGE
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello-deploy   10/10   &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;           &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;          2m29s
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;使用&lt;code&gt;kubectl describe&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;root@lzl:/home/lzl# kubectl describe deploy hello-deploy
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Name:                   hello-deploy
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Namespace:              default
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;CreationTimestamp:      Wed, &lt;span style=&#34;color:#ae81ff&#34;&gt;19&lt;/span&gt; Jan &lt;span style=&#34;color:#ae81ff&#34;&gt;2022&lt;/span&gt; 19:18:16 +0800
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Labels:                 &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Annotations:            deployment.kubernetes.io/revision: &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Selector:               app&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;hello-world
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Replicas:               &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt; desired | &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt; updated | &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt; total | &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt; available | &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; unavailable
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;StrategyType:           RollingUpdate
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;MinReadySeconds:        &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;RollingUpdateStrategy:  &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; max unavailable, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; max surge
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Pod Template:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  Labels:  app&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;hello-world
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  Containers:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;   hello-pod:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    Image:        nigelpoulton/k8sbook:latest
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    Port:         8080/TCP
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    Host Port:    0/TCP
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    Environment:  &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    Mounts:       &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  Volumes:        &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Conditions:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  Type           Status  Reason
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  ----           ------  ------
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  Available      True    MinimumReplicasAvailable
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  Progressing    True    NewReplicaSetAvailable
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;OldReplicaSets:  &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;NewReplicaSet:   hello-deploy-65cbc9474c &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;10/10 replicas created&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Events:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  Type    Reason             Age    From                   Message
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  ----    ------             ----   ----                   -------
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  Normal  ScalingReplicaSet  4m17s  deployment-controller  Scaled up replica set hello-deploy-65cbc9474c to &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;可以使用&lt;code&gt;kubectl get rs&lt;/code&gt;来查看ReplicaSet的状态，以及&lt;code&gt;kubectl describe rs&lt;/code&gt;来查看其详细信息&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;root@lzl:/home/lzl# kubectl get rs
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;NAME                      DESIRED   CURRENT   READY   AGE
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello-deploy-65cbc9474c   &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;        &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;        &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;      5m55s
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;root@lzl:/home/lzl# kubectl describe rs hello-deploy-65cbc9474c
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Name:           hello-deploy-65cbc9474c
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Namespace:      default
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Selector:       app&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;hello-world,pod-template-hash&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;65cbc9474c
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Labels:         app&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;hello-world
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                pod-template-hash&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;65cbc9474c
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Annotations:    deployment.kubernetes.io/desired-replicas: &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                deployment.kubernetes.io/max-replicas: &lt;span style=&#34;color:#ae81ff&#34;&gt;11&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                deployment.kubernetes.io/revision: &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Controlled By:  Deployment/hello-deploy
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Replicas:       &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt; current / &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt; desired
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Pods Status:    &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt; Running / &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; Waiting / &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; Succeeded / &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; Failed
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Pod Template:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  Labels:  app&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;hello-world
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;           pod-template-hash&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;65cbc9474c
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  Containers:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;   hello-pod:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    Image:        nigelpoulton/k8sbook:latest
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    Port:         8080/TCP
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    Host Port:    0/TCP
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    Environment:  &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    Mounts:       &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  Volumes:        &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Events:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  Type    Reason            Age    From                   Message
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  ----    ------            ----   ----                   -------
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  Normal  SuccessfulCreate  7m39s  replicaset-controller  Created pod: hello-deploy-65cbc9474c-plhwm
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  Normal  SuccessfulCreate  7m39s  replicaset-controller  Created pod: hello-deploy-65cbc9474c-8fdqs
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  Normal  SuccessfulCreate  7m39s  replicaset-controller  Created pod: hello-deploy-65cbc9474c-dlv5g
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  Normal  SuccessfulCreate  7m39s  replicaset-controller  Created pod: hello-deploy-65cbc9474c-x2ddb
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  Normal  SuccessfulCreate  7m39s  replicaset-controller  Created pod: hello-deploy-65cbc9474c-qgffd
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  Normal  SuccessfulCreate  7m39s  replicaset-controller  Created pod: hello-deploy-65cbc9474c-67nlw
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  Normal  SuccessfulCreate  7m39s  replicaset-controller  Created pod: hello-deploy-65cbc9474c-gg4r2
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  Normal  SuccessfulCreate  7m39s  replicaset-controller  Created pod: hello-deploy-65cbc9474c-b2v4v
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  Normal  SuccessfulCreate  7m39s  replicaset-controller  Created pod: hello-deploy-65cbc9474c-vbzrd
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  Normal  SuccessfulCreate  7m39s  replicaset-controller  &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;combined from similar events&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;: Created pod: hello-deploy-65cbc9474c-pjwsh
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;访问部署的应用&#34;&gt;访问部署的应用&lt;/h3&gt;
&lt;p&gt;对于Pod来说，其IP会由于销毁或者重建而改变，Pod的IP是一个变量，通常不能直接使用Pod的IP作为通讯。在K8s中，Kubernetes Service对象则解决了这一问题，它为一组Pod提供了一个固定的DNS域名和IP地址。&lt;/p&gt;
&lt;p&gt;下面定义一个Service与上述Pod进行协同工作。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;svc.yaml&lt;/code&gt;：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;v1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;Service&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;hello-svc&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#f92672&#34;&gt;labels&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;app&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;hello-world&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;spec&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#f92672&#34;&gt;type&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;NodePort&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#f92672&#34;&gt;ports&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  - &lt;span style=&#34;color:#f92672&#34;&gt;port&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;8080&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;nodePort&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;30001&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;protocol&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;TCP&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#f92672&#34;&gt;selector&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;app&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;hello-world&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;部署Service：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;root@lzl:/home/lzl# kubectl apply -f ./WorkSpace/k8s/service/svc.yaml
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;service/hello-svc created
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;这样我们有两种方式可以访问该应用：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;在集群内部使用DNS名称&lt;code&gt;hello-svc&lt;/code&gt;和端口&lt;code&gt;8080&lt;/code&gt;访问&lt;/li&gt;
&lt;li&gt;在集群外部通过集群的任意节点和端口号&lt;code&gt;30001&lt;/code&gt;访问&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;首先我们查看我们刚部署的这10个Pod实例的具体信息：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;root@lzl:/home/lzl# kubectl get pods -l app&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;hello-world -o wide
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;NAME                            READY   STATUS    RESTARTS   AGE   IP         NODE    NOMINATED NODE   READINESS GATES
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello-deploy-65cbc9474c-67nlw   1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          72m   10.5.1.4   lzl-b   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello-deploy-65cbc9474c-8fdqs   1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          72m   10.5.2.6   lzl-c   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello-deploy-65cbc9474c-b2v4v   1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          72m   10.5.2.4   lzl-c   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello-deploy-65cbc9474c-dlv5g   1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          72m   10.5.2.7   lzl-c   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello-deploy-65cbc9474c-gg4r2   1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          72m   10.5.2.5   lzl-c   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello-deploy-65cbc9474c-pjwsh   1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          72m   10.5.2.3   lzl-c   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello-deploy-65cbc9474c-plhwm   1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          72m   10.5.1.5   lzl-b   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello-deploy-65cbc9474c-qgffd   1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          72m   10.5.1.2   lzl-b   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello-deploy-65cbc9474c-vbzrd   1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          72m   10.5.1.6   lzl-b   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello-deploy-65cbc9474c-x2ddb   1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          72m   10.5.1.3   lzl-b   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;k8s自动为这些Pod分配了IP地址。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;引自官方文档：&lt;/p&gt;
&lt;p&gt;Kubernetes Service 从逻辑上定义了运行在集群中的一组 Pod，这些 Pod 提供了相同的功能。 当每个 Service 创建时，会被分配一个唯一的 IP 地址（也称为 clusterIP）。 这个 IP 地址与一个 Service 的生命周期绑定在一起，当 Service 存在的时候它也不会改变。 可以配置 Pod 使它与 Service 进行通信，Pod 知道与 Service 通信将被自动地负载均衡到该 Service 中的某些 Pod 上。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;我们查看创建的Service的信息：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;root@lzl:/home/lzl# kubectl get svc hello-svc
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;NAME        TYPE       CLUSTER-IP       EXTERNAL-IP   PORT&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;S&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;          AGE
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello-svc   NodePort   10.110.196.234   &amp;lt;none&amp;gt;        8080:30001/TCP   19m
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;root@lzl:/home/lzl# kubectl describe svc hello-svc
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Name:                     hello-svc
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Namespace:                default
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Labels:                   app&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;hello-world
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Annotations:              &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Selector:                 app&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;hello-world
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Type:                     NodePort
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;IP Family Policy:         SingleStack
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;IP Families:              IPv4
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;IP:                       10.110.196.234
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;IPs:                      10.110.196.234
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Port:                     &amp;lt;unset&amp;gt;  8080/TCP
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;TargetPort:               8080/TCP
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;NodePort:                 &amp;lt;unset&amp;gt;  30001/TCP
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Endpoints:                10.5.1.2:8080,10.5.1.3:8080,10.5.1.4:8080 + &lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt; more...
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Session Affinity:         None
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;External Traffic Policy:  Cluster
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Events:                   &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;这里我遇到了集群内部和集群外部都无法访问应用的情况&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;集群内部无法访问
&lt;ul&gt;
&lt;li&gt;在Pod运行的节点上可以访问，但是在集群其他节点上无法访问&lt;/li&gt;
&lt;li&gt;无法访问Service&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;集群外部无法访问：可以通过运行Pod的主机地址访问，而无法通过没有运行Pod的集群主机地址进行访问&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;解决方案在下一节&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;将问题解决后，我们来看。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;root@lzl-a:/home/lzl/WP/k8s/deploy# kubectl get pods -o wide
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;NAME                           READY   STATUS    RESTARTS        AGE   IP          NODE    NOMINATED NODE   READINESS GATES
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello-deploy-59866ff45-2hp8j   1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;8m20s ago&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;   39m   10.5.1.4    lzl-b   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello-deploy-59866ff45-4lhld   1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;8m20s ago&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;   38m   10.5.1.11   lzl-b   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello-deploy-59866ff45-7pn94   1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;8m20s ago&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;   35m   10.5.1.5    lzl-b   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello-deploy-59866ff45-9d444   1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;8m20s ago&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;   35m   10.5.1.3    lzl-b   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello-deploy-59866ff45-lhx2j   1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;8m20s ago&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;   37m   10.5.1.9    lzl-b   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello-deploy-59866ff45-nwcp8   1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;8m20s ago&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;   36m   10.5.1.2    lzl-b   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello-deploy-59866ff45-prwwd   1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;8m19s ago&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;   36m   10.5.1.7    lzl-b   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello-deploy-59866ff45-rflnv   1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;8m19s ago&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;   34m   10.5.1.6    lzl-b   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello-deploy-59866ff45-tbpt2   1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;8m19s ago&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;   37m   10.5.1.10   lzl-b   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello-deploy-59866ff45-z88ct   1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;8m19s ago&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;   39m   10.5.1.8    lzl-b   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;root@lzl-a:/home/lzl/WP/k8s/deploy# kubectl get svc -o wide
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;NAME         TYPE        CLUSTER-IP      EXTERNAL-IP   PORT&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;S&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;          AGE   SELECTOR
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello-svc    NodePort    10.101.13.201   &amp;lt;none&amp;gt;        8080:30001/TCP   18h   app&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;hello-world
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubernetes   ClusterIP   10.96.0.1       &amp;lt;none&amp;gt;        443/TCP          18h   &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;从集群内访问&#34;&gt;从集群内访问&lt;/h4&gt;
&lt;p&gt;以服务实例&lt;code&gt;hello-deploy-59866ff45-2hp8j&lt;/code&gt;为例，其地址为&lt;code&gt;10.5.1.4:8080&lt;/code&gt;。因此，在集群内部任何一台机器访问该地址都可以访问到这个应用。&lt;/p&gt;
&lt;p&gt;同样的，&lt;code&gt;hello-svc&lt;/code&gt;的地址是&lt;code&gt;10.101.13.201:8080&lt;/code&gt;，加入集群的任何一台主机都可以通过该地址访问到应用。&lt;/p&gt;
&lt;p&gt;**特别的，与Pod的IP不同，Service的IP是固定不变的，而Pod的IP会跟随Deployment的更新、扩缩容等操作改变。**Service实际上相当于所有Pod的一个网关，它有固定的IP地址，并且将请求Pod的流量负载均衡到不同的Pod上，并在Pod地址改变时完成服务发现。&lt;/p&gt;
&lt;h4 id=&#34;从集群外访问&#34;&gt;从集群外访问&lt;/h4&gt;
&lt;p&gt;如果在集群外，那么访问集群内的任何一台主机的&lt;code&gt;30001&lt;/code&gt;端口都可以连接到该应用，因为前面&lt;code&gt;svc.yaml&lt;/code&gt;：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; ports:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  - port: &lt;span style=&#34;color:#ae81ff&#34;&gt;8080&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    nodePort: &lt;span style=&#34;color:#ae81ff&#34;&gt;30001&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    protocol: TCP
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;帮我们做了集群内到集群外的端口映射。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lizonglin313/MyPicGo/master/20220121163556.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lizonglin313/MyPicGo/master/20220121163510.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;解决由于iptables版本差异导致的k8s网络问题&#34;&gt;解决由于iptables版本差异导致的K8s网络问题&lt;/h2&gt;
&lt;p&gt;如上文，我是用Ubuntu18.04搭建K8s1.22.4集群，在启动Service做应用网络入口时，出现了上述问题。找了很久的资料之后认为是k8s1.22.4在使用iptables配置网络规则时由于版本较新，其使用的配置命令在Ubuntu18.04版本上的iptables无法解析，导致网络出现问题。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://bugs.launchpad.net/ubuntu/&amp;#43;source/linux-meta-hwe-5.4/&amp;#43;bug/1899690&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://bugs.launchpad.net/ubuntu/+source/linux-meta-hwe-5.4/+bug/1899690&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;所以我将虚拟机换为Ubuntu20.04后，该问题得到解决。由此看出，K8s对于环境版本一致性的要求还是比较高的。&lt;/p&gt;
&lt;h2 id=&#34;解决由于虚拟机挂起恢复虚拟机后集群网络异常的问题&#34;&gt;解决由于虚拟机挂起，恢复虚拟机后集群网络异常的问题&lt;/h2&gt;
&lt;p&gt;在虚拟机挂起，再恢复之后，集群网络出现了问题，具体表现在：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;无法通过Pod地址访问应用&lt;/li&gt;
&lt;li&gt;无法通过Service地址访问应用&lt;/li&gt;
&lt;li&gt;集群间Pod无法联通&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;在一篇博文中找到了解决方法：https://blog.csdn.net/weixin_43293361/article/details/114731838&lt;/p&gt;
&lt;p&gt;首先，查看Master Node的网络，发现原本的&lt;code&gt;cni0&lt;/code&gt;和&lt;code&gt;flannel.1&lt;/code&gt;网络均不存在了：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lizonglin313/MyPicGo/master/20220121164938.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;然后查看了Work Node的网络，上述两个网络也是不存在的。所以按照&lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/weixin_43293361/article/details/114731838&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;博文&lt;/a&gt;给出的方法：&lt;/p&gt;
&lt;p&gt;1）在Master Node删除flannel网络组件：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl delete -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;2）在Master Node和Work Node上重置集群网络配置（集群所有节点上）：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ifconfig cni0 down
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ip link delete cni0
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ifconfig flannel.1 down
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ip link delete flannel.1
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;rm -rf /var/lib/cni/flannel/*
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;rm -rf /var/lib/cni/networks/cbr0/*
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;rm -rf /var/lib/cni/cache/*
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;rm -f /etc/cni/net.d/*
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;systemctl restart kubelet
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;systemctl restart docker
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;chmod a+w /var/run/docker.sock
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;3）最后在Master Node重新安装flannel网络组件：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;4）查看集群各个节点的网络情况，&lt;code&gt;cni0&lt;/code&gt;和&lt;code&gt;flannel.1&lt;/code&gt;网络均正常出现，然后等待Deployment的Pod自愈，这样集群网络就可以正常恢复。&lt;/p&gt;
&lt;h2 id=&#34;滚动升级与回滚&#34;&gt;滚动升级与回滚&lt;/h2&gt;
&lt;h3 id=&#34;滚动升级&#34;&gt;滚动升级&lt;/h3&gt;
&lt;p&gt;在升级使用的&lt;code&gt;deploy.yaml&lt;/code&gt;文件中：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;apiVersion: apps/v1
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kind: Deployment
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;metadata:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  name: hello-deploy
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;spec:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  replicas: &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  selector:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    matchLabels:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      app: hello-world
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  minReadySeconds: &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  strategy:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    type: RollingUpdate	&lt;span style=&#34;color:#75715e&#34;&gt;# 滚动更新&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    rollingUpdate:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      maxUnavailable: 1	&lt;span style=&#34;color:#75715e&#34;&gt;# 集群中最多有一个不可用Pod&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      maxSurge: 1		&lt;span style=&#34;color:#75715e&#34;&gt;# 集群中Pod最多超过预期值1个&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  template:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    metadata:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      labels:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        app: hello-world
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    spec:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      containers:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      - name: hello-pod
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        image: nigelpoulton/k8sbook:edge	&lt;span style=&#34;color:#75715e&#34;&gt;# 使用了另一个版本的镜像&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        ports:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        - containerPort: &lt;span style=&#34;color:#ae81ff&#34;&gt;8080&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;与上一个&lt;code&gt;deploy.yaml&lt;/code&gt;不同，这里使用了另一个版本的镜像，更新策略由&lt;code&gt;strategy&lt;/code&gt;下的内容决定。&lt;/p&gt;
&lt;p&gt;进行滚动升级：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;root@lzl-a:/home/lzl/WP/k8s/deploy# kubectl apply -f deploy.yaml --record
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Flag --record has been deprecated, --record will be removed in the future
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;deployment.apps/hello-deploy configured
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;root@lzl-a:/home/lzl/WP/k8s/deploy# kubectl rollout status deployment hello-deploy
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Waiting &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; deployment &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;hello-deploy&amp;#34;&lt;/span&gt; rollout to finish: &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; out of &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt; new replicas have been updated...
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;^Croot@lzl-a:/home/lzl/WP/k8s/deploy# kubectl get deploy
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;NAME           READY   UP-TO-DATE   AVAILABLE   AGE
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello-deploy   10/10   &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;            &lt;span style=&#34;color:#ae81ff&#34;&gt;9&lt;/span&gt;           17h
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;root@lzl-a:/home/lzl/WP/k8s/deploy# kubectl get deploy
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;NAME           READY   UP-TO-DATE   AVAILABLE   AGE
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello-deploy   10/10   &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;            &lt;span style=&#34;color:#ae81ff&#34;&gt;9&lt;/span&gt;           17h
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;root@lzl-a:/home/lzl/WP/k8s/deploy# kubectl get deploy
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;NAME           READY   UP-TO-DATE   AVAILABLE   AGE
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello-deploy   9/10    &lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;            &lt;span style=&#34;color:#ae81ff&#34;&gt;9&lt;/span&gt;           17h
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;可以看到，如Docker Swarm一样，在升级过程中，同时存在新版本与旧版本的应用，直至整个升级过程结束。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;root@lzl-a:/home/lzl/WP/k8s/deploy# kubectl get deploy hello-deploy
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;NAME           READY   UP-TO-DATE   AVAILABLE   AGE
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello-deploy   10/10   &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;           &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;          17h
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;回滚&#34;&gt;回滚&lt;/h3&gt;
&lt;p&gt;Kubernetes会维护Deployment的版本历史记录：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;root@lzl-a:/home/lzl/WP/k8s/deploy# kubectl rollout history deployment hello-deploy
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;deployment.apps/hello-deploy 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;REVISION  CHANGE-CAUSE
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;         &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;         kubectl apply --filename&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;deploy.yaml --record&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;true
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;对于Deployment依赖的ReplicaSet来说，每次更新都会保留旧版本的ReplicaSet同时创建一个新的ReplicaSet：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;root@lzl-a:/home/lzl/WP/k8s/deploy# kubectl get rs
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;NAME                      DESIRED   CURRENT   READY   AGE
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello-deploy-59866ff45    &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;        &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;        &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;      158m
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello-deploy-65cbc9474c   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;         &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;         &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;       20h
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;root@lzl-a:/home/lzl/WP/k8s/deploy# kubectl describe rs
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Name:           hello-deploy-59866ff45
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Namespace:      default
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Selector:       app&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;hello-world,pod-template-hash&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;59866ff45
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Labels:         app&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;hello-world
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                pod-template-hash&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;59866ff45
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Annotations:    deployment.kubernetes.io/desired-replicas: &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                deployment.kubernetes.io/max-replicas: &lt;span style=&#34;color:#ae81ff&#34;&gt;11&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                deployment.kubernetes.io/revision: &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                kubernetes.io/change-cause: kubectl apply --filename&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;deploy.yaml --record&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;true
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Controlled By:  Deployment/hello-deploy
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Replicas:       &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt; current / &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt; desired
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Pods Status:    &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt; Running / &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; Waiting / &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; Succeeded / &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; Failed
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Pod Template:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  Labels:  app&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;hello-world
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;           pod-template-hash&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;59866ff45
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  Containers:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;   hello-pod:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    Image:        nigelpoulton/k8sbook:edge
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    Port:         8080/TCP
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    Host Port:    0/TCP
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    Environment:  &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    Mounts:       &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  Volumes:        &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Events:           &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Name:           hello-deploy-65cbc9474c
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Namespace:      default
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Selector:       app&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;hello-world,pod-template-hash&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;65cbc9474c
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Labels:         app&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;hello-world
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                pod-template-hash&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;65cbc9474c
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Annotations:    deployment.kubernetes.io/desired-replicas: &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                deployment.kubernetes.io/max-replicas: &lt;span style=&#34;color:#ae81ff&#34;&gt;11&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                deployment.kubernetes.io/revision: &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Controlled By:  Deployment/hello-deploy
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Replicas:       &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; current / &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; desired
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Pods Status:    &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; Running / &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; Waiting / &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; Succeeded / &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; Failed
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Pod Template:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  Labels:  app&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;hello-world
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;           pod-template-hash&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;65cbc9474c
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  Containers:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;   hello-pod:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    Image:        nigelpoulton/k8sbook:latest
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    Port:         8080/TCP
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    Host Port:    0/TCP
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    Environment:  &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    Mounts:       &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  Volumes:        &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Events:           &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;通过ReplicaSet的信息，可以清楚的知道两个ReplicaSet所做的操作，并且由于旧版本ReplicaSet的存在，回滚操作变得更加简单。下面将应用回滚到版本1，同时别忘记再更新一下yaml文件：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;root@lzl-a:/home/lzl/WP/k8s/deploy# kubectl rollout undo deployment hello-deploy --to-revision&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;deployment.apps/hello-deploy rolled back
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;root@lzl-a:/home/lzl/WP/k8s/deploy# kubectl get pods -o wide
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;NAME                            READY   STATUS              RESTARTS       AGE    IP          NODE    NOMINATED NODE   READINESS GATES
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello-deploy-59866ff45-2hp8j    1/1     Running             &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;135m ago&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;   166m   10.5.1.4    lzl-b   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello-deploy-59866ff45-4lhld    1/1     Running             &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;135m ago&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;   165m   10.5.1.11   lzl-b   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello-deploy-59866ff45-7pn94    1/1     Running             &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;135m ago&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;   162m   10.5.1.5    lzl-b   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello-deploy-59866ff45-9d444    1/1     Running             &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;135m ago&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;   162m   10.5.1.3    lzl-b   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello-deploy-59866ff45-lhx2j    1/1     Terminating         &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;135m ago&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;   164m   10.5.1.9    lzl-b   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello-deploy-59866ff45-nwcp8    1/1     Running             &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;135m ago&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;   163m   10.5.1.2    lzl-b   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello-deploy-59866ff45-prwwd    1/1     Running             &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;135m ago&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;   163m   10.5.1.7    lzl-b   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello-deploy-59866ff45-rflnv    1/1     Running             &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;135m ago&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;   161m   10.5.1.6    lzl-b   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello-deploy-59866ff45-tbpt2    1/1     Running             &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;135m ago&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;   165m   10.5.1.10   lzl-b   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello-deploy-59866ff45-z88ct    1/1     Running             &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;135m ago&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;   166m   10.5.1.8    lzl-b   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello-deploy-65cbc9474c-98bh2   0/1     ContainerCreating   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;              10s    &amp;lt;none&amp;gt;      lzl-b   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello-deploy-65cbc9474c-d4g24   0/1     ContainerCreating   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;              10s    &amp;lt;none&amp;gt;      lzl-b   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;root@lzl-a:/home/lzl/WP/k8s/deploy# kubectl rollout status deployment hello-deploy
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Waiting &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; deployment &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;hello-deploy&amp;#34;&lt;/span&gt; rollout to finish: &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; out of &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt; new replicas have been updated...
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;^Croot@lzl-a:/home/lzl/WP/k8s/deploy# kubectl get pods -o wide
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;NAME                            READY   STATUS              RESTARTS       AGE    IP          NODE    NOMINATED NODE   READINESS GATES
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello-deploy-59866ff45-2hp8j    1/1     Running             &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;136m ago&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;   167m   10.5.1.4    lzl-b   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello-deploy-59866ff45-4lhld    1/1     Running             &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;136m ago&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;   166m   10.5.1.11   lzl-b   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello-deploy-59866ff45-7pn94    1/1     Running             &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;136m ago&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;   163m   10.5.1.5    lzl-b   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello-deploy-59866ff45-9d444    1/1     Running             &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;136m ago&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;   162m   10.5.1.3    lzl-b   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello-deploy-59866ff45-nwcp8    1/1     Running             &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;136m ago&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;   164m   10.5.1.2    lzl-b   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello-deploy-59866ff45-prwwd    1/1     Running             &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;136m ago&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;   164m   10.5.1.7    lzl-b   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello-deploy-59866ff45-rflnv    1/1     Terminating         &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;136m ago&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;   162m   10.5.1.6    lzl-b   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello-deploy-59866ff45-tbpt2    1/1     Running             &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;136m ago&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;   165m   10.5.1.10   lzl-b   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello-deploy-59866ff45-z88ct    1/1     Running             &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;136m ago&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;   167m   10.5.1.8    lzl-b   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello-deploy-65cbc9474c-98bh2   1/1     Running             &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;              47s    10.5.1.12   lzl-b   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello-deploy-65cbc9474c-d4g24   0/1     ContainerCreating   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;              47s    &amp;lt;none&amp;gt;      lzl-b   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello-deploy-65cbc9474c-kglhr   0/1     ContainerCreating   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;              2s     &amp;lt;none&amp;gt;      lzl-b   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;root@lzl-a:/home/lzl/WP/k8s/deploy# kubectl rollout status deployment hello-deploy
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Waiting &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; deployment &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;hello-deploy&amp;#34;&lt;/span&gt; rollout to finish: &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt; out of &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt; new replicas have been updated...
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;^&lt;span style=&#34;color:#f92672&#34;&gt;[[&lt;/span&gt;AWaiting &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; deployment &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;hello-deploy&amp;#34;&lt;/span&gt; rollout to finish: &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt; out of &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt; new replicas have been updated...
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;^Croot@lzl-a:/home/lzl/WP/k8s/deploykubectl get deploy hello-deploy
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;NAME           READY   UP-TO-DATE   AVAILABLE   AGE
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello-deploy   10/10   &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;            &lt;span style=&#34;color:#ae81ff&#34;&gt;9&lt;/span&gt;           20h
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;root@lzl-a:/home/lzl/WP/k8s/deploy# kubectl get deploy hello-deploy
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;NAME           READY   UP-TO-DATE   AVAILABLE   AGE
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello-deploy   10/10   &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;           &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;          20h
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;root@lzl-a:/home/lzl/WP/k8s/deploy# kubectl get pods -o wide
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;NAME                            READY   STATUS    RESTARTS   AGE     IP          NODE    NOMINATED NODE   READINESS GATES
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello-deploy-65cbc9474c-7jrwq   1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          4m32s   10.5.1.19   lzl-b   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello-deploy-65cbc9474c-98bh2   1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          7m56s   10.5.1.12   lzl-b   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello-deploy-65cbc9474c-d4g24   1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          7m56s   10.5.1.13   lzl-b   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello-deploy-65cbc9474c-hkr5r   1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          6m39s   10.5.1.15   lzl-b   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello-deploy-65cbc9474c-jdwsr   1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          3m29s   10.5.1.21   lzl-b   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello-deploy-65cbc9474c-kglhr   1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          7m11s   10.5.1.14   lzl-b   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello-deploy-65cbc9474c-n4mqz   1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          4m1s    10.5.1.20   lzl-b   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello-deploy-65cbc9474c-p7zgs   1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          6m7s    10.5.1.16   lzl-b   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello-deploy-65cbc9474c-rqtrg   1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          5m36s   10.5.1.17   lzl-b   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello-deploy-65cbc9474c-xxk2n   1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          5m4s    10.5.1.18   lzl-b   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;和滚动升级一样，回滚过程中也同时存在新旧版本的应用。由于回滚是命令操作，没有使用到&lt;code&gt;deploy.yaml&lt;/code&gt;文件，因此要注意应用版本与部署文件中镜像版本不一致的问题，可以手动更改部署文件。&lt;/p&gt;
&lt;h2 id=&#34;删除deployment和service&#34;&gt;删除Deployment和Service&lt;/h2&gt;
&lt;p&gt;不再使用该Service和Pod时，将这两个对象删除，使用命令：&lt;code&gt;kubectl delete -f&lt;/code&gt;。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;root@lzl-a:/home/lzl/WP/k8s# kubectl delete -f ./deploy/deploy.yaml 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;deployment.apps &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;hello-deploy&amp;#34;&lt;/span&gt; deleted
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;root@lzl-a:/home/lzl/WP/k8s# kubectl delete -f ./service/svc.yaml 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;service &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;hello-svc&amp;#34;&lt;/span&gt; deleted
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;root@lzl-a:/home/lzl/WP/k8s# kubectl get pods -o wide
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;NAME                            READY   STATUS        RESTARTS   AGE     IP          NODE    NOMINATED NODE   READINESS GATES
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello-deploy-65cbc9474c-7jrwq   1/1     Terminating   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          10m     10.5.1.19   lzl-b   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello-deploy-65cbc9474c-98bh2   1/1     Terminating   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          13m     10.5.1.12   lzl-b   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello-deploy-65cbc9474c-d4g24   1/1     Terminating   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          13m     10.5.1.13   lzl-b   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello-deploy-65cbc9474c-hkr5r   1/1     Terminating   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          12m     10.5.1.15   lzl-b   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello-deploy-65cbc9474c-jdwsr   1/1     Terminating   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          9m19s   10.5.1.21   lzl-b   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello-deploy-65cbc9474c-kglhr   1/1     Terminating   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          13m     10.5.1.14   lzl-b   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello-deploy-65cbc9474c-n4mqz   1/1     Terminating   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          9m51s   10.5.1.20   lzl-b   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello-deploy-65cbc9474c-p7zgs   1/1     Terminating   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          11m     10.5.1.16   lzl-b   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello-deploy-65cbc9474c-rqtrg   1/1     Terminating   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          11m     10.5.1.17   lzl-b   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;hello-deploy-65cbc9474c-xxk2n   1/1     Terminating   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          10m     10.5.1.18   lzl-b   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;root@lzl-a:/home/lzl/WP/k8s# kubectl get svc -o wide
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;NAME         TYPE        CLUSTER-IP   EXTERNAL-IP   PORT&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;S&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;   AGE   SELECTOR
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubernetes   ClusterIP   10.96.0.1    &amp;lt;none&amp;gt;        443/TCP   20h   &amp;lt;none&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;root@lzl-a:/home/lzl/WP/k8s# kubectl get pods -o wide
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;No resources found in default namespace.
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</description>
        </item>
        <item>
        <title>搭建1个Master节点和2个Work节点的集群(k8s实践-2)</title>
        <link>https://lizonglingo.github.io/p/%E6%90%AD%E5%BB%BA1%E4%B8%AAmaster%E8%8A%82%E7%82%B9%E5%92%8C2%E4%B8%AAwork%E8%8A%82%E7%82%B9%E7%9A%84%E9%9B%86%E7%BE%A4k8s%E5%AE%9E%E8%B7%B5-2/</link>
        <pubDate>Tue, 18 Jan 2022 17:39:01 +0800</pubDate>
        
        <guid>https://lizonglingo.github.io/p/%E6%90%AD%E5%BB%BA1%E4%B8%AAmaster%E8%8A%82%E7%82%B9%E5%92%8C2%E4%B8%AAwork%E8%8A%82%E7%82%B9%E7%9A%84%E9%9B%86%E7%BE%A4k8s%E5%AE%9E%E8%B7%B5-2/</guid>
        <description>&lt;blockquote&gt;
&lt;p&gt;本节的目标是：搭建含有一个Master Node和两个Work Node的k8s集群，创建一个admin用户并通过token访问kubernetes dashboard。&lt;/p&gt;
&lt;p&gt;具体步骤如下。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;启动k8主节点&lt;/li&gt;
&lt;li&gt;将两个work节点加入集群&lt;/li&gt;
&lt;li&gt;安装dashboard组件&lt;/li&gt;
&lt;li&gt;创建集群管理员用户&lt;/li&gt;
&lt;li&gt;获取token并登入dashboard&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;启动master-node&#34;&gt;启动Master Node&lt;/h2&gt;
&lt;h3 id=&#34;启动主节点&#34;&gt;启动主节点&lt;/h3&gt;
&lt;p&gt;该部分参照第一节&lt;a class=&#34;link&#34; href=&#34;https://lizonglin313.github.io/post/qi-dong-k8s-de-zhu-jie-dian/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;启动k8s的主节点(k8s实践-1) - Big Carrot (lizonglin313.github.io)&lt;/a&gt;，将集群的主节点启动。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;root@lzl:/home/lzl# kubeadm init --kubernetes-version&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;v1.22.4 --pod-network-cidr&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;10.5.0.0/16 --ignore-preflight-errors&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;Swap
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;init&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Using Kubernetes version: v1.22.4
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;preflight&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Running pre-flight checks
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;preflight&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Pulling images required &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; setting up a Kubernetes cluster
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;preflight&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; This might take a minute or two, depending on the speed of your internet connection
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;preflight&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; You can also perform this action in beforehand using &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;kubeadm config images pull&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;certs&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Using certificateDir folder &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/etc/kubernetes/pki&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;certs&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Generating &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;ca&amp;#34;&lt;/span&gt; certificate and key
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;certs&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Generating &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;apiserver&amp;#34;&lt;/span&gt; certificate and key
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;certs&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; apiserver serving cert is signed &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; DNS names &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local lzl&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; and IPs &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;10.96.0.1 192.168.230.11&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;certs&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Generating &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;apiserver-kubelet-client&amp;#34;&lt;/span&gt; certificate and key
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;certs&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Generating &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;front-proxy-ca&amp;#34;&lt;/span&gt; certificate and key
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;certs&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Generating &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;front-proxy-client&amp;#34;&lt;/span&gt; certificate and key
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;certs&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Generating &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;etcd/ca&amp;#34;&lt;/span&gt; certificate and key
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;certs&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Generating &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;etcd/server&amp;#34;&lt;/span&gt; certificate and key
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;certs&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; etcd/server serving cert is signed &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; DNS names &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;localhost lzl&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; and IPs &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;192.168.230.11 127.0.0.1 ::1&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;certs&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Generating &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;etcd/peer&amp;#34;&lt;/span&gt; certificate and key
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;certs&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; etcd/peer serving cert is signed &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; DNS names &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;localhost lzl&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; and IPs &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;192.168.230.11 127.0.0.1 ::1&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;certs&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Generating &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;etcd/healthcheck-client&amp;#34;&lt;/span&gt; certificate and key
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;certs&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Generating &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;apiserver-etcd-client&amp;#34;&lt;/span&gt; certificate and key
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;certs&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Generating &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;sa&amp;#34;&lt;/span&gt; key and public key
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;kubeconfig&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Using kubeconfig folder &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/etc/kubernetes&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;kubeconfig&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Writing &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;admin.conf&amp;#34;&lt;/span&gt; kubeconfig file
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;kubeconfig&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Writing &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;kubelet.conf&amp;#34;&lt;/span&gt; kubeconfig file
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;kubeconfig&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Writing &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;controller-manager.conf&amp;#34;&lt;/span&gt; kubeconfig file
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;kubeconfig&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Writing &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;scheduler.conf&amp;#34;&lt;/span&gt; kubeconfig file
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;kubelet-start&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Writing kubelet environment file with flags to file &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/var/lib/kubelet/kubeadm-flags.env&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;kubelet-start&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Writing kubelet configuration to file &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/var/lib/kubelet/config.yaml&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;kubelet-start&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Starting the kubelet
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;control-plane&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Using manifest folder &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/etc/kubernetes/manifests&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;control-plane&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Creating static Pod manifest &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;kube-apiserver&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;control-plane&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Creating static Pod manifest &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;kube-controller-manager&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;control-plane&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Creating static Pod manifest &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;kube-scheduler&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;etcd&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Creating static Pod manifest &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; local etcd in &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/etc/kubernetes/manifests&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;wait-control-plane&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Waiting &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; the kubelet to boot up the control plane as static Pods from directory &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/etc/kubernetes/manifests&amp;#34;&lt;/span&gt;. This can take up to 4m0s
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;apiclient&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; All control plane components are healthy after 14.007476 seconds
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;upload-config&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Storing the configuration used in ConfigMap &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;kubeadm-config&amp;#34;&lt;/span&gt; in the &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;kube-system&amp;#34;&lt;/span&gt; Namespace
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;kubelet&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Creating a ConfigMap &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;kubelet-config-1.22&amp;#34;&lt;/span&gt; in namespace kube-system with the configuration &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; the kubelets in the cluster
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;upload-certs&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Skipping phase. Please see --upload-certs
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;mark-control-plane&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Marking the node lzl as control-plane by adding the labels: &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;node-role.kubernetes.io/master&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;deprecated&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt; node-role.kubernetes.io/control-plane node.kubernetes.io/exclude-from-external-load-balancers&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;mark-control-plane&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Marking the node lzl as control-plane by adding the taints &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;node-role.kubernetes.io/master:NoSchedule&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;bootstrap-token&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Using token: 1la5tc.rbk7kyfx0g8cvj2n
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;bootstrap-token&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;bootstrap-token&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; configured RBAC rules to allow Node Bootstrap tokens to get nodes
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;bootstrap-token&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; nodes to get long term certificate credentials
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;bootstrap-token&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;bootstrap-token&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; configured RBAC rules to allow certificate rotation &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; all node client certificates in the cluster
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;bootstrap-token&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Creating the &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;cluster-info&amp;#34;&lt;/span&gt; ConfigMap in the &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;kube-public&amp;#34;&lt;/span&gt; namespace
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;kubelet-finalize&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Updating &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/etc/kubernetes/kubelet.conf&amp;#34;&lt;/span&gt; to point to a rotatable kubelet client certificate and key
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;addons&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Applied essential addon: CoreDNS
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;addons&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Applied essential addon: kube-proxy
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Your Kubernetes control-plane has initialized successfully!
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;To start using your cluster, you need to run the following as a regular user:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  mkdir -p $HOME/.kube
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  sudo chown &lt;span style=&#34;color:#66d9ef&#34;&gt;$(&lt;/span&gt;id -u&lt;span style=&#34;color:#66d9ef&#34;&gt;)&lt;/span&gt;:&lt;span style=&#34;color:#66d9ef&#34;&gt;$(&lt;/span&gt;id -g&lt;span style=&#34;color:#66d9ef&#34;&gt;)&lt;/span&gt; $HOME/.kube/config
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Alternatively, &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; you are the root user, you can run:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  export KUBECONFIG&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;/etc/kubernetes/admin.conf
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;You should now deploy a pod network to the cluster.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Run &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;kubectl apply -f [podnetwork].yaml&amp;#34;&lt;/span&gt; with one of the options listed at:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  https://kubernetes.io/docs/concepts/cluster-administration/addons/
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Then you can join any number of worker nodes by running the following on each as root:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubeadm join 192.168.230.11:6443 --token 1la5tc.rbk7kyfx0g8cvj2n &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;	--discovery-token-ca-cert-hash sha256:4ba0f32696c7c776a99e7e7afc3f51035d6895b786733eacd27e9cb993567f68 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;root@lzl:/home/lzl# export KUBECONFIG&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;/etc/kubernetes/admin.conf
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;配置集群网络&#34;&gt;配置集群网络&lt;/h3&gt;
&lt;p&gt;这里我们使用flannel网络组件作为集群网络。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;root@lzl:/home/lzl# kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Warning: policy/v1beta1 PodSecurityPolicy is deprecated in v1.21+, unavailable in v1.25+
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;podsecuritypolicy.policy/psp.flannel.unprivileged created
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;clusterrole.rbac.authorization.k8s.io/flannel created
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;clusterrolebinding.rbac.authorization.k8s.io/flannel created
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;serviceaccount/flannel created
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;configmap/kube-flannel-cfg created
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;daemonset.apps/kube-flannel-ds created
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;root@lzl:/home/lzl# kubectl get componentstatus
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Warning: v1 ComponentStatus is deprecated in v1.19+
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;NAME                 STATUS      MESSAGE                                                                                       ERROR
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;scheduler            Unhealthy   Get &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;http://127.0.0.1:10251/healthz&amp;#34;&lt;/span&gt;: dial tcp 127.0.0.1:10251: connect: connection refused   
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;controller-manager   Healthy     ok                                                                                            
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;etcd-0               Healthy     &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;health&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;true&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;reason&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;查看集群组件状态，发现主节点的scheduler不正常。根据上一个教程，修改scheduler和controller的配置文件中的端口号。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;root@lzl:/etc/kubernetes/manifests# kubectl get componentstatus
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Warning: v1 ComponentStatus is deprecated in v1.19+
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;NAME                 STATUS    MESSAGE                         ERROR
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;scheduler            Healthy   ok                              
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;controller-manager   Healthy   ok                              
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;etcd-0               Healthy   &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;health&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;true&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;reason&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;root@lzl:/home/lzl# kubectl get nodes
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;NAME   STATUS   ROLES                  AGE   VERSION
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;lzl    Ready    control-plane,master   12m   v1.22.4
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;这样三个组件状态正常，主节点启动成功，下面安装Dashboard。&lt;/p&gt;
&lt;h2 id=&#34;安装kubernetes-dashboard&#34;&gt;安装Kubernetes Dashboard&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;root@lzl:/home/lzl# kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.2.0/aio/deploy/recommended.yaml
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;namespace/kubernetes-dashboard created
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;serviceaccount/kubernetes-dashboard created
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;service/kubernetes-dashboard created
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;secret/kubernetes-dashboard-certs created
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;secret/kubernetes-dashboard-csrf created
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;secret/kubernetes-dashboard-key-holder created
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;configmap/kubernetes-dashboard-settings created
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;role.rbac.authorization.k8s.io/kubernetes-dashboard created
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;clusterrole.rbac.authorization.k8s.io/kubernetes-dashboard created
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;rolebinding.rbac.authorization.k8s.io/kubernetes-dashboard created
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;clusterrolebinding.rbac.authorization.k8s.io/kubernetes-dashboard created
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;deployment.apps/kubernetes-dashboard created
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;service/dashboard-metrics-scraper created
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Warning: spec.template.metadata.annotations&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;seccomp.security.alpha.kubernetes.io/pod&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;: deprecated since v1.19; use the &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;seccompProfile&amp;#34;&lt;/span&gt; field instead
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;deployment.apps/dashboard-metrics-scraper created
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;查看是否能够启动Dashboard，这里使用&lt;code&gt;kubectl proxy&lt;/code&gt;命令启动代理服务，然后访问&lt;code&gt;http://localhost:8001/api/v1/namespaces/kubernetes-dashboard/services/https:kubernetes-dashboard:/proxy/&lt;/code&gt;。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;root@lzl:/home/lzl# kubectl proxy
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Starting to serve on 127.0.0.1:8001
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lizonglin313/MyPicGo/master/20220117180050.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;出现此界面说明Dashboard安装成功并可以启动。&lt;/p&gt;
&lt;h2 id=&#34;将work-node加入集群&#34;&gt;将Work Node加入集群&lt;/h2&gt;
&lt;p&gt;工作节点的加入，在工作节点使用启动主节点是给出的命令就可。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;...
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Then you can join any number of worker nodes by running the following on each as root:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubeadm join 192.168.230.11:6443 --token 1la5tc.rbk7kyfx0g8cvj2n &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;	--discovery-token-ca-cert-hash sha256:4ba0f32696c7c776a99e7e7afc3f51035d6895b786733eacd27e9cb993567f68 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;...
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;我的两个工作节点的IP分别为：&lt;code&gt;192.168.230.12&lt;/code&gt;和&lt;code&gt;192.168.230.13&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;在加入工作节点时 出现了如下错误：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;root@lzl-b:/home/lzl# kubeadm join 192.168.230.11:6443 --token 1la5tc.rbk7kyfx0g8cvj2n --discovery-token-ca-cert-hash sha256:4ba0f32696c7c776a99e7e7afc3f51035d6895b786733eacd27e9cb993567f68
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;preflight&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Running pre-flight checks
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;preflight&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Reading configuration from the cluster...
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;preflight&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; FYI: You can look at this config file with &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;kubectl -n kube-system get cm kubeadm-config -o yaml&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;kubelet-start&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Writing kubelet configuration to file &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/var/lib/kubelet/config.yaml&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;kubelet-start&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Writing kubelet environment file with flags to file &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/var/lib/kubelet/kubeadm-flags.env&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;kubelet-start&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Starting the kubelet
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;kubelet-start&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Waiting &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; the kubelet to perform the TLS Bootstrap...
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;kubelet-check&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Initial timeout of 40s passed.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;kubelet-check&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; It seems like the kubelet isn&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;t running or healthy.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;[kubelet-check] The HTTP call equal to &amp;#39;&lt;/span&gt;curl -sSL http://localhost:10248/healthz&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39; failed with error: Get &amp;#34;http://localhost:10248/healthz&amp;#34;: dial tcp 127.0.0.1:10248: connect: connection refused.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;[kubelet-check] It seems like the kubelet isn&amp;#39;&lt;/span&gt;t running or healthy.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;kubelet-check&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; The HTTP call equal to &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;curl -sSL http://localhost:10248/healthz&amp;#39;&lt;/span&gt; failed with error: Get &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;http://localhost:10248/healthz&amp;#34;&lt;/span&gt;: dial tcp 127.0.0.1:10248: connect: connection refused.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;kubelet-check&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; It seems like the kubelet isn&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;t running or healthy.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;[kubelet-check] The HTTP call equal to &amp;#39;&lt;/span&gt;curl -sSL http://localhost:10248/healthz&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39; failed with error: Get &amp;#34;http://localhost:10248/healthz&amp;#34;: dial tcp 127.0.0.1:10248: connect: connection refused.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;[kubelet-check] It seems like the kubelet isn&amp;#39;&lt;/span&gt;t running or healthy.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;kubelet-check&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; The HTTP call equal to &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;curl -sSL http://localhost:10248/healthz&amp;#39;&lt;/span&gt; failed with error: Get &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;http://localhost:10248/healthz&amp;#34;&lt;/span&gt;: dial tcp 127.0.0.1:10248: connect: connection refused.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;kubelet-check&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; It seems like the kubelet isn&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;t running or healthy.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;[kubelet-check] The HTTP call equal to &amp;#39;&lt;/span&gt;curl -sSL http://localhost:10248/healthz&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;&amp;#39;&lt;/span&gt; failed with error: Get &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;http://localhost:10248/healthz&amp;#34;&lt;/span&gt;: dial tcp 127.0.0.1:10248: connect: connection refused.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;error execution phase kubelet-start: error uploading crisocket: timed out waiting &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; the condition
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;To see the stack trace of this error execute with --v&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt; or higher
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;然后进行排错，出错原因可能有以下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;有说是因为docker的cgroup驱动设置的问题：https://blog.csdn.net/imonkeyi/article/details/120452471&lt;/li&gt;
&lt;li&gt;没有关闭主机swap也会产生问题&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;按照我上一篇的文章的前置环境和上述博文进行设置，关闭swap分区并设置docker的cgroup驱动，成功解决，直接使用k8s master节点的给出的提示命令就可以将work节点加入集群。&lt;/p&gt;
&lt;p&gt;所以需要注意，工作节点加入集群的前置条件是（可能不完整）：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;必须需安装kubelet、kubeadm&lt;/li&gt;
&lt;li&gt;关闭swap分区&lt;/li&gt;
&lt;li&gt;设置好docker的cgroup驱动&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;然后使用&lt;code&gt;kubeadm reset&lt;/code&gt;将环境重置，重新将工作节点加入集群。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;root@lzl-b:/home/lzl# kubeadm reset
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;reset&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; WARNING: Changes made to this host by &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;kubeadm init&amp;#39;&lt;/span&gt; or &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;kubeadm join&amp;#39;&lt;/span&gt; will be reverted.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;reset&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Are you sure you want to proceed? &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;y/N&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;: y
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;preflight&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Running pre-flight checks
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;W0117 19:06:49.180263   &lt;span style=&#34;color:#ae81ff&#34;&gt;37850&lt;/span&gt; removeetcdmember.go:80&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;reset&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; No kubeadm config, using etcd pod spec to get data directory
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;reset&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; No etcd config found. Assuming external etcd
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;reset&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Please, manually reset etcd to prevent further issues
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;reset&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Stopping the kubelet service
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;reset&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Unmounting mounted directories in &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/var/lib/kubelet&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;reset&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Deleting contents of config directories: &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;/etc/kubernetes/manifests /etc/kubernetes/pki&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;reset&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Deleting files: &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;/etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/bootstrap-kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;reset&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Deleting contents of stateful directories: &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;/var/lib/kubelet /var/lib/dockershim /var/run/kubernetes /var/lib/cni&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;The reset process does not clean CNI configuration. To &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt; so, you must remove /etc/cni/net.d
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;The reset process does not reset or clean up iptables rules or IPVS tables.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;If you wish to reset iptables, you must &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt; so manually by using the &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;iptables&amp;#34;&lt;/span&gt; command.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;If your cluster was setup to utilize IPVS, run ipvsadm --clear &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;or similar&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;to reset your system&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;s IPVS tables.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;The reset process does not clean your kubeconfig files and you must remove them manually.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Please, check the contents of the $HOME/.kube/config file.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;root@lzl-b:/home/lzl# kubeadm join 192.168.230.11:6443 --token 1la5tc.rbk7kyfx0g8cvj2n --discovery-token-ca-cert-hash sha256:4ba0f32696c7c776a99e7e7afc3f51035d6895b786733eacd27e9cb993567f68
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;[preflight] Running pre-flight checks
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;[preflight] Reading configuration from the cluster...
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;[preflight] FYI: You can look at this config file with &amp;#39;&lt;/span&gt;kubectl -n kube-system get cm kubeadm-config -o yaml&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;[kubelet-start] Writing kubelet configuration to file &amp;#34;/var/lib/kubelet/config.yaml&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;[kubelet-start] Writing kubelet environment file with flags to file &amp;#34;/var/lib/kubelet/kubeadm-flags.env&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;[kubelet-start] Starting the kubelet
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;[kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap...
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;This node has joined the cluster:
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;* Certificate signing request was sent to apiserver and a response was received.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;* The Kubelet was informed of the new secure connection details.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Run &amp;#39;&lt;/span&gt;kubectl get nodes&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;&amp;#39;&lt;/span&gt; on the control-plane to see this node join the cluster.
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;依次加入两个工作节点&lt;code&gt;lzl-b&lt;/code&gt;和&lt;code&gt;lzl-c&lt;/code&gt;，然后在主节点查看集群节点信息:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;root@lzl:/home/lzl# kubectl get nodes
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;NAME    STATUS   ROLES                  AGE    VERSION
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;lzl     Ready    control-plane,master   110m   v1.22.4
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;lzl-b   Ready    &amp;lt;none&amp;gt;                 21m    v1.22.4
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;lzl-c   Ready    &amp;lt;none&amp;gt;                 10m    v1.22.4
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;然后验证整个集群的工作状态：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;root@lzl:/home/lzl# kubectl get pods --all-namespaces
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;NAMESPACE              NAME                                         READY   STATUS    RESTARTS   AGE
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kube-system            coredns-78fcd69978-7fspq                     1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          110m
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kube-system            coredns-78fcd69978-7vffp                     1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          110m
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kube-system            etcd-lzl                                     1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          111m
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kube-system            kube-apiserver-lzl                           1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          111m
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kube-system            kube-controller-manager-lzl                  1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          100m
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kube-system            kube-flannel-ds-mjxd8                        1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          105m
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kube-system            kube-flannel-ds-r7s7c                        1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          11m
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kube-system            kube-flannel-ds-wjsz4                        1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          22m
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kube-system            kube-proxy-4n6xk                             1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          11m
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kube-system            kube-proxy-w7vl7                             1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          22m
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kube-system            kube-proxy-xw6c9                             1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          110m
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kube-system            kube-scheduler-lzl                           1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          101m
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubernetes-dashboard   dashboard-metrics-scraper-856586f554-2snbz   1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          94m
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubernetes-dashboard   kubernetes-dashboard-78c79f97b4-j6k9r        1/1     Running   &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;          94m
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;至此就使用kubeadm成功搭建了一个主节点和两个工作节点的集群，如果安装失败可以使用kubeadm reset命令将主机恢复，然后重新安装。&lt;/p&gt;
&lt;h2 id=&#34;配置kubernetes-dashboard&#34;&gt;配置Kubernetes Dashboard&lt;/h2&gt;
&lt;p&gt;如果想在k8s中使用Dashboard对集群状态进行监控等操作，需要创建用户，这里结合以下三个示例：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/kubernetes/dashboard/blob/master/docs/user/access-control/creating-sample-user.md&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/kubernetes/dashboard/blob/master/docs/user/access-control/creating-sample-user.md&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://jimmysong.io/kubernetes-handbook/guide/auth-with-kubeconfig-or-token.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://jimmysong.io/kubernetes-handbook/guide/auth-with-kubeconfig-or-token.html&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://andrewpqc.github.io/2018/04/25/k8s-dashboard-auth/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://andrewpqc.github.io/2018/04/25/k8s-dashboard-auth/&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;创建用户角色的文件如下，创建一个ServiceAccount然后将该账户绑定到cluster权限上。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;v1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;ServiceAccount&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;admin-user&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#f92672&#34;&gt;namespace&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;kubernetes-dashboard&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;---
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;apiVersion&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;rbac.authorization.k8s.io/v1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;ClusterRoleBinding&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;metadata&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;admin-user&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;roleRef&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#75715e&#34;&gt;# &amp;#34;roleRef&amp;#34; 指定与某 Role 或 ClusterRole 的绑定关系&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#f92672&#34;&gt;apiGroup&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;rbac.authorization.k8s.io&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;ClusterRole &lt;/span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;# 此字段必须是 Role 或 ClusterRole&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;cluster-admin &lt;/span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;# 此字段必须与你要绑定的 Role 或 ClusterRole 的名称匹配&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;subjects&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;- &lt;span style=&#34;color:#f92672&#34;&gt;kind&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;ServiceAccount&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#f92672&#34;&gt;name&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;admin-user&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#f92672&#34;&gt;namespace&lt;/span&gt;: &lt;span style=&#34;color:#ae81ff&#34;&gt;kubernetes-dashboard&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;下面创建用户并获取用户的token，进行dashboard的登录。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;root@lzl:/home/lzl# kubectl create -f admin-role.yaml
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;serviceaccount/admin-user created
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;clusterrolebinding.rbac.authorization.k8s.io/admin-user created
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;root@lzl:/home/lzl# kubectl -n kubernetes-dashboard get secret &lt;span style=&#34;color:#66d9ef&#34;&gt;$(&lt;/span&gt;kubectl -n kubernetes-dashboard get sa/admin-user -o jsonpath&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;{.secrets[0].name}&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;)&lt;/span&gt; -o go-template&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;{{.data.token | base64decode}}&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;eyJhbGciOiJSUzI1NiIsImtpZCI6Ild5MHVweWVackR5b1RYcUFKLWgwUlBKTG9UVFM3U2pIMWYzRFJ1Mi1kUm8ifQ.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlcm5ldGVzLWRhc2hib2FyZCIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJhZG1pbi11c2VyLXRva2VuLWprMjhoIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6ImFkbWluLXVzZXIiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiJjN2Y0NzkwZC03YWZlLTRiYWUtOWI0OC0wOTFkZTE4ZjVhYTYiLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZXJuZXRlcy1kYXNoYm9hcmQ6YWRtaW4tdXNlciJ9.fmSCJRpiFCqu36umiT7GFXH3WvNE3O3cLmbrwaljYsI48JZXk35tzr10HPWRNBts9vHaoQOaZxGbWeUvxa51QQNlJEAt0b5fdIahCr9myYTSJZHCUNaS3nftvROv0XIHcLZvLGgJngguChrcOO5XK7-7i1hawBf_d3Xesga-uWS0NYxZR5Fsv_Ponipet4Hkr329EjFs3JD0yTMJEnEpwLnDJioz4KkmPdpE2rZBj65Sc6UxOjZrY3kdSMITj8nWMdKetfm8zbvkt3yxKi88FzBfNOUeUMFxywf4cUiWw-z7v9_pSU6xjkK7-P_9LxiaDHW0ZrfYoXEPf6oLVpR1EQ
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;root@lzl:/home/lzl# kubectl proxy
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Starting to serve on 127.0.0.1:8001
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;再次打开dashboard界面，输入token登录。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lizonglin313/MyPicGo/master/20220118174817.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;已经有正常的资源信息显示了。&lt;/p&gt;
&lt;p&gt;至此，我们已经搭建了包含一个master节点和两个work节点的k8s集群，并且可以通过创建的角色访问dashboard来管理集群资源了。&lt;/p&gt;
&lt;h2 id=&#34;相关参考&#34;&gt;相关参考&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/kubernetes/dashboard&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Kubernetes  Dashboard项目Github主页&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/kubernetes/dashboard/blob/master/docs/user/access-control/creating-sample-user.md&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Dashboard-Creating sample user&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://kubernetes.io/zh/docs/reference/access-authn-authz/rbac/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;k8s-基于角色的访问控制-使用 RBAC 鉴权&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>笔记 &gt; SHOWAR: Right-Sizing And Efficient Scheduling of Microservices</title>
        <link>https://lizonglingo.github.io/p/%E7%AC%94%E8%AE%B0-showar-right-sizing-and-efficient-scheduling-of-microservices/</link>
        <pubDate>Mon, 20 Dec 2021 14:51:34 +0800</pubDate>
        
        <guid>https://lizonglingo.github.io/p/%E7%AC%94%E8%AE%B0-showar-right-sizing-and-efficient-scheduling-of-microservices/</guid>
        <description>&lt;h2 id=&#34;摘要&#34;&gt;摘要&lt;/h2&gt;
&lt;p&gt;提出微服务的面临的一个挑战是为每个微服务找到最佳的分配资源和服务实例的数量。达到保证性能的同时最大限度的提高资源利用率这样一个目标。本文的SHOWAR是一个通过确定服务实例数量（横向扩展）以及每个服务实例的资源如CPU和内存（纵向扩展）来配置资源的框架。&lt;/p&gt;
&lt;p&gt;对于纵向扩展，SHOWAR通过历史资源中的经验方差来寻找最佳资源分配量，保证性能同时减少不必要的资源浪费；对于横向扩展，使用控制理论的基本思想以及内核级性能指标来实施。&lt;/p&gt;
&lt;p&gt;在确定微服务的现有状态后，SHOWAR使用调度程序生成亲和性规则来弥合最佳资源分配和调度之间的差距，实现资源分配和性能提高。&lt;/p&gt;
&lt;p&gt;实验表明，SHOWAR与现有的最先进的自动缩放和调度系统相比，资源分配提高了22%，同时降低了99%的端到端请求延迟20%。&lt;/p&gt;
&lt;h2 id=&#34;intro&#34;&gt;Intro&lt;/h2&gt;
&lt;p&gt;本文的SHOWAR是一个用于微服务横向和纵向自动扩展的微服务管理系统，用于Kubernetes编排的微服务系统。&lt;/p&gt;
&lt;p&gt;对于纵向缩放，SHOWAR 依赖&lt;strong&gt;历史资源使用情况的差异&lt;/strong&gt;，找到每个微服务的最佳资源大小，保持良好的性能的同时提高资源利用率。&lt;/p&gt;
&lt;p&gt;对于横向自动缩放，SHOWAR 使用来自 &lt;strong&gt;Linux 内核线程调度程序队列的指标&lt;/strong&gt;（特别是 eBPF 运行时延迟）作为其自动缩放信号，以做出更准确和有意义的自动缩放决策。为了实现这个目标，SHOAWR使用了控制理论的基本思想，基于来自&lt;strong&gt;微服务运行时&lt;/strong&gt;的信号控制每个微服务的副本数量。&lt;/p&gt;
&lt;p&gt;该团队设计了一个比例积分微分proportional–integral–derivative (PID) 控制器作为有状态自动缩放器，它使用历史自动缩放操作和当前运行时测量来做出下一个水平自动缩放决策并保持微服务“稳定”。此外，SHOWAR考虑不同微服务之间的依赖关系，优先考虑被依赖的微服务，以防止不必要的自动缩放操作和低资源利用率。&lt;/p&gt;
&lt;p&gt;除了使用自动缩放器来确定微服务的资源外，SHOWAR还旨在桥接微服务的最佳资源分配和高效调度，&lt;strong&gt;在达成最佳资源分配和高效调度之间取得最佳平衡&lt;/strong&gt;。一旦确定了微服务的最佳大小，SHOWAR就会协助集群调度程序调度微服务以获得更好的端到端性能。为了防止资源争用和管理噪声邻居对微服务性能的影响，SHOWAR使用不同微服务之间历史资源使用情况的估计相关性来为Kubernetes调度程序生成规则。例如，这些规则可能会建议调度程序共同定位（调度亲和性）与某种资源类型具有负相关性的微服务，或者以其他方式分发它们（调度反亲和性）。&lt;/p&gt;
&lt;p&gt;文章通过在AWS公共云上的虚拟机集群部署各种交互式微服务应用程序来评估SHOWAR。将SHOWAR的性能与两种最先进的自动缩放系统进行了比较：Google Autopilot和Kubernetes 默认的自动缩放器。使用实际生产工作负载，结果表明，SHOWAR在有效资源分配和端到端请求延迟的尾部分布方面优于这些参照。SHOWAR 平均将资源分配提高了22%，这可以直接转化为集群相关成本的总节省22%，同时将99%的端到端用户请求延迟降低20%。&lt;/p&gt;
&lt;h2 id=&#34;贡献&#34;&gt;贡献&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;提出一种自动化的纵向扩容和横向扩容框架，达到保证服务性能的前提下提高资源利用率的目标&lt;/li&gt;
&lt;li&gt;提出调度亲和性和反亲和规则，通过生成调度亲和性和反亲和性规则来帮助调度程序更好地放置微服务并提高微服务性能，弥合了适当调整微服务规模以提高资源效率和高效微服务调度之间的差距&lt;/li&gt;
&lt;li&gt;通过实验证明SHOWAR的良好表现&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;前置知识&#34;&gt;前置知识&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lizonglin313/MyPicGo/master/20211220134037.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;这一个比较典型的微服务架构示意图，微服务之间的依赖关系错综复杂。&lt;strong&gt;其中一些微服务依赖于其他微服务，SHOWAR使用此依赖关系图信息来做出更好的自动缩放决策&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;除了 CPU 和内存使用数据外，SHOWAR还使用扩展的伯克利数据包过滤 ( Berkeley Packet Filtering - eBPF) [6] 指标数据进行水平自动缩放决策。&lt;strong&gt;eBPF 是最新的Linux内核技术，它支持在内核级别运行安全且低开销的程序，以从内核级别的事件（例如 CPU 调度程序决策事件、内存分配事件和内核网络堆栈中的数据包事件）中收集准确的指标&lt;/strong&gt;。它已被广泛用于微服务可观察性，用于性能改进、分析和跟踪、负载平衡、网络监控和安全等广泛目的。&lt;/p&gt;
&lt;h2 id=&#34;showar&#34;&gt;SHOWAR&lt;/h2&gt;
&lt;h3 id=&#34;系统架构&#34;&gt;系统架构&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lizonglin313/MyPicGo/master/20211220141140.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;SHOWAR使用每个节点上的相应代理来收集资源使用日志以及 eBPF 指标，然后聚合到时间序列数据库中。&lt;/p&gt;
&lt;p&gt;SHOWAR使用收集到的指标通过分别与Kubernetes API服务器及其调度程序通信来做出自动缩放决策以及调度亲和性和反亲和性规则。&lt;/p&gt;
&lt;h3 id=&#34;系统实现&#34;&gt;系统实现&lt;/h3&gt;
&lt;p&gt;SHOWAR 作为服务部署在控制器节点并与kubernetes API服务器及其调度程序交互以进行自动缩放操作以及为微服务应用生成的亲和性和反亲和性规则。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;监控代理Monitoring Agents&lt;/p&gt;
&lt;p&gt;监控和日志数据是任何应用程序部署最重要的部分。监控数据用于可观察性、健康检查和自动缩放。本文使用最先进的监控和指标收集工具Prometheus从节点和容器收集不同的指标。Prometheus在集群中的每个节点上启动一个监控代理来收集容器指标，例如 CPU 使用率、内存使用率、网络带宽使用率等。代理被配置为每秒收集和报告指标（一秒是Prometheus 代理可以收集指标的最短时间。为了获得尽可能多的数据点，我们每秒钟收集一次数据）。Prometheus 带有一个时间序列数据库，代理存储收集的指标。此外，提供查询语言来查询其他模块使用的时间序列数据库以利用收集的指标。&lt;/p&gt;
&lt;p&gt;除Prometheus外，文章还开发了一个eBPF程序，该程序作为监控代理部署在集群中的每个节点上，以收集横向自动缩放器使用的 𝑟𝑢𝑛𝑞 𝑙𝑎𝑡𝑒𝑛𝑐𝑦 指标。该指标是每个pod中的CPU线程在获取CPU之前所经历的延迟直方图。程序每1秒收集一张𝑟𝑢𝑛𝑞 𝑙𝑎𝑡𝑒𝑛𝑐𝑖𝑒𝑠的直方图并存储在Prometheus时间序列数据库中。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;纵向缩放器The Vertical Autoscaler&lt;/p&gt;
&lt;p&gt;这一个简单的循环，每分钟进行一轮。在前 5 分钟的窗口内为每种资源类型 𝑟（CPU 和内存）计算 𝑠𝑟 =𝜇𝑟 +3∗𝜎𝑟，如果 𝑠 的值变化超过 15%，它会更新服务的资源需求为𝑠。&lt;/p&gt;
&lt;p&gt;触发缩放器的另一个条件是微服务报告 OOM 错误时。在应用微服务的新资源需求之前，纵向自动缩放器通过共享通道向横向自动缩放器发送消息，不让其进行任何横向自动缩放操作，因为纵向自动缩放操作的优先级高于水平自动缩放。&lt;/p&gt;
&lt;p&gt;如果该微服务的 CPU 数量超过一个 CPU 内核（即 𝑠𝐶𝑃𝑈 &amp;gt;1000𝑚），纵向自动缩放器也不会对微服务进行自动缩放操作，在这种情况下，它会通过另一个共享通道发送消息到横向自动缩放器触发横向自动缩放操作。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;横向缩放器The Horizontal Autoscaler&lt;/p&gt;
&lt;p&gt;横向自动缩放器的核心是一个 PID 控制器，旨在保持每个微服务稳定。对于给定的目标 𝑟𝑢𝑛𝑞 𝑙𝑎𝑡𝑒𝑛𝑐𝑦，它对该微服务执行水平自动缩放操作，使其始终具有𝑟𝑢𝑛𝑞𝑟𝑢𝑛𝑞𝑙控制器每 1 分钟做出决定，eBPF 程序收集 60 个度量直方图实例（每秒 1 个）。对于每个直方图，选择第 95 个百分位数，控制器使用这 60 个数据点的平均值作为其当前观察（也称为测量）来执行其控制操作。每个水平扩展操作添加或删除至少 1 个或可配置百分比（默认为 10%）的微服务当前副本数，分别用于扩展和缩减。PID 控制参数的初始值取为 𝑘𝑃 =𝑘𝐼 =𝑘𝐷 =1/3（每个参数约束为 ∈ [0,10]）。这些参数的增量变化是 10%（我们通过实验发现 10% 的性能非常好）。控制器输出的波动是进行此类更改的基础，使用之前的 𝑁 = 10 个样本进行测量。此外，控制器的“速度”被测量为达到区间 [target(1 −𝛼),target(1 + 𝛼)] 所需的迭代次数，因为 𝛼 =10%。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;亲和规则生成器The Affinity Rule Generator&lt;/p&gt;
&lt;p&gt;SHOWAR的亲和性规则生成器每 5 分钟使用一次 CPU、内存和网络利用率，这是一个由 300 个数据点组成的向量（每个数据点是微服务副本的平均值）来计算每个数据点之间不同资源类型的相关系数。消除弱相关或无相关实例，[−0.8,+0.8] 中的任何值都将被丢弃。其他强负相关和强正相关微服务用于生成亲和性和反亲和性规则。资源使用模式会随着工作负载的变化（也称为工作负载转移）而变化，因此如果在随后的 5 分钟时间窗口内强烈的负相关或正相关变化超过 20%（可配置），SHOWAR 将撤销关联（或anti-affinity）规则。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;SHOWAR的开销&lt;/p&gt;
&lt;p&gt;SHOWAR是作为Kubernetes的控制器构建的，它对于自动缩放器和其他类型的控制器具有高度可插拔性。SHOWAR使用常用的 Kubernetes监控代理（如Prometheus）和一个自定义eBPF指标监控代理。因此，与默认的Kubernetes自动缩放器相比，SHOWAR 不会引入任何额外的开销。此外，自动缩放器被调度在控制器节点上，并且不与调度在工作节点上的应用程序 Pod 共享资源。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>笔记 &gt; Service-Level Fault Injection Testing</title>
        <link>https://lizonglingo.github.io/p/%E7%AC%94%E8%AE%B0-service-level-fault-injection-testing/</link>
        <pubDate>Sat, 18 Dec 2021 15:35:42 +0800</pubDate>
        
        <guid>https://lizonglingo.github.io/p/%E7%AC%94%E8%AE%B0-service-level-fault-injection-testing/</guid>
        <description>&lt;blockquote&gt;
&lt;p&gt;来源：SoCC&#39;21&lt;/p&gt;
&lt;p&gt;Meiklejohn C S, Estrada A, Song Y, et al. Service-Level Fault Injection Testing[C]//Proceedings of the ACM Symposium on Cloud Computing. 2021: 388-402.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;摘要&#34;&gt;摘要&lt;/h2&gt;
&lt;p&gt;越来越多的企业使用微服务架构发布他们的大规模的移动或是Web应用。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;问题在于&lt;/strong&gt;，并非所有系统开发人员都有分布式系统的管理经验，由于这些大规模的应用多是部署与分布式系统中，所以在生产环境中的故障很有可能在开发环境中不会出现。一旦这些微服务部署在分布式系统中，就有可能出现故障。所以，一种好的解决方法就是尽早找出这些问题：在测试环境或者在代码交付生产前就将其解决。&lt;/p&gt;
&lt;p&gt;本文提出&lt;strong&gt;服务级别故障注入测试&lt;/strong&gt;，并实现一个原型“filibuster”，用来系统的识别开发环境中微服务的弹性问题。“Filibuster”使用静态分析及并发风格的执行，还有新颖的动态缩减算法，来扩展现有功能测试的套件，减少开发人员的工作。&lt;/p&gt;
&lt;p&gt;为了证明工具的适用性，文章展示了4个包含错误的真实工业微服务应用程序的语料库。数据来自大公司生产中运行的实验公开信息。文章展示了实验如何在开发过程中运行，并在投入生产环境之前就检测到错误。&lt;/p&gt;
&lt;h2 id=&#34;前置知识&#34;&gt;前置知识&lt;/h2&gt;
&lt;h3 id=&#34;1-混沌工程&#34;&gt;1. 混沌工程&lt;/h3&gt;
&lt;p&gt;在本文中，多次讲到“chaos engineering”，在我个人理解，混沌工程是本文的“服务级故障注入测试”的基础，或者说是“上一个版本”。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;混沌工程代表项目，Netflix创建的“Chaos Monkey”可以在系统的随机位置引发故障，可以随时终止&lt;strong&gt;生产环境&lt;/strong&gt;中运行的虚拟机和容器实例。通过“Chaos Monkey”，开发者可以快速了解构建的服务的健壮性，是否可以弹性扩容以及处理意外故障。&lt;/p&gt;
&lt;p&gt;参考：&lt;a class=&#34;link&#34; href=&#34;https://zhuanlan.zhihu.com/p/90294032&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;知乎-系统架构设计之路&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;混沌工程，是一种提高技术架构弹性能力的复杂技术手段。Chaos工程经过实验可以确保系统的可用性。混沌工程旨在将故障扼杀在襁褓之中，也就是在故障造成中断之前将它们识别出来。通过主动制造故障，测试系统在各种压力下的行为，识别并修复故障问题，避免造成严重后果。&lt;/p&gt;
&lt;p&gt;主要针对于&lt;strong&gt;分布式系统&lt;/strong&gt;上的故障测试。&lt;/p&gt;
&lt;h4 id=&#34;11-混沌工程与故障注入的区别&#34;&gt;1.1 混沌工程与故障注入的区别&lt;/h4&gt;
&lt;p&gt;混沌工程是一种生成新信息的实践，而故障注入是测试一种情况的一种特定方法。&lt;/p&gt;
&lt;h4 id=&#34;12-混沌工程实验的步骤&#34;&gt;1.2 混沌工程实验的步骤&lt;/h4&gt;
&lt;p&gt;通常混沌工程由以下四个步骤组成。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;定义测试系统的“稳定状态”。精确定义指标，表明系统按照应有的方式运行。 Netflix使用客户点击视频流设备上播放按钮的速率作为指标，称为“每秒流量”。请注意，这更像是商业指标而非技术指标；在混沌工程中，&lt;strong&gt;业务指标通常比技术指标更有用&lt;/strong&gt;，因为它们更适合衡量用户体验或运营。&lt;/li&gt;
&lt;li&gt;创建假设。与任何实验一样，您需要一个假设来进行测试。因为你试图破坏系统正常运行时的稳定状态，你的假设将是这样的，“当我们做X时，这个系统的稳定状态应该没有变化。”为什么用这种方式表达？如果你的期望是你的动作会破坏系统的稳定状态，那么你会做的第一件事会是修复问题。混沌工程应该包括真正的实验，涉及真正的未知数。&lt;/li&gt;
&lt;li&gt;模拟现实世界中可能发生的事情，目前有如下混沌工程实践方法：模拟数据中心的故障、强制系统时钟不同步、在驱动程序代码中模拟I/O异常、模拟服务之间的延迟、随机引发函数抛异常。通常，您希望模拟可能导致系统不可用或导致其性能降低的场景。首先考虑可能出现什么问题，然后进行模拟。一定要优先考虑潜在的错误。 “当你拥有非常复杂的系统时，很容易引起出乎意料的下游效应，这是混沌工程寻找的结果之一，”“因此，系统越复杂，越重要，它就越有可能成为混沌工程的候选对象。”&lt;/li&gt;
&lt;li&gt;证明或反驳你的假设。将稳态指标与干扰注入系统后收集的指标进行比较。如果您发现测量结果存在差异，那么您的混沌工程实验已经成功 - 您现在可以继续加固系统，以便现实世界中的类似事件不会导致大问题。或者，如果您发现稳定状态可以保持，那么你对该系统的稳定性大可放心。&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;13-案例&#34;&gt;1.3 案例&lt;/h4&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/chaos-mesh/chaos-mesh&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/chaos-mesh/chaos-mesh&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/chaosblade-io&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/chaosblade-io&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;into&#34;&gt;Into&lt;/h2&gt;
&lt;p&gt;混沌测试（一种用于生产环境中的错误注入，来模拟在用户角度的服务bug）已经证明了的可行性。本文要做的就是把这个过程放在更早的阶段——在开发阶段就检测到这些错误。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;现在又有这样的问题&lt;/strong&gt;：缺少开源的微服务应用。仅有的开源微服务应用仅仅用来展示如何构建这些微服务应用，并没有展示这些应用在开发、部署时会出现什么错误。因此，该研究不得不和公司合作，并且需要签订严格的保密措施。&lt;/p&gt;
&lt;h2 id=&#34;本文贡献&#34;&gt;本文贡献&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;提出一种微服务测试方法：服务级别的故障注入测试&lt;/li&gt;
&lt;li&gt;一种新的动态归约算法：将应用程序分解成独立的微服务来减少搜索空间的组合爆炸&lt;/li&gt;
&lt;li&gt;实现了这个服务级别的故障注入测试方法——Filibuster：基于Python开发，可以测试提供HTTP通信的微服务&lt;/li&gt;
&lt;li&gt;一个用Python实现的微服务应用和故障的语料库：包含8个小心微服务应用程序，每个应用程序都展示了微服务应用中使用的单一模式；还有4个从公开会议演讲中的工业级应用实例——Audible、Expedia、Mailchimp、Netflix&lt;/li&gt;
&lt;li&gt;并通过该语料库对Filibuster做出评价：表明Filibuster可以用于识别语料中的所有错误，并且展示了通过动态减少可能进行的优化，还提供了如何设计微服务应用程序以实现可测试性的见解。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;挑战应对&#34;&gt;挑战——应对&lt;/h2&gt;
&lt;p&gt;目前困难主要在于：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;缺少开源的工业级微服务应用案例和相关的错误报告。而这两个内容是软件推动软件测试领域的主要语料库。&lt;/li&gt;
&lt;li&gt;现有的一些的对于软件测试的研究都是基于一些开源的bug数据库和开源社区的软件，问题在于，这些软件架构多是单体架构，而故障也不是微服务架构所特有的。所以，需要有微服务应用特有的故障以供研究。&lt;/li&gt;
&lt;li&gt;而对于大型的微服务应用提供商，往往不能直接去研究。这些产品往往是企业的核心，一般不会开源，并且内部的漏洞也不会公开。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;所以，文章系统回顾了50个关于混沌工程的演讲，从这些公开的视频中寻找案例。这些公开演讲中的公司主要关注两个问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;开发中的软件的可靠性&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;运行这些软件的基础设施的稳定性&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;进一步团队根据下面的条件寻找语料：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;演讲中是否提供了使用混沌工程发现的真正的详细错误信息&lt;/li&gt;
&lt;li&gt;所展示的混沌工程是否可以在本地复现（也就是在非生产环境中进行混沌测试）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;最终，文章选取了4个案例，它们来自 Audible、Expedia、Mailchimp和Netflix。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;案例来源&lt;/th&gt;
&lt;th&gt;服务类型&lt;/th&gt;
&lt;th&gt;使用混沌工程发现的问题简述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Audible&lt;/td&gt;
&lt;td&gt;有声读物移动应用&lt;/td&gt;
&lt;td&gt;代码中未处理的错误，该错误会通过通用错误消息传播传到移动客户端&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Expedia&lt;/td&gt;
&lt;td&gt;旅游预订服务&lt;/td&gt;
&lt;td&gt;基于相关性排序的酒店评价服务不可用，回退到基于时间排序的&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Mailchimp&lt;/td&gt;
&lt;td&gt;电子邮件管理应用&lt;/td&gt;
&lt;td&gt;两处不处理返回错误的问题&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Netflix&lt;/td&gt;
&lt;td&gt;流媒体应用&lt;/td&gt;
&lt;td&gt;1.加载客户主页设计的服务故障；2.配置错误超时；3.服务回退失败；4.关键服务未配置回退策略&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;技术细节&#34;&gt;技术细节&lt;/h2&gt;
&lt;h3 id=&#34;架构示意图&#34;&gt;架构示意图&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lizonglin313/MyPicGo/master/20211219115042.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;对每个测试服务器进行检测调用，识别调用从何处发起，从何处接收，并在测试期间注入故障。考虑上图，服务A调用服务B，然后服务B调用服务C，最后将结果返回。&lt;/p&gt;
&lt;p&gt;SFIT（Service-Level Fault Injection Testing ）建立在当今微服务程序开发的三个关键点之上：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;微服务是独立开发的：不同微服务开发团队难以知晓其他团队服务的内部细节和详细使用规范，难以验证其他服务的问题&lt;/li&gt;
&lt;li&gt;如果对于微服务进行故障模拟测试，能很大程度上保证生产环境下服务正常运行：但是从文章选取的案例来看，许多团队并没有这样做，可能是因为这样耗费时间或者性价比太低&lt;/li&gt;
&lt;li&gt;功能测试是黄金标准：开发者使用端到端的测试，并认为这是非常有用的， 本文也因此也在这一点切入。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;sfit实现细节&#34;&gt;SFIT实现细节&lt;/h3&gt;
&lt;p&gt;假设服务通过HTTP提供，并且单个功能测试可以测试所有应用程序行为。&lt;/p&gt;
&lt;h4 id=&#34;overview&#34;&gt;Overview&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;通过常规测试，排除服务的逻辑错误。&lt;/li&gt;
&lt;li&gt;在两个微服务的通信端点，再设计一个测试，并且对微服务之间的请求进行错误注入。如果这次错误注入可以引起不同的服务错误，那么对于每种错误都再复现一次。&lt;/li&gt;
&lt;li&gt;这些后续的执行放在堆栈上，然后递归执行，直到探索到所有的问题点。&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;故障注入&#34;&gt;故障注入&lt;/h4&gt;
&lt;p&gt;本文的方法依赖于远程调用，如HTTP或gRPC，因此需要有干预微服务之间请求的能力。Opentelemetry、Opentracing等工具已经提供了远程通信的公共调用库。利用这种工具设计故障注入：根据注入的故障，返回故障响应。&lt;/p&gt;
&lt;h4 id=&#34;故障识别&#34;&gt;故障识别&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;发起请求调用源点的故障：例如Python中request库执行HTTP请求时，执行该请求会引发23个异常，本演示只考虑两个最常见的故障——超时和连接错误。&lt;/li&gt;
&lt;li&gt;接收请求的远程服务的故障：如果一个服务依赖的另一个服务抛出Timeout异常，那么调用它的服务可能会捕获到，并返回500。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;此外，还有一点是，HTTP请求使用URL标识。相似的URL可能用于不同的服务，所以需要对调用的服务进行一个标识，以此明确服务调用双方的身份。&lt;/p&gt;
&lt;h4 id=&#34;测试适配&#34;&gt;测试适配&lt;/h4&gt;
&lt;p&gt;本文提供了一个模块帮助开发者编写故障注入测试，从而减轻开发人员编写复杂测试的负担。需要注意，本文的测试是非入侵的。&lt;/p&gt;
&lt;h2 id=&#34;故障缩减&#34;&gt;故障缩减&lt;/h2&gt;
&lt;p&gt;如果组成应用有几十上百的微服务，那么出现错误的空间将非常大。所以有必要在实现故障最大覆盖率的同时，减少搜索空间，提高效率。利用服务分解，对每个独立的微服务进行排障。&lt;/p&gt;
&lt;p&gt;为此，我们可以利用以下 3 个关键观察结果：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;充分了解服务依赖项可能失败的所有方式。确保我们了解单个服务的一个或多个依赖项失败时的行为以及该服务返回的结果失败是什么。参考图Audible示例，探索 ADS 依赖项可能失败的方式组合（以及 CDS 依赖项失败的方式等）&lt;/li&gt;
&lt;li&gt;如果我打算在两个或多个不同服务的至少一个依赖项上注入故障，我们已经知道这些故障将对将它们作为依赖项的服务产生的影响。以图Audible示例，我们已经知道当 ADS 的依赖项以任何可能的组合失败时会返回什么，因为我们已经运行了该测试。我们也已经知道当 CDS 的依赖项出于同样的原因以任何可能的组合失败时，它会返回什么。因此，我们不必在依赖项处注入故障，直接在 ADS 或 CDS 中直接注入适当的响应。&lt;/li&gt;
&lt;li&gt;如果我们已经在该服务中注入了该故障，那么测试就是多余的，因为我们已经观察到了应用程序的这种行为。如果我们参考图Audible示例，我们不需要测试 Stats 服务失败与 Audio Assets 或 Audio Metadata 服务的失败，因为我们已经知道这些失败的结果，这些服务将它们作为依赖；我们也已经观察到这些结果。&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;动态归约算法&#34;&gt;动态归约算法&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lizonglin313/MyPicGo/master/20211219125759.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;filibuster&#34;&gt;Filibuster&lt;/h2&gt;
&lt;p&gt;这是该团队实现的原型，利用Python以及一些开源库实现的。&lt;/p&gt;
&lt;p&gt;Filibuster可以注入这些故障：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;调用端异常：由请求库抛出，指示连接错误或超时等条件。对于所有异常类型，Filibuster 可以在抛出异常之前有条件地联系其他服务。对于超时，Filibuster 可以在抛出超时异常之前有条件地等待超时时间。&lt;/li&gt;
&lt;li&gt;错误响应：从远程服务使用标准 HTTP 错误代码指示内部服务器错误或服务不可用等情况。对于每个错误代码，Filibuster 可以有条件地返回一个关联的正文。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;由于 Filibuster 是作为服务器编写的，跨语言支持是可能的，但尚未实现。仪器和 Filibuster 服务器之间的所有通信都是通过独立于语言的协议进行的；任何特定于语言的东西都在仪器库中完成。&lt;/p&gt;
&lt;h2 id=&#34;应用语料库&#34;&gt;应用语料库&lt;/h2&gt;
&lt;h3 id=&#34;电影应用案例&#34;&gt;电影应用案例&lt;/h3&gt;
&lt;p&gt;由四个微服务组成：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;放映时间：返回电影的放映时间&lt;/li&gt;
&lt;li&gt;电影：返回给定电影的信息&lt;/li&gt;
&lt;li&gt;预订：给定用户名，返回有关该用户预订的信息&lt;/li&gt;
&lt;li&gt;用户：存储用户信息并通过首先请求用户的预订来编排来自最终用户的请求，并且对于每个预订执行对电影服务的后续请求以获取有关电影的信息&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;根据上述的基础案例，文章又改造了7个示例：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Cinema-2：直接预定电影&lt;/li&gt;
&lt;li&gt;Cinema-3：与cinema-2 相同，但users 服务在调用bookings 服务时有一个重试循环&lt;/li&gt;
&lt;li&gt;Cinema-4：与cinema-2 相同，但每个服务在发出任何请求之前都与外部服务对话：用户服务向IMDB 发出请求；预订服务向 Fandango 提出请求；电影服务向 Rotten Tomatoes 提出请求&lt;/li&gt;
&lt;li&gt;Cinema-5：无论失败与否，所有请求都会发生；在失败的情况下，使用硬编码的默认响应。&lt;/li&gt;
&lt;li&gt;Cinema-6：添加了预订的第二个副本，在主要副本出现故障时联系该副本。&lt;/li&gt;
&lt;li&gt;Cinema-7：与cinema-6 相同，但用户服务在发出实际请求之前调用主要预订副本上的健康检查端点。&lt;/li&gt;
&lt;li&gt;Cinema-8：示例被折叠成单体，其中 API 服务器通过重试循环向它发出请求&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;工业级案例audibleexpediamailchimp-和-netflix&#34;&gt;工业级案例Audible、Expedia、Mailchimp 和 Netflix&lt;/h3&gt;
&lt;p&gt;示例并不是要重现这些公司的整个微服务架构：我们只关注他们执行的特定混沌实验中涉及的服务。&lt;/p&gt;
&lt;h4 id=&#34;audible&#34;&gt;Audible&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lizonglin313/MyPicGo/master/20211219121932.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;示例 Audible微服务架构&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;这个案例包含8个微服务和一个移动客户端：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;内容交付服务（CDS）：给定图书标识符和用户标识符，授权后返回实际音频内容和音频元数据&lt;/li&gt;
&lt;li&gt;内容交付引擎 (CDE)：返回要请求的的正确 CDS 的 URL&lt;/li&gt;
&lt;li&gt;Audible App：模拟移动应用程序，向CDE发出请求，根据图书标识符查找相应CDS实例的URL，然后向其发出请求&lt;/li&gt;
&lt;li&gt;声音下载服务（ADS）：一旦所有权得到验证，就会协调日志记录和 DRM 授权&lt;/li&gt;
&lt;li&gt;所有权：验证书的所有权&lt;/li&gt;
&lt;li&gt;激活：为用户激活 DRM 许可证&lt;/li&gt;
&lt;li&gt;统计：维护书籍和许可证激活统计&lt;/li&gt;
&lt;li&gt;资产元数据：存储包含章节描述信息的音频资产元数据&lt;/li&gt;
&lt;li&gt;音频资产：音频文件的存储&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;由于实际的服务是部署在AWS上的微服务，本文则简化并模拟了这些服务：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;首先，资产元数据和音频资产服务是 AWS S3 存储桶（云存储）。为了模拟这一点，我们创建了 HTTP 服务，如果可用则返回包含资产的 200 OK，或者如果资产不存在则返回 404 Not Found。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;其次，所有权和激活服务是 AWS RDS 实例。为了模拟这一点，我们创建了实现 REST 模式的 HTTP 服务：如果用户不拥有这本书，则返回 403 Forbidden，如果这本书不存在，则返回 404 Not Found，否则返回 200 OK。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;第三，Stats 服务是一个 AWS DynamoDB 实例。为了模拟这一点，我们创建了一个返回 200 OK 的 HTTP 服务&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;expedia&#34;&gt;Expedia&lt;/h4&gt;
&lt;p&gt;包含三个微服务：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;按相关性顺序返回评论&lt;/li&gt;
&lt;li&gt;按时间顺序返回评论&lt;/li&gt;
&lt;li&gt;API 网关：根据可用性从 Review ML 或 Review Time 向用户返回评论&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;mailchimp&#34;&gt;Mailchimp&lt;/h4&gt;
&lt;p&gt;包含3个微服务：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Requestmapper：将电子邮件活动中的高亮URL映射到实际资源URL&lt;/li&gt;
&lt;li&gt;DB Primary：他们数据库的主要副本&lt;/li&gt;
&lt;li&gt;DB Secondary：他们数据库的次要副本&lt;/li&gt;
&lt;li&gt;App Server：向Requestmapper服务请求解析URL，然后对数据库执行read-then-write请求，当主副本不可用时回退到二级数据库副本&lt;/li&gt;
&lt;li&gt;负载均衡器：负载均衡请求&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;与 Mailchimp 的实际部署相比，我们表示为服务的一些组件实际上是非 HTTP 服务。我们在这里列举了这些差异和调整。首先，DB Primary 和 Secondary 服务是 MySQL 实例。为了模拟这一点，我们创建了一个 HTTP 服务，该服务在成功读取或写入时返回 200 OK，如果数据库为只读则返回 403 Forbidden。其次，Load Balancer 服务是一个 HAProxy 实例。为了模拟这一点，我们创建了一个 HTTP 代理。&lt;/p&gt;
&lt;p&gt;Mailchimp 示例的错误包含两个：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;MySQL 实例只读。当 MySQL 实例为只读时，数据库会返回一个错误，该错误在代码的某个区域未处理。由于 Mailchimp 使用 PHP，这个错误被直接呈现到页面的输出中，我们通过将 403 Forbidden 响应转换为直接插入页面的输出来模拟这一点。&lt;/li&gt;
&lt;li&gt;Requestmapper 不可用。当 Requestmapper 服务不可用时，App Server 无法正确处理错误，向负载均衡器返回 500 Internal Server Error。但是，负载均衡器仅配置为通过返回格式化的错误页面来处理 503 Service Unavailable 错误。这是丢失或不正确的故障处理示例。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;netflix&#34;&gt;Netflix&lt;/h4&gt;
&lt;p&gt;包含10个微服务，与Audible示例类似，我们使用服务模拟 Netflix 移动应用程序，这里称为客户端：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;客户端：模拟移动客户端&lt;/li&gt;
&lt;li&gt;API 网关：组装用户主页&lt;/li&gt;
&lt;li&gt;用户档案：返回档案信息&lt;/li&gt;
&lt;li&gt;书签：返回上次查看的位置&lt;/li&gt;
&lt;li&gt;我的列表：返回用户列表中的电影列表&lt;/li&gt;
&lt;li&gt;用户推荐：返回用户推荐的电影&lt;/li&gt;
&lt;li&gt;评分：返回用户的评分&lt;/li&gt;
&lt;li&gt;遥测：记录遥测信息&lt;/li&gt;
&lt;li&gt;趋势：返回热门电影&lt;/li&gt;
&lt;li&gt;全局推荐：返回推荐的电影&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Netflix示例的bug包含三个，可以使用环境变量激活：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;错误配置的超时。用户配置文件服务以 10 秒的超时时间调用遥测服务；但是，API 网关会以 1 秒的超时时间调用用户配置文件服务&lt;/li&gt;
&lt;li&gt;服务回退到同一服务器。如果我的列表服务不可用，系统将重试（我的理解是，一个服务有3个实例，其中一个实例不可用，本应该请求其他实例，结果再次请求了那个不可用的实例）&lt;/li&gt;
&lt;li&gt;没有回退的关键服务。用户配置文件服务没有后备处理逻辑&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>微服务网关--kong</title>
        <link>https://lizonglingo.github.io/p/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E7%BD%91%E5%85%B3--kong/</link>
        <pubDate>Thu, 02 Dec 2021 19:20:18 +0800</pubDate>
        
        <guid>https://lizonglingo.github.io/p/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E7%BD%91%E5%85%B3--kong/</guid>
        <description>&lt;p&gt;Kong网关是一个轻量级、高性能、可拓展的云原生API网关。下面我们以docker的形式搭建kong环境。&lt;/p&gt;
&lt;h3 id=&#34;1-拉取kong-gateway镜像并打上标签&#34;&gt;1. 拉取kong-gateway镜像并打上标签&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;lzl@lzl:~$ docker pull kong/kong-gateway:2.6.0.1-alpine
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;2.6.0.1-alpine: Pulling from kong/kong-gateway
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;a0d0a0d46f8b: Already exists 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;292d8c0f5367: Pulling fs layer 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;8f939e93459a: Pulling fs layer 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;8335045176a7: Pulling fs layer 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;2.6.0.1-alpine: Pulling from kong/kong-gateway
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;a0d0a0d46f8b: Already exists 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;292d8c0f5367: Pull complete 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;8f939e93459a: Pull complete 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;8335045176a7: Pull complete 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Digest: sha256:20d1f65138b36ffeadd6c63abe0dc1b496d42ab7bd49553328524d0bbf622026
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Status: Downloaded newer image &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; kong/kong-gateway:2.6.0.1-alpine
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;docker.io/kong/kong-gateway:2.6.0.1-alpine
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;lzl@lzl:~$ docker tag kong/kong-gateway:2.6.0.1-alpine kong
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;2-创建kong和其组件使用的网络&#34;&gt;2. 创建kong和其组件使用的网络&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;lzl@lzl:~$ docker network create kong-net
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;db4a092863e8dc77f26cf4aa43ffb62d09e19c1c66e9b15418d92277850c83a3
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;lzl@lzl:~$ docker network ls
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;NETWORK ID     NAME              DRIVER    SCOPE
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;505f6cc0e5b7   bridge            bridge    local
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;9027fdbdc8f6   docker_gwbridge   bridge    local
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;7a84b4fa35eb   host              host      local
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;db4a092863e8   kong-net          bridge    local
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;66b37b687b76   none              null      local
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;3配置kong所使用的database&#34;&gt;3.配置kong所使用的database&lt;/h3&gt;
&lt;p&gt;这里我们使用&lt;code&gt;postgres&lt;/code&gt;，当然也可以使用别的数据库。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;lzl@lzl:~$ docker run -d --name kong-database &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&amp;gt; --network&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;kong-net &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&amp;gt; -p 5432:5432 &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&amp;gt; -e &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;POSTGRES_USER=kong&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&amp;gt; -e &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;POSTGRES_DB=kong&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&amp;gt; -e &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;POSTGRES_PASSWORD=kong&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&amp;gt; postgres:9.6
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;0d9691c833ab59555dadee339a1f7e15fcc4948793bede7a39112e9f39d62ee7
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;4-正式启动kong之前需要迁移数据库&#34;&gt;4. 正式启动kong之前需要迁移数据库&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;lzl@lzl:~$ docker run --rm &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&amp;gt; --network&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;kong-net &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&amp;gt; -e &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;KONG_DATABASE=postgres&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&amp;gt; -e &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;KONG_PG_HOST=kong-database&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&amp;gt; -e &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;KONG_PG_USER=kong&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&amp;gt; -e &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;KONG_PG_PASSWORD=kong&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&amp;gt; -e &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;KONG_CASSANDRA_CONTACT_POINTS=kong-database&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&amp;gt; kong:latest kong migrations bootstrap
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Bootstrapping database...
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;migrating core on database &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;kong&amp;#39;&lt;/span&gt;...
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;core migrated up to: 000_base &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;executed&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;core migrated up to: 003_100_to_110 &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;executed&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;core migrated up to: 004_110_to_120 &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;executed&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;core migrated up to: 005_120_to_130 &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;executed&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;···
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;···
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;migrating enterprise.response-transformer-advanced on database &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;kong&amp;#39;&lt;/span&gt;...
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;enterprise.response-transformer-advanced migrated up to: 001_1500_to_2100 &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;executed&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;82&lt;/span&gt; migrations processed
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;82&lt;/span&gt; executed
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Database is up-to-date
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;5-启动kong&#34;&gt;5. 启动kong&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;lzl@lzl:~$ docker run -d --name kong &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&amp;gt; --network&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;kong-net &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&amp;gt; -e &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;KONG_DATABASE=postgres&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&amp;gt; -e &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;KONG_PG_HOST=kong-database&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&amp;gt; -e &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;KONG_PG_USER=kong&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&amp;gt; -e &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;KONG_PG_PASSWORD=kong&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&amp;gt; -e &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;KONG_CASSANDRA_CONTACT_POINTS=kong-database&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&amp;gt; -e &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;KONG_PROXY_ACCESS_LOG=/dev/stdout&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&amp;gt; -e &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;KONG_ADMIN_ACCESS_LOG=/dev/stdout&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&amp;gt; -e &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;KONG_PROXY_ERROR_LOG=/dev/stderr&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&amp;gt; -e &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;KONG_ADMIN_ERROR_LOG=/dev/stderr&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&amp;gt; -e &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;KONG_ADMIN_LISTEN=0.0.0.0:8001, 0.0.0.0:8444 ssl&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&amp;gt; -p 8000:8000 &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&amp;gt; -p 8443:8443 &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&amp;gt; -p 8001:8001 &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&amp;gt; -p 8444:8444 &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&amp;gt; kong:latest
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;e549737ac5cd6bcc49bcf073619950402b40f312fbe7affc028c6b46039a7f20
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;到这里，&lt;code&gt;kong-gateway&lt;/code&gt;就已经启动了。这里开放的几个端口说明一下：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;端口&lt;/th&gt;
&lt;th&gt;用途&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;8000&lt;/td&gt;
&lt;td&gt;监听客户端传入的HTTP请求并进行转发&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;8443&lt;/td&gt;
&lt;td&gt;监听客户端传入的HTTPS请求并进行转发&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;8001&lt;/td&gt;
&lt;td&gt;Admin API，管理者通过这个端口对Kong的监听服务进行配置、插件设置、API的配置以及负载均衡等&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;8444&lt;/td&gt;
&lt;td&gt;可通过此端口对HTTPS请求进行监控&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;6-为配置kong的可视化界面konga配置数据库&#34;&gt;6. 为配置kong的可视化界面konga配置数据库&lt;/h3&gt;
&lt;p&gt;进入到&lt;code&gt;postgres&lt;/code&gt;中添加新的用户，并创建konga用的数据库。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;lzl@lzl:~$ docker exec -it kong-database /bin/bash
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;root@0d9691c833ab:/# psql -U kong -W
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Password &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; user kong: 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;psql &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;9.6.24&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Type &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;help&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; help.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kong&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# create user konga with password &amp;#39;konga&amp;#39;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;CREATE ROLE
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kong&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# create database konga owner konga;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;CREATE DATABASE
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kong&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# grant all privileges on database konga to konga;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;GRANT
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kong&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# &lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;7-预启动konga&#34;&gt;7. 预启动konga&lt;/h3&gt;
&lt;p&gt;这一步主要是为了konga配置数据库。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;lzl@lzl:~$ docker run --rm pantsel/konga:latest &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&amp;gt; -c prepare &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&amp;gt; -a postgres &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&amp;gt; -u postgresql://konga:konga@10.0.20.25:5432/konga
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;debug: Preparing database...
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Using postgres DB Adapter.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Database exists. Continue...
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;debug: Hook:api_health_checks:process&lt;span style=&#34;color:#f92672&#34;&gt;()&lt;/span&gt; called
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;debug: Hook:health_checks:process&lt;span style=&#34;color:#f92672&#34;&gt;()&lt;/span&gt; called
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;debug: Hook:start-scheduled-snapshots:process&lt;span style=&#34;color:#f92672&#34;&gt;()&lt;/span&gt; called
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;debug: Hook:upstream_health_checks:process&lt;span style=&#34;color:#f92672&#34;&gt;()&lt;/span&gt; called
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;debug: Hook:user_events_hook:process&lt;span style=&#34;color:#f92672&#34;&gt;()&lt;/span&gt; called
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;debug: Seeding User...
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;debug: User seed planted
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;debug: Seeding Kongnode...
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;debug: Kongnode seed planted
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;debug: Seeding Emailtransport...
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;debug: Emailtransport seed planted
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;debug: Database migrations completed!
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;8-启动konga&#34;&gt;8. 启动konga&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;lzl@lzl:~$ docker run -d --name konga &lt;span style=&#34;color:#ae81ff&#34;&gt;\-&lt;/span&gt;-network&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;kong-net 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&amp;gt; -e &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;DB_ADAPTER=postgres&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&amp;gt; -e &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;DB_HOST=10.0.20.25&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&amp;gt; -e &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;DB_PORT=5432&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&amp;gt; -e &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;DB_USER=konga&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&amp;gt; -e &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;DB_PASSWORD=konga&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&amp;gt; -e &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;DB_DATABASE=konga&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&amp;gt; -e &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;DB_PG_SCHEMA=public&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&amp;gt; -e &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;NODE_ENV=production&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&amp;gt; -p 1337:1337 pantsel/konga
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;7031e0fb024b3c1919895b1f9ae516f06a3e95a805aee0076a3cfb99f3d889f5
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 开放这个端口，以免不能正常访问&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;lzl@lzl:~$ sudo iptables -A INPUT -p udp --dport &lt;span style=&#34;color:#ae81ff&#34;&gt;1337&lt;/span&gt; -j ACCEPT
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;lzl@lzl:~$ sudo iptables -A INPUT -p tcp --dport &lt;span style=&#34;color:#ae81ff&#34;&gt;1337&lt;/span&gt; -j ACCEPT
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;9-现在就可以打开界面玩一玩了&#34;&gt;9. 现在就可以打开界面玩一玩了&lt;/h3&gt;
&lt;p&gt;创建连接，将konga连接到kong的API。这里注意&lt;code&gt;Kong Admin URL&lt;/code&gt;就写&lt;code&gt;http://kong:8001&lt;/code&gt;，我写&lt;code&gt;http://localhost:8001&lt;/code&gt;怎么都连不上。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lizonglin313/MyPicGo/master/20211202164224.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lizonglin313/MyPicGo/master/20211202164254.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;创建服务。这个服务可以是一个应用，也可以是某个接口。我把我的博客作为服务，让网关帮我做转发。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lizonglin313/MyPicGo/master/20211202164536.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;然后配置转发路由。这里输入完一定要按下回车。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lizonglin313/MyPicGo/master/20211202171542.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;现在访问&lt;code&gt;:8000/blog&lt;/code&gt;端口会自动转到。但是目前还存在许多问题。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;使用kong之后我的宿主机无法访问虚拟机的内容了。&lt;/li&gt;
&lt;li&gt;对于kong网关的转发和路由机制还没搞清楚。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lizonglin313/MyPicGo/master/20211202171616.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;除此之外，kong-gateway还可以接入身份认证插件（如：JWT），链路追踪插件（如：zipkin），监控插件（如：prometheus），值得好好研究一下。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;参考：&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.cnblogs.com/jerryqm/p/12901036.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.cnblogs.com/jerryqm/p/12901036.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.jianshu.com/p/551a4c61e224&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.jianshu.com/p/551a4c61e224&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
</description>
        </item>
        <item>
        <title>启动k8s的主节点(k8s实践-1)</title>
        <link>https://lizonglingo.github.io/p/%E5%90%AF%E5%8A%A8k8s%E7%9A%84%E4%B8%BB%E8%8A%82%E7%82%B9k8s%E5%AE%9E%E8%B7%B5-1/</link>
        <pubDate>Sun, 28 Nov 2021 20:37:15 +0800</pubDate>
        
        <guid>https://lizonglingo.github.io/p/%E5%90%AF%E5%8A%A8k8s%E7%9A%84%E4%B8%BB%E8%8A%82%E7%82%B9k8s%E5%AE%9E%E8%B7%B5-1/</guid>
        <description>&lt;h1 id=&#34;概念&#34;&gt;概念&lt;/h1&gt;
&lt;p&gt;关于k8s的一些概念在官网讲的很详细，这里着重说几个。&lt;/p&gt;
&lt;h2 id=&#34;主节点&#34;&gt;主节点&lt;/h2&gt;
&lt;p&gt;主节点是组成集群控制平面的系统服务集合。生产环境中一般建议有3或5个主节点保证管理的高可用HA。主节点的服务有：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;API Server：为所有组件提供通信支持&lt;/li&gt;
&lt;li&gt;集群存储：比如etcd&lt;/li&gt;
&lt;li&gt;管理器controller：实现全部的后台循环控制，完成对集群节点的监控并对事件做出响应，目的是保证集群的当前状态与期望状态相同&lt;/li&gt;
&lt;li&gt;调度器scheduler：通过监听API Server启动新的工作任务并将其分配到合适的节点中&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;此外，还有云controller管理器，是针对运行在云平台（如AWS、Azure）的用户集群进行管理的组件。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;关于工作节点的内容在后面的文章中会跟上。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&#34;启动k8s的master节点&#34;&gt;启动k8s的master节点&lt;/h1&gt;
&lt;blockquote&gt;
&lt;p&gt;成功启动还是花了不少时间的，先把相关的参考列上：&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://kubernetes.io/zh/docs/setup/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://kubernetes.io/zh/docs/setup/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://kubernetes.io/zh/docs/tasks/tools/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://kubernetes.io/zh/docs/tasks/tools/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/professorman/article/details/118150688&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://blog.csdn.net/professorman/article/details/118150688&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://stackoverflow.com/questions/52119985/kubeadm-init-shows-kubelet-isnt-running-or-healthy&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://stackoverflow.com/questions/52119985/kubeadm-init-shows-kubelet-isnt-running-or-healthy&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://bbs.huaweicloud.com/forum/thread-76599-1-1.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://bbs.huaweicloud.com/forum/thread-76599-1-1.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.cnblogs.com/potato-chip/p/13973760.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.cnblogs.com/potato-chip/p/13973760.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://blog.51cto.com/zhangxueliang/2980956&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://blog.51cto.com/zhangxueliang/2980956&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;前置环境&#34;&gt;前置环境&lt;/h2&gt;
&lt;p&gt;在安装k8s（泛指运行k8s所需要的环境、组件等）之前，我的环境是这样的：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一台Ubuntu&lt;del&gt;18.04&lt;/del&gt;20.04虚拟机，4G内存（最好是4G，我尝试了2G内存结果虚拟机容易卡死）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这里要特别的注意，一开始我是用的是Ubuntu18.04，但是在k8s系列的下一篇文章中，启动Service来访问集群时，出现了问题。这应该是由于&lt;a class=&#34;link&#34; href=&#34;https://bugs.launchpad.net/ubuntu/&amp;#43;source/linux-meta-hwe-5.4/&amp;#43;bug/1899690&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Ubuntu18.04内核的一个bug&lt;/a&gt;，因为我搭建的环境是Kubernetes1.22.4，启动Service时需要使用iptables来配置规则，而Kubernetes使用的iptables版本要新于Ubuntu18.04的iptables，进而导致有iptables新版本的命令旧版本无法正常执行，导致无法完成Service配置。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;当我将环境更换到Ubuntu20.04时，该问题得到解决，所以建议使用Ubuntu20.04来进行实验。&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;需要配置好docker环境&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;关闭swap&#34;&gt;关闭swap&lt;/h3&gt;
&lt;p&gt;这一点是k8s强烈建议的，我看到所有的教程几乎都说明了关闭swap，可以提高性能。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;swapoff -a
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo sed -i &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/ swap / s/^/#/&amp;#39;&lt;/span&gt; /etc/fstab
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;应该需要重启机器才生效。&lt;/p&gt;
&lt;h3 id=&#34;开放端口&#34;&gt;开放端口&lt;/h3&gt;
&lt;p&gt;对于管理节点和工作节点来说，有一些端口需要开放给k8s的组件进行通信：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;控制平面节点&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;协议&lt;/th&gt;
&lt;th&gt;方向&lt;/th&gt;
&lt;th&gt;端口范围&lt;/th&gt;
&lt;th&gt;作用&lt;/th&gt;
&lt;th&gt;使用者&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;TCP&lt;/td&gt;
&lt;td&gt;入站&lt;/td&gt;
&lt;td&gt;6443&lt;/td&gt;
&lt;td&gt;Kubernetes API 服务器&lt;/td&gt;
&lt;td&gt;所有组件&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;TCP&lt;/td&gt;
&lt;td&gt;入站&lt;/td&gt;
&lt;td&gt;2379-2380&lt;/td&gt;
&lt;td&gt;etcd 服务器客户端 API&lt;/td&gt;
&lt;td&gt;kube-apiserver, etcd&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;TCP&lt;/td&gt;
&lt;td&gt;入站&lt;/td&gt;
&lt;td&gt;10250&lt;/td&gt;
&lt;td&gt;Kubelet API&lt;/td&gt;
&lt;td&gt;kubelet 自身、控制平面组件&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;TCP&lt;/td&gt;
&lt;td&gt;入站&lt;/td&gt;
&lt;td&gt;10251&lt;/td&gt;
&lt;td&gt;kube-scheduler&lt;/td&gt;
&lt;td&gt;kube-scheduler 自身&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;TCP&lt;/td&gt;
&lt;td&gt;入站&lt;/td&gt;
&lt;td&gt;10252&lt;/td&gt;
&lt;td&gt;kube-controller-manager&lt;/td&gt;
&lt;td&gt;kube-controller-manager 自身&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ul&gt;
&lt;li&gt;工作节点&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;协议&lt;/th&gt;
&lt;th&gt;方向&lt;/th&gt;
&lt;th&gt;端口范围&lt;/th&gt;
&lt;th&gt;作用&lt;/th&gt;
&lt;th&gt;使用者&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;TCP&lt;/td&gt;
&lt;td&gt;入站&lt;/td&gt;
&lt;td&gt;10250&lt;/td&gt;
&lt;td&gt;Kubelet API&lt;/td&gt;
&lt;td&gt;kubelet 自身、控制平面组件&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;TCP&lt;/td&gt;
&lt;td&gt;入站&lt;/td&gt;
&lt;td&gt;30000-32767&lt;/td&gt;
&lt;td&gt;NodePort 服务†&lt;/td&gt;
&lt;td&gt;所有组件&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;以上端口我使用&lt;code&gt;iptables&lt;/code&gt;打开。&lt;/p&gt;
&lt;h3 id=&#34;开启ip转发&#34;&gt;开启ip转发&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#开启ip转发&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;vim /etc/sysctl.conf
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;net.ipv4.ip_forward&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#查看状态&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sysctl -p
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;设置iptables转发规则&#34;&gt;设置iptables转发规则&lt;/h3&gt;
&lt;p&gt;这是后来发现的坑，有的机器上iptables的Chain Forward规则是&lt;code&gt;Chain FORWARD (policy DROP)&lt;/code&gt;，这样就无法通过集群地址访问部署在别的节点上的Pod，Service也不可用。所以保险起见还是要查看下有没有打开，没有就给他ACCEPT。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;iptables -P FORWARD ACCEPT
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;更换docker的cgroup驱动&#34;&gt;更换docker的cgroup驱动&lt;/h3&gt;
&lt;p&gt;因为k8s的cgroup驱动是&lt;code&gt;systems&lt;/code&gt;但是docker的是&lt;code&gt;systemd&lt;/code&gt;，所以在&lt;code&gt;/etc/docker/daemon.json&lt;/code&gt;中添加设置：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-json&#34; data-lang=&#34;json&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;{
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;&amp;#34;exec-opts&amp;#34;&lt;/span&gt;: [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;native.cgroupdriver=systemd&amp;#34;&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;然后重启docker：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; sudo systemctl daemon-reload
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; sudo systemctl restart docker
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;# 因为这个错误我是在安装完kubelet后才出现的 所以我也重启了kubelet&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt; sudo systemctl restart kubelet
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;安装k8s&#34;&gt;安装k8s&lt;/h2&gt;
&lt;h3 id=&#34;添加证书&#34;&gt;添加证书&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;curl https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | apt-key add - 
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;添加apt源&#34;&gt;添加apt源&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;cat &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;lt;&amp;lt;EOF &amp;gt;/etc/apt/sources.list.d/kubernetes.list
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;deb https://mirrors.aliyun.com/kubernetes/apt/ kubernetes-xenial main
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;EOF&lt;/span&gt;  
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;apt-get update
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;安装&#34;&gt;安装&lt;/h3&gt;
&lt;p&gt;默认的，安装最新版本的k8s&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code class=&#34;language-she&#34; data-lang=&#34;she&#34;&gt;apt-get install -y kubelet kubeadm kubectl
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;也可以安装想要的版本：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;apt-get install -y kubelet&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;1.18.4-00 kubeadm&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;1.18.4-00 kubectl&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;1.18.4-00
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;获取构建k8s需要的镜像&#34;&gt;获取构建k8s需要的镜像&lt;/h3&gt;
&lt;p&gt;首先查看需要的镜像版本：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;lzl@lzl-b:~$ kubeadm config images list
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;k8s.gcr.io/kube-apiserver:v1.22.4
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;k8s.gcr.io/kube-controller-manager:v1.22.4
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;k8s.gcr.io/kube-scheduler:v1.22.4
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;k8s.gcr.io/kube-proxy:v1.22.4
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;k8s.gcr.io/pause:3.5
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;k8s.gcr.io/etcd:3.5.0-0
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;k8s.gcr.io/coredns/coredns:v1.8.4
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;由于直接通过pull会被墙，所以推荐通过配置了国内源的docker先pull下来，然后再打上想要的tag。整个流程的shell文件如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/kube-apiserver:v1.22.4
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/kube-controller-manager:v1.22.4
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/kube-scheduler:v1.22.4
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy:v1.22.4
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.5
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/etcd:3.5.0-0
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/coredns:v1.8.4
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/kube-apiserver:v1.22.4 k8s.gcr.io/kube-apiserver:v1.22.4
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/kube-controller-manager:v1.22.4 k8s.gcr.io/kube-controller-manager:v1.22.4
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/kube-scheduler:v1.22.4 k8s.gcr.io/kube-scheduler:v1.22.4
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy:v1.22.4 k8s.gcr.io/kube-proxy:v1.22.4
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.5 k8s.gcr.io/pause:3.5
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/etcd:3.5.0-0 k8s.gcr.io/etcd:3.5.0-0
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/coredns:v1.8.4 k8s.gcr.io/coredns/coredns:v1.8.4
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;然后检查下有没有问题：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;lzl@lzl:~/Desktop$ docker image ls
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;REPOSITORY                                                                    TAG          IMAGE ID       CREATED         SIZE
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;k8s.gcr.io/kube-apiserver                                                     v1.22.4      8a5cc299272d   &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt; days ago     128MB
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;registry.cn-hangzhou.aliyuncs.com/google_containers/kube-apiserver            v1.22.4      8a5cc299272d   &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt; days ago     128MB
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;k8s.gcr.io/kube-scheduler                                                     v1.22.4      721ba97f54a6   &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt; days ago     52.7MB
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;registry.cn-hangzhou.aliyuncs.com/google_containers/kube-scheduler            v1.22.4      721ba97f54a6   &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt; days ago     52.7MB
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;k8s.gcr.io/kube-controller-manager                                            v1.22.4      0ce02f92d3e4   &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt; days ago     122MB
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;registry.cn-hangzhou.aliyuncs.com/google_containers/kube-controller-manager   v1.22.4      0ce02f92d3e4   &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt; days ago     122MB
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;k8s.gcr.io/kube-proxy                                                         v1.22.4      edeff87e4802   &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt; days ago     104MB
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy                v1.22.4      edeff87e4802   &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt; days ago     104MB
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;nginx                                                                         latest       ea335eea17ab   &lt;span style=&#34;color:#ae81ff&#34;&gt;11&lt;/span&gt; days ago     141MB
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;alpine                                                                        &amp;lt;none&amp;gt;       0a97eee8041e   &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; weeks ago     5.61MB
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;counter-app-master_web-fe                                                     latest       1e3f0e452820   &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; weeks ago     52.5MB
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;carrotliduo/web                                                               latest       8b05e3c03d63   &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt; weeks ago     77MB
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;test                                                                          latest       8b05e3c03d63   &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt; weeks ago     77MB
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;web                                                                           latest       8b05e3c03d63   &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt; weeks ago     77MB
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;python                                                                        3.6-alpine   c5aebf5e06c5   &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt; weeks ago     40.8MB
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ubuntu                                                                        latest       ba6acccedd29   &lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt; weeks ago     72.8MB
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;redis                                                                         alpine       e24d2b9deaec   &lt;span style=&#34;color:#ae81ff&#34;&gt;7&lt;/span&gt; weeks ago     32.3MB
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;alpine                                                                        latest       14119a10abf4   &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt; months ago    5.6MB
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;nigelpoulton/tu-demo                                                          latest       c610c6a38555   &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt; months ago    58.1MB
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;nigelpoulton/tu-demo                                                          v2           c610c6a38555   &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt; months ago    58.1MB
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;nigelpoulton/tu-demo                                                          v1           6ba12825d092   &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt; months ago    58.1MB
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;nigelpoulton/pluralsight-docker-ci                                            latest       1c201f15a046   &lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt; months ago    79.5MB
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;registry.cn-hangzhou.aliyuncs.com/google_containers/etcd                      3.5.0-0      &lt;span style=&#34;color:#ae81ff&#34;&gt;004811815584&lt;/span&gt;   &lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt; months ago    295MB
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;k8s.gcr.io/etcd                                                               3.5.0-0      &lt;span style=&#34;color:#ae81ff&#34;&gt;004811815584&lt;/span&gt;   &lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt; months ago    295MB
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;k8s.gcr.io/coredns/coredns                                                    v1.8.4       8d147537fb7d   &lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt; months ago    47.6MB
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;registry.cn-hangzhou.aliyuncs.com/google_containers/coredns                   v1.8.4       8d147537fb7d   &lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt; months ago    47.6MB
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;k8s.gcr.io/pause                                                              3.5          ed210e3e4a5b   &lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt; months ago    683kB
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;registry.cn-hangzhou.aliyuncs.com/google_containers/pause                     3.5          ed210e3e4a5b   &lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt; months ago    683kB
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;nigelpoulton/tu-demo                                                          v2-old       d5e1e48cf932   &lt;span style=&#34;color:#ae81ff&#34;&gt;20&lt;/span&gt; months ago   104MB
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;nigelpoulton/tu-demo                                                          v1-old       6852022de69d   &lt;span style=&#34;color:#ae81ff&#34;&gt;20&lt;/span&gt; months ago   104MB
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;dockersamples/atseasampleshopapp_reverse_proxy                                &amp;lt;none&amp;gt;       32b8411b497a   &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt; years ago     18.6MB
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;dockersamples/visualizer
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;然后我们就可以初始化master节点了&#34;&gt;然后我们就可以初始化master节点了&lt;/h3&gt;
&lt;p&gt;这里注意要以&lt;code&gt;root&lt;/code&gt;角色启动。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;root@lzl:/home/lzl# kubeadm init --kubernetes-version&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;v1.22.4 --pod-network-cidr&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;10.0.20.0/24 --ignore-preflight-errors&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;Swap
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;init&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Using Kubernetes version: v1.22.4
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;preflight&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Running pre-flight checks
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;	&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;WARNING HTTPProxy&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;: Connection to &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;https://10.0.20.25&amp;#34;&lt;/span&gt; uses proxy &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;http://10.0.20.17:1080/&amp;#34;&lt;/span&gt;. If that is not intended, adjust your proxy settings
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;	&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;WARNING HTTPProxyCIDR&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;: connection to &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;10.96.0.0/12&amp;#34;&lt;/span&gt; uses proxy &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;http://10.0.20.17:1080/&amp;#34;&lt;/span&gt;. This may lead to malfunctional cluster setup. Make sure that Pod and Services IP ranges specified correctly as exceptions in proxy configuration
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;	&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;WARNING HTTPProxyCIDR&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;: connection to &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;10.0.20.0/24&amp;#34;&lt;/span&gt; uses proxy &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;http://10.0.20.17:1080/&amp;#34;&lt;/span&gt;. This may lead to malfunctional cluster setup. Make sure that Pod and Services IP ranges specified correctly as exceptions in proxy configuration
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;preflight&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Pulling images required &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; setting up a Kubernetes cluster
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;preflight&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; This might take a minute or two, depending on the speed of your internet connection
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;preflight&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; You can also perform this action in beforehand using &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;kubeadm config images pull&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;certs&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Using certificateDir folder &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/etc/kubernetes/pki&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;certs&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Generating &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;ca&amp;#34;&lt;/span&gt; certificate and key
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;certs&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Generating &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;apiserver&amp;#34;&lt;/span&gt; certificate and key
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;certs&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; apiserver serving cert is signed &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; DNS names &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local lzl&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; and IPs &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;10.96.0.1 10.0.20.25&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;certs&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Generating &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;apiserver-kubelet-client&amp;#34;&lt;/span&gt; certificate and key
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;certs&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Generating &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;front-proxy-ca&amp;#34;&lt;/span&gt; certificate and key
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;certs&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Generating &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;front-proxy-client&amp;#34;&lt;/span&gt; certificate and key
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;certs&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Generating &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;etcd/ca&amp;#34;&lt;/span&gt; certificate and key
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;certs&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Generating &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;etcd/server&amp;#34;&lt;/span&gt; certificate and key
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;certs&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; etcd/server serving cert is signed &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; DNS names &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;localhost lzl&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; and IPs &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;10.0.20.25 127.0.0.1 ::1&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;certs&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Generating &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;etcd/peer&amp;#34;&lt;/span&gt; certificate and key
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;certs&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; etcd/peer serving cert is signed &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; DNS names &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;localhost lzl&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; and IPs &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;10.0.20.25 127.0.0.1 ::1&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;certs&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Generating &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;etcd/healthcheck-client&amp;#34;&lt;/span&gt; certificate and key
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;certs&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Generating &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;apiserver-etcd-client&amp;#34;&lt;/span&gt; certificate and key
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;certs&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Generating &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;sa&amp;#34;&lt;/span&gt; key and public key
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;kubeconfig&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Using kubeconfig folder &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/etc/kubernetes&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;kubeconfig&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Writing &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;admin.conf&amp;#34;&lt;/span&gt; kubeconfig file
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;kubeconfig&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Writing &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;kubelet.conf&amp;#34;&lt;/span&gt; kubeconfig file
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;kubeconfig&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Writing &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;controller-manager.conf&amp;#34;&lt;/span&gt; kubeconfig file
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;kubeconfig&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Writing &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;scheduler.conf&amp;#34;&lt;/span&gt; kubeconfig file
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;kubelet-start&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Writing kubelet environment file with flags to file &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/var/lib/kubelet/kubeadm-flags.env&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;kubelet-start&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Writing kubelet configuration to file &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/var/lib/kubelet/config.yaml&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;kubelet-start&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Starting the kubelet
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;control-plane&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Using manifest folder &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/etc/kubernetes/manifests&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;control-plane&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Creating static Pod manifest &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;kube-apiserver&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;control-plane&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Creating static Pod manifest &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;kube-controller-manager&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;control-plane&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Creating static Pod manifest &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;kube-scheduler&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;etcd&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Creating static Pod manifest &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; local etcd in &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/etc/kubernetes/manifests&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;wait-control-plane&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Waiting &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; the kubelet to boot up the control plane as static Pods from directory &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/etc/kubernetes/manifests&amp;#34;&lt;/span&gt;. This can take up to 4m0s
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;apiclient&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; All control plane components are healthy after 7.778428 seconds
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;upload-config&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Storing the configuration used in ConfigMap &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;kubeadm-config&amp;#34;&lt;/span&gt; in the &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;kube-system&amp;#34;&lt;/span&gt; Namespace
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;kubelet&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Creating a ConfigMap &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;kubelet-config-1.22&amp;#34;&lt;/span&gt; in namespace kube-system with the configuration &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; the kubelets in the cluster
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;upload-certs&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Skipping phase. Please see --upload-certs
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;mark-control-plane&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Marking the node lzl as control-plane by adding the labels: &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;node-role.kubernetes.io/master&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;deprecated&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt; node-role.kubernetes.io/control-plane node.kubernetes.io/exclude-from-external-load-balancers&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;mark-control-plane&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Marking the node lzl as control-plane by adding the taints &lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;node-role.kubernetes.io/master:NoSchedule&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;bootstrap-token&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Using token: y5u12k.h101qh26f94557u7
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;bootstrap-token&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;bootstrap-token&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; configured RBAC rules to allow Node Bootstrap tokens to get nodes
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;bootstrap-token&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; nodes to get long term certificate credentials
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;bootstrap-token&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;bootstrap-token&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; configured RBAC rules to allow certificate rotation &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; all node client certificates in the cluster
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;bootstrap-token&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Creating the &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;cluster-info&amp;#34;&lt;/span&gt; ConfigMap in the &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;kube-public&amp;#34;&lt;/span&gt; namespace
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;kubelet-finalize&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Updating &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/etc/kubernetes/kubelet.conf&amp;#34;&lt;/span&gt; to point to a rotatable kubelet client certificate and key
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;addons&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Applied essential addon: CoreDNS
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;addons&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; Applied essential addon: kube-proxy
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Your Kubernetes control-plane has initialized successfully!
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;To start using your cluster, you need to run the following as a regular user:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  mkdir -p $HOME/.kube
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  sudo chown &lt;span style=&#34;color:#66d9ef&#34;&gt;$(&lt;/span&gt;id -u&lt;span style=&#34;color:#66d9ef&#34;&gt;)&lt;/span&gt;:&lt;span style=&#34;color:#66d9ef&#34;&gt;$(&lt;/span&gt;id -g&lt;span style=&#34;color:#66d9ef&#34;&gt;)&lt;/span&gt; $HOME/.kube/config
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Alternatively, &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; you are the root user, you can run:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  export KUBECONFIG&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;/etc/kubernetes/admin.conf
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;You should now deploy a pod network to the cluster.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Run &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;kubectl apply -f [podnetwork].yaml&amp;#34;&lt;/span&gt; with one of the options listed at:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  https://kubernetes.io/docs/concepts/cluster-administration/addons/
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Then you can join any number of worker nodes by running the following on each as root:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kubeadm join 10.0.20.25:6443 --token y5u12k.h101qh26f94557u7 &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;	--discovery-token-ca-cert-hash sha256:ef50610dda443d0dc461f3a74e8e73921c2e86dd24a2f39519b4f315a018d7f8 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;root@lzl:/home/lzl# 
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;看到&lt;code&gt;Your Kubernetes control-plane has initialized successfully!&lt;/code&gt;就说明第一阶段配置完成了。&lt;/p&gt;
&lt;h2 id=&#34;继续配环境&#34;&gt;继续配环境&lt;/h2&gt;
&lt;p&gt;我们先切到普通用户，然后根据刚才的提示设置以下的环境：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;lzl@lzl:~$ mkdir -p $HOME/.kube
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;lzl@lzl:~$ sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;sudo&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; password &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; lzl: 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;lzl@lzl:~$ sudo chown &lt;span style=&#34;color:#66d9ef&#34;&gt;$(&lt;/span&gt;id -u&lt;span style=&#34;color:#66d9ef&#34;&gt;)&lt;/span&gt;:&lt;span style=&#34;color:#66d9ef&#34;&gt;$(&lt;/span&gt;id -g&lt;span style=&#34;color:#66d9ef&#34;&gt;)&lt;/span&gt; $HOME/.kube/config
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;然后查看一下各组件的状态：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;lzl@lzl:~$ kubectl get componentstatus
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Warning: v1 ComponentStatus is deprecated in v1.19+
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;NAME                 STATUS      MESSAGE                                                                                       ERROR
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;scheduler            Unhealthy   Get &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;http://127.0.0.1:10251/healthz&amp;#34;&lt;/span&gt;: dial tcp 127.0.0.1:10251: connect: connection refused   
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;controller-manager   Healthy     ok                                                                                            
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;etcd-0               Healthy     &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;health&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;true&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;reason&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;发现调度器掉线。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;出现这种情况，是&lt;code&gt;/etc/kubernetes/manifests/&lt;/code&gt;下的&lt;code&gt;kube-controller-manager.yaml&lt;/code&gt;和&lt;code&gt;kube-scheduler.yaml&lt;/code&gt;设置的默认端口是0导致的，解决方式是注释掉对应的port即可。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;我们按照别人的教程操作：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;···
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;spec:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  containers:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  - command:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    - kube-scheduler
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    - --authentication-kubeconfig&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;/etc/kubernetes/scheduler.conf
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    - --authorization-kubeconfig&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;/etc/kubernetes/scheduler.conf
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    - --bind-address&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;127.0.0.1
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    - --kubeconfig&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;/etc/kubernetes/scheduler.conf
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    - --leader-elect&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;true
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#    - --port=0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    env:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    - name: HTTP_PROXY
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      value: http://10.0.20.17:1080/
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    - name: FTP_PROXY
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      value: http://10.0.20.17:1080/
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    - name: https_proxy
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      value: http://10.0.20.17:1080/
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;···
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;再次查看组件状态：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;lzl@lzl:/etc/kubernetes/manifests$ kubectl get componentstatus
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Warning: v1 ComponentStatus is deprecated in v1.19+
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;NAME                 STATUS    MESSAGE                         ERROR
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;scheduler            Healthy   ok                              
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;controller-manager   Healthy   ok                              
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;etcd-0               Healthy   &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;health&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;true&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;reason&amp;#34;&lt;/span&gt;:&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;  
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;这样三个组件就全部在线了。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>云原生在实践中的技术组成</title>
        <link>https://lizonglingo.github.io/p/%E4%BA%91%E5%8E%9F%E7%94%9F%E5%9C%A8%E5%AE%9E%E8%B7%B5%E4%B8%AD%E7%9A%84%E6%8A%80%E6%9C%AF%E7%BB%84%E6%88%90/</link>
        <pubDate>Mon, 08 Nov 2021 23:41:03 +0800</pubDate>
        
        <guid>https://lizonglingo.github.io/p/%E4%BA%91%E5%8E%9F%E7%94%9F%E5%9C%A8%E5%AE%9E%E8%B7%B5%E4%B8%AD%E7%9A%84%E6%8A%80%E6%9C%AF%E7%BB%84%E6%88%90/</guid>
        <description>&lt;h2 id=&#34;1-微服务&#34;&gt;1. 微服务&lt;/h2&gt;
&lt;p&gt;微服务的引入解决了单体服务的复杂性，将明确定义的功能分成粒度更小的服务，是每个微服务独立迭代、独立部署，独立拓展、独立重启。达到服务之间的松耦合，进而使得业务的频繁变更在用户看来低感知。&lt;/p&gt;
&lt;p&gt;相比传统单体架构，微服务的优点如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;单个微服务复杂度降低&lt;/li&gt;
&lt;li&gt;独立迭代、独立部署，独立拓展&lt;/li&gt;
&lt;li&gt;跨语言&lt;/li&gt;
&lt;li&gt;开发敏捷&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;同时，将单体服务拆分成微服务，也引入一些问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;运维复杂&lt;/li&gt;
&lt;li&gt;分布式系统复杂&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;进一步引出需要解决的网络延迟、容错性、消息序列化、网络稳定性、异步机制、版本差异、调用链过长等问题。&lt;/p&gt;
&lt;p&gt;你可能会问了，既然微服务会引入这么多问题，那为什么还要用微服务呢？&lt;/p&gt;
&lt;p&gt;答案就是：在真正需要使用微服务架构的地方使用微服务，会大大提高生产力。（所以一些单体架构就能满足的简单业务就没有必要使用微服务了）&lt;/p&gt;
&lt;h2 id=&#34;2-容器&#34;&gt;2. 容器&lt;/h2&gt;
&lt;p&gt;容器的出现是以虚拟化技术为依托，容器在低级虚拟化的基础上，实现了OS层面之上的虚拟化，或者说进程级别的虚拟化。每个容器有自己的文件空间、网络、计算等资源，虽然它们共享主机的资源，但是这些资源是隔离的。&lt;/p&gt;
&lt;p&gt;容器技术分为&lt;strong&gt;运行时&lt;/strong&gt;和&lt;strong&gt;编排&lt;/strong&gt;两个层次。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;运行时：与容器的计算、存储、网络等实际的计算任务有关&lt;/li&gt;
&lt;li&gt;编排：对容器集群的调度、服务发现和资源管理等&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Docker和Kubernetes的组合实现了从服务打包成镜像、移植、编排、部署、扩缩容、维护等一系列工作。&lt;/p&gt;
&lt;h2 id=&#34;3-服务网格&#34;&gt;3. 服务网格&lt;/h2&gt;
&lt;p&gt;在微服务中可分为两种架构，入侵式架构和非入侵式架构。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;入侵式架构：服务框架嵌入程序代码，开发者在开发时需要组合各种插件实现业务之外的架构问题；如：RCP、负载均衡、熔断等。&lt;/li&gt;
&lt;li&gt;非入侵式架构：业务之外的组件以代理的形式与应用程序部署在一起，结果应用程序的网络且对其透明，开发者只需注重业务本身，其中代表的技术就是服务网格。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lizonglin313/MyPicGo/master/IMG_20211108_233231_edit_205576557382171.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;Service Mesh使系统技术栈下移，可以说作为&lt;strong&gt;微服务的基础设施&lt;/strong&gt;。用于处理服务间的请求响应的可靠传递、服务治理，解耦服务监控、链路追踪、熔断、服务发现等问题。&lt;/p&gt;
&lt;h2 id=&#34;4-devops&#34;&gt;4. DevOps&lt;/h2&gt;
&lt;p&gt;关于DevOps，可能给不出一个具体的定义，但是这代表一种思想，一种开发、运维的模式，其主要目的在于将开发和运维之间的关系拉近，它永远是面向业务的。这种实践包括持续集成、持续测试、持续交付、持续部署，使得业务可以滚动式的升级。打通团队从研发、测试、运维甚至产品、客户反馈的业务链条。来适应快速变化的市场和稍纵即逝的风口。&lt;/p&gt;
</description>
        </item>
        
    </channel>
</rss>
