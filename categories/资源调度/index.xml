<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>资源调度 on Li Duo</title>
    <link>https://lizonglingo.github.io/categories/%E8%B5%84%E6%BA%90%E8%B0%83%E5%BA%A6/</link>
    <description>Recent content in 资源调度 on Li Duo</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <lastBuildDate>Sun, 26 Jun 2022 15:00:34 +0800</lastBuildDate><atom:link href="https://lizonglingo.github.io/categories/%E8%B5%84%E6%BA%90%E8%B0%83%E5%BA%A6/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Sinan: ML-Based and QoS-Aware Resource Management for Cloud Microservices</title>
      <link>https://lizonglingo.github.io/p/sinan-ml-based-and-qos-aware-resource-management-for-cloud-microservices/</link>
      <pubDate>Sun, 26 Jun 2022 15:00:34 +0800</pubDate>
      
      <guid>https://lizonglingo.github.io/p/sinan-ml-based-and-qos-aware-resource-management-for-cloud-microservices/</guid>
      <description>来源：ASPLOS&#39;21 ccf-a 作者：Cornell University 正如题目所说，这篇文章主要就是使用机器学习的方法，针对微服务架构的应用进行资源配置，当然是保</description>
    </item>
    
    <item>
      <title>Cocktail: A Multidimensional Optimization for Model Serving in Cloud</title>
      <link>https://lizonglingo.github.io/p/cocktail-a-multidimensional-optimization-for-model-serving-in-cloud/</link>
      <pubDate>Sun, 15 May 2022 21:07:08 +0800</pubDate>
      
      <guid>https://lizonglingo.github.io/p/cocktail-a-multidimensional-optimization-for-model-serving-in-cloud/</guid>
      <description>来源：NSDI&#39;22 推荐阅读！ 摘要 背景 越来越多的ML模型运行在公有云环境下。为这些模型服务的框架能够以最小的延迟提供高度准确的预测，并降低部</description>
    </item>
    
    <item>
      <title>A Case for Task Sampling based Learning  for Cluster Job Scheduling</title>
      <link>https://lizonglingo.github.io/p/a-case-for-task-sampling-based-learning-for-cluster-job-scheduling/</link>
      <pubDate>Sat, 14 May 2022 20:09:49 +0800</pubDate>
      
      <guid>https://lizonglingo.github.io/p/a-case-for-task-sampling-based-learning-for-cluster-job-scheduling/</guid>
      <description>来源：NSDI &amp;lsquo;22 摘要 背景 精确定预估任务运行时间为有效的任务调度提供遍历。现有的任务调度基于历史数据学习，使用任务历史信息预估新任务。但是，由</description>
    </item>
    
    <item>
      <title>RunWild: Resource Management System with Generalized Modeling for Microservices on Cloud</title>
      <link>https://lizonglingo.github.io/p/runwild-resource-management-system-with-generalized-modeling-for-microservices-on-cloud/</link>
      <pubDate>Sun, 24 Apr 2022 15:17:07 +0800</pubDate>
      
      <guid>https://lizonglingo.github.io/p/runwild-resource-management-system-with-generalized-modeling-for-microservices-on-cloud/</guid>
      <description>来源：IEEE CLOUD&#39;21 作者：IBM :star:摘要 问题背景 微服务内部通信的复杂性，必须考虑资源利用、调度策略和请求均衡之间的平衡，以防止跨微服务级</description>
    </item>
    
    <item>
      <title>IEEE CLOUD 21 云上资源管理相关合辑</title>
      <link>https://lizonglingo.github.io/p/ieee-cloud-21-%E4%BA%91%E4%B8%8A%E8%B5%84%E6%BA%90%E7%AE%A1%E7%90%86%E7%9B%B8%E5%85%B3%E5%90%88%E8%BE%91/</link>
      <pubDate>Thu, 21 Apr 2022 14:33:47 +0800</pubDate>
      
      <guid>https://lizonglingo.github.io/p/ieee-cloud-21-%E4%BA%91%E4%B8%8A%E8%B5%84%E6%BA%90%E7%AE%A1%E7%90%86%E7%9B%B8%E5%85%B3%E5%90%88%E8%BE%91/</guid>
      <description>本篇整理自IEEE CLOUD&#39;21会议中的文章，主题为云背景下的资源管理。 RunWild: Resource Management System withGeneralized Modeling for Microservices on Cloud :star:摘要 问题背景 微服务内部通信的复杂性</description>
    </item>
    
    <item>
      <title>Characterizing microservice dependency and performance: Alibaba trace analysis</title>
      <link>https://lizonglingo.github.io/p/characterizing-microservice-dependency-and-performance-alibaba-trace-analysis/</link>
      <pubDate>Tue, 29 Mar 2022 13:40:56 +0800</pubDate>
      
      <guid>https://lizonglingo.github.io/p/characterizing-microservice-dependency-and-performance-alibaba-trace-analysis/</guid>
      <description>来源： SoCC&#39;21 作者： Alibaba Group http://cloud.siat.ac.cn/pdca/socc2021-AlibabaTraceAnalysis.pdf 摘要 背景 理解微服务的特征，对利用微服务架构的特性很重要。然而，目前还没有对微服务及其相关系统在生产环境下的全面研究。 工作</description>
    </item>
    
    <item>
      <title>MLaaS in the Wild: Workload Analysis and Scheduling in Large-Scale Heterogeneous GPU Clusters</title>
      <link>https://lizonglingo.github.io/p/mlaas-in-the-wild-workload-analysis-and-scheduling-in-large-scale-heterogeneous-gpu-clusters/</link>
      <pubDate>Mon, 21 Mar 2022 21:05:51 +0800</pubDate>
      
      <guid>https://lizonglingo.github.io/p/mlaas-in-the-wild-workload-analysis-and-scheduling-in-large-scale-heterogeneous-gpu-clusters/</guid>
      <description>来源： NSDI&#39;22 作者：Alibaba Group 摘要 在ML as a Service中，数据中心为ML提供算力保证。而多样的ML工作负载面对异构GPU集群时会出现一些</description>
    </item>
    
  </channel>
</rss>
