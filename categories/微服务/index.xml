<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>微服务 on Li Duo</title>
        <link>https://lizonglingo.github.io/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/</link>
        <description>Recent content in 微服务 on Li Duo</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-CN</language>
        <lastBuildDate>Sun, 26 Jun 2022 15:00:34 +0800</lastBuildDate><atom:link href="https://lizonglingo.github.io/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>Sinan: ML-Based and QoS-Aware Resource Management for Cloud Microservices</title>
        <link>https://lizonglingo.github.io/p/sinan-ml-based-and-qos-aware-resource-management-for-cloud-microservices/</link>
        <pubDate>Sun, 26 Jun 2022 15:00:34 +0800</pubDate>
        
        <guid>https://lizonglingo.github.io/p/sinan-ml-based-and-qos-aware-resource-management-for-cloud-microservices/</guid>
        <description>&lt;blockquote&gt;
&lt;p&gt;来源：ASPLOS&#39;21  ccf-a&lt;/p&gt;
&lt;p&gt;作者：Cornell University&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;正如题目所说，这篇文章主要就是使用&lt;strong&gt;机器学习&lt;/strong&gt;的方法，针对&lt;strong&gt;微服务架构&lt;/strong&gt;的应用进行&lt;strong&gt;资源配置&lt;/strong&gt;，当然是&lt;strong&gt;保证QoS的前提&lt;/strong&gt;下提高资源分配和使用的效率。&lt;/li&gt;
&lt;li&gt;利用ML方法帮助调度的决策&lt;/li&gt;
&lt;li&gt;面向以容器和虚拟机构建及部署的微服务应用&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;问题的痛点是什么或是要解决什么问题他们的idea有什么值得学习的地方&#34;&gt;问题的痛点是什么？或是要解决什么问题？他们的idea有什么值得学习的地方？&lt;/h2&gt;
&lt;h3 id=&#34;先前的工作&#34;&gt;先前的工作&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;为满足QoS而忽视资源利用率，往往有较高的资源分配上限，把边界划定的很远，虽然是为了更好的满足QoS要求但是牺牲了资源&lt;/li&gt;
&lt;li&gt;针对单体系统而没有考虑微服务架构的特点&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;本文idea&#34;&gt;本文idea&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;突出QoS、E2E时延&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;资源分配突出了一个满足QoS要求，并且多次提到OOM错误&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;考虑到微服务架构的层级结构(tier)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;考虑到微服务架构的拓扑图，也就是微服务之间的依赖关系&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;提到了微服务中某些排队队列的环节会因为QoS违规导致更长时间的排队等候，进而提出了需要一个较长时间的预测&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;具体是什么云环境应用以什么样的方式部署&#34;&gt;具体是什么云环境？应用以什么样的方式部署？&lt;/h2&gt;
&lt;p&gt;Docker + VM组成的云环境。应用以被打包成Docker镜像然后部署在虚拟机上。&lt;/p&gt;
&lt;h2 id=&#34;使用了什么机器学习方法这个学习解决的是什么问题&#34;&gt;使用了什么机器学习方法？这个学习解决的是什么问题？&lt;/h2&gt;
&lt;p&gt;文章提出了一个“two-stage model”。第一阶段，使用CNN预测下一个时间步的E2E时延，这对精确性提出了很高的要求；第二阶段，使用Boosted Trees预测QoS违规（需要使用CNN模型的输出）。&lt;/p&gt;
&lt;p&gt;第一阶段和第二阶段分别代表了短期和长期的预测结果，以辅助调度的决策。&lt;/p&gt;
&lt;h3 id=&#34;cnn卷积神经网络&#34;&gt;CNN卷积神经网络&lt;/h3&gt;
&lt;p&gt;CNN模型主要用于短期的性能预测。&lt;/p&gt;
&lt;p&gt;具体来说，使用CNN来预测下一个时间窗口的时延分布，是秒级的窗口(默认是5秒)。但是文章发现，预测时延是件很困难的事情，并且随着预测时间的增加，效果不理想。&lt;/p&gt;
&lt;p&gt;因此进一步的，文章将预测策略变为：预测是否出现QoS违规，也就是随后的时间段出现QoS违规的概率。（因为通常将QoS与E2E时延划等号，出现QoS违规相当于E2E时延过长，所以QoS违规给调度决策带来的信息是足够的）&lt;/p&gt;
&lt;h4 id=&#34;模型使用到的输入数据&#34;&gt;模型使用到的输入数据&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;CPU使用信息&lt;/li&gt;
&lt;li&gt;内存使用信息（包括常驻内存和缓存）&lt;/li&gt;
&lt;li&gt;网络使用信息（如接收和发送的数据包）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这些都是用Docker cgroup的接口收集。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;上一个窗口E2E时延的分布&lt;/li&gt;
&lt;li&gt;能够在下一个时间窗口分配的资源信息&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;模型的预测输出&#34;&gt;模型的预测输出&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;下一个时间窗口的时延信息，该信息会进一步用于Boosted Tree中&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;boosted-tree&#34;&gt;Boosted Tree&lt;/h3&gt;
&lt;p&gt;增长树模型主要用于长期的性能预测。具体来说，进行一个二分类问题的预测——接下来的资源分配是否会造成QoS违规，通过这个预测来减少未来预期之外的负面影响。&lt;/p&gt;
&lt;h4 id=&#34;模型使用到的输入数据-1&#34;&gt;模型使用到的输入数据&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;使用到CNN中的预测输出的时延信息&lt;/li&gt;
&lt;li&gt;资源分配信息&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;模型的预测输出-1&#34;&gt;模型的预测输出&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;在接下来时间步k中，是否会出现QoS违规现象&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;系统架构是什么样的如何分配资源&#34;&gt;系统架构是什么样的？如何分配资源？&lt;/h2&gt;
&lt;h3 id=&#34;系统架构&#34;&gt;系统架构&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/202206261434874.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220626143414765&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;中心化的调度器&lt;/li&gt;
&lt;li&gt;分布式的节点代理&lt;/li&gt;
&lt;li&gt;单独部署的预测服务&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;系统流程如上图。&lt;/p&gt;
&lt;h3 id=&#34;资源分配&#34;&gt;资源分配&lt;/h3&gt;
&lt;p&gt;系统中资源分配的几种动作如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/202206261443689.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220626144302597&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;评估怎么做的使用了什么应用&#34;&gt;评估怎么做的？使用了什么应用？&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;在本地集群和Google Cloud上面做的实验&lt;/li&gt;
&lt;li&gt;使用了微服务benchmark套件&lt;strong&gt;DeathStarBench&lt;/strong&gt;(有论文的这个套件)以及其中的应用Hotel Reservation，Social Network。&lt;/li&gt;
&lt;li&gt;使用Docker Swarm进行部署&lt;/li&gt;
&lt;li&gt;收集了31302和58499条Hotel和Social Network的数据&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;实验环境&#34;&gt;实验环境&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;本地集群：80core CPU/256GB RAM&lt;/li&gt;
&lt;li&gt;GCE集群：93containers&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;微服务应用&#34;&gt;微服务应用&lt;/h3&gt;
&lt;h4 id=&#34;hotel-reservation&#34;&gt;Hotel Reservation&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/202206242159386.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220624215932271&#34;
	
	
&gt;&lt;/p&gt;
&lt;h4 id=&#34;social-network&#34;&gt;Social Network&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/202206242159015.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220624215947934&#34;
	
	
&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;做实验时可以参考本文实验设计&lt;/p&gt;
&lt;/blockquote&gt;
</description>
        </item>
        <item>
        <title>Characterizing microservice dependency and performance: Alibaba trace analysis</title>
        <link>https://lizonglingo.github.io/p/characterizing-microservice-dependency-and-performance-alibaba-trace-analysis/</link>
        <pubDate>Tue, 29 Mar 2022 13:40:56 +0800</pubDate>
        
        <guid>https://lizonglingo.github.io/p/characterizing-microservice-dependency-and-performance-alibaba-trace-analysis/</guid>
        <description>&lt;blockquote&gt;
&lt;p&gt;来源： SoCC&#39;21&lt;/p&gt;
&lt;p&gt;作者： Alibaba Group&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;http://cloud.siat.ac.cn/pdca/socc2021-AlibabaTraceAnalysis.pdf&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;http://cloud.siat.ac.cn/pdca/socc2021-AlibabaTraceAnalysis.pdf&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;摘要&#34;&gt;摘要&lt;/h2&gt;
&lt;h3 id=&#34;背景&#34;&gt;背景&lt;/h3&gt;
&lt;p&gt;理解微服务的特征，对利用微服务架构的特性很重要。然而，目前还没有对微服务及其相关系统在生产环境下的全面研究。&lt;/p&gt;
&lt;h3 id=&#34;工作&#34;&gt;工作&lt;/h3&gt;
&lt;p&gt;我们对阿里巴巴集群中大规模部署微服务进行了详实的分析。研究重点是&lt;strong&gt;描述微服务的依赖关系及其运行时性能&lt;/strong&gt;。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;对微服务调用图进行了深入剖析，以量化它们与数据并行作业的传统DAG之间的区别&lt;/li&gt;
&lt;li&gt;为合成更有代表性的微服务追踪轨迹，构建了数学模型去模拟调用图&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;结论&#34;&gt;结论&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;通过分析，发现调用图是重尾分布的&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;它们的&lt;strong&gt;拓扑结构类似于树&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;而且许多微服务都是热点(hot-spots)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;发现三类有意义的调用依赖，可以&lt;strong&gt;用来优化微服务的设计&lt;/strong&gt;。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;大多数&lt;strong&gt;微服务对CPU受到的干扰比对内存受到的干扰更加敏感&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;分析目标有20000个微服务，时间是7天，表征了它们的特性，包括动态的调用图，表征了微服务间调用依赖还有运行时性能分析。&lt;/p&gt;
&lt;h4 id=&#34;微服务调用图与传统的数据并行处理任务dag图明显不同&#34;&gt;微服务调用图与传统的数据并行处理任务DAG图明显不同&lt;/h4&gt;
&lt;p&gt;虽然可以看作有向图，但是有下面几个明显的不同：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;调用图的大小遵循重尾分布，有10%的调用图包含超过40个微服务生命阶段，其他大多数只有几个阶段（&lt;strong&gt;因为由于服务运行时的动态性，不同时刻的调用图不同&lt;/strong&gt;）&lt;/li&gt;
&lt;li&gt;调用图的形状像树，大部分节点只有一条入边，与大数据任务的明显不同&lt;/li&gt;
&lt;li&gt;存在微服务热点，&lt;strong&gt;5%的微服务被90%的微服务调用&lt;/strong&gt;，而传统的DAG图中不会存在节点共享的情况&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;微服务在运行时有高度动态的调用关系&lt;/strong&gt;，在极端的情况下，同一个在线服务有超过9类拓扑上不同的图&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;微服务的强依赖关系为优化微服务设计提供了方向&#34;&gt;微服务的强依赖关系为优化微服务设计提供了方向&lt;/h4&gt;
&lt;p&gt;例如，优化两个强依赖关系的调用接口，提升上游、下游微服务间的通信效率，避免形成局部的性能瓶颈。&lt;/p&gt;
&lt;h4 id=&#34;微服务对cpu扰动比对内存扰动更加敏感&#34;&gt;微服务对CPU扰动比对内存扰动更加敏感&lt;/h4&gt;
&lt;p&gt;CPU扰动会严重影响到响应时间。例如，CPU利用率在10%和30%时，响应时间相差20%。&lt;/p&gt;
&lt;p&gt;同时，这表明需要对有效的任务调度策略有极大的需求，以平衡不同机器上CPU的利用率。&lt;/p&gt;
&lt;h4 id=&#34;随机模型可以很好地模拟动态微服务调用图&#34;&gt;随机模型可以很好地模拟动态微服务调用图&lt;/h4&gt;
&lt;p&gt;现有的一些调用图不能展现服务运行时的调用状态，在整个生命周期中不会跟随请求的发生而动态改变。&lt;/p&gt;
&lt;p&gt;为此，文章构建了一个随机模型，通过对微服务进行分类来生成调用图。&lt;/p&gt;
&lt;h3 id=&#34;contribution&#34;&gt;Contribution&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;首次对生产集群中的微服务进行详细的研究，包括微服务调用图的结构和依赖属性&lt;/li&gt;
&lt;li&gt;对微服务运行时表现进行详细的表征，对微服务调度和资源管理给出深入的洞见&lt;/li&gt;
&lt;li&gt;构建图模型来有效的生成大规模的微服务追踪结构，对在模拟图中表征结构性质进行了理论分析&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;microservice-background-and-alibaba-trace-overview&#34;&gt;Microservice Background And Alibaba Trace Overview&lt;/h2&gt;
&lt;h3 id=&#34;微服务架构&#34;&gt;微服务架构&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/image-20220327210505343.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220327210505343&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;追踪概览&#34;&gt;追踪概览&lt;/h3&gt;
&lt;p&gt;收集了超过100亿次调用的追踪。&lt;/p&gt;
&lt;h4 id=&#34;物理运行环境&#34;&gt;物理运行环境&lt;/h4&gt;
&lt;p&gt;使用Kubernetes管理裸金属云环境，依赖硬件优化加强集群性能表现，并实现不同服务间的隔离性。如下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/image-20220327210843935.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220327210843935&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在线服务和离线服务会存在同一个裸金属节点上，以加强资源利用率&lt;/li&gt;
&lt;li&gt;在线服务运行在容器中，直接被K8s所管理，而离线任务被分配定量的pods，交给调度器进行调度&lt;/li&gt;
&lt;li&gt;批处理任务被放到安全容器中来保证安全性&lt;/li&gt;
&lt;li&gt;有状态应用被部署在专门的节点上，不和其他无状态或是批处理应用共享机器&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;微服务系统测量&#34;&gt;微服务系统测量&lt;/h4&gt;
&lt;p&gt;如Figure 2(b)，微服务监控对每个容器的指标进行测量，隔段时间再求均值。测量的范围从硬件层面的缓存miss率，到操作系统层面的CPU利用率还有内存使用等，还有容器应用层面的例如JVM的堆使用和垃圾回收。&lt;/p&gt;
&lt;p&gt;测量用Timestamp来作为时间序列的表征。&lt;/p&gt;
&lt;h4 id=&#34;调用图中的微服务调用指标&#34;&gt;调用图中的微服务调用指标&lt;/h4&gt;
&lt;p&gt;如Figure 2(c)：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;微服务调用通过TraceID作为请求标识，代表一个调用图&lt;/li&gt;
&lt;li&gt;interface是上游服务和下游服务的调用接口&lt;/li&gt;
&lt;li&gt;还记录了上下游服务Pod的IP&lt;/li&gt;
&lt;li&gt;上下游调用的响应时间&lt;/li&gt;
&lt;li&gt;&amp;hellip;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;聚合调用&#34;&gt;聚合调用&lt;/h4&gt;
&lt;p&gt;如Figure 2(d)，微服务的调用情况也会被记录：调用时间戳、响应时间、微服务、调用和被调用的接口、上下游微服务。&lt;/p&gt;
&lt;h2 id=&#34;解析调用图&#34;&gt;解析调用图&lt;/h2&gt;
&lt;h3 id=&#34;微服务调用图的特性&#34;&gt;微服务调用图的特性&lt;/h3&gt;
&lt;p&gt;**微服务调用图的数量呈现重尾分布。**大多数调用图只包含少数微服务，调用层级不超过3层。但有的调用图包含大量的微服务和很深的层次，如下图：&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;图中的微服务数量呈现Burr分布&lt;/li&gt;
&lt;li&gt;超过10%的服务包含超过40个不同的微服务&lt;/li&gt;
&lt;li&gt;超过40个微服务的大型应用中，大约有50%的微服务是缓存服务（因为系统越庞大，需要缓存来加快系统响应时间，使用缓存比数据库有更高的效率）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;下图是调用图深度的分布：&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;平均深度为4.27层&lt;/li&gt;
&lt;li&gt;深度在3层的服务居多&lt;/li&gt;
&lt;li&gt;仍有超过4%的调用图超过10层&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;所带来的问题是，&lt;strong&gt;如何使用深度学习方法，为这些服务分配正确的容器数量&lt;/strong&gt;，如[17, 40]。这些方法将不同层次的微服务进行编码，并将实时的资源分配作为神经网络的输入向量。但是这样很容易产生过拟合现象，调用图规模太大，而用于调整模型的负标签太少，如RT violation现象。&lt;/p&gt;
&lt;p&gt;因此，&lt;strong&gt;急需找到合适的方法有效的为大规模微服务分配资源&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;微服务调用图像一棵树，许多图包含一条较长的链&lt;/strong&gt;。如下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/image-20220328112852049.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220328112852049&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;当微服务数量不断增加，调用深度逐渐稳定&lt;/li&gt;
&lt;li&gt;如果一个微服务调用涉及到有状态服务，那么一般来说这条调用链不会再延长，终止于有状态服务&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;关于调用图节点的出边和入边分布如下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/image-20220328113313961.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220328113313961&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;超过10%的有状态服务至少有5条出边&lt;/li&gt;
&lt;li&gt;大多数微服务只有一条入边&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;一旦微服务层数大于2时，相关层包含的微服务一般只有一个，如下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/image-20220328120224056.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220328120224056&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;例如，当层数在10层时，有超过50%的情况是这层只有一个微服务。也就是上面提到的，&lt;strong&gt;为什么深度越深，就越是表现出链式结构&lt;/strong&gt;。此外，这种情况也利于查找微服务调用中出现的瓶颈。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;无状态服务容易成为hot-spots&lt;/strong&gt;。如上面的Figure 4所示，超过5%的微服务在聚合调用后有超过16条入边，这些超级微服务承载力将近90%的调用，涉及到95%的调用。因此这种&lt;strong&gt;松耦合架构展现了严重的负载不平衡&lt;/strong&gt;。这有利于资源扩展，因为系统管理员应该只关注单个微服务的扩展，并为这些超级微服务分配更多的容器。&lt;/p&gt;
&lt;p&gt;**微服务调用图有很高的动态性。**即使是同一个在线应用，它们生成的调用拓扑图都有显著的差异。例如同一个付款请求，一个有优惠券的用户和一个会员用户或者一个普通用户，请求的调用的微服务都有显著的不同。如下图，所有在线服务都至少有两类图拓扑结构：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/image-20220328122519395.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220328122519395&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;另外，还有超过10%的微服务呈现9中调用模式。**这进一步给基于图的微服务预测任务带来了巨大的挑战。**现有的基于CNN的微服务资源管理方法不能描述这些动态特性，也不适用于实际的工业应用。&lt;/p&gt;
&lt;h3 id=&#34;图学习算法&#34;&gt;图学习算法&lt;/h3&gt;
&lt;p&gt;该算法的目的在于：将调用图中的微服务进行分类。&lt;strong&gt;关键点是将每个微服务转换为一个向量&lt;/strong&gt;。如InfoGraph算法，这是无监督学习，它将节点信息（如某种微服务），还有边信息（如微服务的调用关系），做成邻接矩阵作为深度神经网络的输入。&lt;/p&gt;
&lt;p&gt;通过综合训练集的信息，InfoGraph可以为每个图生成一个嵌入向量。&lt;/p&gt;
&lt;p&gt;文章分别训练每个在线服务，并在嵌入的20维向量上使用K-means聚类，将该服务生成的所有调用图分组为多个类。聚类的数量在[2,10]中，&lt;strong&gt;并用来生成平均轮廓系数&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;在聚类后，使用通用方法Graph Kernel，用来生成两个图间的相似度。&lt;/p&gt;
&lt;p&gt;对图进行聚类和相似判断的算法如下：&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;h3 id=&#34;详细分析&#34;&gt;详细分析&lt;/h3&gt;
&lt;h4 id=&#34;无状态微服务的调用模式在不同的层上有很大的不同&#34;&gt;无状态微服务的调用模式在不同的层上有很大的不同&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;通常无状态服务没有下游微服务，调用图一般不会在无状态服务处继续扩展&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;消息队列对减少深层次的调用图的端到端时延很有帮助&#34;&gt;消息队列对减少深层次的调用图的端到端时延很有帮助&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;对于依赖缓存的服务，当缓存未命中时，会花费大量时间调用数据库服务&lt;/li&gt;
&lt;li&gt;当深度增加时，无状态微服务和数据库(即S2D)之间的通信百分比呈亚线性增长&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;下图中：&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;图a展示不同类型的无状态服务对调用层数的影响&lt;/li&gt;
&lt;li&gt;图b展示了随着深度增加，服务间通信类型，请求类型的占比&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;无状态服务间依赖&#34;&gt;无状态服务间依赖&lt;/h2&gt;
&lt;p&gt;上文中提到，无状态服务过多依赖其他的存储服务，一些时候不可避免的带来服务资源占用。通过研究无状态服务间依赖以避免通信过载和死锁的发生。&lt;/p&gt;
&lt;h3 id=&#34;循环依赖关系&#34;&gt;循环依赖关系&lt;/h3&gt;
&lt;p&gt;下图为循环依赖关系的简单实例：&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;这种依赖分为：强依赖关系和弱依赖关系。强循环依赖如果设计不合理，会导致死锁。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;强循环依赖关系：上游的输入接口与下游的应答接口相同，直接的就是I1=I3&lt;/li&gt;
&lt;li&gt;弱循环依赖关系：I1 != I3&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;循环依赖关系在调用图同不可忽视&#34;&gt;循环依赖关系在调用图同不可忽视&lt;/h4&gt;
&lt;p&gt;下图展示循环依赖的占比以及这些依赖使用的通信方式：&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;大多数通信模式使用RPC进行&lt;/li&gt;
&lt;li&gt;在所有的循环依赖中，2.7%是强依赖关系&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;耦合依赖高频率的调用次数和长调用时间&#34;&gt;耦合依赖：高频率的调用次数和长调用时间&lt;/h3&gt;
&lt;p&gt;对于调用率和调用次数的计算如下：&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;Count(X)：上游Y调用下游M的次数（相邻两层中，X可能会被Y多次调用）&lt;/p&gt;
&lt;p&gt;Sum：表示所有调用图中由Y触发的两层调用的数量&lt;/p&gt;
&lt;p&gt;N：为两层调用中X被调用的数量&lt;/p&gt;
&lt;p&gt;如果Call Probability和Call Time的值超过2和0.9，就说这两个服务是耦合依赖的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;对于有强耦合依赖的服务，可以将它们的接口做到一起以优化，减轻网络拥塞&lt;/strong&gt;。&lt;/p&gt;
&lt;h3 id=&#34;并行依赖&#34;&gt;并行依赖&lt;/h3&gt;
&lt;p&gt;并行依赖可以减轻上游服务的响应时间。但是在这种情况下建议将服务做进一个微服务中。&lt;/p&gt;
&lt;h2 id=&#34;微服务运行时表现&#34;&gt;微服务运行时表现&lt;/h2&gt;
&lt;p&gt;理解微服务运行时的情况有利于保证服务质量。在本节中，文章研究图拓扑和资源干扰以及微服务调用率(MCR)对响应时间的影响。&lt;/p&gt;
&lt;h3 id=&#34;微服务调用率&#34;&gt;微服务调用率&lt;/h3&gt;
&lt;p&gt;MCR记录了每个容器每分钟接收调用的次数。如果MCR过大，可能意味着资源紧张。&lt;/p&gt;
&lt;p&gt;使用Spearman相关系数来评估MCR序列和微服务容器运行时的序列。如下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/image-20220329130343180.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220329130343180&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;上图展示了MCR和多种不同的系统层面和应用层面的资源调用的累积分布。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;微服务调用率与CPU利用率和Young GC高度相关，但与内存利用率无关&lt;/li&gt;
&lt;li&gt;说明CPU利用率和Young GCs最能反应资源紧张程度&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;微服务响应时间表现&#34;&gt;微服务响应时间表现&lt;/h3&gt;
&lt;p&gt;本部分研究调用图的复杂性、资源竞争和MCR以及其他因素对微服务响应时间表现的影响。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;端到端时延在拓扑结构类似的调用图中较为稳定，而在拓扑结构不同的调用图中显得很大不同。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;通过上面的图聚类算法将调用图进行分类，对每类图中的响应时间进行计算。这进一步说明图拓扑结构对端到端RT有很大的影响。此外，文章&lt;strong&gt;设计的图学习算法可以用于预测RT性能。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;端到端性能会由于CPU的高占用而下降。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;**在微服务调用率变化时，时延并没有太大波动，**这是由于在集群中及时处理了调用请求避免消息堆积。&lt;/p&gt;
&lt;h2 id=&#34;用概率模型生成微服务图&#34;&gt;用概率模型生成微服务图&lt;/h2&gt;
&lt;p&gt;涉及到的算法暂时没看太懂&amp;hellip;&lt;/p&gt;
&lt;h2 id=&#34;相关工作&#34;&gt;相关工作&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Microservice benchmarks&lt;/li&gt;
&lt;li&gt;Serverless benchmarks&lt;/li&gt;
&lt;li&gt;Cloud workloads&lt;/li&gt;
&lt;li&gt;Cloud trace analysis&lt;/li&gt;
&lt;li&gt;Performance characterization of online services&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>3MileBeach: A Tracer with Teeth</title>
        <link>https://lizonglingo.github.io/p/3milebeach-a-tracer-with-teeth/</link>
        <pubDate>Mon, 14 Mar 2022 19:12:33 +0800</pubDate>
        
        <guid>https://lizonglingo.github.io/p/3milebeach-a-tracer-with-teeth/</guid>
        <description>&lt;blockquote&gt;
&lt;p&gt;来源：ACM SoCC&#39;21&lt;/p&gt;
&lt;p&gt;作者：UC Santa Cruz&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;摘要&#34;&gt;摘要&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;提出&lt;em&gt;3MileBeach&lt;/em&gt;，一个针对微服务架构的追踪和故障注入平台。&lt;/li&gt;
&lt;li&gt;通过介入一个消息序列化库，避免了代码层面的监控（这是传统的追踪和故障注入会做的），可以提供更细粒度的追踪和故障注入。&lt;/li&gt;
&lt;li&gt;&lt;em&gt;3MileBeach&lt;/em&gt;提供了一个消息级别的分布式追踪，其开销只有最先进追踪框架的一半；提供故障注入比现有方案有更高的精度。&lt;/li&gt;
&lt;li&gt;使用&lt;em&gt;3MileBeach&lt;/em&gt;进行一种新型故障注入&lt;em&gt;Temporal Fault Injection&lt;/em&gt;（TFI）。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;追踪和故障注入现存的问题&#34;&gt;追踪和故障注入现存的问题&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;运行时开销和工作量过大；&lt;/li&gt;
&lt;li&gt;对异构应用程序和基础代码，基础设置的入侵性改动；&lt;/li&gt;
&lt;li&gt;微服务组件以不同的语言进行设计，之间使用不同的通信机制；&lt;/li&gt;
&lt;li&gt;故障注入需要在精度、粒度和成本上进行取舍。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;3milebeach的能力&#34;&gt;3MileBeach的能力&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;其只需要应用程序级的插件就能实现功能；&lt;/li&gt;
&lt;li&gt;提供细粒度的追踪，比最先进的技术节省25%~50%的成本；&lt;/li&gt;
&lt;li&gt;提供丰富且严格的跟踪指标；&lt;/li&gt;
&lt;li&gt;支持大规模并发故障注入，适用于生产环境；&lt;/li&gt;
&lt;li&gt;实现新型故障注入模式TFI，这基于时序谓词（nlp中的技术），可以识别可能处于休眠状态中的技术。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;motivation&#34;&gt;Motivation&lt;/h2&gt;
&lt;p&gt;目前最先进的分布式系统故障注入存在两个基础的问题：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;存在对细粒度、并发测试、不受blast radius影响的需求；&lt;/li&gt;
&lt;li&gt;现有的故障注入技术没有足够的表现力。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;time-of-check-to-time-of-usertocttou-error&#34;&gt;Time of Check to Time of User(TOCTTOU error)&lt;/h3&gt;
&lt;p&gt;假设一个在线购物平台存在如下问题，用户准备为购物车的物品付款时调用前端：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;前端发送一条消息给信用卡服务来验证（一个下游服务用来验证用户信用卡信息）；&lt;/li&gt;
&lt;li&gt;如果验证成功，前端会发送信息给商品服务来计算费用；&lt;/li&gt;
&lt;li&gt;计算完成后再次调用信用服务，扣除费用。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;试想这种情况：第一次调用信用卡服务成功，通过验证，而第二次（提出扣费申请时）发送了一个错误请求。&lt;/p&gt;
&lt;p&gt;简单来说，同一个服务在一小段时间后从可用状态变为不可用。&lt;/p&gt;
&lt;h3 id=&#34;temporal-discretization&#34;&gt;Temporal Discretization&lt;/h3&gt;
&lt;p&gt;大多数故障注入工具没有考虑到时间维度上的故障。&lt;/p&gt;
&lt;p&gt;首先，时间是一个连续的概念，往往考虑在请求的生命周期里发生故障，而忽略在发送请求时刻、流传输中发生故障；在一个确定时间引入故障或许没有什么意义。&lt;/p&gt;
&lt;p&gt;以上述案例为例，将前端服务视为黑盒，可以观察到信用卡服务可能不可用的四个离散的逻辑时间：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;在前端的第一次请求到来之前；&lt;/li&gt;
&lt;li&gt;在前端第一次请求到来之后，信用卡服务返回响应之前；&lt;/li&gt;
&lt;li&gt;在信用卡服务返回第一次响应之后，和前端请求第二次到来之前；&lt;/li&gt;
&lt;li&gt;在前端第二次请求到来之后，信用卡服务返回第二次响应之前。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;如果以粗粒度来看，前端调用信用卡服务发生的错误实际上又&lt;strong&gt;可以分为粒度更小的四种导致错误的原因&lt;/strong&gt;。&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;h3 id=&#34;communication-is-the-thing&#34;&gt;Communication is The Thing&lt;/h3&gt;
&lt;p&gt;3MileBeach为能够达成细粒度故障注入，从消息序列化、反序列化入手。例如从gRPC请求转换为HTTP请求，存在Protocol Buffer到JSON的序列化和反序列化过程。&lt;strong&gt;在该过程中添加元数据来装饰消息，以跟踪每个消息的上下文&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;因为远程服务的故障总是表现为服务边界出现的延迟、报错等错误。通过错误处理，避免引发blast radius，从而可以实现并发测试。&lt;/p&gt;
&lt;p&gt;通过对第三方库的修改（增加请求和响应消息的上下文传播），来对事件进行持续跟踪，记录完整的服务调用历程。&lt;/p&gt;
&lt;p&gt;通过故障注入逻辑检查这些数据，就可以得知以下信息：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;错误来自哪一个请求？which&lt;/li&gt;
&lt;li&gt;当前是哪一个服务遇到了错误？where&lt;/li&gt;
&lt;li&gt;注入的是什么服务？how&lt;/li&gt;
&lt;li&gt;故障何时被注入？when&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;实现&#34;&gt;实现&lt;/h2&gt;
&lt;h3 id=&#34;架构抽象&#34;&gt;架构抽象&lt;/h3&gt;
&lt;p&gt;下图定义了边界组件模型，即微服务框架和服务处理程序之间的边界。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/image-20220312124636575.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220312124636575&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;大多数微服务框架都提供了服务处理handler和边界组件的交互方式。&lt;/p&gt;
&lt;p&gt;Panorama [40] 通过将可观察性抽象为直接调用处理程序函数的方向和以（输入/输出）队列/代理作为缓存层的异步调用处理程序函数的间接性，引入了组件交互的四种设计模式。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Full direction。所有的函数被分配到一个线程，在该线程中依次调用入站操作、处理请求、出站操作。&lt;/li&gt;
&lt;li&gt;Inbound indirection。在被工作线程选择之前，将入站消息存到队列中，当出站组件调用时，被唤醒执行。&lt;/li&gt;
&lt;li&gt;Outbound indirection。入站组件和服务handler直接在一个工作线程中调用，处理后将消息放到出站线程队列等待被网络运输。&lt;/li&gt;
&lt;li&gt;Full indirection。将入站和出站的消息都放入队列进行调度，中间通过服务handler和网络请求唤醒调用。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;第2，3，4种做法都实现了上下文传播机制，可以通过handler和边界组件传递身份信息。&lt;/p&gt;
&lt;p&gt;因此3MileBeach选择上述的上下文传播的设计模式。&lt;/p&gt;
&lt;p&gt;入站组件对从网络来的row message进行反序列化，调用service handler。出站组件将处理后的message进行序列化。&lt;/p&gt;
&lt;p&gt;对数据流进行两种抽象：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Direct Response Circle（&lt;strong&gt;DRC&lt;/strong&gt;）；&lt;/li&gt;
&lt;li&gt;Synchronized Request-Response Circle（&lt;strong&gt;SRC&lt;/strong&gt;）。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;数据结构&#34;&gt;数据结构&lt;/h3&gt;
&lt;p&gt;将负载命名为&lt;em&gt;3mb-payload&lt;/em&gt;，具体实现称为&lt;strong&gt;Trace&lt;/strong&gt;。Trace是一个高层数据结构，由以下三部分组成：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;一系列的事件（Event-s）；&lt;/li&gt;
&lt;li&gt;必要的追踪元数据（如ID），来帮助3MileBeach为追踪识别和组装事件；&lt;/li&gt;
&lt;li&gt;一个故障注入配置列表（fault injection configuration-s，FIC-s）&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;event&#34;&gt;Event&lt;/h4&gt;
&lt;p&gt;Event记录了一个事件的必要信息，从中可以知道在什么时候那哪个服务接收或者发送了一个请求或一个响应，并且具体的服务名字。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Timestamp&lt;/li&gt;
&lt;li&gt;Service&lt;/li&gt;
&lt;li&gt;Action&lt;/li&gt;
&lt;li&gt;MessageType&lt;/li&gt;
&lt;li&gt;Name&lt;/li&gt;
&lt;li&gt;UUID&lt;/li&gt;
&lt;li&gt;&amp;hellip;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如下图所示，有4个事件联系到同一个UUID，指明一个SRC。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/image-20220312135514421.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220312135514421&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;其中两个由Svc1记录，一个是在Svc1发送请求时记录的，另一个是在Svc1接收响应时记录的。&lt;/p&gt;
&lt;h4 id=&#34;fault-injection-configuration&#34;&gt;Fault Injection Configuration&lt;/h4&gt;
&lt;p&gt;使用FIC来描述一个TFI和RLFI（Request Level Fault Injection）测试案例。&lt;/p&gt;
&lt;p&gt;考虑一个应用由n个服务组成。RLFI在客户端级请求生命周期中将故障注入服务。我们使用FIC{Type: Crash, Name: Svc_i}来表示服务i的故障。为测试所有的崩溃模式，RLFI的实验空间有$2^n$个。但是在模拟客户端级别的请求时，不需要调用全部的微服务。例如有m个服务不会被调用，实际上只需要调用$2^{n-m}$个案例。&lt;/p&gt;
&lt;p&gt;在TFI中，根据逻辑时序在某个测试的执行期间模拟故障。文章使用&lt;strong&gt;After&lt;/strong&gt;，这是一个&lt;strong&gt;TFIMetas&lt;/strong&gt;列表，用此存储故障的临时先决条件。TFI 可以触发的故障空间是RLFI故障空间的超集，因为当After为空时，RLFI是TFI的特例。&lt;/p&gt;
&lt;p&gt;另外通过时间离散化，FIC可以大大减少TFI的测试空间。&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;如上图 ，Svc1在处理客户端请求时，从Svc0处接收到Req1和Req2。RLFI只判断这两个请是成功还是失败。如果希望Req2失败而不影响Req1，我们模拟的错误应发生在t1-t2时，而在t3之后结束。&lt;/p&gt;
&lt;p&gt;而TFI通过模拟崩溃时间来缩减故障的注入时间段，即在t1-t2之间注入故障，使用如下FIC来描述：FIC{Type: Crash, Name: Req2, After: [TFIMeta{Name: Req1, Times:1}]}。&lt;/p&gt;
&lt;h3 id=&#34;算法&#34;&gt;算法&lt;/h3&gt;
&lt;p&gt;本部分主要讲如何通过序列化&lt;em&gt;3mb-payload&lt;/em&gt;来接入边界组件，以及重写序列化函数在数据流中的作用。&lt;/p&gt;
&lt;h4 id=&#34;interpose-via-serialization-functions&#34;&gt;Interpose via Serialization Functions&lt;/h4&gt;
&lt;p&gt;为追踪处理客户端请求的服务，3MileBeach扩展了序列化函数，叫做&lt;strong&gt;Deserialize’ Serialize’&lt;/strong&gt;。使用存储S来存储追踪的上下文对象Ctx。Ctx来源于现存的上下文传播机制，携带了请求的元数据。&lt;/p&gt;
&lt;p&gt;在入站组件中，3MileBeach从入站消息获取ID，并将ID分配给Ctx（算法1）。当服务handler发送请求时，3MileBeach将观测到的追踪数据（这个数据存在S中）附加在出站消息中（算法2）。下表中有相关的关键函数。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/image-20220313151022017.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220313151022017&#34;
	
	
&gt;&lt;/p&gt;
&lt;h4 id=&#34;serialization-functions-and-data-flows&#34;&gt;Serialization Functions and Data Flows&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Direct Response Circle (DRC)&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
&lt;li&gt;框架从上游服务或client接收请求；&lt;/li&gt;
&lt;li&gt;入站组件唤醒Deserialize’将请求反序列化，将事件作为追踪记录，并存储到S中，将追踪元数据写到Ctx中；&lt;/li&gt;
&lt;li&gt;框架调用服务handler并等待调用结束;&lt;/li&gt;
&lt;li&gt;框架收到响应；&lt;/li&gt;
&lt;li&gt;出站组件唤醒Serialize’，并从S中检索追踪Ctx的元数据，追加到发送事件，序列化响应；&lt;/li&gt;
&lt;li&gt;框架返回响应到上游服务或client。&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Synchronized Request-Response Circle (SRC)&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
&lt;li&gt;服务handler通过阻塞函数调用发送一个请求到下游服务；&lt;/li&gt;
&lt;li&gt;出站组件唤醒Serialize’，从S和Ctx中检索追踪数据，这些数据是微服务从上游服务或client的SEND事件中来的，模拟了故障信息。调用序列化函数对消息进行序列化；&lt;/li&gt;
&lt;li&gt;框架发送请求给下游服务并等待响应；&lt;/li&gt;
&lt;li&gt;框架收到下游的响应；&lt;/li&gt;
&lt;li&gt;入站请求唤醒Deserialize将响应反序列化，追加事件并存储；&lt;/li&gt;
&lt;li&gt;服务handler会接受响应。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/image-20220313155122436.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220313155122436&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/image-20220313155136954.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220313155136954&#34;
	
	
&gt;&lt;/p&gt;
&lt;h4 id=&#34;fault-simulation&#34;&gt;Fault Simulation&lt;/h4&gt;
&lt;p&gt;3MileBeach通过模拟下游的外部可观测错误来实现故障注入，从请求者的角度来看，这些错误可能是由于网络问题或者返回响应的handler产生。&lt;/p&gt;
&lt;p&gt;3MileBeach不会因为故障测试而崩溃或者重启，因此可以执行并发测试，也能控制blast radius。&lt;/p&gt;
&lt;p&gt;典型的SRC包括两个服务和两个数据流。（Requester Responder ReqFlow RespFlow）。故障触发时，requester不能知道下游的故障根源，这取决于具体的实现，它能知道这些错误的返回码，例如timeout、connection closed、package loss等，依次证实的确发现了问题。&lt;/p&gt;
&lt;p&gt;3MileBeach在FICs定义的故障触发条件得到满足时触发故障。&lt;/p&gt;
&lt;h2 id=&#34;实验&#34;&gt;实验&lt;/h2&gt;
&lt;p&gt;测量3MileBeach框架的端到端的延迟来展示其效率表现，并提供两个本地案例。&lt;/p&gt;
&lt;h3 id=&#34;实验设置&#34;&gt;实验设置&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;演示程序：Hipster Shop，一个部署在GKE上的微服务程序。&lt;/li&gt;
&lt;li&gt;客户端生成测试用例来进行跟踪和故障注入、应用性能调整及错误定位。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;hipster-shop&#34;&gt;Hipster Shop&lt;/h4&gt;
&lt;p&gt;包含以下微服务：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Frontend - &lt;strong&gt;Svc_fe&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;CART - &lt;strong&gt;Svc_cart&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Recommendation&lt;/li&gt;
&lt;li&gt;ProductCatalog - &lt;strong&gt;Svc_p&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Shipping&lt;/li&gt;
&lt;li&gt;Currency - &lt;strong&gt;Svc_c&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Payment&lt;/li&gt;
&lt;li&gt;Email&lt;/li&gt;
&lt;li&gt;Checkout&lt;/li&gt;
&lt;li&gt;Ad - &lt;strong&gt;Svc_a&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;涉及到的序列化库有：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;JSON&lt;/li&gt;
&lt;li&gt;PROTOCOL&lt;/li&gt;
&lt;li&gt;RESTFUL&lt;/li&gt;
&lt;li&gt;GRPC&lt;/li&gt;
&lt;li&gt;GORILLA等&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;开发语言：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GO&lt;/li&gt;
&lt;li&gt;C#&lt;/li&gt;
&lt;li&gt;Node.js&lt;/li&gt;
&lt;li&gt;Python&lt;/li&gt;
&lt;li&gt;Java&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;综上，可以看出这个应用很适合作为microservice的代表来对3MileBeach进行测试。&lt;/p&gt;
&lt;h4 id=&#34;clusters&#34;&gt;Clusters&lt;/h4&gt;
&lt;p&gt;集群情况如下：&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;h4 id=&#34;client&#34;&gt;Client&lt;/h4&gt;
&lt;p&gt;客户端在不同级别的并发下向Svc_fe发送请求，使用N来确定并发数。同时，将应用和Client部署在一个集群上以最大程度减少网络延迟。&lt;/p&gt;
&lt;h3 id=&#34;tracing-benchmark&#34;&gt;Tracing Benchmark&lt;/h3&gt;
&lt;p&gt;本部分涉及到链路追踪情况，主要考察增加链路追踪给系统带来的延迟上的开销。通过并发测量端到端延迟来比较。&lt;/p&gt;
&lt;p&gt;在进行追踪时势必会给系统增加开销，因此在这方面进行比较，与Jaeger框架进行比较。以下为延迟情况以及延迟和吞吐量之间的关系。&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/image-20220314162513457.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220314162513457&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;fault-injection&#34;&gt;Fault Injection&lt;/h3&gt;
&lt;p&gt;为测试3MileBeach对TFI测试的速度，在Svc_fe中设计了两个bug：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;DEEPRLFI。它在Svc_a和Svc_c都关闭时可以触发，不受事件影响。所以需要使用&lt;em&gt;3mb-payloads&lt;/em&gt;来同时触发Svc_a和Svc_c的崩溃。&lt;/li&gt;
&lt;li&gt;SimpleTFI。是一个TOCTTOU bug。为了触发这个问题，需要让请求携带可以使Svc_c崩溃的&lt;em&gt;3mb-payloads&lt;/em&gt;。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;通过下面几个图详细说明：&lt;/p&gt;
&lt;p&gt;（a）第一次调用Svc_c，Svc_fe可以容错；若Svc_c可访问，Svc_fe会认为在整个过程中Svc_c都是可以工作的；反正，Svc_fe会执行回退策略，使用默认的价钱。注意红色！的位置，Currency没有正常返回数据，但Svc_fe最终仍可以正常运行完，参考最后的绿色箭头。使用RLFI去模拟Svc_c的崩溃可以得到对应的结果。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/image-20220314163636670.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220314163636670&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;（b）当Svc_a不可用时，Svc_fe会应用回退策略，使用默认的广告推荐，并继续向Svc_c发送请求进行结算。使用RLFI去模拟Svc_a的崩溃可以得到对应的结果。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/image-20220314163715311.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220314163715311&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;（c）由上面两张图看出，在Currency和Ad二者中，只有一个出现问题时并不会引发Frontend的崩溃。下图则表示当Ad和Currency都崩溃时，Fronted才会崩。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/image-20220314163733335.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220314163733335&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/image-20220314163756339.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220314163756339&#34;
	
	
&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Service-Level Fault Injection Testing</title>
        <link>https://lizonglingo.github.io/p/service-level-fault-injection-testing/</link>
        <pubDate>Thu, 24 Feb 2022 19:25:41 +0800</pubDate>
        
        <guid>https://lizonglingo.github.io/p/service-level-fault-injection-testing/</guid>
        <description>&lt;blockquote&gt;
&lt;p&gt;来源：ACM SoCC&#39;21&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://acmsocc.org/2021/accepted-papers.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://acmsocc.org/2021/accepted-papers.html&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;摘要为什么需要服务级别的故障注入测试&#34;&gt;摘要——为什么需要服务级别的故障注入测试&lt;/h2&gt;
&lt;p&gt;由于微服务架构的特点，负责每个模块的工程师只需专注自己的部分而不需要过多关注整个应用系统。这些应用程序的开发人员不一定都是分布式系统工程师，因此无法预计系统出现部分故障：一旦部署到生产环境中，他们的服务会面临一个或多个依赖项不可用的问题。&lt;/p&gt;
&lt;p&gt;作者提出了一种称为服务级故障注入测试的方法和一种称为 Filibuster 的原型实现，可用于在微服务应用程序开发的早期系统地识别弹性问题。&lt;/p&gt;
&lt;p&gt;Filibuster 将静态分析和 concolic-style 执行与一种新颖的动态缩减算法相结合，以扩展现有的功能测试套件，以最少的开发人员工作量覆盖故障场景。&lt;/p&gt;
&lt;p&gt;并使用 4 个真实工业微服务应用程序的语料库来进行实验。&lt;/p&gt;
&lt;h2 id=&#34;贡献&#34;&gt;贡献&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;一种测试微服务应用程序弹性的方法：服务级故障注入测试 (SFIT) &lt;strong&gt;结合了静态分析和 concolic 测试&lt;/strong&gt;，以探索微服务之间所有可能的故障，从现有的通过功能测试套件开始。&lt;/li&gt;
&lt;li&gt;一种新颖的动态缩减算法： SFIT 使用一种算法，通过利用将应用程序分解为独立的微服务来&lt;strong&gt;减少搜索空间的组合爆炸&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;实现了SFIT的原型Filibuster：这个基于 Python 的工具可用于测试与 HTTP 通信的服务。我们的原型允许在本地测试服务的弹性，并证明它可以在 Amazon CodeBuild CI/CD 环境中运行，以便在问题进入生产之前检测它们。&lt;/li&gt;
&lt;li&gt;用 Python 实现的微服务应用程序和错误的语料库：该语料库包含 8 个小型微服务应用程序，每个应用程序都展示了微服务应用程序中使用的单一模式；和 4 个从公开会议演讲中重新实现的行业示例：Audible、Expedia、Mailchimp 和 Netflix。&lt;/li&gt;
&lt;li&gt;在该语料库上对Filibuster进行评价：证明 Filibuster 可用于识别语料库中的所有错误。我们展示了通过动态缩减可能进行的优化，并提供了有关如何最好地设计微服务应用程序以实现可测试性的见解。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;难点&#34;&gt;难点&lt;/h2&gt;
&lt;p&gt;缺乏开源微服务工业应用程序及其相关的错误报告（这两个主要的语料库通常有助于软件测试领域的研究），回答这些错误是否可以在开发过程的早期检测到的问题并不简单。&lt;/p&gt;
&lt;p&gt;最终作者构建了4个案例语料库。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Audible：一家提供有声读物流媒体移动应用程序的公司。在他们的演示文稿中，他们描述了一个错误，即应用程序服务器在从 Amazon S3 读取数据时不会收到 NotFound 错误。此错误在代码中未处理，并通过一般错误消息传播回移动客户端。他们使用混沌工程发现了这个错误。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Expedia：一家提供旅行预订的公司。他们讨论了使用混沌工程来验证如果他们的应用程序服务器尝试从基于相关性对它们进行排序的服务中检索酒店评论，并且该服务不可用，他们将回退到另一个提供按时间排序的评论。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Mailchimp：一款用于电子邮件通讯管理的产品。在他们的演示中，他们讨论了两个错误。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;遗留代码无法处理其数据库服务器返回的指示其为只读情况的错误代码。&lt;/li&gt;
&lt;li&gt;一项服务变得不可用并将未处理的错误返回给应用程序。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Netflix：讨论了他们使用混沌工程基础设施发现的几个错误。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;错误配置的超时，某个服务调用不正确配置，导致请求花费比预期更长的时间，但保持在超时间隔内。&lt;/li&gt;
&lt;li&gt;服务配置了回退指向错误的服务。&lt;/li&gt;
&lt;li&gt;关键的为服务没有配置回退。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;架构概述&#34;&gt;架构概述&lt;/h2&gt;
&lt;p&gt;SFIT 采用开发人员优先的方法，尽早将故障注入测试集成到开发过程中，而无需开发人员使用特定的规范语言编写规范。&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;SFIT 建立在开发微服务应用程序的以下三个关键点上。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;微服务独立开发：由于微服务之间可以通过约定的API进行通信，负责其他模块的个别团队成员通常不能很好地理解超出其控制范围的服务的状态或内部结构，无法编写应用程序的详细规范以使用模型检查器自动验证它。&lt;/li&gt;
&lt;li&gt;Mock测试可以防止问题出现：虽然编写模拟测试可以查出一些问题，但是由于这费时费力，对开发来说效益太少，所以开发人员很少进行测试。&lt;/li&gt;
&lt;li&gt;功能测试的重要性：开发人员编写多个验证应用程序行为的端到端功能测试，而不是编写规范。任何成功的故障注入方法都应该从功能测试开始。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;sfit的实现思路&#34;&gt;SFIT的实现思路&lt;/h3&gt;
&lt;p&gt;基于上述三个关键点及下面的两个简单假设：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;服务通过HTTP进行通信。&lt;/li&gt;
&lt;li&gt;一个单一的功能测试可以实现所有应用程序行为。&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;测试流程概述&#34;&gt;测试流程概述&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;假设从一个通过的功能测试开始，该测试由开发人员编写，在一些未失败的场景下执行应用程序，并验证一些应用程序行为。我们假设通过测试已经排除了逻辑错误。&lt;/li&gt;
&lt;li&gt;在该测试点注入故障。如果请求出现多种错误，则为每一个错误安排一次测试。这些后续执行被放置在堆栈上，并递归地应用该策略，直到所有路径都被探索。这种算法的灵感来自于DART的concolic测试算法[28]。&lt;/li&gt;
&lt;li&gt;以Audible App的例子来说，第一个请求发现内容分发服务出现了&lt;em&gt;Timeout or ConnectionError&lt;/em&gt;。然后我们向堆栈中追加两次测试执行。&lt;/li&gt;
&lt;li&gt;接着对内容分发服务进行堆栈中的测试，如果测试中暴露出新的问题，就可以寻找新的错误路径，内容交付引擎的故障可能会导致另一条路径暴露给日志服务。我们继续探索，直到所有的道路都被充分探索。（如：内容交付引擎的故障可能是由于日志服务暴露出的问题，因此搜索到日志服务路径。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;在本例中，多个服务具有相互依赖关系；例如，音频下载服务与所有权服务、激活服务和统计服务对话。在这种情况下，我们必须安排覆盖整个失败空间的执行——每个服务可能独立失败的所有方式，以及由于微服务相互影响而导致失败的所有组合。在第4节中，我们将讨论如何减少冗余的路径搜索。&lt;/p&gt;
&lt;p&gt;此外，在进行故障注入测试时，需要根据故障情况调整功能测试。为此作者开发了帮助组件使得开发者可以编写条件断言来判断错误的出现。还提供了一个机制来重现错误。&lt;/p&gt;
&lt;h4 id=&#34;故障注入&#34;&gt;故障注入&lt;/h4&gt;
&lt;p&gt;该注入方法可以对远程调用继续注入，并通过远程库改变响应。例如一些HTTP、gRPC的库。故障注入的设计思路如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;不返回远程服务的实际响应&lt;/li&gt;
&lt;li&gt;基于注入的故障返回故障响应（通过修改远程服务响应）&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;故障识别&#34;&gt;故障识别&lt;/h4&gt;
&lt;p&gt;故障识别主要包含&lt;strong&gt;识别具体的故障&lt;/strong&gt;和&lt;strong&gt;识别故障发生于哪一个微服务&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;注入的故障类型都源自于微服务可能发生的故障类型。通常有以下两种错误：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;服务调用端故障。如Python的&lt;em&gt;request&lt;/em&gt;库在发出请求时会有23中意外情况。可以通过指定包含异常的模块或者配置中手动指定这些问题，依此识别故障。这里作者将该类请求中的&lt;em&gt;Timeout&lt;/em&gt;和&lt;em&gt;ConnectionError&lt;/em&gt;作为主要考虑的错误类型。&lt;/li&gt;
&lt;li&gt;被调用端故障。被调用的服务也可能返回一个错误响应。例如一个服务依赖的另一个微服务抛出了&lt;em&gt;Timeout&lt;/em&gt;，那这个服务就可能返回&lt;em&gt;500&lt;/em&gt;。作者通过对程序源码使用静态分析技术对类似的响应进行识别。例如在Flask框架中查找&lt;em&gt;return&lt;/em&gt;或&lt;em&gt;raise&lt;/em&gt;语句。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;但还存在一个问题：在使用HTTP做请求时，&lt;strong&gt;请求的URL并不能作为识别服务本体的标识&lt;/strong&gt;。为解决这个问题，使用额外的工具记录调用的服务。该工具放置在接收服务请求的Web框架上，因此可以在被调用之前记录被调用者的服务信息。在获取该被调用者的信息后，将信息传给中台，以便进行后续的测试。&lt;/p&gt;
&lt;h4 id=&#34;注入故障后对功能的调整&#34;&gt;注入故障后对功能的调整&lt;/h4&gt;
&lt;p&gt;开发者需要根据故障注入的结果去调整功能，修复没有考虑到的问题。作者提供了一个帮助模块去编写故障断言，例如：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;a&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;fault&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;was&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;injected&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;on&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;Service&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;A&lt;/span&gt; {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#f92672&#34;&gt;...&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;对系统行为在失败的情况下进行捕获和处理。开发人员应将这些条件断言添加到现有的功能测试中。&lt;/p&gt;
&lt;p&gt;一个典型的流程如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;开发者进行功能测试并通过。&lt;/li&gt;
&lt;li&gt;注入故障&lt;/li&gt;
&lt;li&gt;原有的功能测试因为故障的注入出现问题&lt;/li&gt;
&lt;li&gt;开发者通过提供的帮助工具，可以对新出现的故障进行断言，从而捕获因故障注入出现的故障。例如：Audible会报出&lt;code&gt;if a fault was injected on the stats ser- vice, the service should still play the audiobook.&lt;/code&gt;。基于此，开发者可以使用反例来重现先前的测试，以证明这些断言。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;故障搜索路径动态缩减&#34;&gt;故障搜索路径动态缩减&lt;/h2&gt;
&lt;p&gt;为了识别尽可能多的错误，必须理想地探索服务失败的组合。为了实现故障空间的最大覆盖所需的测试执行次数是非常多的。&lt;/p&gt;
&lt;p&gt;但是，可将应用分解成多个独立的微服务来显著减少搜索空间并且保证完整性。以下图为例：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lizonglin313/MyPicGo/master/image-20220224122453207.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220224122453207&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;对于ads服务&#34;&gt;对于ADS服务&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;先只考虑服务子集的故障，如ADS下载服务和CDS内容分发服务以及他们的依赖项。&lt;/li&gt;
&lt;li&gt;对于ADS可能产生的故障，需要考虑三种依赖类别：
&lt;ol&gt;
&lt;li&gt;Ownership：验证某个用户是否拥有某本书的所有权；&lt;/li&gt;
&lt;li&gt;Activation：验证用户的请求；&lt;/li&gt;
&lt;li&gt;Stats：对本次事件改变的状态进行记录；&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;如果上面三个依赖服务中的任何一个出现失败，那么ADS服务就会返回错误。但需要注意，Stats的失败不会影响这次请求的结果（因为“where stats failures are ignored”）。&lt;/li&gt;
&lt;li&gt;因此，Ownership和Activation的失败会导致ADS返回&lt;em&gt;500&lt;/em&gt;，但Stats的失败不会影响ADS，如果Ownership和Activation成功而Stats失败，ADS仍返回&lt;em&gt;200&lt;/em&gt;。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;对于cds服务&#34;&gt;对于CDS服务&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;CDS服务依赖的微服务子集是Asset Metadata和Audio Assets，我们需要考虑这两个服务会发生的故障以及他们组合起来会发生的故障。&lt;/li&gt;
&lt;li&gt;但是，由于ADS的请求URL&lt;code&gt;/user/&amp;lt;uesr_id&amp;gt;/books/&amp;lt;book_id&amp;gt;&lt;/code&gt;与Stats的URL相同，又因为CDS服务依赖于ADS服务，所以也应当将Stats服务考虑进去。&lt;/li&gt;
&lt;li&gt;所以实际包含的CDS子服务应是：Asset Metadata+Audio Asset+Stats。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;三条准则&#34;&gt;三条准则&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;充分考虑服务依赖项的所有失败方式，让我们知道每个服务和多个依赖服务失败时会发生什么行为，返回什么结果。&lt;/li&gt;
&lt;li&gt;我们需要明确将故障注入后会对服务产生什么样的影响，并依据此简化注入。例如我们已经知道CDS的某个依赖项在发生错误时会返回&lt;em&gt;500&lt;/em&gt;，那么就可以直接在CDS中注入&lt;em&gt;500&lt;/em&gt;错误响应。&lt;/li&gt;
&lt;li&gt;如果已经在服务中注入了故障，那么就不用进行测试了，因为已经观察到了程序的行为。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;动态缩减算法&#34;&gt;动态缩减算法&lt;/h3&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;该算法将测试的搜索空间指数级缩小，基本思路是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;缩减前：数量级是&lt;strong&gt;服务请求总数&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;缩减后：数量级变成&lt;strong&gt;给定服务最大能发出的请求数&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;具体来说如图2：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;缩减前：最大有8条边需要处理，整个应用有8个请求路径&lt;/li&gt;
&lt;li&gt;缩减后：最大仅需要处理3条边，因为ADS是依赖项最多的服务，有3个请求发送路径&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;另外依据的一个前提是，&lt;strong&gt;微服务调用链拓扑结构上深度优先比广度优先更为明显&lt;/strong&gt;。&lt;/p&gt;
&lt;h2 id=&#34;原型实现filibuster&#34;&gt;原型实现：Filibuster&lt;/h2&gt;
&lt;p&gt;使用Python及相关的开源组件，如使用opentelemetry来实现请求链路追踪、识别服务依赖关系。&lt;/p&gt;
&lt;h3 id=&#34;组件功能&#34;&gt;组件功能&lt;/h3&gt;
&lt;p&gt;系统的组件可以实现服务请求识别、服务依赖关系分析，并于Filibuster通信。服务器负责在本地进程、Docker Compose 或 Kubernetes 中启动与应用程序关联的所有服务。&lt;strong&gt;运行功能测试、记录和维护要执行的测试执行堆栈、执行功能测试断言、报告测试失败并聚合测试覆盖率&lt;/strong&gt;。服务器提供了一个 API，&lt;strong&gt;功能测试可以使用该 API 来编写条件断言，并使用反例文件允许测试重放&lt;/strong&gt;。测试覆盖率由服务器从每个单独的服务中聚合而成。&lt;/p&gt;
&lt;h3 id=&#34;静态分析&#34;&gt;静态分析&lt;/h3&gt;
&lt;p&gt;Filibuster需要进行静态分析，以识别每个服务可以返回的错误类型。&lt;strong&gt;作者使用词法分析技术，遍历源代码的抽象语法树来识别错误&lt;/strong&gt;。Flask中的&lt;em&gt;raise&lt;/em&gt;语句可以被分析道，然后捕获这些语句要发送的HTTP错误响应及状态码。&lt;/p&gt;
&lt;h3 id=&#34;注入故障&#34;&gt;注入故障&lt;/h3&gt;
&lt;p&gt;Filibuster可以注入下面类型的故障；&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;调用端异常：这些异常由&lt;em&gt;request&lt;/em&gt;库抛出，如指示&lt;code&gt;Timeout&lt;/code&gt;的等错误。&lt;/li&gt;
&lt;li&gt;响应异常：来自被调用端返回异常。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;应用语料库&#34;&gt;应用语料库&lt;/h2&gt;
&lt;p&gt;一个包含8种变体示例的电影订票程序，每个示例都展示了微服务应用程序中观察到的特定模式。还有 4 个行业示例：Audible、Expedia、Mailchimp 和 Netflix。&lt;/p&gt;
&lt;p&gt;每个示例都包含单元测试以及验证应用程序功能行为的功能测试。这些示例可以在Docker或K8s环境中运行。&lt;/p&gt;
&lt;h3 id=&#34;电影院订票应用示例&#34;&gt;电影院订票应用示例&lt;/h3&gt;
&lt;p&gt;该应用由4个微服务组成：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Showtimes: returns the show times for movies;&lt;/li&gt;
&lt;li&gt;Movies: returns information for a given movie;&lt;/li&gt;
&lt;li&gt;Bookings: given a username, returns information about the bookings for that user;&lt;/li&gt;
&lt;li&gt;Users: 存储用户信息并处理用户订票请求，并在过程中为用户展示电影信息。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;它的另外7个变体有：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;bookings talks directly to the movies;&lt;/li&gt;
&lt;li&gt;same as 1, but the users service has a retry loop around its calls to the bookings service;&lt;/li&gt;
&lt;li&gt;same as 1, but each service talks to &lt;strong&gt;an external service before issuing any requests&lt;/strong&gt;, the users service makes a request to IMDB, the bookings service makes a request to Fandango, the movies service makes a request to Rotten Tomatoes;&lt;/li&gt;
&lt;li&gt;all requests happen regardless of failure; in the event of failure, a hardcoded, default, response is used;&lt;/li&gt;
&lt;li&gt;adds a second replica of bookings, that is contacted in the event of failure of the primary replica;&lt;/li&gt;
&lt;li&gt;same as 5, but the users service makes a call to a health check endpoint on the primary bookings replica before issuing the actual request;&lt;/li&gt;
&lt;li&gt;example is collapsed into monolith（单体结构） where an API server makes requests to the it with a retry loop.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;工业级应用&#34;&gt;工业级应用&lt;/h3&gt;
&lt;h4 id=&#34;audible&#34;&gt;Audible&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lizonglin313/MyPicGo/master/image-20220224122453207.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220224122453207&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;架构如上图2所示。包含如下服务：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Content Delivery Service (CDS):
&lt;ul&gt;
&lt;li&gt;IN： book_id 和 user_id&lt;/li&gt;
&lt;li&gt;OUT：（在验证之后） 音频内容和元数据&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Content Delivery Engine (CDE):
&lt;ul&gt;
&lt;li&gt;IN： book_id 和 user_id&lt;/li&gt;
&lt;li&gt;OUT：相关CDS的URL&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Audible App：模拟移动应用
&lt;ul&gt;
&lt;li&gt;首先向CDE请求获得内容的URL&lt;/li&gt;
&lt;li&gt;再根据URL请求CDS&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Audible Download Service: 鉴权、授权并记录日志
&lt;ul&gt;
&lt;li&gt;IN： book_id 和 user_id&lt;/li&gt;
&lt;li&gt;OUT：权限鉴别结果&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Ownership: 验证读者对图书的所有权
&lt;ul&gt;
&lt;li&gt;IN：book_id 和 user_id&lt;/li&gt;
&lt;li&gt;OUT：鉴权结果&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Activation：为用户激活DRM许可证
&lt;ul&gt;
&lt;li&gt;IN：book_id&lt;/li&gt;
&lt;li&gt;OUT：DRM Access&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Stats：记录读者和图书许可的信息
&lt;ul&gt;
&lt;li&gt;IN：book_id 和 user_id&lt;/li&gt;
&lt;li&gt;OUT：记录结果&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Asset Metadata：存储音频元数据，如章节信息
&lt;ul&gt;
&lt;li&gt;IN：book_id 和 license&lt;/li&gt;
&lt;li&gt;OUT：检索到的音频XML信息&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Audio Assets：提供音频存储服务
&lt;ul&gt;
&lt;li&gt;IN：book_id 和 license&lt;/li&gt;
&lt;li&gt;OUT：检索到的音频文件&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;作者在实际部署上进行了一些调整：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Asset Metadata和Audio Assets是 AWS S3 存储桶。为了模拟这一点创建 HTTP 服务，如果可用，则返回包含资产的 200 OK，如果资产不存在，则返回 404 Not Found。&lt;/li&gt;
&lt;li&gt;Ownership和Activation是 AWS RDS 实例。为了模拟这一点创建了实现 REST 模式的 HTTP 服务：如果用户不拥有该书，则返回 403 Forbidden，如果该书不存在，则返回 404 Not Found，否则返回 200 OK。&lt;/li&gt;
&lt;li&gt;Stats 服务是一个 AWS DynamoDB 实例。为了模拟这一点，我们创建了一个返回 200 OK 的 HTTP 服务。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;对于功能测试的尝试是为用户下载有声读物的测试。如果缺少图书的章节信息，Asset Metadata可以返回 404 Not Found 响应：这是 Audible 演示中讨论的错误，会导致在移动应用程序中向用户显示一般错误。&lt;/p&gt;
&lt;h4 id=&#34;expedia&#34;&gt;Expedia&lt;/h4&gt;
&lt;p&gt;包含如下三个微服务：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Review ML：按相关性顺序返回评论&lt;/li&gt;
&lt;li&gt;Review Time：按时间顺序返回评论&lt;/li&gt;
&lt;li&gt;API Gateway：根据服务可用性，从 Review ML 或 Review Time 将评论返回给用户&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;mailchimp&#34;&gt;Mailchimp&lt;/h4&gt;
&lt;p&gt;包含五个微服务：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Requestmapper：将电子邮件活动中的 URL 映射到实际资源&lt;/li&gt;
&lt;li&gt;DB Primary：数据库的主要副本&lt;/li&gt;
&lt;li&gt;DB Secondary：数据库次要副本&lt;/li&gt;
&lt;li&gt;App Server：向 Requestmapper 服务发出请求以解析 URL，然后对数据库执行读后写请求，并在主数据库不可用的情况下回退到辅助数据库副本&lt;/li&gt;
&lt;li&gt;Load Balancer：对请求进行负载均衡&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;同样的，在实际部署时做出一些调整：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;DB Primary 和 Secondary 服务是 MySQL 实例。为了模拟这一点创建一个 HTTP 服务，该服务要么在成功读取或写入时返回 200 OK，要么在数据库为只读时返回 403 Forbidden。&lt;/li&gt;
&lt;li&gt;负载均衡器服务是一个 HAProxy 实例。为了模拟这一点创建一个 HTTP 代理做负载均衡。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;故障信息有两个：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;MySQL instance is read-only：当 MySQL 实例为只读时，数据库会返回一个在代码的一个区域中未处理的错误。由于 Mailchimp 使用 PHP，这个错误会直接呈现到页面的输出中，我们通过将 403 Forbidden 响应转换为直接插入页面的输出来模拟这一点。&lt;/li&gt;
&lt;li&gt;Requestmapper is unavailable：当 Requestmapper 服务不可用时，App Server 无法正确处理错误，向负载均衡器返回 500 Internal Server Error。但是，负载均衡器仅配置为通过返回格式化的错误页面来处理 503 Service Unavailable 错误。&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;netflix&#34;&gt;Netflix&lt;/h4&gt;
&lt;p&gt;包含十个微服务。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Client：模拟移动客户端&lt;/li&gt;
&lt;li&gt;API Gateway：展示用户主页&lt;/li&gt;
&lt;li&gt;User Profile：返回用户信息&lt;/li&gt;
&lt;li&gt;Bookmarks：返回最后查看的位置&lt;/li&gt;
&lt;li&gt;My List：返回用户的电影列表&lt;/li&gt;
&lt;li&gt;User Recs.：返回用户推荐的电影&lt;/li&gt;
&lt;li&gt;Ratings：返回用户的评分&lt;/li&gt;
&lt;li&gt;Telemetry： 记录日志信息&lt;/li&gt;
&lt;li&gt;Trending：返回电影观看趋势&lt;/li&gt;
&lt;li&gt;Global Recs.：返回推荐电影&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;对于功能测试，我们有一个尝试为用户加载 Netflix 主页的功能测试。&lt;/p&gt;
&lt;p&gt;故障信息有三个：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Misconfigured timeouts：User Profile服务以 10 秒的超时时间调用日志服务；但是，API Gateway会以 1 秒的超时时间调用用户配置文件服务。&lt;/li&gt;
&lt;li&gt;Fallbacks to the same server：如果我My List服务不可用，系统将重试。&lt;/li&gt;
&lt;li&gt;Critical services with no fallbacks：User Profile服务没配置回退。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;实验评估&#34;&gt;实验评估&lt;/h2&gt;
&lt;p&gt;在具有 15 GB 内存和 8 个 vCPU 的 AWS CodeBuild 实例上运行了所有示例。在 Filibuster 运行开始时，启动了每个示例的所有服务，等待这些服务上线并在测试结束时终止它们，不会在测试执行之间重新启动服务。&lt;/p&gt;
&lt;h3 id=&#34;tests-generated-and-increased-coverage&#34;&gt;Tests Generated and Increased Coverage&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Test Gen/DR Gen：表示 Filibuster 生成和执行的测试数量。由于每个示例只有一个功能测试，因此这些数字包括该测试的总数，因为 Filibuster 必须首先执行初始通过的功能测试，以确定在哪里注入故障。在语料库中包含错误的所有示例中，可以使用Filibuster 识别错误。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Coverage After：表示报表覆盖率的增加。通过生成涵盖可能故障的测试，我们能够增加应用程序的覆盖率。这些数字仅用于功能测试。生成的测试增加了与未经修改的功能测试未执行的错误处理代码相关的覆盖率。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Time w/DR：表示启用动态缩减的执行时间。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;TG Overhead：表示生成测试的总开销时间。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lizonglin313/MyPicGo/master/image-20220224182652863.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220224182652863&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;dynamic-reduction&#34;&gt;Dynamic Reduction&lt;/h3&gt;
&lt;p&gt;当应用程序以服务图的深度而不是广度的方式构建时，应用程序可以从动态缩减中显着受益，例如Audible就是服务调用关系具有一定的深度。&lt;/p&gt;
&lt;h3 id=&#34;mocks&#34;&gt;Mocks&lt;/h3&gt;
&lt;p&gt;实现语料库时，作者为每个示例中的每个服务编写了单元测试，使用模拟来解释可能的远程服务故障。 在编写这些测试时，只测试了独立的故障。&lt;/p&gt;
&lt;p&gt;如图 2 的 Audible 下载服务，其单元测试包含一个模拟三个依赖项的失败：Ownership、Active和State。在这里省略了服务特定故障的列表，请读者参考图表获取列表。&lt;/p&gt;
&lt;p&gt;同时为&lt;em&gt;Timeout&lt;/em&gt;和&lt;em&gt;ConnectionError&lt;/em&gt;这两个异常分别编写了一个模拟。&lt;/p&gt;
&lt;h2 id=&#34;不足和未来工作&#34;&gt;不足和未来工作&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;语料库中的示例用HTTP 服务取代了真实云服务和数据库的使用，但在实际生产环境中，服务间的通信方式还包括如gRPC等多种服务通信。作者已经开始努力通过 gRPC 支持和对 AWS DynamoDB 和 AWS RDS 等云服务的支持来扩展系统原型。&lt;/li&gt;
&lt;li&gt;该设计不考虑服务响应的损坏，而是关注假设的响应或指示失败的响应。&lt;/li&gt;
&lt;li&gt;系统中将返回错误码就看作请求失败，但是在生产环境中，往往对一些错误响应会给出处理。在某些情况下，可能会提示开发人员编写异常处理程序和其他条件错误处理，以处理实际上可能不会在生产中发生的故障。&lt;/li&gt;
&lt;li&gt;动态缩减在微服务依赖呈现更大的调用深度时表现更好，广度更大时难以起到明显的作用。&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>SHOWAR: Right-Sizing And Efficient Scheduling of Microservices</title>
        <link>https://lizonglingo.github.io/p/showar-right-sizing-and-efficient-scheduling-of-microservices/</link>
        <pubDate>Tue, 22 Feb 2022 13:45:25 +0800</pubDate>
        
        <guid>https://lizonglingo.github.io/p/showar-right-sizing-and-efficient-scheduling-of-microservices/</guid>
        <description>&lt;blockquote&gt;
&lt;p&gt;来源：ACM SoCC&#39;21&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://acmsocc.org/2021/accepted-papers.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://acmsocc.org/2021/accepted-papers.html&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;概述&#34;&gt;概述&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;解决了什么问题：提出一个微服务资源调度框架，解决微服务的调度问题，具体来说从&lt;strong&gt;水平扩缩容——增减服务实例&lt;/strong&gt;和&lt;strong&gt;垂直扩缩容——控制每个服务CPU和内存等资源的配额&lt;/strong&gt;两个维度对微服务进行调度&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;适用于什么环境：该资源调度框架应用于&lt;strong&gt;使用K8s部署的微服务&lt;/strong&gt;上&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;实验的实施和结果：&lt;strong&gt;使用多个微服务应用和现实世界中的负载情况进行实验&lt;/strong&gt;，资源利用表现提高22%，用户端到端实验降低20%&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;目标和宗旨：找到一个最佳资源分配大小，&lt;strong&gt;保持良好服务质量的同时尽可能提高资源利用率&lt;/strong&gt;，减少资源配额&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;微服务调度存在的问题和挑战&#34;&gt;微服务调度存在的问题和挑战&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;确定微服务应用对资源的需求是个复杂工作，难以预先确定&lt;/li&gt;
&lt;li&gt;如果分配过多的资源会造成集群资源利用率低，增加开销&lt;/li&gt;
&lt;li&gt;分配资源过少则导致服务性能下降甚至服务不可用，带来更严重的问题&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;贡献&#34;&gt;贡献&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;垂直和水平扩缩容框架，旨在提高资源分配的效率&lt;/li&gt;
&lt;li&gt;调度亲和性和反亲和性规则，为K8s调度程序生成更好的微服务调度规则，提高调度效率&lt;/li&gt;
&lt;li&gt;实现上述要点并评估&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;设计思路&#34;&gt;设计思路&lt;/h2&gt;
&lt;h3 id=&#34;概述-1&#34;&gt;概述&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;垂直扩缩容：参照&lt;strong&gt;历史资源利用率&lt;/strong&gt;来寻找每个微服务的最佳资源配额，调度的资源是每个服务占用的CPU、RAM、Disk等资源&lt;/li&gt;
&lt;li&gt;水平扩缩容：使用Linux内核线程调度程序队列的指标（如&lt;strong&gt;eBPF runq latency&lt;/strong&gt;）为扩缩容指标，同时利用控制理论的思想，在微服务运行时对实例数量进行控制。并设计了一个&lt;em&gt;proportional-integral-derivative&lt;/em&gt;控制器，利用历史扩缩容操作和当前的运行时状态来做出下一个水平扩缩容决策，并保持服务的稳定，调度的资源是增减服务实例数量&lt;/li&gt;
&lt;li&gt;服务间依赖：同时考虑了&lt;strong&gt;服务间依赖关系&lt;/strong&gt;，优先调度应用中负载压力大的微服务（如某个微服务作为其他微服务的引用）&lt;/li&gt;
&lt;li&gt;服务性能：在找到一个最佳配额后，会协助集群调度微服务以获得更好的端到端性能&lt;/li&gt;
&lt;li&gt;K8s亲和性与反亲和性：通过不同微服务的历史资源使用情况为K8s生成调度规则（如某种微服务和某类资源有正相关性或负相关性）&lt;/li&gt;
&lt;li&gt;调度效率：能够快速适应工作负载变化&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;垂直扩缩容&#34;&gt;垂直扩缩容&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;调度依据指标：实例的历史资源使用情况（CPU、RAM、Disk、Network等）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;需要达成的效果有：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在运行时为服务找到合适的资源需求&lt;/li&gt;
&lt;li&gt;最大限度减少过度配置导致的资源使用松弛（松弛度=资源配额-资源使用量）&lt;/li&gt;
&lt;li&gt;最大限度减少OOM错误和CPU负载过高的情况，保证服务质量&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;垂直扩缩容的局限：每个实例的资源占有量最大不会超过虚拟机的资源量，所以某些情况下即使将虚拟机的所有资源都给到实例也难以满足要求，这就需要水平扩缩容&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;水平扩缩容&#34;&gt;水平扩缩容&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;调度依赖指标：eBPF指标数据&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;eBPF：允许在内核级别允许安全和低开销的程序，从内核级别收集准确的事件信息，如CPU调度程序决策事件、内存分配事件和网络堆栈中的数据包事件。已经被广泛用于微服务检测、性能提升、链路追踪、负载均衡、网络监控和安全中。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;具体思路&#34;&gt;具体思路&lt;/h3&gt;
&lt;h4 id=&#34;垂直自动扩缩容&#34;&gt;垂直自动扩缩容&lt;/h4&gt;
&lt;p&gt;K8s（Google Autopilot也是类似）通过检测一段时间窗口（几分钟到几天）中的CPU和内存使用量来设置下一个事件窗口中的资源。通过一个&lt;code&gt;margin&lt;/code&gt;和观测到的如P95、P99的百分位值，目的是为资源增加一些宽裕度，尽可能减少OOM错误和CPU不够用的情况发生。&lt;strong&gt;作者认为这还不够节约，存在资源浪费的情况发生&lt;/strong&gt;。$\alpha$为宽限额度，$\pi$是某个测量的百分位数值。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lizonglin313/MyPicGo/master/20220221103059.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;而SHOWAR使用“three-sigma”经验法则去分配资源&lt;/strong&gt;。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;SHOWAR收集持续时间W秒的最后一个窗口的每种资源使用的统计数据，每秒收集一次，用于递归计算该窗口上的资源使用平均值$\mu$和方差$\sigma^2$。&lt;/li&gt;
&lt;li&gt;计算$s=\mu + 3\sigma$，这里$s$就是特定资源的一个估计量&lt;/li&gt;
&lt;li&gt;然后每经过T秒（T &amp;laquo; W）评估资源使用量是否发生了很大的变化（如超过15%），一旦超过预期值就实施资源重新分配。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lizonglin313/MyPicGo/master/20220221104502.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;作者认为使用百分数值的3-σ法则能在保证服务良好运行的情况下最大限度的减少资源浪费，同时使用一个阈值来决定是否进行资源重新分配操作能在资源使用差异较小时不会过度配置资源。虽然$\mu+3\sigma$和$\pi(1+\alpha)$都有明确的统计解释，但是使用$3\sigma$可以更加准确的看到均值的分布。如果方差非常小，则分布几乎是恒定的，这是关于 Pod 资源使用情况的单独有用信息。然而，在$\pi(1+\alpha)$方法中，当方差非常小时，尾部百分位数不能传达有用的信息。此外，安全宽裕度参数 $\alpha$的选择可能是任意的，如果未正确指定，可能会导致资源利用率低下或更多OOM错误。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;关于P90、P95等百分位数值的补充资料：https://www.cnblogs.com/hunternet/p/14354983.html&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&#34;水平自动扩缩容&#34;&gt;水平自动扩缩容&lt;/h4&gt;
&lt;p&gt;水平自动扩缩容目前存在一些缺陷：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;由于水平扩缩容的主要形式是通过增减服务实例数量来调整资源分配，服务实例在遇到负载激变发生资源使用抖动时，可能导致极端过度配置或者配置严重不足。为了解决这种情况，有些自动缩放策略引入冷却期的概念，在最后一次操作之后的一段时间内不进行扩缩容。如果出现瞬时负载峰值过高的情况也会因为处于冷却期而避免不必要的扩容操作。&lt;/li&gt;
&lt;li&gt;系统不会将系统微服务的依赖关系考虑在内，而是单独处理某个微服务。实践表明在不考虑微服务相关性的前提下的资源分配和缩放效率低下，并且不一定有助于应对负载变化和保证服务质量。如下图对某个后端服务在5s时注入高负载，然后经过一段时间，后端的高延迟情况传到了前端，如果考虑微服务间依赖关系，那么仅扩容后端微服务就可以解决这个问题。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lizonglin313/MyPicGo/master/20220221112213.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;以往通常使用CPU利用率作为缩放指标，力求在所有微服务中保持目标 CPU 利用率。但CPU 利用率并不是自动缩放和资源分配的最有效指标，随着负载的增加，几乎所有微服务的 CPU 利用率都会增加，而上图的前端微服务的尾部延迟并不总是随着 CPU 利用率的增加而增加（主要是由于后端微服务的高延迟导致的）。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;SHOWAR旨在解决上述问题，使用控制理论基本框架来设计有状态的水平缩放系统，在满足SLO指标下保证服务稳定。&lt;/p&gt;
&lt;p&gt;通过观测值与目标值的差别来控制缩放是不准确的：$e=observation-target$​​，为此作者设计了更复杂的控制器&lt;em&gt;pro-portional–integral–derivative (PID) controller&lt;/em&gt;：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lizonglin313/MyPicGo/master/20220221113150.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;对资源的检测使用我们使用&lt;strong&gt;eBPF Linux&lt;/strong&gt;调度程序&lt;strong&gt;runq 延迟度量&lt;/strong&gt;，它表示线程可运行与获取CPU并运行之间的时间。使用Runq延迟的P95作为目标点。&lt;strong&gt;与CPU利用率不同，高runq延迟与每个单独的微服务的高请求尾延迟高度相关，这表明runq延迟可以用作水平自动缩放的合适指标，以防止请求延迟增加。直观地说，runq延迟优于CPU利用率的原因是它表明应用程序线程如何竞争CPU资源，因此需要更多（或更少）的CPU资源&lt;/strong&gt;。在SHOWAR中，使用者要指定目标runq的延迟值作为配置的一部分。&lt;/p&gt;
&lt;p&gt;水平扩缩容的传递函数很简单，如果runq超出目标值，则系统必须向外扩展并增加副本数量，反正小于目标值则缩减服务实例（这里目标是是一个范围？我是这么认为的）。为了防止执行过多的自动缩放操作以响应 runq 延迟指标中的快速变化和瞬时突发性，作者在目标周围设置了一个可配置的界限$\alpha%$​​（默认为 20%）作为缓冲区并且不执行自动缩放操作。自动缩放的增加或减少量是微服务当前副本数量的可配置 𝛽 百分比（默认为 10%），如果实际缩放副本数小于1则默认是1（我的理解是，如该实例有20个副本，则扩容20×0.1=2个副本，如果是4个副本4×0.1=0.4&amp;lt;1即扩容1个副本）。算法如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lizonglin313/MyPicGo/master/20220221120450.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;水平自动扩缩容的两种架构：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;One For All：单个控制器负责自动扩展所有微服务类型。在每个自动缩放决策中，所有微服务都会根据所有微服务中当前度量值观察的平均值一次缩放。虽然这种方法受益于 PID 控制器，但它没有考虑微服务的微服务依赖关系图。&lt;/li&gt;
&lt;li&gt;One For Each：控制器负责每个微服务。每个控制器监控其相应微服务的自动缩放指标runq，根据上述算法进行缩放。控制器输出的绝对值被排序，具有最高值（最大扩展需求）的那些被优先考虑。对于相等的控制器输出，我们会考虑微服务的依赖关系图，并将后端服务优先于依赖的前端服务（在图的拓扑排序之后）。&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;将二者串联&#34;&gt;将二者串联&lt;/h4&gt;
&lt;p&gt;在K8s等部署平台上推荐的方法是：一次部署仅使用一类缩放器（如为每个微服务确定固定的实例数量的前提下，部署垂直缩放器，自动调整每个实例的资源分配量；或是确定好资源分配量后，令服务通过水平缩放器自动进行实例数量的增减）。&lt;/p&gt;
&lt;p&gt;SHOWAR通过允许串联部署这二者。首先，作者将任何垂直自动缩放决策优先于任何水平自动缩放决策。因为，例如在内存自动缩放的情况下，如果 Pod 的内存不足，应用程序会遇到OOM错误并停止执行，而不管其副本数如何，所以水平自动缩放器无法解决OOM问题。因此，在水平自动缩放控制器动作之前，它首先检查共享通道以查看该微服务是否正在进行垂直自动缩放，如果是则不会继续操作。类似地，在垂直Pod自动缩放器动作之前，它会通过共享通道发送消息通知水平自动缩放器，然后执行其操作。&lt;/p&gt;
&lt;p&gt;此外，由于谷歌云平台的 Kubernetes 最佳实践，建议大多数 Pod 不需要超过一个核心，作者根据这个建议将其合并到 SHOWAR 的垂直自动缩放器设计中：如果垂直自动缩放器决定为 Pod 设置多个核心，它会改为通过共享通道向水平自动缩放器发出信号，并且不会继续执行垂直自动缩放操作。即：核心数增加转化为实例数量增加。&lt;/p&gt;
&lt;h4 id=&#34;利用k8s亲和性和反亲和性获取更好的调度性能&#34;&gt;利用K8s亲和性和反亲和性获取更好的调度性能&lt;/h4&gt;
&lt;p&gt;关于K8s的亲和性和反亲和性可以概括为：服务𝑆2与服务𝑆1的亲和性意味着调度程序将始终（或最好）尝试将服务 𝑆1 的 Pod 调度到服务 𝑆2 所在的节点上。类似地，服务𝑆2与服务𝑆1的反亲和性意味着调度程序永远不会（或最好不）这样做。&lt;/p&gt;
&lt;p&gt;SHOWAR监控和使用微服务的历史（即最后（可配置）时间窗口）CPU、内存和网络使用情况，并计算每对微服务使用模式之间的Paerson相关系数来计算相关性：给定两种微服务类型𝑋和𝑌的CPU（或内存或网络I/O）使用分布，𝑋和𝑌之间的相关系数$\rho$​为：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lizonglin313/MyPicGo/master/20220222104614.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;对于两个微服务𝑆1和𝑆2，资源使用模式（例如CPU或内存）的正相关性越高，它们之间对该资源的资源争用就越高。同样，负相关越低，两个服务之间对该资源的争用就越低。这是 SHOWAR 对 CPU、内存和网络 I/O 等计算资源的亲和性和反亲和性规则的简单基础。&lt;/p&gt;
&lt;p&gt;进一步产生亲和性和反亲和性规则，规则生成机制如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;CPU和NetWork：如果两个服务s1、s2的CPU和网络是用呈现强负相关（$\rho_{s1s2}\leq-0.8$​​​​​）,则为其生成亲和性规则。&lt;/li&gt;
&lt;li&gt;Memeory：如果任何一对微服务s1和s2在它们的内存使用模式中具有强正相关（例如$\rho_{s1s2}\geq-0.8$​），则SHOWAR 为调度程序生成s1和s2的反亲和性规则。(实际上也是负相关$\Longrightarrow$亲和性)。&lt;/li&gt;
&lt;li&gt;此外，为避免调度冲突，每个微服务在任意时间最多参与一个亲和性或反亲和性规则。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;实现&#34;&gt;实现&lt;/h2&gt;
&lt;h3 id=&#34;系统架构&#34;&gt;系统架构&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lizonglin313/MyPicGo/master/20220222110542.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;monitoring-agents&#34;&gt;Monitoring Agents&lt;/h3&gt;
&lt;p&gt;使用Prometheus从节点和容器收集不同的指标。通过集群中的每个节点上启动一个监控代理来收集容器指标，例如CPU使用率、内存使用率、网络带宽使用率等。代理被配置为每秒收集和报告一次指标。Prometheus附带一个时间序列数据库，代理存储收集到的指标。此外，还提供了一种查询语言来查询其他模块使用的时间序列数据库以利用收集的指标。&lt;/p&gt;
&lt;p&gt;此外作者还开发了一个eBPF程序作为监控代理部署在集群中的每个节点上，以收集水平自动缩放器使用的 &lt;em&gt;runq latency&lt;/em&gt;指标。该指标是每个Pod的CPU线程在获取CPU之前所经历的延迟的直方图。程序每 1 秒收集一次&lt;em&gt;runq latency&lt;/em&gt;直方图，并将其存储在Prometheus时间序列数据库中。&lt;/p&gt;
&lt;h3 id=&#34;the-vertical-autoscaler&#34;&gt;The Vertical Autoscaler&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;垂直自动缩放器是一个简单的循环，每分钟发生一次。&lt;/li&gt;
&lt;li&gt;它会在前5分钟的窗口中为每种资源类型r（CPU和内存）评估$s_r = \mu_r + 3*\sigma_r$，如果s的值变化超过 15%，它会更新服务的资源需求s。&lt;/li&gt;
&lt;li&gt;触发垂直自动缩放器的另一个条件是微服务报告 OOM 错误。&lt;/li&gt;
&lt;li&gt;在应用微服务的新资源需求之前，垂直自动缩放器通过共享通道向水平自动缩放器发送一条消息，以不继续任何水平自动缩放操作，因为&lt;strong&gt;垂直自动缩放操作优先于水平自动缩放&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;如果微服务的CPU数量超过一个CPU核心，垂直自动缩放器也不会继续执行微服务的自动缩放操作，在这种情况下，它会通过另一个共享通道向水平自动缩放器以触发水平自动缩放操作。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;the-horizontal-autoscaler&#34;&gt;The Horizontal Autoscaler&lt;/h3&gt;
&lt;p&gt;对于给定的目标&lt;em&gt;runq latency&lt;/em&gt;，它对该微服务执行水平自动缩放操作，使其始终具有目标值的&lt;em&gt;runq latency&lt;/em&gt;。控制器每1分钟决定eBPF程序收集60个度量直方图实例（每秒1个）。对于每个直方图，选择第 95个百分位数，控制器使用这60个数据点的平均值作为其当前观察值（也称为测量值）来执行其控制动作。每个水平扩展操作添加或删除至少1个或可配置百分比（默认为 10%）的微服务当前副本数，分别用于扩缩容。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lizonglin313/MyPicGo/master/20220222112427.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;PID控制参数的初始值取为$k_P=k_I=k_D=1/3$​​（每个参数限制为∈[0,10]，这几个参数会影响控制器的速度、稳定性和准确性）。这些参数的增量变化是 10%（我们通过实验发现 10% 可以提供非常好的性能）。控制器输出的波动是进行此类更改的基础，使用之前的N =10个样本进行测量。此外，控制器的“速度”被测量为达到区间[target(1 − 𝛼), target(1 + 𝛼)] 所需的迭代次数，因为 𝛼 =10%。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;增加$k_P$​会导致控制器速度执行增加（以达到稳定状态），同时过高的值可能引发不稳定性。&lt;/li&gt;
&lt;li&gt;增加$k_I$​也会增加控制器的速度并可能导致不稳定，但增加它会降低控制器的噪声（变化和波动）和稳态误差。&lt;/li&gt;
&lt;li&gt;增加$k_D$​会增加控制器的速度（达到稳态）以及不稳定的可能性，同时会显著放大控制器的噪声。&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
&lt;li&gt;控制器从系数的相等值开始。&lt;/li&gt;
&lt;li&gt;随后这些系数基于监控的工作负载性能和控制器状态进行自适应和增量自调整。&lt;/li&gt;
&lt;li&gt;如果当前指标值（尤其是runq延迟）远离目标指标值，则在每次迭代中增加$k_P$和$k_I$，以提高稳定性以及达到目标指标值的速度。&lt;/li&gt;
&lt;li&gt;此外，如果观察到度量值的波动（在控制器中称为噪声），$k_D$​会逐渐减小以减少工作负载突发性引入的噪声。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;the-affinity-rule-generator&#34;&gt;The Affinity Rule Generator&lt;/h3&gt;
&lt;p&gt;亲和性规则生成器每5分钟使用一次CPU、内存和网络利用率，这是一个由300个数据点组成的向量（每个数据点是微服务副本的平均值）来计算每个资源类型之间的相关系数一对微服务。为消除弱相关或无相关实例，[−0.8,+0.8]中的任何值都会被丢弃。其他强负相关和强正相关的微服务用于生成亲和性和反亲和性规则。资源使用模式会随着工作负载的变化（也称为工作负载转移）而变化，因此如果在随后的5分钟时间窗口内强烈的负相关或正相关变化超过20%（可配置），SHOWAR会撤销亲和性（或那对微服务的反亲和性）规则。&lt;/p&gt;
&lt;h3 id=&#34;其他要点&#34;&gt;其他要点&lt;/h3&gt;
&lt;p&gt;SHOWAR是作为Kubernetes控制器构建的，对于自动扩缩器和其他类型的控制器具有高度可插入性。此外，SHOWAR使用常用的Kubernetes监控代理（例如Prometheus）和一个自定义的eBPF指标监控代理。因此，与默认的Kubernetes自动缩放器相比，&lt;strong&gt;SHOWAR不会引入任何额外的开销&lt;/strong&gt;。此外，自动缩放器被调度在控制器节点上，并且不与调度在工作节点上的应用程序 Pod 共享资源。&lt;/p&gt;
&lt;h2 id=&#34;实验&#34;&gt;实验&lt;/h2&gt;
&lt;p&gt;在AWS部署K8s集群，用Google Autopilot和K8s默认的调度程序作比较。资源利用率提升22%，延迟降低20%。&lt;/p&gt;
&lt;h3 id=&#34;实验设置&#34;&gt;实验设置&lt;/h3&gt;
&lt;h4 id=&#34;applications&#34;&gt;Applications&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;社交网络应用：包含36个微服务，可以关注他人、撰写帖子、阅读他人帖子并与之互动。&lt;/li&gt;
&lt;li&gt;火车票应用：包含41个微服务的应用程序，允许其用户在线预订门票并进行支付。&lt;/li&gt;
&lt;li&gt;谷歌云平台的线上精品店：由 10 个微服务组成，用户可以通过他们的在线购物车购买在线商品并进行支付。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;实验将runq延迟的目标值设置为15𝑚𝑠，即 Linux 内核 sysctl_sched_latency[31] 调度程序参数的 2.5𝑥。&lt;/p&gt;
&lt;h4 id=&#34;cluster-setup&#34;&gt;Cluster Setup&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;在AWS上进行的。&lt;/li&gt;
&lt;li&gt;使用 𝑚5.𝑥𝑙𝑎𝑟𝑔𝑒 VM 实例，每个实例具有 4 个 vCPU、16 GB 内存和 0.192 美元/ℎ𝑟 价格。&lt;/li&gt;
&lt;li&gt;运行Ubuntu 18.04 LTS，配置为支持运行eBPF程序。&lt;/li&gt;
&lt;li&gt;除非另有说明，否则集群都是由25个VM实例组成。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;workload-and-load-generation&#34;&gt;Workload and Load Generation&lt;/h4&gt;
&lt;p&gt;我们使用Wikipedia访问跟踪[59]作为我们的主要工作负载。它是用户与Wikipedia网站交互的真实世界轨迹，由流量模式组成，包括&lt;strong&gt;泊松到达时间、短期突发性和昼夜水平变化&lt;/strong&gt;。由于我们正在评估的微服务是面向用户的应用程序，因此工作负载必须反映真实的用户行为。因此，维基百科访问跟踪非常适合我们的评估。我们以分布式方式使用&lt;strong&gt;locust&lt;/strong&gt; [26]作为我们的工作负载生成器。 Locust客户端驻留在与托管应用程序的主集群不同的VM实例上。&lt;/p&gt;
&lt;h4 id=&#34;baselines&#34;&gt;Baselines&lt;/h4&gt;
&lt;p&gt;Kubernetes默认自动缩放器和 Google Autopilot。&lt;/p&gt;
&lt;h3 id=&#34;vertical-autoscaling&#34;&gt;Vertical Autoscaling&lt;/h3&gt;
&lt;p&gt;首先评估 SHOWAR 的垂直自动缩放器（禁用水平自动缩放器）在减少相对内存松弛方面的有效性。&lt;/p&gt;
&lt;p&gt;使用来下图中所示的 Wikipedia 访问跟踪的一小时长的工作负载进行评估。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lizonglin313/MyPicGo/master/20220222120133.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;每5分钟记录一次垂直自动缩放器为每个微服务设置的内存限制以及微服务的实际使用情况，以计算其内存使用松弛（即松弛 = 限制 - 使用）。&lt;/p&gt;
&lt;p&gt;下图描绘了社交应用所有微服务相对内存使用松弛的&lt;strong&gt;累积分布函数&lt;/strong&gt;（the cumulative distribution function，CDF）。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lizonglin313/MyPicGo/master/20220222120655.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;可以看出，通过历史资源使用的变化（使用3-σ规则），SHOWAR 的垂直自动缩放器与Autopilot 和 Kubernetes 的垂直自动缩放器相比能够改善内存使用松弛度。特别是，对于95%的服务实例，相对内存使用松弛率小于46%，而 Kubernetes 和 Autopilot 分别为 63% 和 66%。这 20% 的内存使用松弛可用于调度更多的服务实例或在集群中使用更少的 VM 资源，这将明显降低成本（见 5.5 小节）。我们还观察到 Kubernetes 的性能优于 Autopilot，因为它在设置限制方面采用了更激进的方法（使用 P95 × 1.15 的过去使用量与最大值相比）。&lt;/p&gt;
&lt;p&gt;虽然低内存或 CPU 使用松弛可以导致高效且具有成本效益的资源分配，但它可能导致更高的 OOM 率或 CPU 节流，从而降低服务性能。下图显示了实验过程中 OOM 的数量。可以看出，虽然与 Kubernetes 相比，SHOWAR 的 OOM 数量相当，但与 Autopilot 相比，它们在内存扩展方面的激进方法导致了更多的 OOM。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lizonglin313/MyPicGo/master/20220222124148.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;下图则描绘了在实验过程中微服务的平均 CPU 节流（CPU 紧松弛的结果）。当 Pod 的 CPU 使用率超过其分配的 CPU 资源时，容器运行时（使用𝑐𝑔𝑟𝑜𝑢𝑝𝑠）会限制 Pod 的 CPU 份额。可以看出，由于微服务 CPU 使用率的高波动（方差），SHOWAR 的 CPU 节流与基线相当。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lizonglin313/MyPicGo/master/20220222124339.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;根据以上三图的分析，&lt;strong&gt;资源松弛度（也反映了资源使用效率）和系统稳定性之间存在权衡&lt;/strong&gt;。SHOWAR和K8s在带来更好的资源效率的同时回不可避免的导致更多的OOM错误和CPU性能限制。而 Autopilot 会导致更多的松弛和更少的 OOM。&lt;/p&gt;
&lt;p&gt;因此，根据任务目标可调整 SHOWAR 和 Kubernetes 以实现更高的稳定性，但代价是更高的资源使用松弛度。例如，在 SHOWAR 中，可以使用 𝑘𝜎 代替 3𝜎 ，其中 𝑘 &amp;gt;3 为单个 Pod 分配更多资源并减轻 OOM 和 CPU 节流。&lt;/p&gt;
&lt;h3 id=&#34;horizontal-autoscaling&#34;&gt;Horizontal Autoscaling&lt;/h3&gt;
&lt;p&gt;使用垂直扩缩容相同的工作负载来评估水平扩缩容。将 SHOWAR 的 One for Each 和 One for All 设计与 Autopilot 和 Kubernetes 水平自动缩放器进行比较。Autopilot 和 Kubernetes 在水平自动缩放中使用相同的方法。我们将 Autopilot 和 Kubernetes 的目标 CPU 利用率设置为 65%，这是通常的建议。&lt;/p&gt;
&lt;p&gt;下图描绘了在实验过程中社交网络应用程序中微服务副本数量的累积分布函数。我们观察到 SHOWAR 的水平自动缩放器都优于 Autopilot 和 Kubernetes 水平自动缩放器，因为它为大多数微服务分配了更少的副本，这反过来又可以更有效地分配资源并节省成本（见 5.5 小节）。通过为每个微服务定制一个控制器，SHOWAR 的 One for Each 设计也优于 One for All。这是因为在 One for All 设计中，单个控制器尝试使用单个目标 runq 延迟值和跨所有微服务的平均 runq 延迟测量来扩展微服务，这会导致不必要的微服务扩展和高 runq 延迟。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lizonglin313/MyPicGo/master/20220222125146.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;再次强调，SHOWAR 的有效性是由于：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;自动缩放器的状态控制器&lt;/li&gt;
&lt;li&gt;用于自动缩放决策的更好的代表性指标（即 runq 延迟而不是 CPU 利用率）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我们看到了在单个微服务的自动扩展决策中使用更有意义和代表性的指标的效果。特别是，在评估过程中，我们观察到 Kubernetes 和 Autopilot 通常为 nginx 设置 16 个副本，这主要是因为它的 CPU 利用率很高。但&lt;strong&gt;高 CPU 利用率并不总是对应于微服务性能的大幅提升&lt;/strong&gt;。相比之下，SHOWAR 只为这个微服务设置了 10 个副本。另一方面，对于其他几个微服务所依赖的 User 微服务，Kubernetes 和 Autopilot 通常只为其设置 3 个副本。相比之下，SHOWAR 通常为此微服务设置 6 个副本。&lt;/p&gt;
&lt;h3 id=&#34;the-effect-of-affinity-and-anti-affinity-rules&#34;&gt;The Effect of Affinity and Anti-Affinity Rules&lt;/h3&gt;
&lt;p&gt;实验使用不同微服务之间 CPU、内存和网络 I/O 使用率的相关性来评估 SHOWAR 生成的 Pod 亲和性和反亲和性规则的效果。仍使用相同的工作负载并禁用垂直和水平扩缩容控制器，以凸显亲和性和反亲和性生成器的工作效果，以此观察K8s调度器受其的影响。&lt;/p&gt;
&lt;p&gt;同时观测了这如何影响端到端请求延迟，如下图所示。通过为调度程序提供调度提示（使用亲和性和反亲和性），SHOWAR 能够改善用户体验的 P99 延迟。特别是，使用 SHOWAR 生成的亲和和反亲和规则，请求延迟的 P99 为 6600 毫秒，而使用 Kubernetes 默认调度决策为 9000 毫秒。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lizonglin313/MyPicGo/master/20220222125945.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;end-to-end-performance&#34;&gt;End-to-End performance&lt;/h3&gt;
&lt;p&gt;在端到端性能评估这部分使用三个组件协同工作，使用下图的工作负载进行测试。为了适应工作负载，我们将集群的大小增加到 30 个 VM 实例。结果表明，与基线相比，SHOWAR 改进了资源分配和利用率，同时保持性能的稳定。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lizonglin313/MyPicGo/master/20220222131341.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;下图描述了用户在实验的 24 小时内经历的端到端请求延迟的 CDF。可以看出，使用 SHOWAR 的端到端性能与基线相当，并且使用其亲和性和反亲和性规则生成器以及依赖关系感知的水平自动缩放，与 Autopilot 和 Kubernetes 相比SHOWAR 能够将 P99 延迟提高 20% 以上。 Autopilot 和 Kubernetes 在 P99th 延迟方面表现出相似的性能，但是，由于为副本分配了更多内存，Autopilot 通常在较低的尾部优于 Kubernetes。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lizonglin313/MyPicGo/master/20220222131527.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;下图显示了实验过程中集群中的总内存分配（即为微服务副本设置的内存限制总和）。与基线相比，SHOWAR 平均为微服务副本分配的内存更少。特别是，SHOWAR 平均分配了 205 GB，而 Autopilot 和 Kubernetes 分别分配了 264 GB 和 249 GB。主要是因为 SHOWAR 的垂直自动缩放器实现了较低的内存使用松弛度，并且其水平自动缩放器为微服务设置了较少的副本数量。因此，使用 SHOWAR 的总内存分配小于基线。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lizonglin313/MyPicGo/master/20220222131959.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;最后，在下图中，展示了每个实验的归一化集群成本。我们将平均内存分配标准化为集群中一台虚拟机的内存大小（即 16 GB 用于𝑚5.𝑥𝑙𝑎𝑟𝑔𝑒 实例），并将其乘以 24 小时内一台虚拟机的成本（即 $0.192/ℎ𝑜𝑢𝑟）。这是因为，通常虚拟机在公共云上的价格是内存大小的线性函数 [17]。可以看出，与 Autopilot 和 Kubernetes 相比，SHOWAR 将集群总成本效益分别提高了 22% 和 17%。这些改进来自这样一个事实，即与基线相比，SHOWAR 的垂直和水平自动缩放器用&lt;strong&gt;分配更少的计算资源就可以达到相同的性能和服务质量&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lizonglin313/MyPicGo/master/20220222135039.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;不足和未来工作&#34;&gt;不足和未来工作&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;SHOWAR是基于历史和现在进行反应式调度的，&lt;strong&gt;缺乏预测能力&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;我们将 SHOWAR 设计为计算量轻且适应性强，这与使用需要训练且无法应对工作负载转移的机器学习的“黑盒”方法形成对比，例如 [39,55,57]。然而，目前 SHOWAR 的一个主要限制是它对微服务的资源使用是反应性的。因此，&lt;strong&gt;一个合适的探索途径是为 SHOWAR 配备近期工作负载和资源使用预测&lt;/strong&gt;，例如 [18]。结合其当前设计，&lt;strong&gt;预测近期工作负载可以改善 SHOWAR 的资源分配并防止由于自动缩放操作不足而导致性能下降&lt;/strong&gt;。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;另一个限制是它只关注微服务自动扩展并假设一个固定大小的集群&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;解决应用程序自动缩放器请求的资源总量超过可用集群资源总量的场景非常重要&lt;/strong&gt;。虽然集群自动缩放与应用程序自动缩放是正交的，但它们需要协同工作以实现资源分配的整体效率和应用程序的性能要求。因此，需要两个自动扩缩器之间的通信和协调才能向集群添加更多资源。在未来的工作中，我们&lt;strong&gt;计划改进 SHOWAR 的自动缩放器以与现有的集群自动缩放器 [12] 一起使用&lt;/strong&gt;。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;还不适用于Serverless类型的工作负载&lt;/p&gt;
&lt;p&gt;原因之一是垂直自动缩放不适用，因为&lt;strong&gt;无服务器功能的容器大小是预定义的&lt;/strong&gt;。 SHOWAR 的水平自动缩放器可能面临额外的复杂性，例如，跟踪“休眠”无服务器函数的数量（可以热启动）以及每个函数“过期”的时间（因此需要冷启动延迟）。我们将探索无服务器功能水平扩展的控制理论方法留给未来的工作。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;计划改进 SHOWAR 的亲和性和反亲和性规则生成器&lt;/p&gt;
&lt;p&gt;目前使用简单的经验资源利用相关系数来确定微服务之间的成对亲和力。例如，我们可以在未来&lt;strong&gt;探索其他统计数据对亲和力的影响&lt;/strong&gt;，例如不同类型资源之间的互相关，并&lt;strong&gt;探索不同类型的调度机制&lt;/strong&gt;，这些调度机制可以直接利用这些“原始”统计信息来提高效率资源利用[19]。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>笔记 &gt; SHOWAR: Right-Sizing And Efficient Scheduling of Microservices</title>
        <link>https://lizonglingo.github.io/p/%E7%AC%94%E8%AE%B0-showar-right-sizing-and-efficient-scheduling-of-microservices/</link>
        <pubDate>Mon, 20 Dec 2021 14:51:34 +0800</pubDate>
        
        <guid>https://lizonglingo.github.io/p/%E7%AC%94%E8%AE%B0-showar-right-sizing-and-efficient-scheduling-of-microservices/</guid>
        <description>&lt;h2 id=&#34;摘要&#34;&gt;摘要&lt;/h2&gt;
&lt;p&gt;提出微服务的面临的一个挑战是为每个微服务找到最佳的分配资源和服务实例的数量。达到保证性能的同时最大限度的提高资源利用率这样一个目标。本文的SHOWAR是一个通过确定服务实例数量（横向扩展）以及每个服务实例的资源如CPU和内存（纵向扩展）来配置资源的框架。&lt;/p&gt;
&lt;p&gt;对于纵向扩展，SHOWAR通过历史资源中的经验方差来寻找最佳资源分配量，保证性能同时减少不必要的资源浪费；对于横向扩展，使用控制理论的基本思想以及内核级性能指标来实施。&lt;/p&gt;
&lt;p&gt;在确定微服务的现有状态后，SHOWAR使用调度程序生成亲和性规则来弥合最佳资源分配和调度之间的差距，实现资源分配和性能提高。&lt;/p&gt;
&lt;p&gt;实验表明，SHOWAR与现有的最先进的自动缩放和调度系统相比，资源分配提高了22%，同时降低了99%的端到端请求延迟20%。&lt;/p&gt;
&lt;h2 id=&#34;intro&#34;&gt;Intro&lt;/h2&gt;
&lt;p&gt;本文的SHOWAR是一个用于微服务横向和纵向自动扩展的微服务管理系统，用于Kubernetes编排的微服务系统。&lt;/p&gt;
&lt;p&gt;对于纵向缩放，SHOWAR 依赖&lt;strong&gt;历史资源使用情况的差异&lt;/strong&gt;，找到每个微服务的最佳资源大小，保持良好的性能的同时提高资源利用率。&lt;/p&gt;
&lt;p&gt;对于横向自动缩放，SHOWAR 使用来自 &lt;strong&gt;Linux 内核线程调度程序队列的指标&lt;/strong&gt;（特别是 eBPF 运行时延迟）作为其自动缩放信号，以做出更准确和有意义的自动缩放决策。为了实现这个目标，SHOAWR使用了控制理论的基本思想，基于来自&lt;strong&gt;微服务运行时&lt;/strong&gt;的信号控制每个微服务的副本数量。&lt;/p&gt;
&lt;p&gt;该团队设计了一个比例积分微分proportional–integral–derivative (PID) 控制器作为有状态自动缩放器，它使用历史自动缩放操作和当前运行时测量来做出下一个水平自动缩放决策并保持微服务“稳定”。此外，SHOWAR考虑不同微服务之间的依赖关系，优先考虑被依赖的微服务，以防止不必要的自动缩放操作和低资源利用率。&lt;/p&gt;
&lt;p&gt;除了使用自动缩放器来确定微服务的资源外，SHOWAR还旨在桥接微服务的最佳资源分配和高效调度，&lt;strong&gt;在达成最佳资源分配和高效调度之间取得最佳平衡&lt;/strong&gt;。一旦确定了微服务的最佳大小，SHOWAR就会协助集群调度程序调度微服务以获得更好的端到端性能。为了防止资源争用和管理噪声邻居对微服务性能的影响，SHOWAR使用不同微服务之间历史资源使用情况的估计相关性来为Kubernetes调度程序生成规则。例如，这些规则可能会建议调度程序共同定位（调度亲和性）与某种资源类型具有负相关性的微服务，或者以其他方式分发它们（调度反亲和性）。&lt;/p&gt;
&lt;p&gt;文章通过在AWS公共云上的虚拟机集群部署各种交互式微服务应用程序来评估SHOWAR。将SHOWAR的性能与两种最先进的自动缩放系统进行了比较：Google Autopilot和Kubernetes 默认的自动缩放器。使用实际生产工作负载，结果表明，SHOWAR在有效资源分配和端到端请求延迟的尾部分布方面优于这些参照。SHOWAR 平均将资源分配提高了22%，这可以直接转化为集群相关成本的总节省22%，同时将99%的端到端用户请求延迟降低20%。&lt;/p&gt;
&lt;h2 id=&#34;贡献&#34;&gt;贡献&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;提出一种自动化的纵向扩容和横向扩容框架，达到保证服务性能的前提下提高资源利用率的目标&lt;/li&gt;
&lt;li&gt;提出调度亲和性和反亲和规则，通过生成调度亲和性和反亲和性规则来帮助调度程序更好地放置微服务并提高微服务性能，弥合了适当调整微服务规模以提高资源效率和高效微服务调度之间的差距&lt;/li&gt;
&lt;li&gt;通过实验证明SHOWAR的良好表现&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;前置知识&#34;&gt;前置知识&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lizonglin313/MyPicGo/master/20211220134037.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;这一个比较典型的微服务架构示意图，微服务之间的依赖关系错综复杂。&lt;strong&gt;其中一些微服务依赖于其他微服务，SHOWAR使用此依赖关系图信息来做出更好的自动缩放决策&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;除了 CPU 和内存使用数据外，SHOWAR还使用扩展的伯克利数据包过滤 ( Berkeley Packet Filtering - eBPF) [6] 指标数据进行水平自动缩放决策。&lt;strong&gt;eBPF 是最新的Linux内核技术，它支持在内核级别运行安全且低开销的程序，以从内核级别的事件（例如 CPU 调度程序决策事件、内存分配事件和内核网络堆栈中的数据包事件）中收集准确的指标&lt;/strong&gt;。它已被广泛用于微服务可观察性，用于性能改进、分析和跟踪、负载平衡、网络监控和安全等广泛目的。&lt;/p&gt;
&lt;h2 id=&#34;showar&#34;&gt;SHOWAR&lt;/h2&gt;
&lt;h3 id=&#34;系统架构&#34;&gt;系统架构&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lizonglin313/MyPicGo/master/20211220141140.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;SHOWAR使用每个节点上的相应代理来收集资源使用日志以及 eBPF 指标，然后聚合到时间序列数据库中。&lt;/p&gt;
&lt;p&gt;SHOWAR使用收集到的指标通过分别与Kubernetes API服务器及其调度程序通信来做出自动缩放决策以及调度亲和性和反亲和性规则。&lt;/p&gt;
&lt;h3 id=&#34;系统实现&#34;&gt;系统实现&lt;/h3&gt;
&lt;p&gt;SHOWAR 作为服务部署在控制器节点并与kubernetes API服务器及其调度程序交互以进行自动缩放操作以及为微服务应用生成的亲和性和反亲和性规则。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;监控代理Monitoring Agents&lt;/p&gt;
&lt;p&gt;监控和日志数据是任何应用程序部署最重要的部分。监控数据用于可观察性、健康检查和自动缩放。本文使用最先进的监控和指标收集工具Prometheus从节点和容器收集不同的指标。Prometheus在集群中的每个节点上启动一个监控代理来收集容器指标，例如 CPU 使用率、内存使用率、网络带宽使用率等。代理被配置为每秒收集和报告指标（一秒是Prometheus 代理可以收集指标的最短时间。为了获得尽可能多的数据点，我们每秒钟收集一次数据）。Prometheus 带有一个时间序列数据库，代理存储收集的指标。此外，提供查询语言来查询其他模块使用的时间序列数据库以利用收集的指标。&lt;/p&gt;
&lt;p&gt;除Prometheus外，文章还开发了一个eBPF程序，该程序作为监控代理部署在集群中的每个节点上，以收集横向自动缩放器使用的 𝑟𝑢𝑛𝑞 𝑙𝑎𝑡𝑒𝑛𝑐𝑦 指标。该指标是每个pod中的CPU线程在获取CPU之前所经历的延迟直方图。程序每1秒收集一张𝑟𝑢𝑛𝑞 𝑙𝑎𝑡𝑒𝑛𝑐𝑖𝑒𝑠的直方图并存储在Prometheus时间序列数据库中。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;纵向缩放器The Vertical Autoscaler&lt;/p&gt;
&lt;p&gt;这一个简单的循环，每分钟进行一轮。在前 5 分钟的窗口内为每种资源类型 𝑟（CPU 和内存）计算 𝑠𝑟 =𝜇𝑟 +3∗𝜎𝑟，如果 𝑠 的值变化超过 15%，它会更新服务的资源需求为𝑠。&lt;/p&gt;
&lt;p&gt;触发缩放器的另一个条件是微服务报告 OOM 错误时。在应用微服务的新资源需求之前，纵向自动缩放器通过共享通道向横向自动缩放器发送消息，不让其进行任何横向自动缩放操作，因为纵向自动缩放操作的优先级高于水平自动缩放。&lt;/p&gt;
&lt;p&gt;如果该微服务的 CPU 数量超过一个 CPU 内核（即 𝑠𝐶𝑃𝑈 &amp;gt;1000𝑚），纵向自动缩放器也不会对微服务进行自动缩放操作，在这种情况下，它会通过另一个共享通道发送消息到横向自动缩放器触发横向自动缩放操作。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;横向缩放器The Horizontal Autoscaler&lt;/p&gt;
&lt;p&gt;横向自动缩放器的核心是一个 PID 控制器，旨在保持每个微服务稳定。对于给定的目标 𝑟𝑢𝑛𝑞 𝑙𝑎𝑡𝑒𝑛𝑐𝑦，它对该微服务执行水平自动缩放操作，使其始终具有𝑟𝑢𝑛𝑞𝑟𝑢𝑛𝑞𝑙控制器每 1 分钟做出决定，eBPF 程序收集 60 个度量直方图实例（每秒 1 个）。对于每个直方图，选择第 95 个百分位数，控制器使用这 60 个数据点的平均值作为其当前观察（也称为测量）来执行其控制操作。每个水平扩展操作添加或删除至少 1 个或可配置百分比（默认为 10%）的微服务当前副本数，分别用于扩展和缩减。PID 控制参数的初始值取为 𝑘𝑃 =𝑘𝐼 =𝑘𝐷 =1/3（每个参数约束为 ∈ [0,10]）。这些参数的增量变化是 10%（我们通过实验发现 10% 的性能非常好）。控制器输出的波动是进行此类更改的基础，使用之前的 𝑁 = 10 个样本进行测量。此外，控制器的“速度”被测量为达到区间 [target(1 −𝛼),target(1 + 𝛼)] 所需的迭代次数，因为 𝛼 =10%。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;亲和规则生成器The Affinity Rule Generator&lt;/p&gt;
&lt;p&gt;SHOWAR的亲和性规则生成器每 5 分钟使用一次 CPU、内存和网络利用率，这是一个由 300 个数据点组成的向量（每个数据点是微服务副本的平均值）来计算每个数据点之间不同资源类型的相关系数。消除弱相关或无相关实例，[−0.8,+0.8] 中的任何值都将被丢弃。其他强负相关和强正相关微服务用于生成亲和性和反亲和性规则。资源使用模式会随着工作负载的变化（也称为工作负载转移）而变化，因此如果在随后的 5 分钟时间窗口内强烈的负相关或正相关变化超过 20%（可配置），SHOWAR 将撤销关联（或anti-affinity）规则。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;SHOWAR的开销&lt;/p&gt;
&lt;p&gt;SHOWAR是作为Kubernetes的控制器构建的，它对于自动缩放器和其他类型的控制器具有高度可插拔性。SHOWAR使用常用的 Kubernetes监控代理（如Prometheus）和一个自定义eBPF指标监控代理。因此，与默认的Kubernetes自动缩放器相比，SHOWAR 不会引入任何额外的开销。此外，自动缩放器被调度在控制器节点上，并且不与调度在工作节点上的应用程序 Pod 共享资源。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>笔记 &gt; Service-Level Fault Injection Testing</title>
        <link>https://lizonglingo.github.io/p/%E7%AC%94%E8%AE%B0-service-level-fault-injection-testing/</link>
        <pubDate>Sat, 18 Dec 2021 15:35:42 +0800</pubDate>
        
        <guid>https://lizonglingo.github.io/p/%E7%AC%94%E8%AE%B0-service-level-fault-injection-testing/</guid>
        <description>&lt;blockquote&gt;
&lt;p&gt;来源：SoCC&#39;21&lt;/p&gt;
&lt;p&gt;Meiklejohn C S, Estrada A, Song Y, et al. Service-Level Fault Injection Testing[C]//Proceedings of the ACM Symposium on Cloud Computing. 2021: 388-402.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;摘要&#34;&gt;摘要&lt;/h2&gt;
&lt;p&gt;越来越多的企业使用微服务架构发布他们的大规模的移动或是Web应用。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;问题在于&lt;/strong&gt;，并非所有系统开发人员都有分布式系统的管理经验，由于这些大规模的应用多是部署与分布式系统中，所以在生产环境中的故障很有可能在开发环境中不会出现。一旦这些微服务部署在分布式系统中，就有可能出现故障。所以，一种好的解决方法就是尽早找出这些问题：在测试环境或者在代码交付生产前就将其解决。&lt;/p&gt;
&lt;p&gt;本文提出&lt;strong&gt;服务级别故障注入测试&lt;/strong&gt;，并实现一个原型“filibuster”，用来系统的识别开发环境中微服务的弹性问题。“Filibuster”使用静态分析及并发风格的执行，还有新颖的动态缩减算法，来扩展现有功能测试的套件，减少开发人员的工作。&lt;/p&gt;
&lt;p&gt;为了证明工具的适用性，文章展示了4个包含错误的真实工业微服务应用程序的语料库。数据来自大公司生产中运行的实验公开信息。文章展示了实验如何在开发过程中运行，并在投入生产环境之前就检测到错误。&lt;/p&gt;
&lt;h2 id=&#34;前置知识&#34;&gt;前置知识&lt;/h2&gt;
&lt;h3 id=&#34;1-混沌工程&#34;&gt;1. 混沌工程&lt;/h3&gt;
&lt;p&gt;在本文中，多次讲到“chaos engineering”，在我个人理解，混沌工程是本文的“服务级故障注入测试”的基础，或者说是“上一个版本”。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;混沌工程代表项目，Netflix创建的“Chaos Monkey”可以在系统的随机位置引发故障，可以随时终止&lt;strong&gt;生产环境&lt;/strong&gt;中运行的虚拟机和容器实例。通过“Chaos Monkey”，开发者可以快速了解构建的服务的健壮性，是否可以弹性扩容以及处理意外故障。&lt;/p&gt;
&lt;p&gt;参考：&lt;a class=&#34;link&#34; href=&#34;https://zhuanlan.zhihu.com/p/90294032&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;知乎-系统架构设计之路&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;混沌工程，是一种提高技术架构弹性能力的复杂技术手段。Chaos工程经过实验可以确保系统的可用性。混沌工程旨在将故障扼杀在襁褓之中，也就是在故障造成中断之前将它们识别出来。通过主动制造故障，测试系统在各种压力下的行为，识别并修复故障问题，避免造成严重后果。&lt;/p&gt;
&lt;p&gt;主要针对于&lt;strong&gt;分布式系统&lt;/strong&gt;上的故障测试。&lt;/p&gt;
&lt;h4 id=&#34;11-混沌工程与故障注入的区别&#34;&gt;1.1 混沌工程与故障注入的区别&lt;/h4&gt;
&lt;p&gt;混沌工程是一种生成新信息的实践，而故障注入是测试一种情况的一种特定方法。&lt;/p&gt;
&lt;h4 id=&#34;12-混沌工程实验的步骤&#34;&gt;1.2 混沌工程实验的步骤&lt;/h4&gt;
&lt;p&gt;通常混沌工程由以下四个步骤组成。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;定义测试系统的“稳定状态”。精确定义指标，表明系统按照应有的方式运行。 Netflix使用客户点击视频流设备上播放按钮的速率作为指标，称为“每秒流量”。请注意，这更像是商业指标而非技术指标；在混沌工程中，&lt;strong&gt;业务指标通常比技术指标更有用&lt;/strong&gt;，因为它们更适合衡量用户体验或运营。&lt;/li&gt;
&lt;li&gt;创建假设。与任何实验一样，您需要一个假设来进行测试。因为你试图破坏系统正常运行时的稳定状态，你的假设将是这样的，“当我们做X时，这个系统的稳定状态应该没有变化。”为什么用这种方式表达？如果你的期望是你的动作会破坏系统的稳定状态，那么你会做的第一件事会是修复问题。混沌工程应该包括真正的实验，涉及真正的未知数。&lt;/li&gt;
&lt;li&gt;模拟现实世界中可能发生的事情，目前有如下混沌工程实践方法：模拟数据中心的故障、强制系统时钟不同步、在驱动程序代码中模拟I/O异常、模拟服务之间的延迟、随机引发函数抛异常。通常，您希望模拟可能导致系统不可用或导致其性能降低的场景。首先考虑可能出现什么问题，然后进行模拟。一定要优先考虑潜在的错误。 “当你拥有非常复杂的系统时，很容易引起出乎意料的下游效应，这是混沌工程寻找的结果之一，”“因此，系统越复杂，越重要，它就越有可能成为混沌工程的候选对象。”&lt;/li&gt;
&lt;li&gt;证明或反驳你的假设。将稳态指标与干扰注入系统后收集的指标进行比较。如果您发现测量结果存在差异，那么您的混沌工程实验已经成功 - 您现在可以继续加固系统，以便现实世界中的类似事件不会导致大问题。或者，如果您发现稳定状态可以保持，那么你对该系统的稳定性大可放心。&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;13-案例&#34;&gt;1.3 案例&lt;/h4&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/chaos-mesh/chaos-mesh&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/chaos-mesh/chaos-mesh&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/chaosblade-io&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://github.com/chaosblade-io&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;into&#34;&gt;Into&lt;/h2&gt;
&lt;p&gt;混沌测试（一种用于生产环境中的错误注入，来模拟在用户角度的服务bug）已经证明了的可行性。本文要做的就是把这个过程放在更早的阶段——在开发阶段就检测到这些错误。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;现在又有这样的问题&lt;/strong&gt;：缺少开源的微服务应用。仅有的开源微服务应用仅仅用来展示如何构建这些微服务应用，并没有展示这些应用在开发、部署时会出现什么错误。因此，该研究不得不和公司合作，并且需要签订严格的保密措施。&lt;/p&gt;
&lt;h2 id=&#34;本文贡献&#34;&gt;本文贡献&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;提出一种微服务测试方法：服务级别的故障注入测试&lt;/li&gt;
&lt;li&gt;一种新的动态归约算法：将应用程序分解成独立的微服务来减少搜索空间的组合爆炸&lt;/li&gt;
&lt;li&gt;实现了这个服务级别的故障注入测试方法——Filibuster：基于Python开发，可以测试提供HTTP通信的微服务&lt;/li&gt;
&lt;li&gt;一个用Python实现的微服务应用和故障的语料库：包含8个小心微服务应用程序，每个应用程序都展示了微服务应用中使用的单一模式；还有4个从公开会议演讲中的工业级应用实例——Audible、Expedia、Mailchimp、Netflix&lt;/li&gt;
&lt;li&gt;并通过该语料库对Filibuster做出评价：表明Filibuster可以用于识别语料中的所有错误，并且展示了通过动态减少可能进行的优化，还提供了如何设计微服务应用程序以实现可测试性的见解。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;挑战应对&#34;&gt;挑战——应对&lt;/h2&gt;
&lt;p&gt;目前困难主要在于：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;缺少开源的工业级微服务应用案例和相关的错误报告。而这两个内容是软件推动软件测试领域的主要语料库。&lt;/li&gt;
&lt;li&gt;现有的一些的对于软件测试的研究都是基于一些开源的bug数据库和开源社区的软件，问题在于，这些软件架构多是单体架构，而故障也不是微服务架构所特有的。所以，需要有微服务应用特有的故障以供研究。&lt;/li&gt;
&lt;li&gt;而对于大型的微服务应用提供商，往往不能直接去研究。这些产品往往是企业的核心，一般不会开源，并且内部的漏洞也不会公开。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;所以，文章系统回顾了50个关于混沌工程的演讲，从这些公开的视频中寻找案例。这些公开演讲中的公司主要关注两个问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;开发中的软件的可靠性&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;运行这些软件的基础设施的稳定性&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;进一步团队根据下面的条件寻找语料：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;演讲中是否提供了使用混沌工程发现的真正的详细错误信息&lt;/li&gt;
&lt;li&gt;所展示的混沌工程是否可以在本地复现（也就是在非生产环境中进行混沌测试）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;最终，文章选取了4个案例，它们来自 Audible、Expedia、Mailchimp和Netflix。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;案例来源&lt;/th&gt;
&lt;th&gt;服务类型&lt;/th&gt;
&lt;th&gt;使用混沌工程发现的问题简述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Audible&lt;/td&gt;
&lt;td&gt;有声读物移动应用&lt;/td&gt;
&lt;td&gt;代码中未处理的错误，该错误会通过通用错误消息传播传到移动客户端&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Expedia&lt;/td&gt;
&lt;td&gt;旅游预订服务&lt;/td&gt;
&lt;td&gt;基于相关性排序的酒店评价服务不可用，回退到基于时间排序的&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Mailchimp&lt;/td&gt;
&lt;td&gt;电子邮件管理应用&lt;/td&gt;
&lt;td&gt;两处不处理返回错误的问题&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Netflix&lt;/td&gt;
&lt;td&gt;流媒体应用&lt;/td&gt;
&lt;td&gt;1.加载客户主页设计的服务故障；2.配置错误超时；3.服务回退失败；4.关键服务未配置回退策略&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;技术细节&#34;&gt;技术细节&lt;/h2&gt;
&lt;h3 id=&#34;架构示意图&#34;&gt;架构示意图&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lizonglin313/MyPicGo/master/20211219115042.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;对每个测试服务器进行检测调用，识别调用从何处发起，从何处接收，并在测试期间注入故障。考虑上图，服务A调用服务B，然后服务B调用服务C，最后将结果返回。&lt;/p&gt;
&lt;p&gt;SFIT（Service-Level Fault Injection Testing ）建立在当今微服务程序开发的三个关键点之上：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;微服务是独立开发的：不同微服务开发团队难以知晓其他团队服务的内部细节和详细使用规范，难以验证其他服务的问题&lt;/li&gt;
&lt;li&gt;如果对于微服务进行故障模拟测试，能很大程度上保证生产环境下服务正常运行：但是从文章选取的案例来看，许多团队并没有这样做，可能是因为这样耗费时间或者性价比太低&lt;/li&gt;
&lt;li&gt;功能测试是黄金标准：开发者使用端到端的测试，并认为这是非常有用的， 本文也因此也在这一点切入。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;sfit实现细节&#34;&gt;SFIT实现细节&lt;/h3&gt;
&lt;p&gt;假设服务通过HTTP提供，并且单个功能测试可以测试所有应用程序行为。&lt;/p&gt;
&lt;h4 id=&#34;overview&#34;&gt;Overview&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;通过常规测试，排除服务的逻辑错误。&lt;/li&gt;
&lt;li&gt;在两个微服务的通信端点，再设计一个测试，并且对微服务之间的请求进行错误注入。如果这次错误注入可以引起不同的服务错误，那么对于每种错误都再复现一次。&lt;/li&gt;
&lt;li&gt;这些后续的执行放在堆栈上，然后递归执行，直到探索到所有的问题点。&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;故障注入&#34;&gt;故障注入&lt;/h4&gt;
&lt;p&gt;本文的方法依赖于远程调用，如HTTP或gRPC，因此需要有干预微服务之间请求的能力。Opentelemetry、Opentracing等工具已经提供了远程通信的公共调用库。利用这种工具设计故障注入：根据注入的故障，返回故障响应。&lt;/p&gt;
&lt;h4 id=&#34;故障识别&#34;&gt;故障识别&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;发起请求调用源点的故障：例如Python中request库执行HTTP请求时，执行该请求会引发23个异常，本演示只考虑两个最常见的故障——超时和连接错误。&lt;/li&gt;
&lt;li&gt;接收请求的远程服务的故障：如果一个服务依赖的另一个服务抛出Timeout异常，那么调用它的服务可能会捕获到，并返回500。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;此外，还有一点是，HTTP请求使用URL标识。相似的URL可能用于不同的服务，所以需要对调用的服务进行一个标识，以此明确服务调用双方的身份。&lt;/p&gt;
&lt;h4 id=&#34;测试适配&#34;&gt;测试适配&lt;/h4&gt;
&lt;p&gt;本文提供了一个模块帮助开发者编写故障注入测试，从而减轻开发人员编写复杂测试的负担。需要注意，本文的测试是非入侵的。&lt;/p&gt;
&lt;h2 id=&#34;故障缩减&#34;&gt;故障缩减&lt;/h2&gt;
&lt;p&gt;如果组成应用有几十上百的微服务，那么出现错误的空间将非常大。所以有必要在实现故障最大覆盖率的同时，减少搜索空间，提高效率。利用服务分解，对每个独立的微服务进行排障。&lt;/p&gt;
&lt;p&gt;为此，我们可以利用以下 3 个关键观察结果：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;充分了解服务依赖项可能失败的所有方式。确保我们了解单个服务的一个或多个依赖项失败时的行为以及该服务返回的结果失败是什么。参考图Audible示例，探索 ADS 依赖项可能失败的方式组合（以及 CDS 依赖项失败的方式等）&lt;/li&gt;
&lt;li&gt;如果我打算在两个或多个不同服务的至少一个依赖项上注入故障，我们已经知道这些故障将对将它们作为依赖项的服务产生的影响。以图Audible示例，我们已经知道当 ADS 的依赖项以任何可能的组合失败时会返回什么，因为我们已经运行了该测试。我们也已经知道当 CDS 的依赖项出于同样的原因以任何可能的组合失败时，它会返回什么。因此，我们不必在依赖项处注入故障，直接在 ADS 或 CDS 中直接注入适当的响应。&lt;/li&gt;
&lt;li&gt;如果我们已经在该服务中注入了该故障，那么测试就是多余的，因为我们已经观察到了应用程序的这种行为。如果我们参考图Audible示例，我们不需要测试 Stats 服务失败与 Audio Assets 或 Audio Metadata 服务的失败，因为我们已经知道这些失败的结果，这些服务将它们作为依赖；我们也已经观察到这些结果。&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;动态归约算法&#34;&gt;动态归约算法&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lizonglin313/MyPicGo/master/20211219125759.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;filibuster&#34;&gt;Filibuster&lt;/h2&gt;
&lt;p&gt;这是该团队实现的原型，利用Python以及一些开源库实现的。&lt;/p&gt;
&lt;p&gt;Filibuster可以注入这些故障：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;调用端异常：由请求库抛出，指示连接错误或超时等条件。对于所有异常类型，Filibuster 可以在抛出异常之前有条件地联系其他服务。对于超时，Filibuster 可以在抛出超时异常之前有条件地等待超时时间。&lt;/li&gt;
&lt;li&gt;错误响应：从远程服务使用标准 HTTP 错误代码指示内部服务器错误或服务不可用等情况。对于每个错误代码，Filibuster 可以有条件地返回一个关联的正文。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;由于 Filibuster 是作为服务器编写的，跨语言支持是可能的，但尚未实现。仪器和 Filibuster 服务器之间的所有通信都是通过独立于语言的协议进行的；任何特定于语言的东西都在仪器库中完成。&lt;/p&gt;
&lt;h2 id=&#34;应用语料库&#34;&gt;应用语料库&lt;/h2&gt;
&lt;h3 id=&#34;电影应用案例&#34;&gt;电影应用案例&lt;/h3&gt;
&lt;p&gt;由四个微服务组成：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;放映时间：返回电影的放映时间&lt;/li&gt;
&lt;li&gt;电影：返回给定电影的信息&lt;/li&gt;
&lt;li&gt;预订：给定用户名，返回有关该用户预订的信息&lt;/li&gt;
&lt;li&gt;用户：存储用户信息并通过首先请求用户的预订来编排来自最终用户的请求，并且对于每个预订执行对电影服务的后续请求以获取有关电影的信息&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;根据上述的基础案例，文章又改造了7个示例：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Cinema-2：直接预定电影&lt;/li&gt;
&lt;li&gt;Cinema-3：与cinema-2 相同，但users 服务在调用bookings 服务时有一个重试循环&lt;/li&gt;
&lt;li&gt;Cinema-4：与cinema-2 相同，但每个服务在发出任何请求之前都与外部服务对话：用户服务向IMDB 发出请求；预订服务向 Fandango 提出请求；电影服务向 Rotten Tomatoes 提出请求&lt;/li&gt;
&lt;li&gt;Cinema-5：无论失败与否，所有请求都会发生；在失败的情况下，使用硬编码的默认响应。&lt;/li&gt;
&lt;li&gt;Cinema-6：添加了预订的第二个副本，在主要副本出现故障时联系该副本。&lt;/li&gt;
&lt;li&gt;Cinema-7：与cinema-6 相同，但用户服务在发出实际请求之前调用主要预订副本上的健康检查端点。&lt;/li&gt;
&lt;li&gt;Cinema-8：示例被折叠成单体，其中 API 服务器通过重试循环向它发出请求&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;工业级案例audibleexpediamailchimp-和-netflix&#34;&gt;工业级案例Audible、Expedia、Mailchimp 和 Netflix&lt;/h3&gt;
&lt;p&gt;示例并不是要重现这些公司的整个微服务架构：我们只关注他们执行的特定混沌实验中涉及的服务。&lt;/p&gt;
&lt;h4 id=&#34;audible&#34;&gt;Audible&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lizonglin313/MyPicGo/master/20211219121932.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;示例 Audible微服务架构&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;这个案例包含8个微服务和一个移动客户端：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;内容交付服务（CDS）：给定图书标识符和用户标识符，授权后返回实际音频内容和音频元数据&lt;/li&gt;
&lt;li&gt;内容交付引擎 (CDE)：返回要请求的的正确 CDS 的 URL&lt;/li&gt;
&lt;li&gt;Audible App：模拟移动应用程序，向CDE发出请求，根据图书标识符查找相应CDS实例的URL，然后向其发出请求&lt;/li&gt;
&lt;li&gt;声音下载服务（ADS）：一旦所有权得到验证，就会协调日志记录和 DRM 授权&lt;/li&gt;
&lt;li&gt;所有权：验证书的所有权&lt;/li&gt;
&lt;li&gt;激活：为用户激活 DRM 许可证&lt;/li&gt;
&lt;li&gt;统计：维护书籍和许可证激活统计&lt;/li&gt;
&lt;li&gt;资产元数据：存储包含章节描述信息的音频资产元数据&lt;/li&gt;
&lt;li&gt;音频资产：音频文件的存储&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;由于实际的服务是部署在AWS上的微服务，本文则简化并模拟了这些服务：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;首先，资产元数据和音频资产服务是 AWS S3 存储桶（云存储）。为了模拟这一点，我们创建了 HTTP 服务，如果可用则返回包含资产的 200 OK，或者如果资产不存在则返回 404 Not Found。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;其次，所有权和激活服务是 AWS RDS 实例。为了模拟这一点，我们创建了实现 REST 模式的 HTTP 服务：如果用户不拥有这本书，则返回 403 Forbidden，如果这本书不存在，则返回 404 Not Found，否则返回 200 OK。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;第三，Stats 服务是一个 AWS DynamoDB 实例。为了模拟这一点，我们创建了一个返回 200 OK 的 HTTP 服务&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;expedia&#34;&gt;Expedia&lt;/h4&gt;
&lt;p&gt;包含三个微服务：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;按相关性顺序返回评论&lt;/li&gt;
&lt;li&gt;按时间顺序返回评论&lt;/li&gt;
&lt;li&gt;API 网关：根据可用性从 Review ML 或 Review Time 向用户返回评论&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;mailchimp&#34;&gt;Mailchimp&lt;/h4&gt;
&lt;p&gt;包含3个微服务：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Requestmapper：将电子邮件活动中的高亮URL映射到实际资源URL&lt;/li&gt;
&lt;li&gt;DB Primary：他们数据库的主要副本&lt;/li&gt;
&lt;li&gt;DB Secondary：他们数据库的次要副本&lt;/li&gt;
&lt;li&gt;App Server：向Requestmapper服务请求解析URL，然后对数据库执行read-then-write请求，当主副本不可用时回退到二级数据库副本&lt;/li&gt;
&lt;li&gt;负载均衡器：负载均衡请求&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;与 Mailchimp 的实际部署相比，我们表示为服务的一些组件实际上是非 HTTP 服务。我们在这里列举了这些差异和调整。首先，DB Primary 和 Secondary 服务是 MySQL 实例。为了模拟这一点，我们创建了一个 HTTP 服务，该服务在成功读取或写入时返回 200 OK，如果数据库为只读则返回 403 Forbidden。其次，Load Balancer 服务是一个 HAProxy 实例。为了模拟这一点，我们创建了一个 HTTP 代理。&lt;/p&gt;
&lt;p&gt;Mailchimp 示例的错误包含两个：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;MySQL 实例只读。当 MySQL 实例为只读时，数据库会返回一个错误，该错误在代码的某个区域未处理。由于 Mailchimp 使用 PHP，这个错误被直接呈现到页面的输出中，我们通过将 403 Forbidden 响应转换为直接插入页面的输出来模拟这一点。&lt;/li&gt;
&lt;li&gt;Requestmapper 不可用。当 Requestmapper 服务不可用时，App Server 无法正确处理错误，向负载均衡器返回 500 Internal Server Error。但是，负载均衡器仅配置为通过返回格式化的错误页面来处理 503 Service Unavailable 错误。这是丢失或不正确的故障处理示例。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;netflix&#34;&gt;Netflix&lt;/h4&gt;
&lt;p&gt;包含10个微服务，与Audible示例类似，我们使用服务模拟 Netflix 移动应用程序，这里称为客户端：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;客户端：模拟移动客户端&lt;/li&gt;
&lt;li&gt;API 网关：组装用户主页&lt;/li&gt;
&lt;li&gt;用户档案：返回档案信息&lt;/li&gt;
&lt;li&gt;书签：返回上次查看的位置&lt;/li&gt;
&lt;li&gt;我的列表：返回用户列表中的电影列表&lt;/li&gt;
&lt;li&gt;用户推荐：返回用户推荐的电影&lt;/li&gt;
&lt;li&gt;评分：返回用户的评分&lt;/li&gt;
&lt;li&gt;遥测：记录遥测信息&lt;/li&gt;
&lt;li&gt;趋势：返回热门电影&lt;/li&gt;
&lt;li&gt;全局推荐：返回推荐的电影&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Netflix示例的bug包含三个，可以使用环境变量激活：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;错误配置的超时。用户配置文件服务以 10 秒的超时时间调用遥测服务；但是，API 网关会以 1 秒的超时时间调用用户配置文件服务&lt;/li&gt;
&lt;li&gt;服务回退到同一服务器。如果我的列表服务不可用，系统将重试（我的理解是，一个服务有3个实例，其中一个实例不可用，本应该请求其他实例，结果再次请求了那个不可用的实例）&lt;/li&gt;
&lt;li&gt;没有回退的关键服务。用户配置文件服务没有后备处理逻辑&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>微服务网关--kong</title>
        <link>https://lizonglingo.github.io/p/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E7%BD%91%E5%85%B3--kong/</link>
        <pubDate>Thu, 02 Dec 2021 19:20:18 +0800</pubDate>
        
        <guid>https://lizonglingo.github.io/p/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E7%BD%91%E5%85%B3--kong/</guid>
        <description>&lt;p&gt;Kong网关是一个轻量级、高性能、可拓展的云原生API网关。下面我们以docker的形式搭建kong环境。&lt;/p&gt;
&lt;h3 id=&#34;1-拉取kong-gateway镜像并打上标签&#34;&gt;1. 拉取kong-gateway镜像并打上标签&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;lzl@lzl:~$ docker pull kong/kong-gateway:2.6.0.1-alpine
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;2.6.0.1-alpine: Pulling from kong/kong-gateway
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;a0d0a0d46f8b: Already exists 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;292d8c0f5367: Pulling fs layer 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;8f939e93459a: Pulling fs layer 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;8335045176a7: Pulling fs layer 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;2.6.0.1-alpine: Pulling from kong/kong-gateway
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;a0d0a0d46f8b: Already exists 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;292d8c0f5367: Pull complete 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;8f939e93459a: Pull complete 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;8335045176a7: Pull complete 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Digest: sha256:20d1f65138b36ffeadd6c63abe0dc1b496d42ab7bd49553328524d0bbf622026
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Status: Downloaded newer image &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; kong/kong-gateway:2.6.0.1-alpine
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;docker.io/kong/kong-gateway:2.6.0.1-alpine
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;lzl@lzl:~$ docker tag kong/kong-gateway:2.6.0.1-alpine kong
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;2-创建kong和其组件使用的网络&#34;&gt;2. 创建kong和其组件使用的网络&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;lzl@lzl:~$ docker network create kong-net
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;db4a092863e8dc77f26cf4aa43ffb62d09e19c1c66e9b15418d92277850c83a3
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;lzl@lzl:~$ docker network ls
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;NETWORK ID     NAME              DRIVER    SCOPE
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;505f6cc0e5b7   bridge            bridge    local
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;9027fdbdc8f6   docker_gwbridge   bridge    local
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;7a84b4fa35eb   host              host      local
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;db4a092863e8   kong-net          bridge    local
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;66b37b687b76   none              null      local
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;3配置kong所使用的database&#34;&gt;3.配置kong所使用的database&lt;/h3&gt;
&lt;p&gt;这里我们使用&lt;code&gt;postgres&lt;/code&gt;，当然也可以使用别的数据库。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;lzl@lzl:~$ docker run -d --name kong-database &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&amp;gt; --network&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;kong-net &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&amp;gt; -p 5432:5432 &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&amp;gt; -e &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;POSTGRES_USER=kong&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&amp;gt; -e &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;POSTGRES_DB=kong&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&amp;gt; -e &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;POSTGRES_PASSWORD=kong&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&amp;gt; postgres:9.6
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;0d9691c833ab59555dadee339a1f7e15fcc4948793bede7a39112e9f39d62ee7
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;4-正式启动kong之前需要迁移数据库&#34;&gt;4. 正式启动kong之前需要迁移数据库&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;lzl@lzl:~$ docker run --rm &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&amp;gt; --network&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;kong-net &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&amp;gt; -e &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;KONG_DATABASE=postgres&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&amp;gt; -e &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;KONG_PG_HOST=kong-database&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&amp;gt; -e &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;KONG_PG_USER=kong&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&amp;gt; -e &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;KONG_PG_PASSWORD=kong&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&amp;gt; -e &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;KONG_CASSANDRA_CONTACT_POINTS=kong-database&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&amp;gt; kong:latest kong migrations bootstrap
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Bootstrapping database...
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;migrating core on database &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;kong&amp;#39;&lt;/span&gt;...
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;core migrated up to: 000_base &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;executed&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;core migrated up to: 003_100_to_110 &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;executed&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;core migrated up to: 004_110_to_120 &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;executed&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;core migrated up to: 005_120_to_130 &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;executed&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;···
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;···
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;migrating enterprise.response-transformer-advanced on database &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;kong&amp;#39;&lt;/span&gt;...
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;enterprise.response-transformer-advanced migrated up to: 001_1500_to_2100 &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;executed&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;82&lt;/span&gt; migrations processed
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;82&lt;/span&gt; executed
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Database is up-to-date
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;5-启动kong&#34;&gt;5. 启动kong&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;lzl@lzl:~$ docker run -d --name kong &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&amp;gt; --network&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;kong-net &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&amp;gt; -e &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;KONG_DATABASE=postgres&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&amp;gt; -e &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;KONG_PG_HOST=kong-database&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&amp;gt; -e &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;KONG_PG_USER=kong&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&amp;gt; -e &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;KONG_PG_PASSWORD=kong&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&amp;gt; -e &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;KONG_CASSANDRA_CONTACT_POINTS=kong-database&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&amp;gt; -e &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;KONG_PROXY_ACCESS_LOG=/dev/stdout&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&amp;gt; -e &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;KONG_ADMIN_ACCESS_LOG=/dev/stdout&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&amp;gt; -e &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;KONG_PROXY_ERROR_LOG=/dev/stderr&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&amp;gt; -e &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;KONG_ADMIN_ERROR_LOG=/dev/stderr&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&amp;gt; -e &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;KONG_ADMIN_LISTEN=0.0.0.0:8001, 0.0.0.0:8444 ssl&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&amp;gt; -p 8000:8000 &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&amp;gt; -p 8443:8443 &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&amp;gt; -p 8001:8001 &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&amp;gt; -p 8444:8444 &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&amp;gt; kong:latest
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;e549737ac5cd6bcc49bcf073619950402b40f312fbe7affc028c6b46039a7f20
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;到这里，&lt;code&gt;kong-gateway&lt;/code&gt;就已经启动了。这里开放的几个端口说明一下：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;端口&lt;/th&gt;
&lt;th&gt;用途&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;8000&lt;/td&gt;
&lt;td&gt;监听客户端传入的HTTP请求并进行转发&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;8443&lt;/td&gt;
&lt;td&gt;监听客户端传入的HTTPS请求并进行转发&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;8001&lt;/td&gt;
&lt;td&gt;Admin API，管理者通过这个端口对Kong的监听服务进行配置、插件设置、API的配置以及负载均衡等&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;8444&lt;/td&gt;
&lt;td&gt;可通过此端口对HTTPS请求进行监控&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;6-为配置kong的可视化界面konga配置数据库&#34;&gt;6. 为配置kong的可视化界面konga配置数据库&lt;/h3&gt;
&lt;p&gt;进入到&lt;code&gt;postgres&lt;/code&gt;中添加新的用户，并创建konga用的数据库。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;lzl@lzl:~$ docker exec -it kong-database /bin/bash
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;root@0d9691c833ab:/# psql -U kong -W
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Password &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; user kong: 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;psql &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;9.6.24&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Type &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;help&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; help.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kong&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# create user konga with password &amp;#39;konga&amp;#39;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;CREATE ROLE
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kong&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# create database konga owner konga;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;CREATE DATABASE
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kong&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# grant all privileges on database konga to konga;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;GRANT
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kong&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# &lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;7-预启动konga&#34;&gt;7. 预启动konga&lt;/h3&gt;
&lt;p&gt;这一步主要是为了konga配置数据库。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;lzl@lzl:~$ docker run --rm pantsel/konga:latest &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&amp;gt; -c prepare &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&amp;gt; -a postgres &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&amp;gt; -u postgresql://konga:konga@10.0.20.25:5432/konga
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;debug: Preparing database...
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Using postgres DB Adapter.
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Database exists. Continue...
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;debug: Hook:api_health_checks:process&lt;span style=&#34;color:#f92672&#34;&gt;()&lt;/span&gt; called
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;debug: Hook:health_checks:process&lt;span style=&#34;color:#f92672&#34;&gt;()&lt;/span&gt; called
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;debug: Hook:start-scheduled-snapshots:process&lt;span style=&#34;color:#f92672&#34;&gt;()&lt;/span&gt; called
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;debug: Hook:upstream_health_checks:process&lt;span style=&#34;color:#f92672&#34;&gt;()&lt;/span&gt; called
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;debug: Hook:user_events_hook:process&lt;span style=&#34;color:#f92672&#34;&gt;()&lt;/span&gt; called
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;debug: Seeding User...
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;debug: User seed planted
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;debug: Seeding Kongnode...
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;debug: Kongnode seed planted
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;debug: Seeding Emailtransport...
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;debug: Emailtransport seed planted
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;debug: Database migrations completed!
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;8-启动konga&#34;&gt;8. 启动konga&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;lzl@lzl:~$ docker run -d --name konga &lt;span style=&#34;color:#ae81ff&#34;&gt;\-&lt;/span&gt;-network&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;kong-net 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&amp;gt; -e &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;DB_ADAPTER=postgres&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&amp;gt; -e &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;DB_HOST=10.0.20.25&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&amp;gt; -e &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;DB_PORT=5432&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&amp;gt; -e &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;DB_USER=konga&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&amp;gt; -e &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;DB_PASSWORD=konga&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&amp;gt; -e &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;DB_DATABASE=konga&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&amp;gt; -e &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;DB_PG_SCHEMA=public&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&amp;gt; -e &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;NODE_ENV=production&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;&amp;gt; -p 1337:1337 pantsel/konga
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;7031e0fb024b3c1919895b1f9ae516f06a3e95a805aee0076a3cfb99f3d889f5
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 开放这个端口，以免不能正常访问&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;lzl@lzl:~$ sudo iptables -A INPUT -p udp --dport &lt;span style=&#34;color:#ae81ff&#34;&gt;1337&lt;/span&gt; -j ACCEPT
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;lzl@lzl:~$ sudo iptables -A INPUT -p tcp --dport &lt;span style=&#34;color:#ae81ff&#34;&gt;1337&lt;/span&gt; -j ACCEPT
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;9-现在就可以打开界面玩一玩了&#34;&gt;9. 现在就可以打开界面玩一玩了&lt;/h3&gt;
&lt;p&gt;创建连接，将konga连接到kong的API。这里注意&lt;code&gt;Kong Admin URL&lt;/code&gt;就写&lt;code&gt;http://kong:8001&lt;/code&gt;，我写&lt;code&gt;http://localhost:8001&lt;/code&gt;怎么都连不上。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lizonglin313/MyPicGo/master/20211202164224.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lizonglin313/MyPicGo/master/20211202164254.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;创建服务。这个服务可以是一个应用，也可以是某个接口。我把我的博客作为服务，让网关帮我做转发。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lizonglin313/MyPicGo/master/20211202164536.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;然后配置转发路由。这里输入完一定要按下回车。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lizonglin313/MyPicGo/master/20211202171542.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;现在访问&lt;code&gt;:8000/blog&lt;/code&gt;端口会自动转到。但是目前还存在许多问题。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;使用kong之后我的宿主机无法访问虚拟机的内容了。&lt;/li&gt;
&lt;li&gt;对于kong网关的转发和路由机制还没搞清楚。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/lizonglin313/MyPicGo/master/20211202171616.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;除此之外，kong-gateway还可以接入身份认证插件（如：JWT），链路追踪插件（如：zipkin），监控插件（如：prometheus），值得好好研究一下。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;参考：&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.cnblogs.com/jerryqm/p/12901036.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.cnblogs.com/jerryqm/p/12901036.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.jianshu.com/p/551a4c61e224&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.jianshu.com/p/551a4c61e224&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
</description>
        </item>
        
    </channel>
</rss>
