<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>链路追踪 on Li Duo</title>
        <link>https://lizonglingo.github.io/categories/%E9%93%BE%E8%B7%AF%E8%BF%BD%E8%B8%AA/</link>
        <description>Recent content in 链路追踪 on Li Duo</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-CN</language>
        <lastBuildDate>Thu, 21 Apr 2022 14:33:47 +0800</lastBuildDate><atom:link href="https://lizonglingo.github.io/categories/%E9%93%BE%E8%B7%AF%E8%BF%BD%E8%B8%AA/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>IEEE CLOUD 21 云上资源管理相关合辑</title>
        <link>https://lizonglingo.github.io/p/ieee-cloud-21-%E4%BA%91%E4%B8%8A%E8%B5%84%E6%BA%90%E7%AE%A1%E7%90%86%E7%9B%B8%E5%85%B3%E5%90%88%E8%BE%91/</link>
        <pubDate>Thu, 21 Apr 2022 14:33:47 +0800</pubDate>
        
        <guid>https://lizonglingo.github.io/p/ieee-cloud-21-%E4%BA%91%E4%B8%8A%E8%B5%84%E6%BA%90%E7%AE%A1%E7%90%86%E7%9B%B8%E5%85%B3%E5%90%88%E8%BE%91/</guid>
        <description>&lt;blockquote&gt;
&lt;p&gt;本篇整理自IEEE CLOUD&#39;21会议中的文章，主题为云背景下的资源管理。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;runwild-resource-management-system-withgeneralized-modeling-for-microservices-on-cloud&#34;&gt;RunWild: Resource Management System withGeneralized Modeling for Microservices on Cloud&lt;/h2&gt;
&lt;h3 id=&#34;star摘要&#34;&gt;:star:摘要&lt;/h3&gt;
&lt;h4 id=&#34;问题背景&#34;&gt;问题背景&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;微服务内部通信的复杂性，必须考虑资源利用、调度策略和请求均衡之间的平衡，以防止跨微服务级联的服务质量下降。&lt;/strong&gt;&lt;/p&gt;
&lt;h4 id=&#34;文章做了什么&#34;&gt;文章做了什么&lt;/h4&gt;
&lt;p&gt;提出资源管理系统&lt;strong&gt;RunWild&lt;/strong&gt;，可以控制所有节点涉及到的微服务管理：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;扩缩容&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;调度&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;自动&lt;/strong&gt;的根据&lt;strong&gt;指定性能表现&lt;/strong&gt;的&lt;strong&gt;负载和性能平衡优化&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;统一的&lt;strong&gt;持续部署方案&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;着重强调了&lt;strong&gt;协同metrics感知&lt;/strong&gt;在&lt;strong&gt;预测资源使用和制定部署计划&lt;/strong&gt;中的重要性。&lt;/p&gt;
&lt;p&gt;在IBM云进行实验，&lt;strong&gt;以K8s的自动调度为基线&lt;/strong&gt;，减少P90响应时间11%，增加10%的吞吐率，降低30%的资源使用。&lt;/p&gt;
&lt;h4 id=&#34;贡献&#34;&gt;贡献&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;扩展的部署框架：&lt;strong&gt;适用于K8s的调度框架&lt;/strong&gt;，用来在资源分配、部署、和运行时来控制部署机制；&lt;/li&gt;
&lt;li&gt;通用的建模方法：综合考虑微服务特性、节点的相对独立性、工作负载和全局协同节点状态感知，通过结合聚类和回归技术预测资源使用；&lt;/li&gt;
&lt;li&gt;微服务间交互指标：一个称为内聚的指标反映了在同一个&lt;strong&gt;节点上放置高度相互通信的微服务的优势&lt;/strong&gt;；&lt;/li&gt;
&lt;li&gt;通过&lt;strong&gt;Service Mesh&lt;/strong&gt;对运行时工作负载进行分区：利用服务网格操作流量路由，用其控制能力来划分工作负载以匹配资源的分配。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;star现有技术存在的问题&#34;&gt;:star:现有技术存在的问题&lt;/h3&gt;
&lt;h4 id=&#34;水平伸缩&#34;&gt;水平伸缩&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;超过某个阈值时，实例的增多与性能表现的增长不匹配，正如收益递减定律所解释的那样；&lt;/li&gt;
&lt;li&gt;资源过度分配并不会显著增加性能表现；&lt;/li&gt;
&lt;li&gt;而资源不足会导致性能下降或者致命错误。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;垂直伸缩&#34;&gt;垂直伸缩&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;K8s虽然可以支持HPA和VPA，但是不能一起工作，同时进行HPA和VPA难免会造成干扰。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;此外，复杂的资源依赖，全局的资源调度策略使得伸缩方案受多方面影响。&lt;/p&gt;
&lt;p&gt;文章的动机是&lt;strong&gt;识别、描述和管理所有因素和维度&lt;/strong&gt;，以实现&lt;strong&gt;统一的部署解决方案&lt;/strong&gt;，而不是运行相互干扰的机制。&lt;/p&gt;
&lt;h4 id=&#34;部署的三个角度&#34;&gt;部署的三个角度&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;所部署的服务的实例副本数；&lt;/li&gt;
&lt;li&gt;节点上每个实例所得到的资源；&lt;/li&gt;
&lt;li&gt;每个实例的网络容量。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;然后引出下面4个重要的问题：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;调度所涉及到的策略、资源和具体情景很复杂，要考虑的东西太多；&lt;/li&gt;
&lt;li&gt;同一节点上部署的服务可能&lt;strong&gt;对资源的争用很敏感&lt;/strong&gt;；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;微服务之间的通信，亲和性&lt;/strong&gt;等因素会影响到&lt;strong&gt;全局的服务性能表现、响应事件及吞吐量&lt;/strong&gt;，最好的方式是使部署的微服务&lt;strong&gt;减少跨节点的通信&lt;/strong&gt;；&lt;/li&gt;
&lt;li&gt;如何将&lt;strong&gt;请求负载均衡到不同实例以带来更好的网络表现&lt;/strong&gt;，虽然Service Mesh能够实现负载的分发，但是难以解决上述问题。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;文章列举了一些其他文章做的工作，并对比这些工作解决了上述4个问题中的哪些：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/image-20220423213910376.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220423213910376&#34;
	
	
&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;该文会精读，请关注最新的文章。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;fast-and-efficient-performance-tuning-of-microservices&#34;&gt;Fast and Efficient Performance Tuning of Microservices&lt;/h2&gt;
&lt;h3 id=&#34;star摘要-1&#34;&gt;:star:摘要&lt;/h3&gt;
&lt;p&gt;针对使用&lt;strong&gt;容器部署的微服务架构应用&lt;/strong&gt;，&lt;strong&gt;以Kubernetes、Docker Swarm容器管理平台为依托&lt;/strong&gt;。在应用正式部署上线之前，也就是在&lt;strong&gt;pre-deployment&lt;/strong&gt;阶段，&lt;strong&gt;迭代的根据资源使用相关指标&lt;/strong&gt;，结合&lt;strong&gt;类多目标优化算法(文章称为heuristic optimization algorithm)&lt;strong&gt;对&lt;/strong&gt;资源分配进行调优&lt;/strong&gt;。&lt;/p&gt;
&lt;h3 id=&#34;star系统架构&#34;&gt;:star:系统架构&lt;/h3&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ol&gt;
&lt;li&gt;将应用部署到云平台；&lt;/li&gt;
&lt;li&gt;进行负载注入；&lt;/li&gt;
&lt;li&gt;基于Jaeger的监控系统开始进行性能测试和追踪(对每个微服务)，收集数据，如响应时间和资源的使用量；&lt;/li&gt;
&lt;li&gt;通过Jaeger解析服务调用序列；&lt;/li&gt;
&lt;li&gt;由Tuning Agent参照服务序列信息、不同类别请求的响应时间和平均资源使用进行调优；&lt;/li&gt;
&lt;li&gt;Tuning Agent预估每个微服务的新的CPU配额信息；&lt;/li&gt;
&lt;li&gt;将这些信息存储到Tuning数据库中；&lt;/li&gt;
&lt;li&gt;编排器根据这些信息对服务进行迭代部署。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;star测量优化的依赖指标&#34;&gt;:star:测量、优化的依赖指标&lt;/h3&gt;
&lt;p&gt;需要对服务进行&lt;strong&gt;请求的注入&lt;/strong&gt;来进行测量，主要指标是&lt;strong&gt;服务响应时间&lt;/strong&gt;。涉及到&lt;strong&gt;链路追踪、性能监控&lt;/strong&gt;。&lt;/p&gt;
&lt;h3 id=&#34;star调优模型抽象&#34;&gt;:star:调优模型抽象&lt;/h3&gt;
&lt;h4 id=&#34;小背景前提和假设&#34;&gt;小背景、前提和假设&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;应用需要一些特定的工作负载$W$&lt;/strong&gt;，这些工作负载发生在特定的情境，例如在线商城的Black Friday。因此，调优过程可以对其他感兴趣的工作负载重放，从而产生一系列特定于工作负载的配置，可以在部署应用程序时适当地使用。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;本文重点关注CPU资源的限制&lt;/strong&gt;，但是该模型可以拓展到其他资源。&lt;/li&gt;
&lt;li&gt;应用包含**$K$个微服务**，每个微服务运行在自己的container中。&lt;/li&gt;
&lt;li&gt;每个应用支持**$C$种不同的请求类别**。&lt;/li&gt;
&lt;li&gt;每个请求类别**$c$关联到不同的响应时间$T_c$**。&lt;/li&gt;
&lt;li&gt;每类请求**$c$涉及到一个微服务调用序列$S_c$**。&lt;/li&gt;
&lt;li&gt;因此这个序列中每个&lt;strong&gt;微服务$k$都涉及到一个CPU需求&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;主机上对应的&lt;strong&gt;服务$k$所需的CPU配额表示为$\alpha_k$&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;资源分配问题抽象&#34;&gt;资源分配问题抽象&lt;/h4&gt;
&lt;p&gt;问题可以抽象为：在&lt;strong&gt;满足响应时间的需求下，求解对每个微服务CPU配额的最小值&lt;/strong&gt;。&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;ol&gt;
&lt;li&gt;目标为最小化CPU配额；&lt;/li&gt;
&lt;li&gt;需要满足前提条件，即：资源配额能够使某类请求的响应时间$R_c$小于等于目标值$T_c$；&lt;/li&gt;
&lt;li&gt;其中响应时间$R_c$是工作负载$W$和对$K$个服务CPU配额的函数；&lt;/li&gt;
&lt;li&gt;最后限制CPU需求总额是有限的。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;star应用案例及实验&#34;&gt;:star:应用案例及实验&lt;/h3&gt;
&lt;p&gt;使用的微服务案例&lt;strong&gt;Bookstore&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/image-20220419153253242.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220419153253242&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;star我的问题&#34;&gt;:star:我的问题&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;工作负载的模拟具体如何实现？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;有哪些开源微服务应用真正可用又具有一定的代表性？&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&#34;skynet-performance-driven-resource-management-for-dynamic-workloads&#34;&gt;Skynet: Performance-driven Resource Management for Dynamic Workloads&lt;/h2&gt;
&lt;h3 id=&#34;star摘要-2&#34;&gt;:star:摘要&lt;/h3&gt;
&lt;h4 id=&#34;问题背景和主要矛盾&#34;&gt;问题背景和主要矛盾&lt;/h4&gt;
&lt;p&gt;云环境下，资源利用率和应用的性能表现之间的矛盾。&lt;/p&gt;
&lt;h4 id=&#34;难点&#34;&gt;难点&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;用户常会&lt;strong&gt;分配过多的资源&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;应用的&lt;strong&gt;多样性和动态性&lt;/strong&gt;，&lt;strong&gt;工作负载的动态性及难以预测性&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;性能表现取决于&lt;strong&gt;多种不同资源&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;文章做了什么怎么做的&#34;&gt;文章做了什么，怎么做的&lt;/h4&gt;
&lt;p&gt;提出Skynet，针对上述三个难点，可以自动对云资源进行管理。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;评估资源需求&lt;strong&gt;依赖的指标&lt;/strong&gt;：Skynet使用performance level objectives(PLOs)准确捕捉用户对所需性能的意图，将用户从资源分配循环中解放。Skynet&lt;strong&gt;通过目标PLO去预估资源需求&lt;/strong&gt;，使用Poportional Integral Derivative(PID)控制器对每个应用调整对应的参数。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;资源需求&lt;strong&gt;计算、分配、调度方法&lt;/strong&gt;：为捕获每个应用对不同资源依赖，&lt;strong&gt;Skynet扩展了传统的一维PID控制器&lt;/strong&gt;(传统的单输入单输出)，实现对CPU、内存、I/O和网络吞吐的预估。Skynet建立一个动态模型，对于每个应用，将目标PLOs映射到资源，同时考虑多种资源和变化的输入负载。事实上，Skynet处于一个&lt;strong&gt;动态循环控制&lt;/strong&gt;来预估资源。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;实现和评估&lt;/strong&gt;：在&lt;strong&gt;kubernetes中将skynetas实现为端到端的定制调度程序&lt;/strong&gt;，并在5个节点的私有集群和60个裸金属服务器AWS上使用真实的工作负载对其进行评估。以K8s为基线，PLO违规降低7.4倍，资源利用提高两倍。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;star系统架构-1&#34;&gt;:star:系统架构&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/image-20220421114835655.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220421114835655&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;用户可以指定PLOs，明确对吞吐量、延迟、处理时间等指标的需求。Skynet根据这些PLOs，使用PID[41]预估每个应用的资源需求量。动态的将PLO映射到资源需求，这样一来可以让Skynet适应变化的工作负载和每个应用不同的生命阶段。&lt;/p&gt;
&lt;h4 id=&#34;示例&#34;&gt;示例&lt;/h4&gt;
&lt;p&gt;一个web应用PLO为1000请求/秒。Skynet给每个新应用分配一个预定义容器。在执行阶段，Skynet主要使用两个组件：Resource Estimator(RE)和Resource Assigner(RA)，来周期性的调整资源配额以满足PLO：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Skynet周期性监控应用性能指标，如果触发PLO违规，会触发RE。&lt;/li&gt;
&lt;li&gt;RE基于PLO调整PIDs的参数。&lt;/li&gt;
&lt;li&gt;基于目标PLO，RE预估应用新的资源需求。&lt;/li&gt;
&lt;li&gt;当可分配资源满足条件时，RA调整应用容器。&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;放置应用以及根据控制器更新应用放置&#34;&gt;放置应用以及根据控制器更新应用放置&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;确定应用资源需求量后，Skynet决定容器的资源限额和放置。具体来说，包括容器打包，节点绑定以及资源配额。其中，容器大小和放置由于需要考虑多种资源的约束，远比打包应用复杂。放置应用的目标是：避免应用间干扰，提高应用性能表现。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;当新应用到来时，Skynet进行扫描，查看是否有某个服务节点可以单独满足应用的资源需求，如果不存在这样的服务节点，就迭代执行下列步骤：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;增加一个容器的数量；&lt;/li&gt;
&lt;li&gt;在容器之间平均分配资源；&lt;/li&gt;
&lt;li&gt;找到能够满足容器需求，并且负载最高的服务节点；&lt;/li&gt;
&lt;li&gt;如果没有，循环执行上述步骤。&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;调整应用资源配额。每次请求改变资源需求时，有三种可能：(理解的有些别扭？)&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;资源不够。该情况下，Skynet决定有没有现存的容器可以移除。然后基于节点负载对节点进行排序，移除额外的容器。&lt;/li&gt;
&lt;li&gt;节点上的可用资源早已被分配给应用。Skynet在容器之间平均增加应用程序的资源，以匹配新的请求。&lt;/li&gt;
&lt;li&gt;可用资源分布在不同的服务节点上。Skynet以放置新应用的思路放置新的容器。&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;总的说，就是处理，&lt;strong&gt;容器应该放置在哪个节点上的问题&lt;/strong&gt;。算法思路如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/image-20220421143003087.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220421143003087&#34;
	
	
&gt;&lt;/p&gt;
&lt;h4 id=&#34;在kubernetes上的实现&#34;&gt;在Kubernetes上的实现&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/image-20220421132506202.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220421132506202&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;使用Golang实现自定义调度器。使用Prometheus进行监控。代码开源[11]。&lt;/p&gt;
&lt;h3 id=&#34;star我的问题-1&#34;&gt;:star:我的问题&lt;/h3&gt;
&lt;h4 id=&#34;关于pid控制理论的补充&#34;&gt;关于PID控制理论的补充&lt;/h4&gt;
&lt;p&gt;已经不止一次在论文中看到使用PID来调整资源分配了。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://zhuanlan.zhihu.com/p/39573490&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://zhuanlan.zhihu.com/p/39573490&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&#34;如果要使用pid算法再细读&#34;&gt;如果要使用PID算法，再细读&lt;/h4&gt;
&lt;p&gt;获得监控数据后具体怎处理？&lt;/p&gt;
&lt;p&gt;分配资源的具体方法？&lt;/p&gt;
&lt;h2 id=&#34;konveyor-move2kube-automatedreplatforming-of-applications-to-kubernetes&#34;&gt;Konveyor Move2Kube: AutomatedReplatforming of Applications to Kubernetes&lt;/h2&gt;
&lt;h3 id=&#34;star摘要-3&#34;&gt;:star:摘要&lt;/h3&gt;
&lt;p&gt;文章提出Move2Kube，一个再部署框架，能够自动调整部署细节，并通过部署pipeline&lt;strong&gt;将非Kubernetes平台部署的应用转移到Kubernetes平台上&lt;/strong&gt;，同时最小限度修改应用架构和实现。&lt;/p&gt;
&lt;p&gt;此外，文章提出&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一个最小化的中间表示，不同的应用部署构建都可以转化到这个中间表示上来。&lt;/li&gt;
&lt;li&gt;一个扩展框架，用于添加对新的部署源平台和目标中间件的支持，同时允许定制化。&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Move2Kube已经开源：https://move2kube.konveyor.io/&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&#34;要解决什么问题&#34;&gt;要解决什么问题&lt;/h4&gt;
&lt;p&gt;在不是K8s平台部署的应用迁移到K8s平台上，同时应该最小限度的修改原系统的实现和软件架构。&lt;/p&gt;
&lt;h4 id=&#34;挑战难点在哪里&#34;&gt;挑战、难点在哪里&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;应用规模：企业级应用往往有上千个组件，人工迁移费时费力；&lt;/li&gt;
&lt;li&gt;应用异构：多样的部署平台，多样的应用架构和种类；&lt;/li&gt;
&lt;li&gt;不同的代码源、组件仓库：代码源或者使用的组件分布在不同的仓库中，很难将其组织到一起，如何分布的数千个目录中找到正确的文件很有挑战；&lt;/li&gt;
&lt;li&gt;容器化挑战：将应用容器化时，对于优化配置和分层安全很有必要，需要对容器内部、镜像技术和应用配置有深入的理解；&lt;/li&gt;
&lt;li&gt;目标平台映射：找到正确的不同平台的配置映射关系是困难的，例如如何选择从简单的K8s service转换到Istio的配置中；&lt;/li&gt;
&lt;li&gt;应用的最佳实践：K8s有最佳实践[6]，如何确保迁移使用K8s的最佳实践；&lt;/li&gt;
&lt;li&gt;定制化的需求和有效的Day 2 Operation：针对不同应用和需求定制化的配置以适应平台特性需要一定的经验和时间，同时需要考虑Day 2 Operation。&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;关于什么是Day 2 Operation：https://jimmysong.io/blog/what-is-day-2-operation/&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&#34;move2kube&#34;&gt;Move2Kube&lt;/h4&gt;
&lt;p&gt;这个开源框架旨在解决应用迁移到Kubernetes平台过程中出现的上述问题。它提供了标准化的Pipeline，包括&lt;strong&gt;容器化、参数化、配置优化、定制化&lt;/strong&gt;等解决方案，满足面向&lt;strong&gt;特定平台的多源、多服务&lt;/strong&gt;的应用部署迁移。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;该文不太属于资源管理方面。&lt;/p&gt;
&lt;/blockquote&gt;
</description>
        </item>
        <item>
        <title>3MileBeach: A Tracer with Teeth</title>
        <link>https://lizonglingo.github.io/p/3milebeach-a-tracer-with-teeth/</link>
        <pubDate>Mon, 14 Mar 2022 19:12:33 +0800</pubDate>
        
        <guid>https://lizonglingo.github.io/p/3milebeach-a-tracer-with-teeth/</guid>
        <description>&lt;blockquote&gt;
&lt;p&gt;来源：ACM SoCC&#39;21&lt;/p&gt;
&lt;p&gt;作者：UC Santa Cruz&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;摘要&#34;&gt;摘要&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;提出&lt;em&gt;3MileBeach&lt;/em&gt;，一个针对微服务架构的追踪和故障注入平台。&lt;/li&gt;
&lt;li&gt;通过介入一个消息序列化库，避免了代码层面的监控（这是传统的追踪和故障注入会做的），可以提供更细粒度的追踪和故障注入。&lt;/li&gt;
&lt;li&gt;&lt;em&gt;3MileBeach&lt;/em&gt;提供了一个消息级别的分布式追踪，其开销只有最先进追踪框架的一半；提供故障注入比现有方案有更高的精度。&lt;/li&gt;
&lt;li&gt;使用&lt;em&gt;3MileBeach&lt;/em&gt;进行一种新型故障注入&lt;em&gt;Temporal Fault Injection&lt;/em&gt;（TFI）。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;追踪和故障注入现存的问题&#34;&gt;追踪和故障注入现存的问题&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;运行时开销和工作量过大；&lt;/li&gt;
&lt;li&gt;对异构应用程序和基础代码，基础设置的入侵性改动；&lt;/li&gt;
&lt;li&gt;微服务组件以不同的语言进行设计，之间使用不同的通信机制；&lt;/li&gt;
&lt;li&gt;故障注入需要在精度、粒度和成本上进行取舍。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;3milebeach的能力&#34;&gt;3MileBeach的能力&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;其只需要应用程序级的插件就能实现功能；&lt;/li&gt;
&lt;li&gt;提供细粒度的追踪，比最先进的技术节省25%~50%的成本；&lt;/li&gt;
&lt;li&gt;提供丰富且严格的跟踪指标；&lt;/li&gt;
&lt;li&gt;支持大规模并发故障注入，适用于生产环境；&lt;/li&gt;
&lt;li&gt;实现新型故障注入模式TFI，这基于时序谓词（nlp中的技术），可以识别可能处于休眠状态中的技术。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;motivation&#34;&gt;Motivation&lt;/h2&gt;
&lt;p&gt;目前最先进的分布式系统故障注入存在两个基础的问题：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;存在对细粒度、并发测试、不受blast radius影响的需求；&lt;/li&gt;
&lt;li&gt;现有的故障注入技术没有足够的表现力。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;time-of-check-to-time-of-usertocttou-error&#34;&gt;Time of Check to Time of User(TOCTTOU error)&lt;/h3&gt;
&lt;p&gt;假设一个在线购物平台存在如下问题，用户准备为购物车的物品付款时调用前端：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;前端发送一条消息给信用卡服务来验证（一个下游服务用来验证用户信用卡信息）；&lt;/li&gt;
&lt;li&gt;如果验证成功，前端会发送信息给商品服务来计算费用；&lt;/li&gt;
&lt;li&gt;计算完成后再次调用信用服务，扣除费用。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;试想这种情况：第一次调用信用卡服务成功，通过验证，而第二次（提出扣费申请时）发送了一个错误请求。&lt;/p&gt;
&lt;p&gt;简单来说，同一个服务在一小段时间后从可用状态变为不可用。&lt;/p&gt;
&lt;h3 id=&#34;temporal-discretization&#34;&gt;Temporal Discretization&lt;/h3&gt;
&lt;p&gt;大多数故障注入工具没有考虑到时间维度上的故障。&lt;/p&gt;
&lt;p&gt;首先，时间是一个连续的概念，往往考虑在请求的生命周期里发生故障，而忽略在发送请求时刻、流传输中发生故障；在一个确定时间引入故障或许没有什么意义。&lt;/p&gt;
&lt;p&gt;以上述案例为例，将前端服务视为黑盒，可以观察到信用卡服务可能不可用的四个离散的逻辑时间：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;在前端的第一次请求到来之前；&lt;/li&gt;
&lt;li&gt;在前端第一次请求到来之后，信用卡服务返回响应之前；&lt;/li&gt;
&lt;li&gt;在信用卡服务返回第一次响应之后，和前端请求第二次到来之前；&lt;/li&gt;
&lt;li&gt;在前端第二次请求到来之后，信用卡服务返回第二次响应之前。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;如果以粗粒度来看，前端调用信用卡服务发生的错误实际上又&lt;strong&gt;可以分为粒度更小的四种导致错误的原因&lt;/strong&gt;。&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;h3 id=&#34;communication-is-the-thing&#34;&gt;Communication is The Thing&lt;/h3&gt;
&lt;p&gt;3MileBeach为能够达成细粒度故障注入，从消息序列化、反序列化入手。例如从gRPC请求转换为HTTP请求，存在Protocol Buffer到JSON的序列化和反序列化过程。&lt;strong&gt;在该过程中添加元数据来装饰消息，以跟踪每个消息的上下文&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;因为远程服务的故障总是表现为服务边界出现的延迟、报错等错误。通过错误处理，避免引发blast radius，从而可以实现并发测试。&lt;/p&gt;
&lt;p&gt;通过对第三方库的修改（增加请求和响应消息的上下文传播），来对事件进行持续跟踪，记录完整的服务调用历程。&lt;/p&gt;
&lt;p&gt;通过故障注入逻辑检查这些数据，就可以得知以下信息：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;错误来自哪一个请求？which&lt;/li&gt;
&lt;li&gt;当前是哪一个服务遇到了错误？where&lt;/li&gt;
&lt;li&gt;注入的是什么服务？how&lt;/li&gt;
&lt;li&gt;故障何时被注入？when&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;实现&#34;&gt;实现&lt;/h2&gt;
&lt;h3 id=&#34;架构抽象&#34;&gt;架构抽象&lt;/h3&gt;
&lt;p&gt;下图定义了边界组件模型，即微服务框架和服务处理程序之间的边界。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/image-20220312124636575.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220312124636575&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;大多数微服务框架都提供了服务处理handler和边界组件的交互方式。&lt;/p&gt;
&lt;p&gt;Panorama [40] 通过将可观察性抽象为直接调用处理程序函数的方向和以（输入/输出）队列/代理作为缓存层的异步调用处理程序函数的间接性，引入了组件交互的四种设计模式。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Full direction。所有的函数被分配到一个线程，在该线程中依次调用入站操作、处理请求、出站操作。&lt;/li&gt;
&lt;li&gt;Inbound indirection。在被工作线程选择之前，将入站消息存到队列中，当出站组件调用时，被唤醒执行。&lt;/li&gt;
&lt;li&gt;Outbound indirection。入站组件和服务handler直接在一个工作线程中调用，处理后将消息放到出站线程队列等待被网络运输。&lt;/li&gt;
&lt;li&gt;Full indirection。将入站和出站的消息都放入队列进行调度，中间通过服务handler和网络请求唤醒调用。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;第2，3，4种做法都实现了上下文传播机制，可以通过handler和边界组件传递身份信息。&lt;/p&gt;
&lt;p&gt;因此3MileBeach选择上述的上下文传播的设计模式。&lt;/p&gt;
&lt;p&gt;入站组件对从网络来的row message进行反序列化，调用service handler。出站组件将处理后的message进行序列化。&lt;/p&gt;
&lt;p&gt;对数据流进行两种抽象：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Direct Response Circle（&lt;strong&gt;DRC&lt;/strong&gt;）；&lt;/li&gt;
&lt;li&gt;Synchronized Request-Response Circle（&lt;strong&gt;SRC&lt;/strong&gt;）。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;数据结构&#34;&gt;数据结构&lt;/h3&gt;
&lt;p&gt;将负载命名为&lt;em&gt;3mb-payload&lt;/em&gt;，具体实现称为&lt;strong&gt;Trace&lt;/strong&gt;。Trace是一个高层数据结构，由以下三部分组成：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;一系列的事件（Event-s）；&lt;/li&gt;
&lt;li&gt;必要的追踪元数据（如ID），来帮助3MileBeach为追踪识别和组装事件；&lt;/li&gt;
&lt;li&gt;一个故障注入配置列表（fault injection configuration-s，FIC-s）&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;event&#34;&gt;Event&lt;/h4&gt;
&lt;p&gt;Event记录了一个事件的必要信息，从中可以知道在什么时候那哪个服务接收或者发送了一个请求或一个响应，并且具体的服务名字。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Timestamp&lt;/li&gt;
&lt;li&gt;Service&lt;/li&gt;
&lt;li&gt;Action&lt;/li&gt;
&lt;li&gt;MessageType&lt;/li&gt;
&lt;li&gt;Name&lt;/li&gt;
&lt;li&gt;UUID&lt;/li&gt;
&lt;li&gt;&amp;hellip;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如下图所示，有4个事件联系到同一个UUID，指明一个SRC。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/image-20220312135514421.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220312135514421&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;其中两个由Svc1记录，一个是在Svc1发送请求时记录的，另一个是在Svc1接收响应时记录的。&lt;/p&gt;
&lt;h4 id=&#34;fault-injection-configuration&#34;&gt;Fault Injection Configuration&lt;/h4&gt;
&lt;p&gt;使用FIC来描述一个TFI和RLFI（Request Level Fault Injection）测试案例。&lt;/p&gt;
&lt;p&gt;考虑一个应用由n个服务组成。RLFI在客户端级请求生命周期中将故障注入服务。我们使用FIC{Type: Crash, Name: Svc_i}来表示服务i的故障。为测试所有的崩溃模式，RLFI的实验空间有$2^n$个。但是在模拟客户端级别的请求时，不需要调用全部的微服务。例如有m个服务不会被调用，实际上只需要调用$2^{n-m}$个案例。&lt;/p&gt;
&lt;p&gt;在TFI中，根据逻辑时序在某个测试的执行期间模拟故障。文章使用&lt;strong&gt;After&lt;/strong&gt;，这是一个&lt;strong&gt;TFIMetas&lt;/strong&gt;列表，用此存储故障的临时先决条件。TFI 可以触发的故障空间是RLFI故障空间的超集，因为当After为空时，RLFI是TFI的特例。&lt;/p&gt;
&lt;p&gt;另外通过时间离散化，FIC可以大大减少TFI的测试空间。&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;如上图 ，Svc1在处理客户端请求时，从Svc0处接收到Req1和Req2。RLFI只判断这两个请是成功还是失败。如果希望Req2失败而不影响Req1，我们模拟的错误应发生在t1-t2时，而在t3之后结束。&lt;/p&gt;
&lt;p&gt;而TFI通过模拟崩溃时间来缩减故障的注入时间段，即在t1-t2之间注入故障，使用如下FIC来描述：FIC{Type: Crash, Name: Req2, After: [TFIMeta{Name: Req1, Times:1}]}。&lt;/p&gt;
&lt;h3 id=&#34;算法&#34;&gt;算法&lt;/h3&gt;
&lt;p&gt;本部分主要讲如何通过序列化&lt;em&gt;3mb-payload&lt;/em&gt;来接入边界组件，以及重写序列化函数在数据流中的作用。&lt;/p&gt;
&lt;h4 id=&#34;interpose-via-serialization-functions&#34;&gt;Interpose via Serialization Functions&lt;/h4&gt;
&lt;p&gt;为追踪处理客户端请求的服务，3MileBeach扩展了序列化函数，叫做&lt;strong&gt;Deserialize’ Serialize’&lt;/strong&gt;。使用存储S来存储追踪的上下文对象Ctx。Ctx来源于现存的上下文传播机制，携带了请求的元数据。&lt;/p&gt;
&lt;p&gt;在入站组件中，3MileBeach从入站消息获取ID，并将ID分配给Ctx（算法1）。当服务handler发送请求时，3MileBeach将观测到的追踪数据（这个数据存在S中）附加在出站消息中（算法2）。下表中有相关的关键函数。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/image-20220313151022017.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220313151022017&#34;
	
	
&gt;&lt;/p&gt;
&lt;h4 id=&#34;serialization-functions-and-data-flows&#34;&gt;Serialization Functions and Data Flows&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Direct Response Circle (DRC)&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
&lt;li&gt;框架从上游服务或client接收请求；&lt;/li&gt;
&lt;li&gt;入站组件唤醒Deserialize’将请求反序列化，将事件作为追踪记录，并存储到S中，将追踪元数据写到Ctx中；&lt;/li&gt;
&lt;li&gt;框架调用服务handler并等待调用结束;&lt;/li&gt;
&lt;li&gt;框架收到响应；&lt;/li&gt;
&lt;li&gt;出站组件唤醒Serialize’，并从S中检索追踪Ctx的元数据，追加到发送事件，序列化响应；&lt;/li&gt;
&lt;li&gt;框架返回响应到上游服务或client。&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Synchronized Request-Response Circle (SRC)&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
&lt;li&gt;服务handler通过阻塞函数调用发送一个请求到下游服务；&lt;/li&gt;
&lt;li&gt;出站组件唤醒Serialize’，从S和Ctx中检索追踪数据，这些数据是微服务从上游服务或client的SEND事件中来的，模拟了故障信息。调用序列化函数对消息进行序列化；&lt;/li&gt;
&lt;li&gt;框架发送请求给下游服务并等待响应；&lt;/li&gt;
&lt;li&gt;框架收到下游的响应；&lt;/li&gt;
&lt;li&gt;入站请求唤醒Deserialize将响应反序列化，追加事件并存储；&lt;/li&gt;
&lt;li&gt;服务handler会接受响应。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/image-20220313155122436.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220313155122436&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/image-20220313155136954.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220313155136954&#34;
	
	
&gt;&lt;/p&gt;
&lt;h4 id=&#34;fault-simulation&#34;&gt;Fault Simulation&lt;/h4&gt;
&lt;p&gt;3MileBeach通过模拟下游的外部可观测错误来实现故障注入，从请求者的角度来看，这些错误可能是由于网络问题或者返回响应的handler产生。&lt;/p&gt;
&lt;p&gt;3MileBeach不会因为故障测试而崩溃或者重启，因此可以执行并发测试，也能控制blast radius。&lt;/p&gt;
&lt;p&gt;典型的SRC包括两个服务和两个数据流。（Requester Responder ReqFlow RespFlow）。故障触发时，requester不能知道下游的故障根源，这取决于具体的实现，它能知道这些错误的返回码，例如timeout、connection closed、package loss等，依次证实的确发现了问题。&lt;/p&gt;
&lt;p&gt;3MileBeach在FICs定义的故障触发条件得到满足时触发故障。&lt;/p&gt;
&lt;h2 id=&#34;实验&#34;&gt;实验&lt;/h2&gt;
&lt;p&gt;测量3MileBeach框架的端到端的延迟来展示其效率表现，并提供两个本地案例。&lt;/p&gt;
&lt;h3 id=&#34;实验设置&#34;&gt;实验设置&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;演示程序：Hipster Shop，一个部署在GKE上的微服务程序。&lt;/li&gt;
&lt;li&gt;客户端生成测试用例来进行跟踪和故障注入、应用性能调整及错误定位。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;hipster-shop&#34;&gt;Hipster Shop&lt;/h4&gt;
&lt;p&gt;包含以下微服务：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Frontend - &lt;strong&gt;Svc_fe&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;CART - &lt;strong&gt;Svc_cart&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Recommendation&lt;/li&gt;
&lt;li&gt;ProductCatalog - &lt;strong&gt;Svc_p&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Shipping&lt;/li&gt;
&lt;li&gt;Currency - &lt;strong&gt;Svc_c&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Payment&lt;/li&gt;
&lt;li&gt;Email&lt;/li&gt;
&lt;li&gt;Checkout&lt;/li&gt;
&lt;li&gt;Ad - &lt;strong&gt;Svc_a&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;涉及到的序列化库有：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;JSON&lt;/li&gt;
&lt;li&gt;PROTOCOL&lt;/li&gt;
&lt;li&gt;RESTFUL&lt;/li&gt;
&lt;li&gt;GRPC&lt;/li&gt;
&lt;li&gt;GORILLA等&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;开发语言：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GO&lt;/li&gt;
&lt;li&gt;C#&lt;/li&gt;
&lt;li&gt;Node.js&lt;/li&gt;
&lt;li&gt;Python&lt;/li&gt;
&lt;li&gt;Java&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;综上，可以看出这个应用很适合作为microservice的代表来对3MileBeach进行测试。&lt;/p&gt;
&lt;h4 id=&#34;clusters&#34;&gt;Clusters&lt;/h4&gt;
&lt;p&gt;集群情况如下：&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;h4 id=&#34;client&#34;&gt;Client&lt;/h4&gt;
&lt;p&gt;客户端在不同级别的并发下向Svc_fe发送请求，使用N来确定并发数。同时，将应用和Client部署在一个集群上以最大程度减少网络延迟。&lt;/p&gt;
&lt;h3 id=&#34;tracing-benchmark&#34;&gt;Tracing Benchmark&lt;/h3&gt;
&lt;p&gt;本部分涉及到链路追踪情况，主要考察增加链路追踪给系统带来的延迟上的开销。通过并发测量端到端延迟来比较。&lt;/p&gt;
&lt;p&gt;在进行追踪时势必会给系统增加开销，因此在这方面进行比较，与Jaeger框架进行比较。以下为延迟情况以及延迟和吞吐量之间的关系。&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/image-20220314162513457.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220314162513457&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;fault-injection&#34;&gt;Fault Injection&lt;/h3&gt;
&lt;p&gt;为测试3MileBeach对TFI测试的速度，在Svc_fe中设计了两个bug：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;DEEPRLFI。它在Svc_a和Svc_c都关闭时可以触发，不受事件影响。所以需要使用&lt;em&gt;3mb-payloads&lt;/em&gt;来同时触发Svc_a和Svc_c的崩溃。&lt;/li&gt;
&lt;li&gt;SimpleTFI。是一个TOCTTOU bug。为了触发这个问题，需要让请求携带可以使Svc_c崩溃的&lt;em&gt;3mb-payloads&lt;/em&gt;。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;通过下面几个图详细说明：&lt;/p&gt;
&lt;p&gt;（a）第一次调用Svc_c，Svc_fe可以容错；若Svc_c可访问，Svc_fe会认为在整个过程中Svc_c都是可以工作的；反正，Svc_fe会执行回退策略，使用默认的价钱。注意红色！的位置，Currency没有正常返回数据，但Svc_fe最终仍可以正常运行完，参考最后的绿色箭头。使用RLFI去模拟Svc_c的崩溃可以得到对应的结果。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/image-20220314163636670.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220314163636670&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;（b）当Svc_a不可用时，Svc_fe会应用回退策略，使用默认的广告推荐，并继续向Svc_c发送请求进行结算。使用RLFI去模拟Svc_a的崩溃可以得到对应的结果。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/image-20220314163715311.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220314163715311&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;（c）由上面两张图看出，在Currency和Ad二者中，只有一个出现问题时并不会引发Frontend的崩溃。下图则表示当Ad和Currency都崩溃时，Fronted才会崩。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/image-20220314163733335.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220314163733335&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://picgo-lzl.oss-cn-beijing.aliyuncs.com/image-20220314163756339.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220314163756339&#34;
	
	
&gt;&lt;/p&gt;
</description>
        </item>
        
    </channel>
</rss>
